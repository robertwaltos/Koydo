{
  "selfish_gene": {
    "meta": {
      "key": "selfish_gene",
      "title": "The Selfish Gene",
      "creator": "Richard Dawkins",
      "filepath": "G:/My Drive/15_E-BOOKS/file012078.epub",
      "subject": "Biology"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "The Selfish Gene RICHARDDAWKINS-TheSelfishGene RICHARD DAWKINS-The Selfish Gene. Ebook v1.0. 'Who should read this book? Everyone interested in the universe and their place in it.' Jeffrey R. Baylis, Animal Behaviour Our genes made us. We animals exist for their preservation and are nothing more than their throwaway survival machines. The world of the selfish gene is one of savage competition, ruthless exploitation, and deceit. But what of the acts of apparent altruism found in nature-the bees who commit suicide when they sting to protect the hive, or the birds who risk their lives to warn the flock of an approaching hawk? Do they contravene the fundamental law of gene selfishness? By no means: Dawkins shows that the selfish gene is also the subtle gene. And he holds out the hope that our species-alone on earth-has the power to rebel against the designs of the selfish gene. This book is a call to arms. It is both manual and manifesto, and it grips like a thriller. The Selfish Gene, Richard Dawkins's brilliant first book and still his most famous, is an international bestseller in thirteen languages. For this new edition there are two major new chapters. 'learned, witty, and very well written...exhilaratingly good .' Sir Peter Medawar, Spectator Richard Dawkins is a Lecturer in Zoology at Oxford University and a Fellow of Mew College, and the author of The Blind Watchmaker. Preface to 1976 edition This book should be read almost as though it were science fiction. It is designed to appeal to the imagination. But it is not science fiction: it is science. Cliche or not, 'stranger than fiction' expresses exactly how I feel about the truth. We are survival machines-robot vehicles blindly programmed to preserve the selfish molecules known as genes. This is a truth which still fills me with astonishment. Though I have known it for years, I never seem to get fully used to it. One of my hopes is that I may have some success in astonishing others. Three imaginary readers looked over my shoulder while I was writing, and I now dedicate the book to them. First the general reader, the layman. For him I have avoided technical jargon almost totally, and where I have had to use specialized words I have defined them. I now wonder why we don't censor most of our jargon from learned journals too. I have assumed that the layman has no special knowledge, but I have not assumed that he is stupid. Anyone can popularize science if he oversimplifies. I have worked hard to try to popularize some subtle and complicated ideas in non-mathematical language, without losing their essence. I do not know how far I have succeeded in this, nor how far I have succeeded in another of my ambitions: to try to make the book as entertaining and gripping as its subject matter deserves. I have long felt that biology ought to seem as exciting as a mystery story, for a mystery story is exactly what biology is. I do not dare to hope that I have conveyed more than a tiny fraction of the excitement which the subject has to offer. My second imaginary reader was the expert. He has been a harsh critic, sharply drawing in his breath at some of my analogies and figures of speech. His favourite phrases are with the exception of; 'but on the other hand'; and 'ugh'. I listened to him attentively, and even completely rewrote one chapter entirely for his benefit, but in the end I have had to tell the story my way. The expert will still not be totally happy with the way I put things. Yet my greatest hope is that even he will find something new here; a new way of looking at familiar ideas perhaps; even stimulation of new ideas of his own. If this is too high an aspiration, may I at least hope that the book will entertain him on a train.' The third reader I had in mind was the student, making the transition from layman to expert. If he still has not made up his mind what field he wants to be an expert in, I hope to encourage him to give my own field of zoology a second glance. There is a better reason for studying zoology than its possible 'usefulness', and the general likeableness of animals. This reason is that we animals are the most complicated and perfectly-designed pieces of machinery in the known universe. Put it like that, and it is hard to see why anybody studies anything else! For the student who has already committed himself to zoology, I hope my book may have some educational value. He is having to work through the original papers and technical books on which my treatment is based. If he finds the original sources hard to digest, perhaps my non-mathematical interpretation may help, as an introduction and adjunct. There are obvious dangers in trying to appeal to three different kinds of reader. I can only say that I have been very conscious of these dangers, but that they seemed to be outweighed by the advantages of the attempt. I am an ethologist, and this is a book about animal behaviour. My debt to the ethological tradition in which I was trained will be obvious. In particular, Niko Tinbergen does not realize the extent of his influence on me during the twelve years I worked under him at Oxford. The phrase 'survival machine', though not actually his own, might well be. But ethology has recently been invigorated by an invasion of fresh ideas from sources not conventionally regarded as ethological. This book is largely based on these new ideas. Their originators are acknowledged in the appropriate places in the text; the dominant figures are G. C. Williams, J. Maynard Smith, W. D. Hamilton, and R. L. Trivers. Various people suggested titles for the book, which I have gratefully used as chapter titles: 'Immortal Coils', John Krebs; 'The Gene Machine', Desmond Morris; 'Genesmanship', Tim Glutton-Brock and Jean Dawkins, independently with apologies to Stephen Potter. Imaginary readers may serve as targets for pious hopes and aspirations, but they are of less practical use than real readers and critics. I am addicted to revising, and Marian Dawkins has been subjected to countless drafts and redrafts of every page. Her considerable knowledge of the biological literature and her understanding of theoretical issues, together with her ceaseless encouragement and moral support, have been essential to me. John Krebs too read the whole book in draft. He knows more about the subject than I do, and he has been generous and unstinting with his advice and suggestions. Glenys Thomson and Walter Bodmer criticized my handling of genetic topics kindly but firmly. I fear that my revision may still not fully satisfy them, but I hope they will find it somewhat improved. I am most grateful for their time and patience. John Dawkins exercised an unerring eye for misleading phraseology, and made excellent constructive suggestions for re-wording. I could not have wished for a more suitable 'intelligent layman' than Maxwell Stamp. His perceptive spotting of an important general flaw in the style of the first draft did much for the final version. Others who constructively criticized particular chapters, or otherwise gave expert advice, were John Maynard Smith, Desmond Morris, Tom Maschler, Nick Blurton Jones, Sarah Kettlewell, Nick Humphrey, Tim Glutton-Brock, Louise Johnson, Christopher Graham, Geoff Parker, and Robert Trivers. Pat Searle and Stephanie Verhoeven not only typed with skill, but encouraged me by seeming to do so with enjoyment. Finally, I wish to thank Michael Rodgers of Oxford University Press who, in addition to helpfully criticizing the manuscript, worked far beyond the call of duty in attending to all aspects of the production of this book. RICHARD DAWKINS Preface to 1989 edition In the dozen years since The Selfish Gene was published its central message has become textbook orthodoxy. This is paradoxical, but not in the obvious way. It is not one of those books that was reviled as revolutionary when published, then steadily won converts until it ended up so orthodox that we now wonder what the fuss was about. Quite the contrary. From the outset the reviews were gratifyingly favourable and it was not seen, initially, as a controversial book. Its reputation for contentiousness took years to grow until, by now, it is widely regarded as a work of radical extremism. But over the very same years as the book's reputation for extremism has escalated, its actual content has seemed less and less extreme, more and more the common currency. The selfish gene theory is Darwin's theory, expressed in a way that Darwin did not choose but whose aptness, I should like to think, he would instantly have recognized and delighted in. It is in fact a logical outgrowth of orthodox neo-Darwinism, but expressed as a novel image. Rather than focus on the individual organism, it takes a gene's-eye view of nature. It is a different way of seeing, not a different theory. In the opening pages of The Extended Phenotype, I explained this using the metaphor of the Necker cube. This is a two-dimensional pattern of ink on paper, but it is perceived as a transparent, three-dimensional cube. Stare at it for a few seconds and it will change to face in a different direction. Carry on staring and it will flip back to the original cube. Both cubes are equally compatible with the two-dimensional data on the retina, so the brain happily alternates between them. Neither is more correct than the other. My point was that there are two ways of looking at natural selection, the gene's angle and that of the individual. If properly understood they are equivalent; two views of the same truth. You can flip from one to the other and it will still be the same neo-Darwinism. I now think that this metaphor was too cautious. Rather than propose a new theory or unearth a new fact, often the most important contribution a scientist can make is to discover a new way of seeing old theories or facts. The Necker cube model is misleading because it suggests that the two ways of seeing are equally good. To be sure, the metaphor gets it partly right: 'angles', unlike theories, cannot be judged by experiment; we cannot resort to our familiar criteria of verification and falsification. But a change of vision can, at its best, achieve something loftier than a theory. It can usher in a whole climate of thinking, in which many exciting and testable theories are born, and unimagined facts laid bare. The Necker cube metaphor misses this completely. It captures the idea of a flip in vision, but fails to do justice to its value. What we are talking about is not a flip to an equivalent view but, in extreme cases, a transfiguration. I hasten to disclaim any such status for my own modest contributions. Nevertheless, it is for this kind of reason that I prefer not to make a clear separation between science and its 'popularization'. Expounding ideas that have hitherto appeared only in the technical literature is a difficult art. It requires insightful new twists of language and revealing metaphors. If you push novelty of language and metaphor far enough, you can end up with a new way of seeing. And a new way of seeing, as I have just argued, can in its own right make an original contribution to science. Einstein himself was no mean popularizer, and I've often suspected that his vivid metaphors did more than just help the rest of us. Didn't they also fuel his creative genius.' The gene's-eye view of Darwinism is implicit in the writings of R. A. Fisher and the other great pioneers of neo-Darwinism in the early thirties, but was made explicit by W. D. Hamilton and G. C. Williams in the sixties. For me their insight had a visionary quality. But I found their expressions of it too laconic, not full-throated enough. I was convinced that an amplified and developed version could make everything about life fall into place, in the heart as well as in the brain. I would write a book extolling the gene's-eye view of evolution. It should concentrate its examples on social behaviour, to help correct the unconscious group-selectionism that then pervaded popular Darwinism. I began the book in 1972 when power-cuts resulting from industrial strife interrupted my laboratory research. The blackouts unfortunately (from one point of view) ended after a mere two chapters, and I shelved the project until I had a sabbatical leave in 1975. Meanwhile the theory had been extended, notably by John Maynard Smith and Robert Trivers. I now see that it was one of those mysterious periods in which new ideas are hovering in the air. I wrote The Selfish Gene in something resembling a fever of excitement. When Oxford University Press approached me for a second edition they insisted that a conventional, comprehensive, page by page revision was inappropriate. There are some books that, from their conception, are obviously destined for a string of editions, and The Selfish Gene was not one of them. The first edition borrowed a youthful quality from the times in which it was written. There was a whiff of revolution abroad, a streak of Wordsworth's blissful dawn. A pity to change a child of those times, fatten it with new facts or wrinkle it with complications and cautions. So, the original text should stand, warts, sexist pronouns and all. Notes at the end would cover corrections, responses and developments. And there should be entirely new chapters, on subjects whose novelty in their own time would carry forward the mood of revolutionary dawn. The result was Chapters 12 and 13. For these I took my inspiration from the two books in the field that have most excited me during the intervening years: Robert Axelrod's The Evolution of Cooperation, because it seems to offer some sort of hope for our future; and my own The Extended Phenotype because for me it dominated those years and because-for what that is worth-it is probably the finest thing I shall ever write. The tide 'Nice guys finish first' is borrowed from the BBC Horizon television programme that I presented in 1985. This was a fifty-minute documentary on game-theoretic approaches to the evolution of cooperation, produced by Jeremy Taylor. The making of this film, and another. The Blind Watchmaker, by the same producer, gave me a new respect for his profession. At their best. Horizon producers (some of their programmes can be seen in America, often repackaged under the name Nova) turn themselves into advanced scholarly experts on the subject in hand. Chapter 12 owes more than just its title to my experience of working closely with Jeremy Taylor and the Horizon team, and I am grateful. I recently learned a disagreeable fact: there are influential scientists in the habit of putting their names to publications in whose composition they have played no part. Apparently some senior scientists claim joint authorship of a paper when all that they have contributed is bench space, grant money and an editorial read-through of the manuscript. For all I know, entire scientific reputations may have been built on the work of students and colleagues! I don't know what can be done to combat this dishonesty. Perhaps journal editors should require signed testimony of what each author contributed. But that is by the way. My reason for raising the matter here is to make a contrast. Helena Cronin has done so much to improve every line-every word-that she should, but for her adamant refusal, be named as joint author of all the new portions of this book. I am deeply grateful to her, and sorry that my acknowledgment must be limited to this. I also thank Mark Ridley, Marian Dawkins and Alan Grafen for advice and for constructive criticism of particular sections. Thomas Webster, Hilary McGlynn and others at Oxford University Press cheerfully tolerated my whims and procrastinations. RICHARD DAWKINS Contents 1. Why are people? 2. The replicators 3. Immortal coils 4. The gene machine 5. Aggression: stability and the selfish machine 6. Genesmanship 7. Family planning 8. Battle of the generations 9. Battle of the sexes 10. You scratch my back, I'll ride on yours 11. Memes: the new replicators 12. Nice guys finish first 13. The long reach of the gene",
        "char_count": 16101
      },
      {
        "heading": "Chapter 2",
        "text": "The Selfish Gene 1. Why are people? Intelligent life on a planet comes of age when it first works out the reason for its own existence. If superior creatures from space ever visit earth, the first question they will ask, in order to assess the level of our civilization, is: 'Have they discovered evolution yet?' Living organisms had existed on earth, without ever knowing why, for over three thousand million years before the truth finally dawned on one of them. His name was Charles Darwin. To be fair, others had had inklings of the truth, but it was Darwin who first put together a coherent and tenable account of why we exist. Darwin made it possible for us to give a sensible answer to the curious child whose question heads this chapter. We no longer have to resort to superstition when faced with the deep problems: Is there a meaning to life.' What are we for? What is man? After posing the last of these questions, the eminent zoologist G. G. Simpson put it thus: 'The point I want to make now is that all attempts to answer that question before 1859 are worthless and that we will be better off if we ignore them completely.' Today the theory of evolution is about as much open to doubt as the theory that the earth goes round the sun, but the full implications of Darwin's revolution have yet to be widely realized. Zoology is still a minority subject in universities, and even those who choose to study it often make their decision without appreciating its profound philosophical significance. Philosophy and the subjects known as 'humanities' are still taught almost as if Darwin had never lived. No doubt this will change in time. In any case, this book is not intended as a general advocacy of Darwinism. Instead, it will explore the consequences of the evolution theory for a particular issue. My purpose is to examine the biology of selfishness and altruism. Apart from its academic interest, the human importance of this subject is obvious. It touches every aspect of our social lives, our loving and hating, fighting and cooperating, giving and stealing, our greed and our generosity. These are claims that could have been made for Lorenz's On Aggression, Ardrey's The Social Contract, and Eibl-Eihesfeldt's Love and Hate. The trouble with these books is that their authors got it totally and utterly wrong. They got it wrong because they misunderstood how evolution works. They made the erroneous assumption that the important thing in evolution is the good of the species (or the group) rather than the good of the individual (or the gene). It is ironic that Ashley Montagu should criticize Lorenz as a 'direct descendant of the “nature red in tooth and claw” thinkers of the nineteenth century ...'. As I understand Lorenz's view of evolution, he would be very much at one with Montagu in rejecting the implications of Tennyson's famous phrase. Unlike both of them, I think 'nature red in tooth and claw' sums up our modern understanding of natural selection admirably. Before beginning on my argument itself, I want to explain briefly what sort of an argument it is, and what sort of an argument it is not. If we were told that a man had lived a long and prosperous life in the world of Chicago gangsters, we would be entitled to make some guesses as to the sort of man he was. We might expect that he would have qualities such as toughness, a quick trigger finger, and the ability to attract loyal friends. These would not be infallible deductions, but you can make some inferences about a man's character if you know something about the conditions in which he has survived and prospered. The argument of this book is that we, and all other animals, are machines created by our genes. Like successful Chicago gangsters, our genes have survived, in some cases for millions of years, in a highly competitive world. This entities us to expect certain qualities in our genes. I shall argue that a predominant quality to be expected in a successful gene is ruthless selfishness. This gene selfishness will usually give rise to selfishness in individual behaviour. However, as we shall see, there are special circumstances in which a gene can achieve its own selfish goals best by fostering a limited form of altruism at the level of individual animals. 'Special' and 'limited' are important words in the last sentence. Much as we might wish to believe otherwise, universal love and the welfare of the species as a whole are concepts that simply do not make evolutionary sense. This brings me to the first point I want to make about what this book is not. I am not advocating a morality based on evolution. I am saying how things have evolved. I am not saying how we humans morally ought to behave. I stress this, because I know I am in danger of being misunderstood by those people, all too numerous, who cannot distinguish a statement of belief in what is the case from an advocacy of what ought to be the case. My own feeling is that a human society based simply on the gene's law of universal ruthless selfishness would be a very nasty society in which to live. But unfortunately, however much we may deplore something, it does not stop it being true. This book is mainly intended to be interesting, but if you would extract a moral from it, read it as a warning. Be warned that if you wish, as I do, to build a society in which individuals cooperate generously and unselfishly towards a common good, you can expect little help from biological nature. Let us try to teach generosity and altruism, because we are born selfish. Let us understand what our own selfish genes are up to, because we may then at least have the chance to upset their designs, something that no other species has ever aspired to. As a corollary to these remarks about teaching, it is a fallacy- incidentally a very common one-to suppose that genetically inherited traits are by definition fixed and unmodifiable. Our genes may instruct us to be selfish, but we are not necessarily compelled to obey them all our lives. It may just be more difficult to learn altruism than it would be if we were genetically programmed to be altruistic. Among animals, man is uniquely dominated by culture, by influences learned and handed down. Some would say that culture is so important that genes, whether selfish or not, are virtually irrelevant to the understanding of human nature. Others would disagree. It all depends where you stand in the debate over 'nature versus nurture' as determinants of human attributes. This brings me to the second thing this book is not: it is not an advocacy of one position or another in the nature/nurture controversy. Naturally I have an opinion on this, but I am not going to express it, except insofar as it is implicit in the view of culture that I shall present in the final chapter. If genes really turn out to be totally irrelevant to the determination of modern human behaviour, if we really are unique among animals in this respect, it is, at the very least, still interesting to inquire about the rate to which we have so recently become the exception. And if our species is not so exceptional as we might like to think, it is even more important that we should study the rule. The third thing this book is not is a descriptive account of the detailed behaviour of man or of any other particular animal species. I shall use factural details as only illustrative examples. I shall not be saying: 'If you look at the behaviour of baboons you will find it to be selfish; therefore the chances are that human behaviour is selfish also'. The logic of my 'Chicago gangster' argument is quite different. It is this. Humans and baboons have evolved by natural selection. If you look at the way natural selection works, it seems to follow that anything that has evolved by natural selection should be selfish. Therefore we must expect that when we go and look at the behaviour of baboons, humans, and all other living creatures, we shall find it to be selfish. If we find that our expectation is wrong, if we observe that human behaviour is truly altruistic, then we shall be faced with something puzzling, something that needs explaining. Before going any further, we need a definition. An entity, such as a baboon, is said to be altruistic if it behaves in such a way as to increase another such entity's welfare at the expense of its own. Selfish behaviour has exactly the opposite effect. 'Welfare' is defined as 'chances of survival', even if the effect on actual life and death prospects is so small as to seem negligible. One of the surprising consequences of the modem version of the Darwinian theory is that apparently trivial tiny influences on survival probability can have a major impact on evolution. This is because of the enormous time available for such influences to make themselves felt. It is important to realize that the above definitions of altruism and selfishness are behavioural, not subjective. I am not concerned here with the psychology of motives. I am not going to argue about whether people who behave altruistically are 'really' doing it for secret or subconscious selfish motives. Maybe they are and maybe they aren't, and maybe we can never know, but in any case that is not what this book is about. My definition is concerned only with whether the effect of an act is to lower or raise the survival prospects of the presumed altruist and the survival prospects of the presumed beneficiary. It is a very complicated business to demonstrate the effects of behaviour on long-term survival prospects. In practice, when we apply the definition to real behaviour, we must qualify it with the word 'apparently'. An apparently altruistic act is one that looks, superficially, as if it must tend to make the altruist more likely (however slightly) to die, and the recipient more likely to survive. It often turns out on closer inspection that acts of apparent altruism are really selfishness in disguise. Once again, I do not mean that the underlying motives are secretly selfish, but that the real effects of the act on survival prospects are the reverse of what we originally thought. I am going to give some examples of apparently selfish and apparently altruistic behaviour. It is difficult to suppress subjective habits of thought when we are dealing with our own species, so I shall choose examples from other animals instead. First some miscellaneous examples of selfish behaviour by individual animals. Blackheaded gulls nest in large colonies, the nests being only a few feet apart. When the chicks first hatch out they are small and defenceless and easy to swallow. It is quite common for a gull to wait until a neighbour's back is turned, perhaps while it is away fishing, and then pounce on one of the neighbour's chicks and swallow it whole. It thereby obtains a good nutritious meal, without having to go to the trouble of catching a fish, and without having to leave its own nest unprotected. More well known is the macabre cannibalism of female praying mantises. Mantises are large carnivorous insects. They normally eat smaller insects such as flies, but they will attack almost anything that moves. When they mate, the male cautiously creeps up on the female, mounts her, and copulates. If the female gets the chance, she will eat him, beginning by biting his head off, either as the male is approaching, or immediately after he mounts, or after they separate. It might seem most sensible for her to wait until copulation is over before she starts to eat him. But the loss of the head does not seem to throw the rest of the male's body off its sexual stride. Indeed, since the insect head is the seat of some inhibitory nerve centres, it is possible that the female improves the male's sexual performance by eating his head. If so, this is an added benefit. The primary one is that she obtains a good meal. The word 'selfish' may seem an understatement for such extreme cases as cannibalism, although these fit well with our definition. Perhaps we can sympathize more directly with the reported cowardly behaviour of emperor penguins in the Antarctic. They have been seen standing on the brink of the water, hesitating before diving in, because of the danger of being eaten by seals. If only one of them would dive in, the rest would know whether there was a seal there or not. Naturally nobody wants to be the guinea pig, so they wait, and sometimes even try to push each other in. More ordinarily, selfish behaviour may simply consist of refusing to share some valued resource such as food, territory, or sexual partners. Now for some examples of apparently altruistic behaviour. The stinging behaviour of worker bees is a very effective defence against honey robbers. But the bees who do the stinging are kamikaze fighters. In the act of stinging, vital internal organs are usually torn out of the body, and the bee dies soon afterwards. Her suicide mission may have saved the colony's vital food stocks, but she herself is not around to reap the benefits. By our definition this is an altruistic behavioural act. Remember that we are not talking about conscious motives. They may or may not be present, both here and in the selfishness examples, but they are irrelevant to our definition. Laying down one's life for one's friends is obviously altruistic, but so also is taking a slight risk for them. Many small birds, when they see a flying predator such as a hawk, give a characteristic 'alarm call', upon which the whole flock takes appropriate evasive action. There is indirect evidence that the bird who gives the alarm call puts itself in special danger, because it attracts the predator's attention particularly to itself. This is only a slight additional risk, but it nevertheless seems, at least at first sight, to qualify as an altruistic act by our definition. The commonest and most conspicuous acts of animal altruism are done by parents, especially mothers, towards their children. They may incubate them, either in nests or in their own bodies, feed them at enormous cost to themselves, and take great risks in protecting them from predators. To take just one particular example, many ground-nesting birds perform a so-called 'distraction display' when a predator such as a fox approaches. The parent bird limps away from the nest, holding out one wing as though it were broken. The predator, sensing easy prey, is lured away from the nest containing the chicks. Finally the parent bird gives up its pretence and leaps into the air just in time to escape the fox's jaws. It has probably saved the life of its nestlings, but at some risk to itself. I am not trying to make a point by telling stories. Chosen examples are never serious evidence for any worthwhile generalization. These stories are simply intended as illustrations of what I mean by altruistic and selfish behaviour at the level of individuals. This book will show how both individual selfishness and individual altruism are explained by the fundamental law that I am calling gene selfishness. But first I must deal with a particular erroneous explanation for altruism, because it is widely known, and even widely taught in schools. This explanation is based on the misconception that I have already mentioned, that living creatures evolve to do things 'for the good of the species' or 'for the good of the group'. It is easy to see how this idea got its start in biology. Much of an animal's life is devoted to reproduction, and most of the acts of altruistic self-sacrifice that are observed in nature are performed by parents towards their young. 'Perpetuation of the species' is a common euphemism for reproduction, and it is undeniably a consequence of reproduction. It requires only a slight over-stretching of logic to deduce that the 'function' of reproduction is 'to' perpetuate the species. From this it is but a further short false step to conclude that animals will in general behave in such a way as to favour the perpetuation of the species. Altruism towards fellow members of the species seems to follow. This line of thought can be put into vaguely Darwinian terms. Evolution works by natural selection, and natural selection means the differential survival of the 'fittest'. But are we talking about the fittest individuals, the fittest races, the fittest species, or what.' For some purposes this does not greatly matter, but when we are talking about altruism it is obviously crucial. If it is species that are competing in what Darwin called the struggle for existence, the individual seems best regarded as a pawn in the game, to be sacrified when the greater interest of the species as a whole requires it. To put it in a slightly more respectable way, a group, such as a species or a population within a species, whose individual members are prepared to sacrifice themselves for the welfare of the group, maybe less likely to go extinct than a rival group whose individual members place their own selfish interests first. Therefore the world becomes populated mainly by groups consisting of self-sacrificing individuals. This is the theory of 'group selection', long assumed to be true by biologists not familiar with the details of evolutionary theory, brought out into the open in a famous book by V. C. Wynne-Edwards, and popularized by Robert Ardrey in The Social Contract. The orthodox alternative is normally called 'individual selection', although I personally prefer to speak of gene selection. The quick answer of the 'individual selectionist' to the argument just put might go something like this. Even in the group of altruists, there will almost certainly be a dissenting minority who refuse to make any sacrifice. If there is just one selfish rebel, prepared to exploit the altruism of the rest, then he, by definition, is more likely than they are to survive and have children. Each of these children will tend to inherit his selfish traits. After several generations of this natural selection, the 'altruistic group' will be over-run by selfish individuals, and will be indistinguishable from the selfish group. Even if we grant the improbable chance existence initially of pure altruistic groups without any rebels, it is very difficult to see what is to stop selfish individuals migrating in from neighbouring selfish groups, and, by inter-marriage, contaminating the purity of the altruistic groups. The individual-selectionist would admit that groups do indeed die out, and that whether or not a group goes extinct may be influenced by the behaviour of the individuals in that group. He might even admit that if only the individuals in a group had the gift of foresight they could see that in the long run their own best interests lay in restraining their selfish greed, to prevent the destruction of the whole group. How many times must this have been said in recent years to the working people of Britain? But group extinction is a slow process compared with the rapid cut and thrust of individual competition. Even while the group is going slowly and inexorably downhill, selfish individuals prosper in the short term at the expense of altruists. The citizens of Britain may or may not be blessed with foresight, but evolution is blind to the future. Although the group-selection theory now commands litte support within the ranks of those professional biologists who understand evolution, it does have great intuitive appeal. Successive generations of zoology students are surprised, when they come up from school, to find that it is not the orthodox point of view. For this they are hardly to be blamed, for in the Nuffield Biology Teachers' Guide, written for advanced level biology schoolteachers in Britain, we find the following: 'In higher animals, behaviour may take the form of individual suicide to ensure the survival of the species.' The anonymous author of this guide is blissfully ignorant of the fact that he has said something controversial. In this respect he is in Nobel Prize-winning company. Konrad Lorenz, in On Aggression, speaks of the 'species preserving' functions of aggressive behaviour, one of these functions being to make sure that only the fittest individuals are allowed to breed. This is a gem of a circular argument, but the point I am making here is that the group selection idea is so deeply ingrained that Lorenz, like the author of the Nuffield Guide, evidently did not realize that his statements contravened orthodox Darwinian theory. I recently heard a delightful example of the same thing on an otherwise excellent B.B.C. television programme about Australian spiders. The 'expert' on the programme observed that the vast majority of baby spiders end up as prey for other species, and she then went on to say: 'Perhaps this is the real purpose of their existence, as only a few need to survive in order for the species to be preserved'! Robert Ardrey, in The Social Contract, used the group-selection theory to account for the whole of social order in general. He clearly sees man as a species that has strayed from the path of animal righteousness. Ardrey at least did his homework. His decision to disagree with orthodox theory was a conscious one, and for this he deserves credit. Perhaps one reason for the great appeal of the group-selection theory is that it is thoroughly in tune with the moral and political ideals that most of us share. We may frequently behave selfishly as individuals, but in our more idealistic moments we honour and admire those who put the welfare of others first. We get a bit muddled over how widely we want to interpret the word 'others', though. Often altruism within a group goes with selfishness between groups. This is a basis of trade unionism. At another level the nation is a major beneficiary of our altruistic self-sacrifice, and young men are expected to die as individuals for the greater glory of their country as a whole. Moreover, they are encouraged to kill other individuals about whom nothing is known except that they belong to a different nation. (Curiously, peace-time appeals for individuals to make some small sacrifice in the rate at which they increase their standard of living seem to be less effective than war-time appeals for individuals to lay down their lives.) Recently there has been a reaction against racialism and patriotism, and a tendency to substitute the whole human species as the object of our fellow feeling. This humanist broadening of the target of our altruism has an interesting corollary, which again seems to buttress the 'good of the species' idea in evolution. The politically liberal, who are normally the most convinced spokesmen of the species ethic, now often have the greatest scorn for those who have gone a little further in widening their altruism, so that it includes other species. If I say that I am more interested in preventing the slaughter of large whales than I am in improving housing conditions for people, I am likely to shock some of my friends. The feeling that members of one's own species deserve special moral consideration as compared with members of other species is old and deep. Killing people outside war is the most seriously regarded crime ordinarily committed. The only thing more strongly forbidden by our culture is eating people (even if they are already dead). We enjoy eating members of other species, however. Many of us shrink from judicial execution of even the most horrible human criminals, while we cheerfully countenance the shooting without trial of fairly mild animal pests. Indeed we kill members of other harmless species as a means of recreation and amusement. A human foetus, with no more human feeling than an amoeba, enjoys a reverence and legal protection far in excess of those granted to an adult chimpanzee. Yet the chimp feels and thinks and-according to recent experimental evidence-may even be capable of learning a form of human language. The foetus belongs to our own species, and is instantly accorded special privileges and rights because of it. Whether the ethic of 'speciesism', to use Richard Ryder's term, can be put on a logical footing any more sound than that of 'racism', I do not know. What I do know is that it has no proper basis in evolutionary biology. The muddle in human ethics over the level at which altruism is desirable-family, nation, race, species, or all living tilings-is mirrored by a parallel muddle in biology over the level at which altruism is to be expected according to the theory of evolution. Even the group-selectionist would not be surprised to find members of rival groups being nasty to each other: in this way, like trade unionists or soldiers, they are favouring their own group in the struggle for limited resources. But then it is worth asking how the group-selectionist decides which level is the important one. If selection goes on between groups within a species, and between species, why should it not also go on between larger groupings? Species are grouped together into genera, genera into orders, and orders into classes. Lions and antelopes are both members of the class Mammalia, as are we. Should we then not expect lions to refrain from killing antelopes, 'for the good of the mammals'? Surely they should hunt birds or reptiles instead, in order to prevent the extinction of the class. But then, what of the need to perpetuate the whole phylum of vertebrates? It is all very well for me to argue by reductio ad absurdum, and to point to the difficulties of the group-selection theory, but the apparent existence of individual altruism still has to be explained. Ardrey goes so far as to say that group selection is the only possible explanation for behaviour such as 'storting' in Thomson's gazelles. This vigorous and conspicuous leaping in front of a predator is analogous to bird alarm calls, in that it seems to warn companions of danger while apparently calling the predator's attention to the stotter himself. We have a responsibility to explain stotting Tommies and all similar phenomena, and this is something I am going to face in later chapters. Before that I must argue for my belief that the best way to look at evolution is in terms of selection occurring at the lowest level of all. In this belief I am heavily influenced by G. C. Williams's great book Adaptation and Natural Selection. The central idea I shall make use of was foreshadowed by A. Weismann in pre-gene days at the turn of the century-his doctrine of the 'continuity of the germ-plasm'. I shall argue that the fundamental unit of selection, and therefore of self-interest, is not the species, nor the group, nor even, strictly, the individual. It is the gene, the unit of heredity. To some biologists this may sound at first like an extreme view. I hope when they see in what sense I mean it they will agree that it is, in substance, orthodox, even if it is expressed in an unfamiliar way. The argument takes time to develop, and we must begin at the beginning, with the very origin of life itself.",
        "char_count": 27012
      },
      {
        "heading": "Chapter 3",
        "text": "The Selfish Gene 2. The replicators. In the beginning was simplicity. It is difficult enough explaining how even a simple universe began. I take it as agreed that it would be even harder to explain the sudden springing up, fully armed, of complex order-life, or a being capable of creating life. Darwin's theory of evolution by natural selection is satisfying because it shows us a way in which simplicity could change into complexity, how unordered atoms could group themselves into ever more complex patterns until they ended up manufacturing people. Darwin provides a solution, the only feasible one so far suggested, to the deep problem of our existence. I will try to explain the great theory in a more general way than is customary, beginning with the time before evolution itself began. Darwin 's 'survival of the fittest' is really a special case of a more general law of survival of the stable. The universe is populated by stable things. A stable thing is a collection of atoms that is permanent enough or common enough to deserve a name. It may be a unique collection of atoms, such as the Matterhorn, that lasts long enough to be worth naming. Or it may be a class of entities, such as rain drops, that come into existence at a sufficiently high rate to deserve a collective name, even if any one of them is short-lived. The things that we see around us, and which we think of as needing explanation-rocks, galaxies, ocean waves-are all, to a greater or lesser extent, stable patterns of atoms. Soap bubbles tend to be spherical because this is a stable configuration for thin films filled with gas. In a spacecraft, water is also stable in spherical globules, but on earth, where there is gravity, the stable surface for standing water is flat and horizontal. Salt crystals tend to be cubes because this is a stable way of packing sodium and chloride ions together. In the sun the simplest atoms of all, hydrogen atoms, are fusing to form helium atoms, because in the conditions that prevail there the helium configuration is more stable. Other even more complex atoms are being formed in stars all over the universe, ever since soon after the 'big bang' which, according to the prevailing theory, initiated the universe. This is originally where the elements on our world came from. Sometimes when atoms meet they link up together in chemical reaction to form molecules, which may be more or less stable. Such molecules can be very large. A crystal such as a diamond can be regarded as a single molecule, a proverbially stable one in this case, but also a very simple one since its internal atomic structure is endlessly repeated. In modern living organisms there are other large molecules which are highly complex, and their complexity shows itself on several levels. The haemoglobin of our blood is a typical protein molecule. It is built up from chains of smaller molecules, amino acids, each containing a few dozen atoms arranged in a precise pattern. In the haemoglobin molecule there are 574 amino acid molecules. These are arranged in four chains, which twist around each other to form a globular three-dimensional structure of bewildering complexity. A model of a haemoglobin molecule looks rather like a dense thornbush. But unlike a real thornbush it is not a haphazard approximate pattern but a definite invariant structure, identically repeated, with not a twig nor a twist out of place, over six thousand million million million times in an average human body. The precise thornbush shape of a protein molecule such as haemoglobin is stable in the sense that two chains consisting of the same sequences of amino acids will tend, like two springs, to come to rest in exactly the same three-dimensional coiled pattern. Haemoglobin thornbushes are springing into their 'preferred' shape in your body at a rate of about four hundred million million per second, and others are being destroyed at the same rate. Haemoglobin is a modern molecule, used to illustrate the principle that atoms tend to fall into stable patterns. The point that is relevant here is that, before the coming of life on earth, some rudimentary evolution of molecules could have occurred by ordinary processes of physics and chemistry. There is no need to think of design or purpose or directedness. If a group of atoms in the presence of energy falls into a stable pattern it will tend to stay that way. The earliest form of natural selection was simply a selection of stable forms and a rejection of unstable ones. There is no mystery about this. It had to happen by definition. From this, of course, it does not follow that you can explain the existence of entities as complex as man by exactly the same principles on their own. It is no good taking the right number of atoms and shaking them together with some external energy till they happen to fall into the right pattern, and out drops Adam! You may make a molecule consisting of a few dozen atoms like that, but a man consists of over a thousand million million million million atoms. To try to make a man, you would have to work at your biochemical cocktail-shaker for a period so long that the entire age of the universe would seem like an eye-blink, and even then you would not succeed. This is where Darwin 's theory, in its most general form, comes to the rescue. Darwin 's theory takes over from where the story of the slow building up of molecules leaves off. The account of the origin of life that I shall give is necessarily speculative; by definition, nobody was around to see what happened. There are a number of rival theories, but they all have certain features in common. The simplified account I shall give is probably not too far from the truth. We do not know what chemical raw materials were abundant on earth before the coming of life, but among the plausible possibilities are water, carbon dioxide, methane, and ammonia: all simple compounds known to be present on at least some of the other planets in our solar system. Chemists have tried to imitate the chemical conditions of the young earth. They have put these simple substances in a flask and supplied a source of energy such as ultraviolet light or electric sparks-artificial simulation of primordial lightning. After a few weeks of this, something interesting is usually found inside the flask: a weak brown soup containing a large number of molecules more complex than the ones originally put in. In particular, amino acids have been found-the building blocks of proteins, one of the two great classes of biological molecules. Before these experiments were done, naturally-occurring amino acids would have been thought of as diagnostic of the presence of life. If they had been detected on, say Mars, life on that planet would have seemed a near certainty. Now, however, their existence need imply only the presence of a few simple gases in the atmosphere and some volcanoes, sunlight, or thundery weather. More recently, laboratory simulations of the chemical conditions of earth before the coming of life have yielded organic substances called purines and pyrimidines. These are building blocks of the genetic molecule, DNA itself Processes analogous to these must have given rise to the 'primeval soup' which biologists and chemists believe constituted the seas some three to four thousand million years ago. The organic substances became locally concentrated, perhaps in drying scum round the shores, or in tiny suspended droplets. Under the further influence of energy such as ultraviolet light from the sun, they combined into larger molecules. Nowadays large organic molecules would not last long enough to be noticed: they would be quickly absorbed and broken down by bacteria or other living creatures. But bacteria and the rest of us are late-comers, and in those days large organic molecules could drift unmolested through the thickening broth. At some point a particularly remarkable molecule was formed by accident. We will call it the Replicator. It may not necessarily have been the biggest or the most complex molecule around, but it had the extraordinary property of being able to create copies of itself This may seem a very unlikely sort of accident to happen. So it was. It was exceedingly improbable. In the lifetime of a man, things that are that improbable can be treated for practical purposes as impossible. That is why you will never win a big prize on the football pools. But in our human estimates of what is probable and what is not, we are not used to dealing in hundreds of millions of years. If you filled in pools coupons every week for a hundred million years you would very likely win several jackpots. Actually a molecule that makes copies of itself is not as difficult to imagine as it seems at first, and it only had to arise once. Think of the replicator as a mould or template. Imagine it as a large molecule consisting of a complex chain of various sorts of building block molecules. The small building blocks were abundantly available in the soup surrounding the replicator. Now suppose that each building block has an affinity for its own kind. Then whenever a building block from out in the soup lands up next to a part of the replicator for which it has an affinity, it will tend to stick there. The building blocks that attach themselves in this way will automatically be arranged in a sequence that mimics that of the replicator itself. It is easy then to think of them joining up to form a stable chain just as in the formation of the original replicator. This process could continue as a progressive stacking up, layer upon layer. This is how crystals are formed. On the other hand, the two chains might split apart, in which case we have two replicators, each of which can go on to make further copies. A more complex possibility is that each building block has affinity not for its own kind, but reciprocally for one particular other kind. Then the replicator would act as a template not for an identical copy, but for a kind of 'negative', which would in its turn re-make an exact copy of the original positive. For our purposes it does not matter whether the original replication process was positive-negative or positive-positive, though it is worth remarking that the modem equivalents of the first replicator, the DNA molecules, use positive-negative replication. What does matter is that suddenly a new kind of 'stability' came into the world. Previously it is probable that no particular kind of complex molecule was very abundant in the soup, because each was dependent on building blocks happening to fall by luck into a particular stable configuration. As soon as the replicator was born it must have spread its copies rapidly throughout the seas, until the smaller building block molecules became a scarce resource, and other larger molecules were formed more and more rarely. So we seem to arrive at a large population of identical replicas. But now we must mention an important property of any copying process: it is not perfect. Mistakes will happen. I hope there are no misprints in this book, but if you look carefully you may find one or two. They will probably not seriously distort the meaning of the sentences, because they will be 'first generation' errors. But imagine the days before printing, when books such as the Gospels were copied by hand. All scribes, however careful, are bound to make a few errors, and some are not above a little wilful 'improvement'. If they all copied from a single master original, meaning would not be greatly perverted. But let copies be made from other copies, which in their turn were made from other copies, and errors will start to become cumulative and serious. We tend to regard erratic copying as a bad thing, and in the case of human documents it is hard to think of examples where errors can be described as improvements. I suppose the scholars of the Septuagint could at least be said to have started something big when they mistranslated the Hebrew word for 'young woman' into the Greek word for 'virgin', coming up with the prophecy: 'Behold a virgin shall conceive and bear a son .. .' Anyway, as we shall see, erratic copying in biological replicators can in a real sense give rise to improvement, and it was essential for the progressive evolution of life that some errors were made. We do not know how accurately the original replicator molecules made their copies. Their modem descendants, the DNA molecules, are astonishingly faithful compared with the most high-fidelity human copying process, but even they occasionally make mistakes, and it is ultimately these mistakes that make evolution possible. Probably the original replicators were far more erratic, but in any case we may be sure that mistakes were made, and these mistakes were cumulative. As mis-copyings were made and propagated, the primeval soup became filled by a population not of identical replicas, but of several varieties of replicating molecules, all 'descended' from the same ancestor. Would some varieties have been more numerous than others? Almost certainly yes. Some varieties would have been inherently more stable than others. Certain molecules, once formed, would be less likely than others to break up again. These types would become relatively numerous in the soup, not only as a direct logical consequence of their 'longevity', but also because they would have a long time available for making copies of themselves. Replicators of high longevity would therefore tend to become more numerous and, other things being equal, there would have been an 'evolutionary trend' towards greater longevity in the population of molecules. But other things were probably not equal, and another property of a replicator variety that must have had even more importance in spreading it through the population was speed of replication or 'fecundity'. If replicator molecules of type A make copies of themselves on average once a week while those of type B make copies of themselves once an hour, it is not difficult to see that pretty soon type A molecules are going to be far outnumbered, even if they 'live' much longer than B molecules. There would therefore probably have been an 'evolutionary trend' towards higher 'fecundity' of molecules in the soup. A third characteristic of replicator molecules which would have been positively selected is accuracy of replication. If molecules of type X and type Y last the same length of time and replicate at the same rate, but A makes a mistake on average every tenth replication while Y makes a mistake only every hundredth replication, Y will obviously become more numerous. The A contingent in the population loses not only the errant 'children' themselves, but also all their descendants, actual or potential. If you already know something about evolution, you may find something slightly paradoxical about the last point. Can we reconcile the idea that copying errors are an essential prerequisite for evolution to occur, with the statement that natural selection favours high copying-fidelity? The answer is that although evolution may seem, in some vague sense, a 'good thing', especially since we are the product of it, nothing actually 'wants' to evolve. Evolution is something that happens, willy-nilly, in spite of all the efforts of the replicators (and nowadays of the genes) to prevent it happening. Jacques Monod made this point very well in his Herbert Spencer lecture, after wryly remarking: 'Another curious aspect of the theory of evolution is that everybody thinks he understands it!' To return to the primeval soup, it must have become populated by stable varieties of molecule; stable in that either the individual molecules lasted a long time, or they replicated rapidly, or they replicated accurately. Evolutionary trends toward these three kinds of stability took place in the following sense: if you had sampled the soup at two different times, the later sample would have contained a higher proportion of varieties with high longevity/fecundity/copying-fidelity. This is essentially what a biologist means by evolution when he is speaking of living creatures, and the mechanism is the same-natural selection. Should we then call the original replicator molecules 'living'? Who cares? I might say to you 'Darwin was the greatest man who has ever lived', and you might say 'No, Newton was', but I hope we would not prolong the argument. The point is that no conclusion of substance would be affected whichever way our argument was resolved. The facts of the lives and achievements of Newton and Darwin remain totally unchanged whether we label them 'great' or not. Similarly, the story of the replicator molecules probably happened something like the way I am telling it, regardless of whether we choose to call them 'Iiving'. Human suffering has been caused because too many of us cannot grasp that words are only tools for our use, and that the mere presence in the dictionary of a word like 'living' does not mean it necessarily has to refer to something definite in the real world. Whether we call the early replicators living or not, they were the ancestors of life; they were our founding fathers. The next important link in the argument, one that Darwin himself laid stress on (although he was talking about animals and plants, not molecules) is competition. The primeval soup was not capable of supporting an infinite number of replicator molecules. For one thing, the earth's size is finite, but other limiting factors must also have been important. In our picture of the replicator acting as a template or mould, we supposed it to be bathed in a soup rich in the small building block molecules necessary to make copies. But when the replicators became numerous, building blocks must have been used up at such a rate that they became a scarce and precious resource. Different varieties or strains of replicator must have competed for them. We have considered the factors that would have increased the numbers of favoured kinds of replicator. We can now see that less-favoured varieties must actually have become less numerous because of competition, and ultimately many of their lines must have gone extinct. There was a struggle for existence among replicator varieties. They did not know they were struggling, or worry about it; the struggle was conducted without any hard feelings, indeed without feelings of any kind. But they were struggling, in the sense that any mis-copying that resulted in a new higher level of stability, or a new way of reducing the stability of rivals, was automatically preserved and multiplied. The process of improvement was cumulative. Ways of increasing stability and of decreasing rivals' stability became more elaborate and more efficient. Some of them may even have 'discovered' how to break up molecules of rival varieties chemically, and to use the building blocks so released for making their own copies. These proto-carnivores simultaneously obtained food and removed competing rivals. Other replicators perhaps discovered how to protect themselves, either chemically, or by building a physical wall of protein around themselves. This may have been how the first living cells appeared. Replicators began not merely to exist, but to construct for themselves containers, vehicles for their continued existence. The replicators that survived were the ones that built survival machines for themselves to live in. The first survival machines probably consisted of nothing more than a protective coat. But making a living got steadily harder as new rivals arose with better and more effective survival machines. Survival machines got bigger and more elaborate, and the process was cumulative and progressive. Was there to be any end to the gradual improvement in the techniques and artifices used by the replicators to ensure their own continuation in the world? There would be plenty of time for improvement. What weird engines of self-preservation would the millennia bring forth? Four thousand million years on, what was to be the fate of the ancient replicators? They did not die out, for they are past masters of the survival arts. But do not look for them floating loose in the sea; they gave up that cavalier freedom long ago. Now they swarm in huge colonies, safe inside gigantic lumbering robots, sealed off from the outside world, communicating with it by tortuous indirect routes, manipulating it by remote control. They are in you and in me; they created us, body and mind; and their preservation is the ultimate rationale for our existence. They have come a long way, those replicators. Now they go by the name of genes, and we are their survival machines.",
        "char_count": 20709
      },
      {
        "heading": "Chapter 4",
        "text": "The Selfish Gene 3. Immortal coils. We are survival machines, but 'we' does not mean just people. It embraces all animals, plants, bacteria, and viruses. The total number of survival machines on earth is very difficult to count and even the total number of species is unknown. Taking just insects alone, the number of living species has been estimated at around three million, and the number of individual insects may be a million million million. Different sorts of survival machine appear very varied on the outside and in their internal organs. An octopus is nothing like a mouse, and both are quite different from an oak tree. Yet in their fundamental chemistry they are rather uniform, and, in particular, the replicators that they bear, the genes, are basically the same kind of molecule in all of us-from bacteria to elephants. We are all survival machines for the same kind of replicator-molecules called DNA-but there are many different ways of making a living in the world, and the replicators have built a vast range of machines to exploit them. A monkey is a machine that preserves genes up trees, a fish is a machine that preserves genes in the water; there is even a small worm that preserves genes in German beer mats. DNA works in mysterious ways. For simplicity I have given the impression that modern genes, made of DNA, are much the same as the first replicators in the primeval soup. It does not matter for the argument, but this may not really be true. The original replicators may have been a related kind of molecule to DNA, or they may have been totally different. In the latter case we might say that their survival machines must have been seized at a later stage by DNA. If so, the original replicators were utterly destroyed, for no trace of them remains in modern survival machines. Along these lines, A. G. Cairns-Smith has made the intriguing suggestion that our ancestors, the first replicators, may have been not organic molecules at all, but inorganic crystals- minerals, little bits of clay. Usurper or not, DNA is in undisputed charge today, unless, as I tentatively suggest in Chapter 11, a new seizure of power is now just beginning. A DNA molecule is a long chain of building blocks, small molecules called nucleotides. Just as protein molecules are chains of amino acids, so DNA molecules are chains of nucleotides. A DNA molecule is too small to be seen, but its exact shape has been ingeniously worked out by indirect means. It consists of a pair of nucleotide chains twisted together in an elegant spiral; the 'double helix'; the 'immortal coil'. The nucleotide building blocks come in only four different kinds, whose names may be shortened to A, T, C, and G. These are the same in all animals and plants. What differs is the order in which they are strung together. A G building block from a man is identical in every particular to a G building block from a snail. But the sequence of building blocks in a man is not only different from that in a snail. It is also different-though less so-from the sequence in every other man (except in the special case of identical twins). Our DNA lives inside our bodies. It is not concentrated in a particular part of the body, but is distributed among the cells. There are about a thousand million million cells making up an average human body, and, with some exceptions which we can ignore, every one of those cells contains a complete copy of that body's DNA. This DNA can be regarded as a set of instructions for how to make a body, written in the A, T, C, G alphabet of the nucleotides. It is as though, in every room of a gigantic building, there was a book-case containing the architect's plans for the entire building. The 'book-case' in a cell is called the nucleus. The architect's plans run to 46 volumes in man-the number is different in other species. The 'volumes' are called chromosomes. They are visible under a microscope as long threads, and the genes are strung out along them in order. It is not easy, indeed it may not even be meaningful, to decide where one gene ends and the next one begins. Fortunately, as this chapter will show, this does not matter for our purposes. I shall make use of the metaphor of the architect's plans, freely mixing the language of the metaphor with the language of the real thing. 'Volume' will be used interchangeably with chromosome. 'Page' will provisionally be used interchangeably with gene, although the division between genes is less clear-cut than the division between the pages of a book. This metaphor will take us quite a long way. When it finally breaks down I shall introduce other metaphors. Incidentally, there is of course no 'architect'. The DNA instructions have been assembled by natural selection. DNA molecules do two important things. Firstly they replicate, that is to say they make copies of themselves. This has gone on nonstop ever since the beginning of life, and the DNA molecules are now very good at it indeed. As an adult, you consist of a thousand million million cells, but when you were first conceived you were just a single cell, endowed with one master copy of the architect's plans. This cell divided into two, and each of the two cells received its own copy of the plans. Successive divisions took the number of cells up to 4, 8, 16, 32, and so on into the billions. At every division the DNA plans were faithfully copied, with scarcely any mistakes. It is one thing to speak of the duplication of DNA. But if the DNA is really a set of plans for building a body, how are the plans put into practice? How are they translated into the fabric of the body? This brings me to the second important thing DNA does. It indirectly supervises the manufacture of a different kind of molecule-protein. The haemoglobin which was mentioned in the last chapter is just one example of the enormous range of protein molecules. The coded message of the DNA, written in the four-letter nucleotide alphabet, is translated in a simple mechanical way into another alphabet. This is the alphabet of amino acids which spells out protein molecules. Making proteins may seem a far cry from making a body, but it is the first small step in that direction. Proteins not only constitute much of the physical fabric of the body; they also exert sensitive control over all the chemical processes inside the cell, selectively turning them on and off at precise times and in precise places. Exactly how this eventually leads to the development of a baby is a story which it will take decades, perhaps centuries, for embryologists to work out. But it is a fact that it does. Genes do indirectly control the manufacture of bodies, and the influence is strictly one way: acquired characteristics are not inherited. No matter how much knowledge and wisdom you acquire during your life, not one jot will be passed on to your children by genetic means. Each new generation starts from scratch. A body is the genes' way of preserving the genes unaltered. The evolutionary importance of the fact that genes control embryonic development is this: it means that genes are at least partly responsible for their own survival in the future, because their survival depends on the efficiency of the bodies in which they live and which they helped to build. Once upon a time, natural selection consisted of the differential survival of replicators floating free in the primeval soup. Now, natural selection favours replicators that are good at building survival machines, genes that are skilled in the art of controlling embryonic development. In this, the replicators are no more conscious or purposeful than they ever were. The same old processes of automatic selection between rival molecules by reason of their longevity, fecundity, and copying-fidelity, still go on as blindly and as inevitably as they did in the far-off days. Genes have no foresight. They do not plan ahead. Genes just are, some genes more so than others, and that is all there is to it. But the qualities that determine a gene's longevity and fecundity are not so simple as they were. Not by a long way. In recent years-the last six hundred million or so-the replicators have achieved notable triumphs of survival-machine technology such as the muscle, the heart, and the eye (evolved several times independently). Before that, they radically altered fundamental features of their way of life as replicators, which must be understood if we are to proceed with the argument. The first thing to grasp about a modern replicator is that it is highly gregarious. A survival machine is a vehicle containing not just one gene but many thousands. The manufacture of a body is a cooperative venture of such intricacy that it is almost impossible to disentangle the contribution of one gene from that of another. A given gene will have many different effects on quite different parts of the body. A given part of the body will be influenced by many genes, and the effect of any one gene depends on interaction with many others. Some genes act as master genes controlling the operation of a cluster of other genes. In terms of the analogy, any given page of the plans makes reference to many different parts of the building; and each page makes sense only in terms of cross-references to numerous other pages. This intricate inter-dependence of genes may make you wonder why we use the word 'gene' at all. Why not use a collective noun like 'gene complex'? The answer is that for many purposes that is indeed quite a good idea. But if we look at things in another way, it does make sense too to think of the gene complex as being divided up into discrete replicators or genes. This arises because of the phenomenon of sex. Sexual reproduction has the effect of mixing and shuffling genes. This means that any one individual body is just a temporary vehicle for a short-lived combination of genes. The combination of genes that is any one individual may be short-lived, but the genes themselves are potentially very long-lived. Their paths constantly cross and recross down the generations. One gene maybe regarded as a unit that survives through a large number of successive individual bodies. This is the central argument that will be developed in this chapter. It is an argument that some of my most respected colleagues obstinately refuse to agree with, so you must forgive me if I seem to labour it! First I must briefly explain the facts of sex. I said that the plans for building a human body are spelt out in 46 volumes. In fact this was an over-simplification. The truth is rather bizarre. The 46 chromosomes consist of 23 pairs of chromosomes. We might say that, filed away in the nucleus of every cell, are two alternative sets of 23 volumes of plans. Call them Volume 1a and 1b, Volume 2a and Volume 2b etc., down to Volume 23a and Volume 23b. Of course the identifying numbers I use for volumes and, later, pages, are purely arbitrary. We receive each chromosome intact from one of our two parents, in whose testis or ovary it was assembled. Volumes 1a, 2a, 3a, ... came, say, from the father. Volumes 1b, 2b, 3b,... came from the mother. It is very difficult in practice, but in theory you could look with a microscope at the 46 chromosomes in any one of your cells, and pick out the 23 that came from your father and the 23 that came from your mother. The paired chromosomes do not spend all their lives physically in contact with each other, or even near each other. In what sense then are they 'paired'? In the sense that each volume coming originally from the father can be regarded, page for page, as a direct alternative to one particular volume coming originally from the mother. For instance, Page 6 of Volume 13a and Page 6 of Volume 13b might both be 'about' eye colour; perhaps one says 'blue' while the other says 'brown'. Sometimes the two alternative pages are identical, but in other cases, as in our example of eye colour, they differ. If they make contradictory 'recommendations', what does the body do? The answer varies. Sometimes one reading prevails over the other. In the eye colour example just given, the person would actually have brown eyes: the instructions for making blue eyes would be ignored in the building of the body, though this does not stop them being passed on to future generations. A gene that is ignored in this way is called recessive. The opposite of a recessive gene is a dominant gene. The gene for brown eyes is dominant to the gene for blue eyes. A person has blue eyes only if both copies of the relevant page are unanimous in recommending blue eyes. More usually when two alternative genes are not identical, the result is some kind of compromise-the body is built to an intermediate design or something completely different. When two genes, like the brown eye and the blue eye gene, are rivals for the same slot on a chromosome, they are called alleles of each other. For our purposes, the word allele is synonymous with rival. Imagine the volumes of architects' plans as being loose-leaf binders, whose pages can be detached and interchanged. Every Volume 13 must have a Page 6, but there are several possible Page 6s which could go in the binder between Page 5 and Page 7. One version says 'blue eyes', another possible version says 'brown eyes'; there may be yet other versions in the population at large which spell out other colours like green. Perhaps there are half a dozen alternative alleles sitting in the Page 6 position on the 13 th chromosomes scattered around the population as a whole. Any given person only has two Volume 13 chromosomes. Therefore he can have a maximum of two alleles in the Page 6 slot. He may, like a blue-eyed person, have two copies of the same allele, or he may have any two alleles chosen from the half dozen alternatives available in the population at large. You cannot, of course, literally go and choose your genes from a pool of genes available to the whole population. At any given time all the genes are tied up inside individual survival machines. Our genes are doled out to us at conception, and there is nothing we can do about this. Nevertheless, there is a sense in which, in the long term, the genes of the population in general can be regarded as a gene pool. This phrase is in fact a technical term used by geneticists. The gene pool is a worthwhile abstraction because sex mixes genes up, albeit in a carefully organized way. In particular, something like the detaching and interchanging of pages and wads of pages from loose-leaf binders really does go on, as we shall presently see. I have described the normal division of a cell into two new cells, each one receiving a complete copy of all 46 chromosomes. This normal cell division is called mitosis. But there is another kind of cell division called meiosis. This occurs only in the production of the sex cells; the sperms or eggs. Sperms and eggs are unique among our cells in that, instead of containing 46 chromosomes, they contain only 23. This is, of course, exactly half of 46-convenient when they fuse in sexual fertilization to make a new individual! Meiosis is a special kind of cell division, taking place only in testicles and ovaries, in which a cell with the full double set of 46 chromosomes divides to form sex cells with the single set of 23 (all the time using the human numbers for illustration). A sperm, with its 23 chromosomes, is made by the meiotic division of one of the ordinary 46-chromosome cells in the testicle. Which 23 are put into any given sperm cell? It is clearly important that a sperm should not get just any old 23 chromosomes: it mustn't end up with two copies of Volume 13 and none of Volume 17. It would theoretically be possible for an individual to endow one of his sperms with chromosomes which came, say, entirely from his mother; that is Volume 1b, 2b, 3b,..., 23b. In this unlikely event, a child conceived by the sperm would inherit half her genes from her paternal grandmother, and none from her paternal grandfather. But in fact this kind of gross, whole-chromosome distribution does not happen. The truth is rather more complex. Remember that the volumes (chromosomes) are to be thought of as loose-leaf binders. What happens is that, during the manufacture of the sperm, single pages, or rather multi-page chunks, are detached and swapped with the corresponding chunks from the alternative volume. So, one particular sperm cell might make up its Volume 1 by taking the first 65 pages from Volume 1a, and pages 66 to the end from Volume 1b. This sperm cell's other 22 volumes would be made up in a similar way. Therefore every sperm cell made by an individual is unique, even though all his sperms assembled their 23 chromosomes from bits of the same set of 46 chromosomes. Eggs are made in a similar way in ovaries, and they too are all unique. The real-life mechanics of this mixing are fairly well understood. During the manufacture of a sperm (or egg), bits of each paternal chromosome physically detach themselves and change places with exactly corresponding bits of maternal chromosome. (Remember that we are talking about chromosomes that came originally from the parents of the individual making the sperm, i.e., from the paternal grandparents of the child who is eventually conceived by the sperm). The process of swapping bits of chromosome is called crossing over. It is very important for the whole argument of this book. It means that if you got out your microscope and looked at the chromosomes in one of your own sperms (or eggs if you are female) it would be a waste of time trying to identify chromosomes that originally came from your father and chromosomes that originally came from your mother. (This is in marked contrast to the case of ordinary body cells (see page 25). Any one chromosome in a sperm would be a patchwork, a mosaic of maternal genes and paternal genes. The metaphor of the page for the gene starts to break down here. In a loose-leaf binder a whole page may be inserted, removed or exchanged, but not a fraction of a page. But the gene complex is just a long string of nucleotide letters, not divided into discrete pages in an obvious way at all. To be sure, there are special symbols for end of PROTEIN CHAIN MESSAGE and START OF PROTEIN CHAIN MESSAGE written in the same four-letter alphabet as the protein messages themselves. In between these two punctuation marks are the coded instructions for making one protein. If we wish, we can define a single gene as a sequence of nucleotide letters lying between a start and an end symbol, and coding for one protein chain. The word cistron has been used for a unit defined in this way, and some people use the word gene interchangeably with cistron. But crossing-over does not respect boundaries between cistrons. Splits may occur within cistrons as well as between them. It is as though the architect's plans were written out, not on discrete pages, but on 46 rolls of ticker tape. Cistrons are not of fixed length. The only way to tell where one cistron ends and the next begins would be to read the symbols on the tape, looking for end of message and start of message symbols. Crossing-over is represented by taking matching paternal and maternal tapes, and cutting and exchanging matching portions, regardless of what is written on them. In the title of this book the word gene means not a single cistron but something more subtle. My definition will not be to everyone's taste, but there is no universally agreed definition of a gene. Even if there were, there is nothing sacred about definitions. We can define a word how we like for our own purposes, provided we do so clearly and unambiguously. The definition I want to use comes from G. C. Williams. A gene is defined as any portion of chromosomal material that potentially lasts for enough generations to serve as a unit of natural selection. In the words of the previous chapter, a gene is a replicator with high copying-fidelity. Copying-fidelity is another way of saying longevity-in-the-form-of-copies and I shall abbreviate this simply to longevity. The definition will take some justifying. On any definition, a gene has to be a portion of a chromosome. The question is, how big a portion-how much of the ticker tape? Imagine any sequence of adjacent code-letters on the tape. Call the sequence a genetic unit. It might be a sequence of only ten letters within one cistron; it might be a sequence of eight cistrons; it might start and end in mid-cistron. It will overlap with other genetic units. It will include smaller units, and it will form part of larger units. No matter how long or short it is, for the purposes of the present argument, this is what we are calling a genetic unit. It is just a length of chromosome, not physically differentiated from the rest of the chromosome in any way. Now comes the important point. The shorter a genetic unit is, the longer-in generations-it is likely to live. In particular, the less likely it is to be split by any one crossing-over. Suppose a whole chromosome is, on average, likely to undergo one cross-over every time a sperm or egg is made by meiotic division, and this cross-over can happen anywhere along its length. If we consider a very large genetic unit, say half the length of the chromosome, there is a 50 per cent chance that the unit will be split at each meiosis. If the genetic unit we are considering is only 1 per cent of the length of the chromosome, we can assume that it has only a 1 per cent chance of being split in any one meiotic division. This means that the unit can expect to survive for a large number of generations in the individual's descendants. A single cistron is likely to be much less than 1 per cent of the length of a chromosome. Even a group of several neighbouring cistrons can expect to live many generations before being broken up by crossing over. The average life-expectancy of a genetic unit can conveniently be expressed in generations, which can in turn be translated into years. If we take a whole chromosome as our presumptive genetic unit, its life story lasts for only one generation. Suppose it is your chromosome number 8a, inherited from your father. It was created inside one of your father's testicles, shortly before you were conceived. It had never existed before in the whole history of the world. It was created by the meiotic shuffling process, forged by the coming together of pieces of chromosome from your paternal grandmother and your paternal grandfather. It was placed inside one particular sperm, and it was unique. The sperm was one of several millions, a vast armada of tiny vessels, and together they sailed into your mother. This particular sperm (unless you are a non-identical twin) was the only one of the flotilla which found harbour in one of your mother's eggs-that is why you exist. The genetic unit we are considering, your chromosome number 8a, set about replicating itself along with all the rest of your genetic material. Now it exists, in duplicate form, all over your body. But when you in your turn come to have children, this chromosome will be destroyed when you manufacture eggs (or sperms). Bits of it will be interchanged with bits of your maternal chromosome number 8b. In any one sex cell, a new chromosome number 8 will be created, perhaps 'better' than the old one, perhaps 'worse', but, barring a rather improbable coincidence, definitely different, definitely unique. The life-span of a chromosome is one generation. What about the life-span of a smaller genetic unit, say 1/100 of the length of your chromosome 8a? This unit too came from your father, but it very probably was not originally assembled in him. Following the earlier reasoning, there is a 99 per cent chance that he received it intact from one of his two parents. Suppose it was from his mother, your paternal grandmother. Again, there is a 99 per cent chance that she inherited it intact from one of her parents. Eventually, if we trace the ancestry of a small genetic unit back far enough, we will come to its original creator. At some stage it must have been created for the first time inside a testicle or an ovary of one of your ancestors. Let me repeat the rather special sense in which I am using the word 'create'. The smaller sub-units which make up the genetic unit we are considering may well have existed long before. Our genetic unit was created at a particular moment only in the sense that the particular arrangement of sub-units by which it is defined did not exist before that moment. The moment of creation may have occurred quite recently, say in one of your grandparents. But if we consider a very small genetic unit, it may have been first assembled in a much more distant ancestor, perhaps an ape-like pre-human ancestor. Moreover, a small genetic unit inside you may go on just as far into the future, passing intact through a long line of your descendants. Remember too that an individual's descendants constitute not a single line but a branching line. Whichever of your ancestors it was who 'created' a particular short length of your chromosome 8a, he or she very likely has many other descendants besides you. One of your genetic units may also be present in your second cousin. It may be present in me, and in the Prime Minister, and in your dog, for we all share ancestors if we go back far enough. Also the same small unit might be assembled several times independently by chance: if the unit is small, the coincidence is not too improbable. But even a close relative is unlikely to share a whole chromosome with you. The smaller a genetic unit is, the more likely it is that another individual shares it-the more likely it is to be represented many times over in the world, in the form of copies. The chance coming together, through crossing-over, of previously existing sub-units is the usual way for a new genetic unit to be formed. Another way-of great evolutionary importance even though it is rare-is called point mutation. A point mutation is an error corresponding to a single misprinted letter in a book. It is rare, but clearly the longer a genetic unit is, the more likely it is to be altered by a mutation somewhere along its length. Another rare kind of mistake or mutation which has important long-term consequences is called inversion. A piece of chromosome detaches itself at both ends, turns head over heels, and reattaches itself in the inverted position. In terms of the earlier analogy, this would necessitate some renumbering of pages. Sometimes portions of chromosomes do not simply invert, but become reattached in a completely different part of the chromosome, or even join up with a different chromosome altogether. This corresponds to the transfer of a wad of pages from one volume to another. The importance of this kind of mistake is that, though usually disastrous, it can occasionally lead to the close linkage of pieces of genetic material which happen to work well together. Perhaps two cistrons which have a beneficial effect only when they are both present-they complement or reinforce each other in some way-will be brought close to each other by means of inversion. Then natural selection may tend to favour the new 'genetic unit' so formed, and it will spread through the future population. It is possible that gene complexes have, over the years, been extensively rearranged or 'edited' in this kind of way. One of the neatest examples of this concerns the phenomenon known as mimicry. Some butterflies taste nasty. They are usually brightly and distinctively coloured, and birds learn to avoid them by their 'warning' marks. Now other species of butterfly that do not taste nasty cash in. They mimic the nasty ones. They are born looking like them in colour and shape (but not taste). They frequently fool human naturalists, and they also fool birds. A bird who has once tasted a genuinely nasty butterfly tends to avoid all butterflies that look the same. This includes the mimics, and so genes for mimicry are favoured by natural selection. That is how mimicry evolves. There are many different species of 'nasty' butterfly and they do not all look alike. A mimic cannot resemble all of them: it has to commit itself to one particular nasty species. In general, any particular species of mimic is a specialist at mimicking one particular nasty species. But there are species of mimic that do something very strange. Some individuals of the species mimic one nasty species; other individuals mimic another. Any individual who was intermediate or who tried to mimic both would soon be eaten; but such intermediates are not born. Just as an individual is either definitely male or definitely female, so an individual butterfly mimics either one nasty species or the other. One butterfly may mimic species A while his brother mimics species B. It looks as though a single gene determines whether an individual will mimic species A or species B. But how can a single gene determine all the multifarious aspects of mimicry-colour, shape, spot pattern, rhythm of flight? The answer is that one gene in the sense of a cistron probably cannot. But by the unconscious and automatic 'editing' achieved by inversions and other accidental rearrangements of genetic material, a large cluster of formerly separate genes has come together in a tight linkage group on a chromosome. The whole cluster behaves like a single gene-indeed, by our definition it now is a single gene-and it has an 'allele' which is really another cluster. One cluster contains the cistrons concerned with mimicking species A; the other those concerned with mimicking species B. Each cluster is so rarely split up by crossing-over that an intermediate butterfly is never seen in nature, but they do very occasionally turn up if large numbers of butterflies are bred in the laboratory. I am using the word gene to mean a genetic unit that is small enough to last for a large number of generations and to be distributed around in the form of many copies. This is not a rigid all-or-nothing definition, but a kind of fading-out definition, like the definition of 'big' or 'old'. The more likely a length of chromosome is to be split by crossing-over, or altered by mutations of various kinds, the less it qualifies to be called a gene in the sense in which I am using the term. A cistron presumably qualifies, but so also do larger units. A dozen cistrons may be so close to each other on a chromosome that for our purposes they constitute a single long-lived genetic unit. The butterfly mimicry cluster is a good example. As the cistrons leave one body and enter the next, as they board sperm or egg for the journey into the next generation, they are likely to find that the little vessel contains their close neighbours of the previous voyage, old shipmates with whom they sailed on the long odyssey from the bodies of distant ancestors. Neighbouring cistrons on the same chromosome form a tightly-knit troupe of travelling companions who seldom fail to get on board the same vessel when meiosis time comes around. To be strict, this book should be called not The Selfish Cistron nor The Selfish Chromosome, but The slightly selfish big bit of chromosome and the even more selfish little bit of chromosome. To say the least this is not a catchy tide so, defining a gene as a little bit of chromosome which potentially lasts for many generations, I call the book The Selfish Gene. We have now arrived back at the point we left at the end of Chapter i. There we saw that selfishness is to be expected in any entity that deserves the title of a basic unit of natural selection. We saw that some people regard the species as the unit of natural selection, others the population or group within the species, and yet others the individual. I said that I preferred to think of the gene as the fundamental unit of natural selection, and therefore the fundamental unit of self-interest. What I have now done is to define the gene in such a way that I cannot really help being right! Natural selection in its most general form means the differential survival of entities. Some entities live and others die but, in order for this selective death to have any impact on the world, an additional condition must be met. Each entity must exist in the form of lots of copies, and at least some of the entities must be potentially capable of surviving-in the form of copies-for a significant period of evolutionary time. Small genetic units have these properties: individuals, groups, and species do not. It was the great achievement of Gregor Mendel to show that hereditary units can be treated in practice as indivisible and independent particles. Nowadays we know that this is a little too simple. Even a cistron is occasionally divisible and any two genes on the same chromosome are not wholly independent. What I have done is to define a gene as a unit which, to a high degree, approaches the ideal of indivisible particulateness. A gene is not indivisible, but it is seldom divided. It is either definitely present or definitely absent in the body of any given individual. A gene travels intact from grandparent to grandchild, passing straight through the intermediate generation without being merged with other genes. If genes continually blended with each other, natural selection as we now understand it would be impossible. Incidentally, this was proved in Darwin's lifetime, and it caused Darwin great worry since in those days it was assumed that heredity was a blending process. Mendel's discovery had already been published, and it could have rescued Darwin, but alas he never knew about it: nobody seems to have read it until years after Darwin and Mendel had both died. Mendel perhaps did not realize the significance of his findings, otherwise he might have written to Darwin. Another aspect of the particulateness of the gene is that it does not grow senile; it is no more likely to die when it is a million years old than when it is only a hundred. It leaps from body to body down the generations, manipulating body after body in its own way and for its own ends, abandoning a succession of mortal bodies before they sink in senility and death. The genes are the immortals, or rather, they are defined as genetic entities that come close to deserving the title. We, the individual survival machines in the world, can expect to live a few more decades. But the genes in the world have an expectation of life that must be measured not in decades but in thousands and millions of years. In sexually reproducing species, the individual is too large and too temporary a genetic unit to qualify as a significant unit of natural selection. The group of individuals is an even larger unit. Genetically speaking, individuals and groups are like clouds in the sky or dust-storms in the desert. They are temporary aggregations or federations. They are not stable through evolutionary time. Populations may last a long while, but they are constantly blending with other populations and so losing their identity. They are also subject to evolutionary change from within. A population is not a discrete enough entity to be a unit of natural selection, not stable and unitary enough to be 'selected' in preference to another population. An individual body seems discrete enough while it lasts, but alas, how long is that? Each individual is unique. You cannot get evolution by selecting between entities when there is only one copy of each entity! Sexual reproduction is not replication. Just as a population is contaminated by other populations, so an individual's posterity is contaminated by that of his sexual partner. Your children are only half you, your grandchildren only a quarter you. In a few generations the most you can hope for is a large number of descendants, each of whom bears only a tiny portion of you-a few genes-even if a few do bear your surname as well. Individuals are not stable things, they are fleeting. Chromosomes too are shuffled into oblivion, like hands of cards soon after they are dealt. But the cards themselves survive the shuffling. The cards are the genes. The genes are not destroyed by crossing-over, they merely change partners and march on. Of course they march on. That is their business. They are the replicators and we are their survival machines. When we have served our purpose we are cast aside. But genes are denizens of geological time: genes are forever. Genes, like diamonds, are forever, but not quite in the same way as diamonds. It is an individual diamond crystal that lasts, as an unaltered pattern of atoms. DNA molecules don't have that kind of permanence. The life of any one physical DNA molecule is quite short-perhaps a matter of months, certainly not more than one lifetime. But a DNA molecule could theoretically live on in the form of copies of itself for a hundred million years. Moreover, just like the ancient replicators in the primeval soup, copies of a particular gene may be distributed all over the world. The difference is that the modern versions are all neatly packaged inside the bodies of survival machines. What I am doing is emphasizing the potential near-immortality of a gene, in the form of copies, as its defining property. To define a gene as a single cistron is good for some purposes, but for the purposes of evolutionary theory it needs to be enlarged. The extent of the enlargement is determined by the purpose of the definition. We want to find the practical unit of natural selection. To do this we begin by identifying the properties that a successful unit of natural selection must have. In the terms of the last chapter, these are longevity, fecundity, and copying-fidelity. We then simply define a 'gene' as the largest entity which, at least potentially, has these properties. The gene is a long-lived replicator, existing in the form of many duplicate copies. It is not infinitely long-lived. Even a diamond is not literally everlasting, and even a cistron can be cut in two by crossing-over. The gene is defined as a piece of chromosome which is sufficiently short for it to last, potentially, for long enough for it to function as a significant unit of natural selection. Exactly how long is 'long enough'? There is no hard and fast answer. It will depend on how severe the natural selection 'pressure' is. That is, on how much more likely a 'bad' genetic unit is to die than its 'good' allele. This is a matter of quantitative detail which will vary from example to example. The largest practical unit of natural selection-the gene-will usually be found to lie somewhere on the scale between cistron and chromosome. It is its potential immortality that makes a gene a good candidate as the basic unit of natural selection. But now the time has come to stress the word 'potential'. A gene can live for a million years, but many new genes do not even make it past their first generation. The few new ones that succeed do so partly because they are lucky, but mainly because they have what it takes, and that means they are good at making survival machines. They have an effect on the embryonic development of each successive body in which they find themselves, such that that body is a little bit more likely to live and reproduce than it would have been under the influence of the rival gene or allele. For example, a 'good' gene might ensure its survival by tending to endow the successive bodies in which it finds itself with long legs, which help those bodies to escape from predators. This is a particular example, not a universal one. Long legs, after all, are not always an asset. To a mole they would be a handicap. Rather than bog ourselves down in details, can we think of any universal qualities that we would expect to find in all good (i.e. long-lived) genes? Conversely, what are the properties that instantly mark a gene out as a 'bad', short-lived one? There might be several such universal properties, but there is one that is particularly relevant to this book: at the gene level, altruism must be bad and selfishness good. This follows inexorably from our definitions of altruism and selfishness. Genes are competing directly with their alleles for survival, since their alleles in the gene pool are rivals for their slot on the chromosomes of future generations. Any gene that behaves in such a way as to increase its own survival chances in the gene pool at the expense of its alleles will, by definition, tautologously, tend to survive. The gene is the basic unit of selfishness. The main message of this chapter has now been stated. But I have glossed over some complications and hidden assumptions. The first complication has already been briefly mentioned. However independent and free genes may be in their journey through the generations, they are very much not free and independent agents in their control of embryonic development. They collaborate and interact in inextricably complex ways, both with each other, and with their external environment. Expressions like 'gene for long legs' or 'gene for altruistic behaviour' are convenient figures of speech, but it is important to understand what they mean. There is no gene which single-handedly builds a leg, long or short. Building a leg is a multi-gene cooperative enterprise. Influences from the external environment too are indispensable: after all, legs are actually made of food! But there may well be a single gene which, other things being equal, tends to make legs longer than they would have been under the influence of the gene's allele. As an analogy, think of the influence of a fertilizer, say nitrate, on the growth of wheat. Everybody knows that wheat plants grow bigger in the presence of nitrate than in its absence. But nobody would be so foolish as to claim that, on its own, nitrate can make a wheat plant. Seed, soil, sun, water, and various minerals are obviously all necessary as well. But if all these other factors are held constant, and even if they are allowed to vary within limits, addition of nitrate will make the wheat plants grow bigger. So it is with single genes in the development of an embryo. Embryonic development is controlled by an interlocking web of relationships so complex that we had best not contemplate it. No one factor, genetic or environmental, can be considered as the single 'cause' of any part of a baby. All parts of a baby have a near infinite number of antecedent causes. But a difference between one baby and another, for example a difference in length of leg, might easily be traced to one or a few simple antecedent differences, either in environment or in genes. It is differences that matter in the competitive struggle to survive; and it is genetically-controlled differences that matter in evolution. As far as a gene is concerned, its alleles are its deadly rivals, but other genes are just a part of its environment, comparable to temperature, food, predators, or companions. The effect of the gene depends on its environment, and this includes other genes. Sometimes a gene has one effect in the presence of a particular other gene, and a completely different effect in the presence of another set of companion genes. The whole set of genes in a body constitutes a kind of genetic climate or background, modifying and influencing the effects of any particular gene. But now we seem to have a paradox. If building a baby is such an intricate cooperative venture, and if every gene needs several thousands of fellow genes to complete its task, how can we reconcile this with my picture of indivisible genes, springing like immortal chamois from body to body down the ages: the free, untrammelled, and self-seeking agents of life? Was that all nonsense? Not at all. I may have got a bit carried away with the purple passages, but I was not talking nonsense, and there is no real paradox. We can explain this by means of another analogy. One oarsman on his own cannot win the Oxford and Cambridge boat race. He needs eight colleagues. Each one is a specialist who always sits in a particular part of the boat-bow or stroke or cox etc. Rowing the boat is a cooperative venture, but some men are nevertheless better at it than others. Suppose a coach has to choose his ideal crew from a pool of candidates, some specializing in the bow position, others specializing as cox, and so on. Suppose that he makes his selection as follows. Every day he puts together three new trial crews, by random shuffling of the candidates for each position, and he makes the three crews race against each other. After some weeks of this it will start to emerge that the winning boat often tends to contain the same individual men. These are marked up as good oarsmen. Other individuals seem consistently to be found in slower crews, and these are eventually rejected. But even an outstandingly good oarsman might sometimes be a member of a slow crew, either because of the inferiority of the other members, or because of bad luck-say a strong adverse wind. It is only on average that the best men tend to be in the winning boat. The oarsmen are genes. The rivals for each seat in the boat are alleles potentially capable of occupying the same slot along the length of a chromosome. Rowing fast corresponds to building a body which is successful at surviving. The wind is the external environment. The pool of alternative candidates is the gene pool. As far as the survival of any one body is concerned, all its genes are in the same boat. Many a good gene gets into bad company, and finds itself sharing a body with a lethal gene, which kills the body off in childhood. Then the good gene is destroyed along with the rest. But this is only one body, and replicas of the same good gene live on in other bodies which lack the lethal gene. Many copies of good genes are dragged under because they happen to share a body with bad genes, and many perish through other forms of ill luck, say when their body is struck by lightning. But by definition luck, good and bad, strikes at random, and a gene that is consistently on the losing side is not unlucky; it is a bad gene. One of the qualities of a good oarsman is teamwork, the ability to fit in and cooperate with the rest of a crew. This may be just as important as strong muscles. As we saw in the case of the butterflies, natural selection may unconsciously 'edit' a gene complex by means of inversions and other gross movements of bits of chromosome, thereby bringing genes that cooperate well together into closely linked groups. But there is also a sense in which genes which are in no way linked to each other physically can be selected for their mutual compatibility. A gene that cooperates well with most of the other genes that it is likely to meet in successive bodies, i.e. the genes in the whole of the rest of the gene pool, will tend to have an advantage. For example, a number of attributes are desirable in an efficient carnivore's body, among them sharp cutting teeth, the right kind of intestine for digesting meat, and many other things. An efficient herbivore, on the other hand, needs flat grinding teeth, and a much longer intestine with a different kind of digestive chemistry. In a herbivore gene pool, any new gene that conferred on its possessors sharp meat-eating teeth would not be very successful. This is not because meat-eating is universally a bad idea, but because you cannot efficiently eat meat unless you also have the right sort of intestine, and all the other attributes of a meat-eating way of life. Genes for sharp, meat-eating teeth are not inherently bad genes. They are only bad genes in a gene-pool that is dominated by genes for herbivorous qualities. This is a subtle, complicated idea. It is complicated because the 'environment' of a gene consists largely of other genes, each of which is itself being selected for its ability to cooperate with its environment of other genes. An analogy adequate to cope with this subtle point does exist, but it is not from everyday experience. It is the analogy with human 'game theory', which will be introduced in Chapter 5 in connection with aggressive contests between individual animals. I therefore postpone further discussion of this point until the end of that chapter, and return to the central message of this one. This is that the basic unit of natural selection is best regarded not as the species, nor as the population, nor even as the individual, but as some small unit of genetic material which it is convenient to label the gene. The cornerstone of the argument, as given earlier, was the assumption that genes are potentially immortal, while bodies and all other higher units are temporary. This assumption rests upon two facts: the fact of sexual reproduction and crossing-over, and the fact of individual mortality. These facts are undeniably true. But this does not stop us asking why they are true. Why do we and most other survival machines practise sexual reproduction? Why do our chromosomes cross over? And why do we not live for ever? The question of why we die of old age is a complex one, and the details are beyond the scope of this book. In addition to particular reasons, some more general ones have been proposed. For example, one theory is that senility represents an accumulation of deleterious copying errors and other kinds of gene damage which occur during the individual's lifetime. Another theory, due to Sir Peter Medawar, is a good example of evolutionary thinking in terms of gene selection. Medawar first dismisses traditional arguments such as: 'Old individuals die as an act of altruism to the rest of the species, because if they stayed around when they were too decrepit to reproduce, they would clutter up the world to no good purpose.' As Medawar points out, this is a circular argument, assuming what it sets out to prove, namely that old animals are too decrepit to reproduce. It is also a naive group-selection or species-selection kind of explanation, although that part of it could be rephrased more respectably. Medawar's own theory has a beautiful logic. We can build up to it as follows. We have already asked what are the most general attributes of a 'good' gene, and we decided that 'selfishness' was one of them. But another general quality that successful genes will have is a tendency to postpone the death of their survival machines at least until after reproduction. No doubt some of your cousins and great-uncles died in childhood, but not a single one of your ancestors did. Ancestors just don't die young! A gene that makes it possessors die is called a lethal gene. A semi-lethal gene has some debilitating effect, such that it makes death from other causes more probable. Any gene exerts its maximum effect on bodies at some particular stage of life, and lethals and semilethals are not exceptions. Most genes exert their influence during foetal life, others during childhood, other during young adulthood, others in middle age, and yet others in old age. (Reflect that a caterpillar and the butterfly it turns into have exactly the same set of genes.) Obviously lethal genes will tend to be removed from the gene pool. But equally obviously a late-acting lethal will be more stable in the gene pool than an early-acting lethal. A gene that is lethal in an older body may still be successful in the gene pool, provided its lethal effect does not show itself until after the body has had time to do at least some reproducing. For instance, a gene that made old bodies develop cancer could be passed on to numerous offspring because the individuals would reproduce before they got cancer. On the other hand, a gene that made young adult bodies develop cancer would not be passed on to very many offspring, and a gene that made young children develop fatal cancer would not be passed on to any offspring at all. According to this theory then, senile decay is simply a by-product of the accumulation in the gene pool of late-acting lethal and semi-lethal genes, which have been allowed to slip through the net of natural selection simply because they are late-acting. The aspect that Medawar himself emphasizes is that selection will favour genes that have the effect of postponing the operation of other, lethal genes, and it will also favour genes that have the effect of hastening the effect of good genes. It may be that a great deal of evolution consists of genetically-controlled changes in the time of onset of gene activity. It is important to notice that this theory does not need to make any prior assumptions about reproduction occurring only at certain ages. Taking as a starting assumption that all individuals were equally likely to have a child at any age, the Medawar theory would quickly predict the accumulation in the gene pool of late-acting deleterious genes, and the tendency to reproduce less in old age would follow as a secondary consequence. As an aside, one of the good features of this theory is that it leads us to some rather interesting speculations. For instance it follows from it that if we wanted to increase the human life span, there are two general ways in which we could do it. Firstly, we could ban reproduction before a certain age, say forty. After some centuries of this the minimum age limit would be raised to fifty, and so on. It is conceivable that human longevity could be pushed up to several centuries by this means. I cannot imagine that anyone would seriously want to institute such a policy. Secondly we could try to 'fool' genes into thinking that the body they are sitting in is younger than it really is. In practice this would mean identifying changes in the internal chemical environment of a body that take place during ageing. Any of these could be the 'cues' that 'turn on' late-acting lethal genes. By simulating the superficial chemical properties of a young body it might be possible to prevent the turning on of late-acting deleterious genes. The interesting point is that chemical signals of old age need not in any normal sense be deleterious in themselves. For instance, suppose that it incidentally happens to be a fact that a substance S is more concentrated in the bodies of old individuals than of young individuals. S in itself might be quite harmless, perhaps some substance in the food which accumulates in the body over time. But automatically, any gene that just happened to exert a deleterious effect in the presence of S, but which otherwise had a good effect, would be positively selected in the gene pool, and would in effect be a gene 'for' dying of old age. The cure would simply be to remove S from the body. What is revolutionary about this idea is that S itself is only a 'label' for old age. Any doctor who noticed that high concentrations of S tended to lead to death, would probably think of S as a kind of poison, and would rack his brains to find a direct causal link between S and bodily malfunctioning. But in the case of our hypothetical example, he might be wasting his time! There might also be a substance Y a 'label' for youth in the sense that it was more concentrated in young bodies than in old ones. Once again, genes might be selected that would have good effects in the presence of Y but which would be deleterious in its absence. Without having any way of knowing what S or Y are-there could be many such substances-we can simply make the general prediction that the more you can simulate or mimic the properties of a young body in an old one, however superficial these properties may seem, the longer should that old body live. I must emphasize that these are just speculations based on the Medawar theory. Although there is a sense in which the Medawar theory logically must have some truth in it, this does not mean necessarily that it is the right explanation for any given practical example of senile decay. What matters for present purposes is that the gene-selection view of evolution has no difficulty in accounting for the tendency of individuals to die when they get old. The assumption of individual mortality, which lay at the heart of our argument in this chapter, is justifiable within the framework of the theory. The other assumption I have glossed over, that of the existence of sexual reproduction and crossing-over, is more difficult to justify. Crossing-over does not always have to happen. Male fruit-flies do not do it. There is a gene that has the effect of suppressing crossing-over in females as well. If we were to breed a population of flies in which this gene was universal, the chromosome in a 'chromosome pool' would become the basic indivisible unit of natural selection. In fact, if we followed our definition to its logical conclusion, a whole chromosome would have to be regarded as one 'gene'. Then again, alternatives to sex do exist. Female greenflies can bear live, fatherless, female offspring, each one containing all the genes of its mother. (Incidentally, an embryo in her mother's 'womb' may have an even smaller embryo inside her own womb. So a greenfly female may give birth to a daughter and a grand-daughter simultaneously, both of them being equivalent to her own identical twins.) Many plants propagate vegetatively by sending out suckers. In this case we might prefer to speak of growth rather than of reproduction; but then, if you think about it, there is rather little distinction between growth and non-sexual reproduction anyway, since both occur by simple mitotic cell division. Sometimes the plants produced by vegetative reproduction become detached from the 'parent'. In other cases, for instance elm trees, the connecting suckers remain intact. In fact an entire elm wood might be regarded as a single individual. So, the question is: if greenflies and elm trees don't do it, why do the rest of us go to such lengths to mix our genes up with somebody else's before we make a baby? It does seem an odd way to proceed. Why did sex, that bizarre perversion of straightforward replication, ever arise in the first place? What is the good of sex? This is an extremely difficult question for the evolutionist to answer. Most serious attempts to answer it involve sophisticated mathematical reasoning. I am frankly going to evade it except to say one thing. This is that at least some of the difficulty that theorists have with explaining the evolution of sex results from the fact that they habitually think of the individual as trying to maximize the number of his genes that survive. In these terms, sex appears paradoxical because it is an 'inefficient' way for an individual to propagate her genes: each child has only 50 per cent of the individual's genes, the other 50 per cent being provided by the sexual partner. If only, like a greenfly, she would bud-off children who were exact replicas of herself, she would pass 100 per cent of her genes on to the next generation in the body of every child. This apparent paradox has driven some theorists to embrace group-selectionism, since it is relatively easy to think of group-level advantages for sex. As W. F. Bodmer has succinctly put it, sex 'facilitates the accumulation in a single individual of advantageous mutations which arose separately in different individuals.' But the paradox seems less paradoxical if we follow the argument of this book, and treat the individual as a survival machine built by a short-lived confederation of long-lived genes. 'Efficiency' from the whole individual's point of view is then seen to be irrelevant. Sexuality versus non-sexuality will be regarded as an attribute under single-gene control, just like blue eyes versus brown eyes. A gene 'for' sexuality manipulates all the other genes for its own selfish ends. So does a gene for crossing-over. There are even genes-called mutators-that manipulate the rates of copying-errors in other genes. By definition, a copying error is to the disadvantage of the gene which is miscopied. But if it is to the advantage of the selfish mutator gene that induces it, the mutator can spread through the gene pool. Similarly, if crossing-over benefits a gene for crossing-over, that is a sufficient explanation for the existence of crossing-over. And if sexual, as opposed to non-sexual, reproduction benefits a gene for sexual reproduction, that is a sufficient explanation for the existence of sexual reproduction. Whether or not it benefits all the rest of an individual's genes is comparatively irrelevant. Seen from the selfish gene's point of view, sex is not so bizarre after all. This comes perilously close to being a circular argument, since the existence of sexuality is a precondition for the whole chain of reasoning that leads to the gene being regarded as the unit of selection. I believe there are ways of escaping from the circularity, but this book is not the place to pursue the question. Sex exists. That much is true. It is a consequence of sex and crossing-over that the small genetic unit or gene can be regarded as the nearest thing we have to a fundamental, independent agent of evolution. Sex is not the only apparent paradox that becomes less puzzling the moment we learn to think in selfish gene terms. For instance, it appears that the amount of DNA in organisms is more than is strictly necessary for building them: a large fraction of the DNA is never translated into protein. From the point of view of the individual organism this seems paradoxical. If the 'purpose' of DNA is to supervise the building of bodies, it is surprising to find a large quantity of DNA which does no such thing. Biologists are racking their brains trying to think what useful task this apparently surplus DNA is doing. But from the point of view of the selfish genes themselves, there is no paradox. The true 'purpose' of DNA is to survive, no more and no less. The simplest way to explain the surplus DNA is to suppose that it is a parasite, or at best a harmless but useless passenger, hitching a ride in the survival machines created by the other DNA. Some people object to what they see as an excessively gene-centred view of evolution. After all, they argue, it is whole individuals with all their genes who actually live or die. I hope I have said enough in this chapter to show that there is really no disagreement here. Just as whole boats win or lose races, it is indeed individuals who live or die, and the immediate manifestation of natural selection is nearly always at the individual level. But the long-term consequences of non-random individual death and reproductive success are manifested in the form of changing gene frequencies in the gene pool. With reservations, the gene pool plays the same role for the modern replicators as the primeval soup did for the original ones. Sex and chromosomal crossing-over have the effect of preserving the liquidity of the modern equivalent of the soup. Because of sex and crossing-over the gene pool is kept well stirred, and the genes partially shuffled. Evolution is the process by which some genes become more numerous and others less numerous in the gene pool. It is good to get into the habit, whenever we are trying to explain the evolution of some characteristic, such as altruistic behaviour, of asking ourselves simply: 'what effect will this characteristic have on frequencies of genes in the gene pool?' At times, gene language gets a bit tedious, and for brevity and vividness we shall lapse into metaphor. But we shall always keep a sceptical eye on our metaphors, to make sure they can be translated back into gene language if necessary. As far as the gene is concerned, the gene pool is just the new sort of soup where it makes its living. All that has changed is that nowadays it makes its living by cooperating with successive groups of companions drawn from the gene pool in building one mortal survival machine after another. It is to survival machines themselves, and the sense in which genes may be said to control their behaviour, that we turn in the next chapter.",
        "char_count": 64058
      },
      {
        "heading": "Chapter 5",
        "text": "The Selfish Gene 4. The Gene Machine. Survival machines began as passive receptacles for the genes, providing little more than walls to protect them from the chemical warfare of their rivals and the ravages of accidental molecular bombardment. In the early days they 'fed' on organic molecules freely available in the soup. This easy life came to an end when the organic food in the soup, which had been slowly built up under the energetic influence of centuries of sunlight, was all used up. A major branch of survival machines, now called plants, started to use sunlight directly themselves to build up complex molecules from simple ones, re-enacting at much higher speed the synthetic processes of the original soup. Another branch, now known as animals, 'discovered' how to exploit the chemical labours of the plants, either by eating them, or by eating other animals. Both main branches of survival machines evolved more and more ingenious tricks to increase their efficiency in their various ways of life, and new ways of life were continually being opened up. Sub-branches and sub-sub-branches evolved, each one excelling in a particular specialized way of making a living: in the sea, on the ground, in the air, underground, up trees, inside other living bodies. This sub-branching has given rise to the immense diversity of animals and plants which so impresses us today. Both animals and plants evolved into many-celled bodies, complete copies of all the genes being distributed to every cell. We do not know when, why, or how many times independently, this happened. Some people use the metaphor of a colony, describing a body as a colony of cells. I prefer to think of the body as a colony of genes, and of the cell as a convenient working unit for the chemical industries of the genes. Colonies of genes they maybe but, in their behaviour, bodies have undeniably acquired an individuality of their own. An animal moves as a coordinated whole, as a unit. Subjectively I feel like a unit, not a colony . This is to be expected. Selection has favoured genes that cooperate with others. In the fierce competition for scarce resources, in the relentless struggle to eat other survival machines, and to avoid being eaten, there must have been a premium on central coordination rather than anarchy within the communal body. Nowadays the intricate mutual co-evolution of genes has proceeded to such an extent that the communal nature of an individual survival machine is virtually unrecognizable. Indeed many biologists do not recognize it, and will disagree with me. Fortunately for what journalists would call the 'credibility' of the rest of this book, the disagreement is largely academic. Just as it is not convenient to talk about quanta and fundamental particles when we discuss the workings of a car, so it is often tedious and unnecessary to keep dragging genes in when we discuss the behaviour of survival machines. In practice it is usually convenient, as an approximation, to regard the individual body as an agent 'trying' to increase the numbers of all its genes in future generations. I shall use the language of convenience. Unless otherwise stated, 'altruistic behaviour' and 'selfish behaviour' will mean behaviour directed by one animal body toward another. This chapter is about behaviour-the trick of rapid movement which has been largely exploited by the animal branch of survival machines. Animals became active go-getting gene vehicles: gene machines. The characteristic of behaviour, as biologists use the term, is that it is fast. Plants move, but very slowly. When seen in highly speeded-up film, climbing plants look like active animals. But most plant movement is really irreversible growth. Animals, on the other hand, have evolved ways of moving hundreds of thousands of times faster. Moreover, the movements they make are reversible, and repeatable an indefinite number of times. The gadget that animals evolved to achieve rapid movement was the muscle. Muscles are engines which, like the steam engine and the internal combustion engine, use energy stored in chemical fuel to generate mechanical movement. The difference is that the immediate mechanical force of a muscle is generated in the form of tension, rather than gas pressure as in the case of the steam and internal combustion engines. But muscles are like engines in that they often exert their force on cords, and levers with hinges. In us the levers are known as bones, the cords as tendons, and the hinges as joints. Quite a lot is known about the exact molecular ways in which muscles work, but I find more interesting the question of how muscle contractions are timed. Have you ever watched an artificial machine of some complexity, a knitting or sewing machine, a loom, an automatic bottling factory, or a hay baler? Motive power comes from somewhere, an electric motor say, or a tractor. But much more baffling is the intricate timing of the operations. Valves open and shut in the right order, steel fingers deftly tie a knot round a hay bale, and then at just the right moment a knife shoots out and cuts the string. In many artificial machines timing is achieved by that brilliant invention the cam. This translates simple rotary motion into a complex rhythmic pattern of operations by means of an eccentric or specially shaped wheel. The principle of the musical box is similar. Other machines such as the steam organ and the pianola use paper rolls or cards with holes punched in a pattern. Recently there has been a trend towards replacing such simple mechanical timers with electronic ones. Digital computers are examples of large and versatile electronic devices which can be used for generating complex timed patterns of movements. The basic component of a modern electronic machine like a computer is the semiconductor, of which a familiar form is the transistor. Survival machines seem to have bypassed the cam and the punched card altogether. The apparatus they use for timing their movements has more in common with an electronic computer, although it is strictly different in fundamental operation. The basic unit of biological computers, the nerve cell or neurone, is really nothing like a transistor in its internal workings. Certainly the code in which neurones communicate with each other seems to be a little bit like the pulse codes of digital computers, but the individual neurone is a much more sophisticated data-processing unit than the transistor. Instead of just three connections with other components, a single neurone may have tens of thousands. The neurone is slower than the transistor, but it has gone much further in the direction of miniaturization, a trend which has dominated the electronics industry over the past two decades. This is brought home by the fact that there are some ten thousand million neurones in the human brain: you could pack only a few hundred transistors into a skull. Plants have no need of the neurone, because they get their living without moving around, but it is found in the great majority of animal groups. It may have been 'discovered' early in animal evolution, and inherited by all groups, or it may have been rediscovered several times independently. Neurones are basically just cells, with a nucleus and chromosomes like other cells. But their cell walls are drawn out in long, thin, wire-like projections. Often a neurone has one particularly long 'wire' called the axon. Although the width of an axon is microscopic, its length may be many feet: there are single axons which run the whole length of a giraffe's neck. The axons are usually bundled together in thick multi-stranded cables called nerves. These lead from one part of the body to another carrying messages, rather like trunk telephone cables. Other neurones have short axons, and are confined to dense concentrations of nervous tissue called ganglia, or, when they are very large, brains. Brains may be regarded as analogous in function to computers. They are analogous in that both types of machine generate complex patterns of output, after analysis of complex patterns of input, and after reference to stored information. The main way in which brains actually contribute to the success of survival machines is by controlling and coordinating the contractions of muscles. To do this they need cables leading to the muscles, and these are called motor nerves. But this leads to efficient preservation of genes only if the timing of muscle contractions bears some relation to the timing of events in the outside world. It is important to contract the jaw muscles only when the jaws contain something worth biting, and to contract the leg muscles in running patterns only when there is something worth running towards or away from. For this reason, natural selection favoured animals that became equipped with sense organs, devices which translate patterns of physical events in the outside world into the pulse code of the neurones. The brain is connected to the sense organs-eyes, ears, taste-buds, etc.-by means of cables called sensory nerves. The workings of the sensory systems are particularly baffling, because they can achieve far more sophisticated feats of pattern-recognition than the best and most expensive man-made machines; if this were not so, all typists would be redundant, superseded by speech-recognizing machines, or machines for reading handwriting. Human typists will be needed for many decades yet. There may have been a time when sense organs communicated more or less directly with muscles; indeed, sea anemones are not far from this state today, since for their way of life it is efficient. But to achieve more complex and indirect relationships between the timing of events in the outside world and the timing of muscular contractions, some kind of brain was needed as an intermediary. A notable advance was the evolutionary 'invention' of memory. By this device, the timing of muscle contractions could be influenced not only by events in the immediate past, but by events in the distant past as well. The memory, or store, is an essential part of a digital computer too. Computer memories are more reliable than human ones, but they are less capacious, and enormously less sophisticated in their techniques of information-retrieval. One of the most striking properties of survival-machine behaviour is its apparent purposiveness. By this I do not just mean that it seems to be well calculated to help the animal's genes to survive, although of course it is. I am talking about a closer analogy to human purposeful behaviour. When we watch an animal 'searching' for food, or for a mate, or for a lost child, we can hardly help imputing to it some of the subjective feelings we ourselves experience when we search. These may include 'desire' for some object, a 'mental picture' of the desired object, an 'aim' or 'end in view'. Each one of us knows, from the evidence of our own introspection, that, at least in one modern survival machine, this purposiveness has evolved the property we call 'consciousness'. I am not philosopher enough to discuss what this means, but fortunately it does not matter for our present purposes because it is easy to talk about machines that behave as if motivated by a purpose, and to leave open the question whether they actually are conscious. These machines are basically very simple, and the principles of unconscious purposive behaviour are among the commonplaces of engineering science. The classic example is the Watt steam governor. The fundamental principle involved is called negative feedback, of which there are various different forms. In general what happens is this. The 'purpose machine', the machine or thing that behaves as if it had a conscious purpose, is equipped with some kind of measuring device which measures the discrepancy between the current state of things, and the 'desired' state. It is built in such a way that the larger this discrepancy is, the harder the machine works. In this way the machine will automatically tend to reduce the discrepancy-this is why it is called negative feedback-and it may actually come to rest if the 'desired' state is reached. The Watt governor consists of a pair of balls which are whirled round by a steam engine. Each ball is on the end of a hinged arm. The faster the balls fly round, the more does centrifugal force push the arms towards a horizontal position, this tendency being resisted by gravity. The arms are connected to the steam valve feeding the engine, in such a way that the steam tends to be shut off when the arms approach the horizontal position. So, if the engine goes too fast, some of its steam will be shut off, and it will tend to slow down. If it slows down too much, more steam will automatically be fed to it by the valve, and it will speed up again. Such purpose machines often oscillate due to over-shooting and time-lags, and it is part of the engineer's art to build in supplementary devices to reduce the oscillations. The 'desired' state of the Watt governor is a particular speed of rotation. Obviously it does not consciously desire it. The 'goal' of a machine is simply defined as that state to which it tends to return. Modern purpose machines use extensions of basic principles like negative feedback to achieve much more complex 'lifelike' behaviour. Guided missiles, for example, appear to search actively for their target, and when they have it in range they seem to pursue it, taking account of its evasive twists and turns, and sometimes even 'predicting' or 'anticipating' them. The details of how this is done are not worth going into. They involve negative feedback of various kinds, 'feed-forward', and other principles well understood by engineers and now known to be extensively involved in the working of living bodies. Nothing remotely approaching consciousness needs to be postulated, even though a layman, watching its apparently deliberate and purposeful behaviour, finds it hard to believe that the missile is not under the direct control of a human pilot. It is a common misconception that because a machine such as a guided missile was originally designed and built by conscious man, then it must be truly under the immediate control of conscious man. Another variant of this fallacy is 'computers do not really play chess, because they can only do what a human operator tells them'. It is important that we understand why this is fallacious, because it affects our understanding of the sense in which genes can be said to 'control' behaviour. Computer chess is quite a good example for making the point, so I will discuss it briefly. Computers do not yet play chess as well as human grand masters, but they have reached the standard of a good amateur. More strictly, one should say programs have reached the standard of a good amateur, for a chess-playing program is not fussy which physical computer it uses to act out its skills. Now, what is the role of the human programmer? First, he is definitely not manipulating the computer from moment to moment, like a puppeteer pulling strings. That would be just cheating. He writes the program, puts it in the computer, and then the computer is on its own: there is no further human intervention, except for the opponent typing in his moves. Does the programmer perhaps anticipate all possible chess positions, and provide the computer with a long list of good moves, one for each possible contingency? Most certainly not, because the number of possible positions in chess is so great that the world would come to an end before the list had been completed. For the same reason, the computer cannot possibly be programmed to try out 'in its head' all possible moves, and all possible follow-ups, until it finds a winning strategy. There are more possible games of chess than there are atoms in the galaxy. So much for the trivial non-solutions to the problem of programming a computer to play chess. It is in fact an exceedingly difficult problem, and it is hardly surprising that the best programs have still not achieved grand master status. The programmer's actual role is rather more like that of a father teaching his son to play chess. He tells the computer the basic moves of the game, not separately for every possible starting position, but in terms of more economically expressed rules. He does not literally say-in plain English 'bishops move in a diagonal', but he does say-something mathematically equivalent, such as, though more briefly: 'New coordinates of bishop are obtained from old coordinates, by adding the same constant, though not necessarily with the same sign, to both old x coordinate and old y coordinate.' Then he might program in some 'advice', written in the same sort of mathematical or logical language, but amounting in human terms to hints such as 'don't leave your king unguarded', or useful tricks such as 'forking' with the knight. The details are intriguing, but they would take us too far afield. The important point is this. When it is actually playing, the computer is on its own, and can expect no help from its master. All the programmer can do is to set the computer up beforehand in the best way possible, with a proper balance between lists of specific knowledge, and hints about strategies and techniques. The genes too control the behaviour of their survival machines, not directly with their fingers on puppet strings, but indirectly like the computer programmer. All they can do is to set it up beforehand; then the survival machine is on its own, and the genes can only sit passively inside. Why are they so passive? Why don't they grab the reins and take charge from moment to moment? The answer is that they cannot because of time-lag problems. This is best shown by another analogy, taken from science fiction. A for Andromeda by Fred Hoyle and John Elliot is an exciting story, and, like all good science fiction, it has some interesting scientific points lying behind it. Strangely, the book seems to lack explicit mention of the most important of these underlying points. It is left to the reader's imagination. I hope the authors will not mind if I spell it out here. There is a civilization 200 light-years away, in the constellation of Andromeda. They want to spread their culture to distant worlds. How best to do it? Direct travel is out of the question. The speed of light imposes a theoretical upper limit to the rate at which you can get from one place to another in the universe, and mechanical considerations impose a much lower limit in practice. Besides, there may not be all that many worlds worth going to, and how do you know which direction to go in? Radio is a better way of communicating with the rest of the universe, since, if you have enough power to broadcast your signals in all directions rather than beam them in one direction, you can reach a very large number of worlds (the number increasing as the square of the distance the signal travels). Radio waves travel at the speed of light, which means the signal takes 200 years to reach earth from Andromeda. The trouble with this sort of distance is that you can never hold a conversation. Even if you discount the fact that each successive message from earth would be transmitted by people separated from each other by twelve generations, it would be just plain wasteful to attempt to converse over such distances. This problem will soon arise in earnest for us: it takes about four minutes for radio waves to travel between earth and Mars. There can be no doubt that spacemen will have to get out of the habit of conversing in short alternating sentences, and will have to use long soliloquies or monologues, more like letters than conversations. As another example, Roger Payne has pointed out that the acoustics of the sea have certain peculiar properties, which mean that the exceedingly loud 'song' of some whales could theoretically be heard all the way round the world, provided the whales swim at a certain depth. It is not known whether they actually do communicate with each other over very great distances, but if they do they must be in much the same predicament as an astronaut on Mars. The speed of sound in water is such that it would take nearly two hours for the song to travel across the Atlantic Ocean and for a reply to return. I suggest this as an explanation for the fact that some whales deliver a continuous soliloquy, without repeating themselves, for a full eight minutes. They then go back to the beginning of the song and repeat it all over again, many times over, each complete cycle lasting about eight minutes. The Andromedans of the story did the same thing. Since there was no point in waiting for a reply, they assembled everything they wanted to say into one huge unbroken message, and then they broadcast it out into space, over and over again, with a cycle time of several months. Their message was very different from that of the whales, however. It consisted of coded instructions for the building and programming of a giant computer. Of course the instructions were in no human language, but almost any code can be broken by a skilled cryptographer, especially if the designers of the code intended it to be easily broken. Picked up by the Jodrell Bank radio telescope, the message was eventually decoded, the computer built, and the program run. The results were nearly disastrous for mankind, for the intentions of the Andromedans were not universally altruistic, and the computer was well on the way to dictatorship over the world before the hero eventually finished it off with an axe. From our point of view, the interesting question is in what sense the Andromedans could be said to be manipulating events on Earth. They had no direct control over what the computer did from moment to moment; indeed they had no possible way of even knowing the computer had been built, since the information would have taken 200 years to get back to them. The decisions and actions of the computer were entirely its own. It could not even refer back to its masters for general policy instructions. All its instructions had to be built-in in advance, because of the inviolable 200 year barrier. In principle, it must have been programmed very much like a chess-playing computer, but with greater flexibility and capacity for absorbing local information. This was because the program had to be designed to work not just on earth, but on any world possessing an advanced technology, any of a set of worlds whose detailed conditions the Andromedans had no way of knowing. Just as the Andromedans had to have a computer on earth to take day-to-day decisions for them, our genes have to build a brain. But the genes are not only the Andromedans who sent the coded instructions; they are also the instructions themselves. The reason why they cannot manipulate our puppet strings directly is the same: time-lags. Genes work by controlling protein synthesis. This is a powerful way of manipulating the world, but it is slow. It takes months of patiently pulling protein strings to build an embryo. The whole point about behaviour, on the other hand, is that it is fast. It works on a time-scale not of months but of seconds and fractions of seconds. Something happens in the world, an owl flashes overhead, a rustle in the long grass betrays prey, and in milliseconds nervous systems crackle into action, muscles leap, and someone's life is saved-or lost. Genes don't have reaction-times like that. Like the Andromedans, the genes can only do their best in advance by building a fast executive computer for themselves, and programming it in advance with rules and 'advice' to cope with as many eventualities as they can 'anticipate'. But life, like the game of chess, offers too many different possible eventualities for all of them to be anticipated. Like the chess programmer, the genes have to 'instruct' their survival machines not in specifics, but in the general strategies and tricks of the living trade. As J. Z. Young has pointed out, the genes have to perform a task analogous to prediction. When an embryo survival machine is being built, the dangers and problems of its life lie in the future. Who can say what carnivores crouch waiting for it behind what bushes, or what fleet-footed prey will dart and zig-zag across its path? No human prophet, nor any gene. But some general predictions can be made. Polar bear genes can safely predict that the future of their unborn survival machine is going to be a cold one. They do not think of it as a prophecy, they do not think at all: they just build in a thick coat of hair, because that is what they have always done before in previous bodies, and that is why they still exist in the gene pool. They also predict that the ground is going to be snowy, and their prediction takes the form of making the coat of hair white and therefore camouflaged. If the climate of the Arctic changed so rapidly that the baby bear found itself born into a tropical desert, the predictions of the genes would be wrong, and they would pay the penalty. The young bear would die, and they inside it. Prediction in a complex world is a chancy business. Every decision that a survival machine takes is a gamble, and it is the business of genes to program brains in advance so that on average they take decisions that pay off. The currency used in the casino of evolution is survival, strictly gene survival, but for many purposes individual survival is a reasonable approximation. If you go down to the water-hole to drink, you increase your risk of being eaten by predators who make their living lurking for prey by water-holes. If you do not go down to the water-hole you will eventually die of thirst. There are risks whichever way you turn, and you must take the decision that maximizes the long-term survival chances of your genes. Perhaps the best policy is to postpone drinking until you are very thirsty, then go and have one good long drink to last you a long time. That way you reduce the number of separate visits to the water-hole, but you have to spend a long time with your head down when you finally do drink. Alternatively the best gamble might be to drink little and often, snatching quick gulps of water while running past the water-hole. Which is the best gambling strategy depends on all sorts of complex things, not least the hunting habit of the predators, which itself is evolved to be maximally efficient from their point of view. Some form of weighing up of the odds has to be done. But of course we do not have to think of the animals as making the calculations consciously. All we have to believe is that those individuals whose genes build brains in such a way that they tend to gamble correctly are as a direct result more likely to survive, and therefore to propagate those same genes. We can carry the metaphor of gambling a little further. A gambler must think of three main quantities, stake, odds, and prize. If the prize is very large, a gambler is prepared to risk a big stake. A gambler who risks his all on a single throw stands to gain a great deal. He also stands to lose a great deal, but on average high-stake gamblers are no better and no worse off than other players who play for low winnings with low stakes. An analogous comparison is that between speculative and safe investors on the stock market. In some ways the stock market is a better analogy than a casino, because casinos are deliberately rigged in the bank's favour (which means, strictly, that high-stake players will on average end up poorer than low-stake players; and low-stake players poorer than those who do not gamble at all. But this is for a reason not germane to our discussion). Ignoring this, both high-stake play and low-stake play seem reasonable. Are there animal gamblers who play for high stakes, and others with a more conservative game? In Chapter 9 we shall see that it is often possible to picture males as high-stake high-risk gamblers, and females as safe investors, especially in polygamous species in which males compete for females. Naturalists who read this book maybe able to think of species that can be described as high-stake high-risk players, and other species that play a more conservative game. I now return to the more general theme of how genes make 'predictions' about the future. One way for genes to solve the problem of making predictions in rather unpredictable environments is to build in a capacity for learning. Here the program may take the form of the following instructions to the survival machine: 'Here is a list of things defined as rewarding: sweet taste in the mouth, orgasm, mild temperature, smiling child. And here is a list of nasty things: various sorts of pain, nausea, empty stomach, screaming child. If you should happen to do something that is followed by one of the nasty things, don't do it again, but on the other hand repeat anything that is followed by one of the nice things.' The advantage of this sort of programming is that it greatly cuts down the number of detailed rules that have to be built into the original program; and it is also capable of coping with changes in the environment that could not have been predicted in detail. On the other hand, certain predictions have to be made still. In our example the genes are predicting that sweet taste in the mouth, and orgasm, are going to be 'good' in the sense that eating sugar and copulating are likely to be beneficial to gene survival. The possibilities of saccharine and masturbation are not anticipated according to this example; nor are the dangers of over-eating sugar in our environment where it exists in unnatural plenty. Learning-strategies have been used in some chess-playing computer programs. These programs actually get better as they play against human opponents or against other computers. Although they are equipped with a repertoire of rules and tactics, they also have a small random tendency built into their decision procedure. They record past decisions, and whenever they win a game they slightly increase the weighting given to the tactics that preceded the victory, so that next time they are a little bit more likely to choose those same tactics again. One of the most interesting methods of predicting the future is simulation. If a general wishes to know whether a particular military plan will be better than alternatives, he has a problem in prediction. There are unknown quantities in the weather, in the morale of his own troops, and in the possible countermeasures of the enemy. One way of discovering whether it is a good plan is to try and see, but it is undesirable to use this test for all the tentative plans dreamed up, if only because the supply of young men prepared to die 'for their country' is exhaustible, and the supply of possible plans is very large. It is better to try the various plans out in dummy runs rather than in deadly earnest. This may take the form of full-scale exercises with 'Northland' fighting 'Southland' using blank ammunition, but even this is expensive in time and materials. Less wastefully, war games may be played, with tin soldiers and little toy tanks being shuffled around a large map. Recently, computers have taken over large parts of the simulation function, not only in military strategy, but in all fields where prediction of the future is necessary, fields like economics, ecology, sociology, and many others. The technique works like this. A model of some aspect of the world is set up in the computer. This does not mean that if you unscrewed the lid you would see a little miniature dummy inside with the same shape as the object simulated. In the chess-playing computer there is no 'mental picture' inside the memory banks recognizable as a chess board with knights and pawns sitting on it. The chess board and its current position would be represented by lists of electronically coded numbers. To us a map is a miniature scale model of a part of the world, compressed into two dimensions. In a computer, a map might alternatively be represented as a list of towns and other spots, each with two numbers-its latitude and longitude. But it does not matter how the computer actually holds its model of the world in its head, provided that it holds it in a form in which it can operate on it, manipulate it, do experiments with it, and report back to the human operators in terms which they can understand. Through the technique of simulation, model battles can be won or lost, simulated airliners fly or crash, economic policies lead to prosperity or to ruin. In each case the whole process goes on inside the computer in a tiny fraction of the time it would take in real life. Of course there are good models of the world and bad ones, and even the good ones are only approximations. No amount of simulation can predict exactly what will happen in reality, but a good simulation is enormously preferable to blind trial and error. Simulation could be called vicarious trial and error, a term unfortunately pre-empted long ago by rat psychologists. If simulation is such a good idea, we might expect that survival machines would have discovered it first. After all, they invented many of the other techniques of human engineering long before we came on the scene: the focusing lens and the parabolic reflector, frequency analysis of sound waves, servo-control, sonar, buffer storage of incoming information, and countless others with long names, whose details don't matter. What about simulation? Well, when you yourself have a difficult decision to make involving unknown quantities in the future, you do go in for a form of simulation. You imagine what would happen if you did each of the alternatives open to you. You set up a model in your head, not of everything in the world, but of the restricted set of entities which you think may be relevant. You may see them vividly in your mind's eye, or you may see and manipulate stylized abstractions of them. In either case it is unlikely that somewhere laid out in your brain is an actual spatial model of the events you are imagining. But, just as in the computer, the details of how your brain represents its model of the world are less important than the fact that it is able to use it to predict possible events. Survival machines that can simulate the future are one jump ahead of survival machines who can only learn on the basis of overt trial and error. The trouble with overt trial is that it takes time and energy. The trouble with overt error is that it is often fatal. Simulation is both safer and faster. The evolution of the capacity to simulate seems to have culminated in subjective consciousness. Why this should have happened is, to me, the most profound mystery facing modern biology. There is no reason to suppose that electronic computers are conscious when they simulate, although we have to admit that in the future they may become so. Perhaps consciousness arises when the brain's simulation of the world becomes so complete that it must include a model of itself. Obviously the limbs and body of a survival machine must constitute an important part of its simulated world; presumably for the same kind of reason, the simulation itself could be regarded as part of the world to be simulated. Another word for this might indeed be 'self-awareness', but I don't find this a fully satisfying explanation of the evolution of consciousness, and this is only partly because it involves an infinite regress-if there is a model of the model, why not a model of the model of the model...? Whatever the philosophical problems raised by consciousness, for the purpose of this story it can be thought of as the culmination of an evolutionary trend towards the emancipation of survival machines as executive decision-takers from their ultimate masters, the genes. Not only are brains in charge of the day-to-day running of survival-machine affairs, they have also acquired the ability to predict the future and act accordingly. They even have the power to rebel against the dictates of the genes, for instance in refusing to have as many children as they are able to. But in this respect man is a very special case, as we shall see. What has all this to do with altruism and selfishness? I am trying to build up the idea that animal behaviour, altruistic or selfish, is under the control of genes in only an indirect, but still very powerful, sense. By dictating the way survival machines and their nervous systems are built, genes exert ultimate power over behaviour. But the moment-to-moment decisions about what to do next are taken by the nervous system. Genes are the primary policy-makers; brains are the executives. But as brains became more highly developed, they took over more and more of the actual policy decisions, using tricks like learning and simulation in doing so. The logical conclusion to this trend, not yet reached in any species, would be for the genes to give the survival machine a single overall policy instruction: do whatever you think best to keep us alive. Analogies with computers and with human decision-taking are all very well. But now we must come down to earth and remember that evolution in fact occurs step-by-step, through the differential survival of genes in the gene pool. Therefore, in order for a behaviour pattern-altruistic or selfish-to evolve, it is necessary that a gene 'for' that behaviour should survive in the gene pool more successfully than a rival gene or allele for some different behaviour. A gene for altruistic behaviour means any gene that influences the development of nervous systems in such a way as to make them likely to behave altruistically. Is there any experimental evidence for the genetic inheritance of altruistic behaviour? No, but that is hardly surprising, since little work has been done on the genetics of any behaviour. Instead, let me tell you about one study of a behaviour pattern which does not happen to be obviously altruistic, but which is complex enough to be interesting. It serves as a model for how altruistic behaviour might be inherited. Honey bees suffer from an infectious disease called foul brood. This attacks the grubs in their cells. Of the domestic breeds used by beekeepers, some are more at risk from foul brood than others, and it turns out that the difference between strains is, at least in some cases, a behavioural one. There are so-called hygienic strains which quickly stamp out epidemics by locating infected grubs, pulling them from their cells and throwing them out of the hive. The susceptible strains are susceptible because they do not practise this hygienic infanticide. The behaviour actually involved in hygiene is quite complicated. The workers have to locate the cell of each diseased grub, remove the wax cap from the cell, pull out the larva, drag it through the door of the hive, and throw it on the rubbish tip. Doing genetic experiments with bees is quite a complicated business for various reasons. Worker bees themselves do not ordinarily reproduce, and so you have to cross a queen of one strain with a drone (= male) of the other, and then look at the behaviour of the daughter workers. This is what W. C. Rothenbuhler did. He found that all first-generation hybrid daughter hives were non-hygienic: the behaviour of their hygienic parent seemed to have been lost, although as things turned out the hygienic genes were still there but were recessive, like human genes for blue eyes. When Rothenbuhler 'back-crossed' first-generation hybrids with a pure hygienic strain (again of course using queens and drones), he obtained a most beautiful result. The daughter hives fell into three groups. One group showed perfect hygienic behaviour, a second showed no hygienic behaviour at all, and the third went half way. This last group uncapped the wax cells of diseased grubs, but they did not follow through and throw out the larvae. Rothenbuhler surmised that there might be two separate genes, one gene for uncapping, and one gene for throwing-out. Normal hygienic strains possess both genes, susceptible strains possess the alleles-rivals- of both genes instead. The hybrids who only went halfway presumably possessed the uncapping gene (in double dose) but not the throwing-out gene. Rothenbuhler guessed that his experimental group of apparently totally non-hygienic bees might conceal a subgroup possessing the throwing-out gene, but unable to show it because they lacked the uncapping gene. He confirmed this most elegantly by removing caps himself. Sure enough, half of the apparently non-hygienic bees thereupon showed perfectly normal throwing-out behaviour. This story illustrates a number of important points which came up in the previous chapter. It shows that it can be perfectly proper to speak of a 'gene for behaviour so-and-so' even if we haven't the faintest idea of the chemical chain of embryonic causes leading from gene to behaviour. The chain of causes could even turn out to involve learning. For example, it could be that the uncapping gene exerts its effect by giving bees a taste for infected wax. This means they will find the eating of the wax caps covering disease-victims rewarding, and will therefore tend to repeat it. Even if this is how the gene works, it is still truly a gene for uncapping provided that, other things being equal, bees possessing the gene end up by uncapping, and bees not possessing the gene do not uncap. Secondly it illustrates the fact that genes 'cooperate' in their effects on the behaviour of the communal survival machine. The throwing-out gene is useless unless it is accompanied by the uncapping gene and vice versa. Yet the genetic experiments show equally clearly that the two genes are in principle quite separable in their journey through the generations. As far as their useful work is concerned you can think of them as a single cooperating unit, but as replicating genes they are two free and independent agents. For purposes of argument it will be necessary to speculate about genes 'for' doing all sorts of improbable things. If I speak, for example, of a hypothetical gene 'for saving companions from drowning', and you find such a concept incredible, remember the story of the hygienic bees. Recall that we are not talking about the gene as the sole antecedent cause of all the complex muscular contractions, sensory integrations, and even conscious decisions, that are involved in saving somebody from drowning. We are saying nothing about the question of whether learning, experience, or environmental influences enter into the development of the behaviour. All you have to concede is that it is possible for a single gene, other things being equal and lots of other essential genes and environmental factors being present, to make a body more likely to save somebody from drowning than its allele would. The difference between the two genes may turn out at bottom to be a slight difference in some simple quantitative variable. The details of the embryonic developmental process, interesting as they may be, are irrelevant to evolutionary considerations. Konrad Lorenz has put this point well. The genes are master programmers, and they are programming for their lives. They are judged according to the success of their programs in coping with all the hazards that life throws at their survival machines, and the judge is the ruthless judge of the court of survival. We shall come later to ways in which gene survival can be fostered by what appears to be altruistic behaviour. But the obvious first priorities of a survival machine, and of the brain that takes the decisions for it, are individual survival and reproduction. All the genes in the 'colony' would agree about these priorities. Animals therefore go to elaborate lengths to find and catch food; to avoid being caught and eaten themselves; to avoid disease and accident; to protect themselves from unfavourable climatic conditions; to find members of the opposite sex and persuade them to mate; and to confer on their children advantages similar to those they enjoy themselves. I shall not give examples-if you want one just look carefully at the next wild animal that you see. But I do want to mention one particular kind of behaviour because we shall need to refer to it again when we come to speak of altruism and selfishness. This is the behaviour that can be broadly labelled communication. A survival machine may be said to have communicated with another one when it influences its behaviour or the state of its nervous system. This is not a definition I should like to have to defend for very long, but it is good enough for present purposes. By influence I mean direct causal influence. Examples of communication are numerous: song in birds, frogs, and crickets; tail-wagging and hackle-raising in dogs; 'grinning' in chimpanzees; human gestures and language. A great number of survival-machine actions promote their genes' welfare indirectly by influencing the behaviour of other survival machines. Animals go to great lengths to make this communication effective. The songs of birds enchant and mystify successive generations of men. I have already referred to the even more elaborate and mysterious song of the humpback whale, with its prodigious range, its frequencies spanning the whole of human hearing from subsonic rumblings to ultrasonic squeaks. Mole-crickets amplify their song to stentorian loudness by singing down in a burrow which they carefully dig in the shape of a double exponential horn, or megaphone. Bees dance in the dark to give other bees accurate information about the direction and distance of food, a feat of communication rivalled only by human language itself. The traditional story of ethologists is that communication signals evolve for the mutual benefit of both sender and recipient. For instance, baby chicks influence their mother's behaviour by giving high piercing cheeps when they are lost or cold. This usually has the immediate effect of summoning the mother, who leads the chick back to the main clutch. This behaviour could be said to have evolved for mutual benefit, in the sense that natural selection has favoured babies that cheep when they are lost, and also mothers that respond appropriately to the cheeping. If we wish to (it is not really necessary), we can regard signals such as the cheep call as having a meaning, or as carrying information: in this case 'I am lost.' The alarm call given by small birds, which I mentioned in Chapter i, could be said to convey the information 'There is a hawk.' Animals who receive this information and act on it are benefited. Therefore the information can be said to be true. But do animals ever communicate false information; do they ever tell lies? The notion of an animal telling a lie is open to misunderstanding, so I must try to forestall this. I remember attending a lecture given by Beatrice and Allen Gardner about their famous 'talking' chimpanzee Washoe (she uses American Sign Language, and her achievement is of great potential interest to students of language). There were some philosophers in the audience, and in the discussion after the lecture they were much exercised by the question of whether Washoe could tell a lie. I suspected that the Gardners thought there were more interesting things to talk about, and I agreed with them. In this book I am using words like 'deceive' and 'lie' in a much more straightforward sense than those philosophers. They were interested in conscious intention to deceive. I am talking simply about having an effect functionally equivalent to deception. If a bird used the 'There is a hawk' signal when there was no hawk, thereby frightening his colleagues away, leaving him to eat all their food, we might say he had told a lie. We would not mean he had deliberately intended consciously to deceive. All that is implied is that the liar gained food at the other birds' expense, and the reason the other birds flew away was that they reacted to the liar's cry in a way appropriate to the presence of a hawk. Many edible insects, like the butterflies of the previous chapter, derive protection by mimicking the external appearance of other distasteful or stinging insects. We ourselves are often fooled into thinking that yellow and black striped hover-flies are wasps. Some bee-mimicking flies are even more perfect in their deception. Predators too tell lies. Angler fish wait patiently on the bottom of the sea, blending in with the background. The only conspicuous part is a wriggling worm-like piece of flesh on the end of a long 'fishing rod', projecting from the top of the head. When a small prey fish comes near, the angler will dance its worm-like bait in front of the little fish, and lure it down to the region of the angler's own concealed mouth. Suddenly it opens its jaws, and the little fish is sucked in and eaten. The angler is telling a lie, exploiting the little fish's tendency to approach wriggling worm-like objects. He is saying 'Here is a worm', and any little fish who 'believes' the lie is quickly eaten. Some survival machines exploit the sexual desires of others. Bee orchids induce bees to copulate with their flowers, because of their strong resemblance to female bees. What the orchid has to gain from this deception is pollination, for a bee who is fooled by two orchids will incidentally carry pollen from one to the other. Fireflies (which are really beetles) attract their mates by flashing lights at them. Each species has its own particular dot-dash flashing pattern, which prevents confusion between species, and consequent harmful hybridization. Just as sailors look out for the flash patterns of particular lighthouses, so fireflies seek the coded flash patterns of their own species. Females of the genus Photuris have 'discovered' that they can lure males of the genus Photinus if they imitate the flashing code of a Photinus female. This they do, and when a Photinus male is fooled by the lie into approaching, he is summarily eaten by the Photuris female. Sirens and Lorelei spring to mind as analogies, but Cornishmen will prefer to think of the wreckers of the old days, who used lanterns to lure ships on to the rocks, and then plundered the cargoes that spilled out of the wrecks. Whenever a system of communication evolves, there is always the danger that some will exploit the system for their own ends. Brought up as we have been on the 'good of the species' view of evolution, we naturally think first of liars and deceivers as belonging to different species: predators, prey, parasites, and so on. However, we must expect lies and deceit, and selfish exploitation of communication to arise whenever the interests of the genes of different individuals diverge. This will include individuals of the same species. As we shall see, we must even expect that children will deceive their parents, that husbands will cheat on wives, and that brother will lie to brother. Even the belief that animal communication signals originally evolve to foster mutual benefit, and then afterwards become exploited by malevolent parties, is too simple. It may well be that all animal communication contains an element of deception right from the start, because all animal interactions involve at least some conflict of interest. The next chapter introduces a powerful way of thinking about conflicts of interest from an evolutionary point of view.",
        "char_count": 51531
      },
      {
        "heading": "Chapter 6",
        "text": "The Selfish Gene 5. Aggression: stability and the selfish machine. This chapter is mostly about the much-misunderstood topic of aggression. We shall continue to treat the individual as a selfish machine, programmed to do whatever is best for its genes as a whole. This is the language of convenience. At the end of the chapter we return to the language of single genes. To a survival machine, another survival machine (which is not its own child or another close relative) is part of its environment, like a rock or a river or a lump of food. It is something that gets in the way, or something that can be exploited. It differs from a rock or a river in one important respect: it is inclined to hit back. This is because it too is a machine that holds its immortal genes in trust for the future, and it too will stop at nothing to preserve them. Natural selection favours genes that control their survival machines in such a way that they make the best use of their environment. This includes making the best use of other survival machines, both of the same and of different species. In some cases survival machines seem to impinge rather little on each others' lives. For instance moles and blackbirds do not eat each other, mate with each other, or compete with each other for living space. Even so, we must not treat them as completely insulated. They may compete for something, perhaps earthworms. This does not mean you will ever see a mole and a blackbird engaged in a tug of war over a worm; indeed a blackbird may never set eyes on a mole in its life. But if you wiped out the population of moles, the effect on blackbirds might be dramatic, although I could not hazard a guess as to what the details might be, nor by what tortuously indirect routes the influence might travel. Survival machines of different species influence each other in a variety of ways. They may be predators or prey, parasites or hosts, competitors for some scarce resource. They may be exploited in special ways, as for instance when bees are used as pollen carriers by flowers. Survival machines of the same species tend to impinge on each others' lives more directly. This is for many reasons. One is that half the population of one's own species may be potential mates, and potentially hard-working and exploitable parents to one's children. Another reason is that members of the same species, being very similar to each other, being machines for preserving genes in the same kind of place, with the same kind of way of life, are particularly direct competitors for all the resources necessary for life. To a blackbird, a mole may be a competitor, but it is not nearly so important a competitor as another blackbird. Moles and blackbirds may compete for worms, but blackbirds and blackbirds compete with each other for worms and for everything else. If they are members of the same sex, they may also compete for mating partners. For reasons that we shall see, it is usually the males who compete with each other for females. This means that a male might benefit his own genes if he does something detrimental to another male with whom he is competing. The logical policy for a survival machine might therefore seem to be to murder its rivals, and then, preferably, to eat them. Although murder and cannibalism do occur in nature, they are not as common as a naive interpretation of the selfish gene theory might predict. Indeed Konrad Lorenz, in On Aggression, stresses the restrained and gentlemanly nature of animal fighting. For him the notable thing about animal fights is that they are formal tournaments, played according to rules like those of boxing or fencing. Animals fight with gloved fists and blunted foils. Threat and bluff take the place of deadly earnest. Gestures of surrender are recognized by victors, who then refrain from dealing the killing blow or bite that our naive theory might predict. This interpretation of animal aggression as being restrained and formal can be disputed. In particular, it is certainly wrong to condemn poor old Homo sapiens as the only species to kill his own kind, the only inheritor of the mark of Cain, and similar melodramatic charges. Whether a naturalist stresses the violence or the restraint of animal aggression depends partly on the kinds of animals he is used to watching, and partly on his evolutionary preconceptions-Lorenz is, after all, a 'good of the species' man. Even if it has been exaggerated, the gloved fist view of animal fights seems to have at least some truth. Superficially this looks like a form of altruism. The selfish gene theory must face up to the difficult task of explaining it. Why is it that animals do not go all out to kill rival members of their species at every possible opportunity? The general answer to this is that there are costs as well as benefits resulting from outright pugnacity, and not only the obvious costs in time and energy. For instance, suppose that B and C are both my rivals, and I happen to meet B. It might seem sensible for me as a selfish individual to try to kill him. But wait. C is also my rival, and C is also B's rival. By killing B, I am potentially doing a good turn to C by removing one of his rivals. I might have done better to let B live, because he might then have competed or fought with C, thereby benefiting me indirectly. The moral of this simple hypothetical example is that there is no obvious merit in indiscriminately trying to kill rivals. In a large and complex system of rivalries, removing one rival from the scene does not necessarily do any good: other rivals may be more likely to benefit from his death than oneself. This is the kind of hard lesson that has been learned by pest-control officers. You have a serious agricultural pest, you discover a good way to exterminate it and you gleefully do so, only to find that another pest benefits from the extermination even more than human agriculture does, and you end up worse off than you were before. On the other hand, it might seem a good plan to kill, or at least fight with, certain particular rivals in a discriminating way. If B is an elephant seal in possession of a large harem full of females, and if I, another elephant seal, can acquire his harem by killing him, I might be well advised to attempt to do so. But there are costs and risks even in selectivity pugnacity. It is to B's advantage to fight back, to defend his valuable property. If I start a fight, I am just as likely to end up dead as he is. Perhaps even more so. He holds a valuable resource, that is why I want to fight him. But why does he hold it? Perhaps he won it in combat. He has probably beaten off other challengers before me. He is probably a good fighter. Even if I win the fight and gain the harem, I may be so badly mauled in the process that I cannot enjoy the benefits. Also, fighting uses up time and energy. These might be better conserved for the time being. If I concentrate on feeding and on keeping out of trouble for a time, I shall grow bigger and stronger. I'll fight him for the harem in the end, but I may have a better chance of winning eventually if I wait, rather than rush in now. This subjective soliloquy is just a way of pointing out that the decision whether or not to fight should ideally be preceded by a complex, if unconscious, 'cost-benefit' calculation. The potential benefits are not all stacked up on the side of fighting, although undoubtedly some of them are. Similarly, during a fight, each tactical decision over whether to escalate the fight or cool it has costs and benefits which could, in principle, be analysed. This has long been realized by ethologists in a vague sort of way, but it has taken J. Maynard Smith, not normally regarded as an ethologist, to express the idea forcefully and clearly. In collaboration with G. R. Price and G. A. Parker, he uses the branch of mathematics known as Game Theory. Their elegant ideas can be expressed in words without mathematical symbols, albeit at some cost in rigour. The essential concept Maynard Smith introduces is that of the evolutionarily stable strategy, an idea that he traces back to W. D. Hamilton and R. H. MacArthur. A 'strategy' is a pre-programmed behavioural policy. An example of a strategy is: 'Attack opponent; if he flees pursue him; if he retaliates run away.' It is important to realize that we are not thinking of the strategy as being consciously worked out by the individual. Remember that we are picturing the animal as a robot survival machine with a pre-programmed computer controlling the muscles. To write the strategy out as a set of simple instructions in English is just a convenient way for us to think about it. By some unspecified mechanism, the animal behaves as if he were following these instructions. An evolutionarily stable strategy or ESS is defined as a strategy which, if most members of a population adopt it, cannot be bettered by an alternative strategy. It is a subtle and important idea. Another way of putting it is to say that the best strategy for an individual depends on what the majority of the population are doing. Since the rest of the population consists of individuals, each one trying to maximize his own success, the only strategy that persists will be one which, once evolved, cannot be bettered by any deviant individual. Following a major environmental change there may be a brief period of evolutionary instability, perhaps even oscillation in the population. But once an ESS is achieved it will stay: selection will penalize deviation from it. To apply this idea to aggression, consider one of Maynard Smith's simplest hypothetical cases. Suppose that there are only two sorts of fighting strategy in a population of a particular species, named hawk and dove. (The names refer to conventional human usage and have no connection with the habits of the birds from whom the names are derived: doves are in fact rather aggressive birds.) Any individual of our hypothetical population is classified as a hawk or a dove. Hawks always fight as hard and as unrestrainedly as they can, retreating only when seriously injured. Doves merely threaten in a dignified conventional way, never hurting anybody. If a hawk fights a dove the dove quickly runs away, and so does not get hurt. If a hawk fights a hawk they go on until one of them is seriously injured or dead. If a dove meets a dove nobody gets hurt; they go on posturing at each other for a long time until one of them tires or decides not to bother any more, and therefore backs down. For the time being, we assume that there is no way in which an individual can tell, in advance, whether a particular rival is a hawk or a dove. He only discovers this by fighting him, and he has no memory of past fights with particular individuals to guide him. Now as a purely arbitrary convention we allot contestants 'points'. Say 50 points for a win, 0 for losing, -100 for being seriously injured, and -10 for wasting time over a long contest. These points can be thought of as being directly convertible into the currency of gene survival. An individual who scores high points, who has a high average 'pay-off, is an individual who leaves many genes behind him in the gene pool. Within broad limits the actual numerical values do not matter for the analysis, but they help us to think about the problem. The important thing is that we are not interested in whether hawks will tend to beat doves when they fight them. We already know the answer to that: hawks will always win. We want to know whether either hawk or dove is an evolutionarily stable strategy. If one of them is an ESS and the other is not, we must expect that the one which is the ESS will evolve. It is theoretically possible for there to be two ESSs. This would be true if, whatever the majority strategy of the population happened to be, whether hawk or dove, the best strategy for any given individual was to follow suit. In this case the population would tend to stick at whichever one of its two stable states it happened to reach first. However, as we shall now see, neither of these two strategies, hawk or dove, would in fact be evolutionarily stable on its own, and we should therefore not expect either of them to evolve. To show this we must calculate average pay-offs. Suppose we have a population consisting entirely of doves. Whenever they fight, nobody gets hurt. The contests consist of prolonged ritual tournaments, staring matches perhaps, which end only when one rival backs down. The winner then scores 50 points for gaining the resource in dispute, but he pays a penalty of -10 for wasting time over a long staring match, so scores 40 in all. The loser also is penalized -10 points for wasting time. On average, any one individual dove can expect to win half his contests and lose half. Therefore his average pay-off per contest is the average of +40 and - 10, which is +15. Therefore, every individual dove in a population of doves seems to be doing quite nicely. But now suppose a mutant hawk arises in the population. Since he is the only hawk around, every fight he has is against a dove. Hawks always beat doves, so he scores +50 every fight, and this is his average pay-off. He enjoys an enormous advantage over the doves, whose net pay-off is only +15. Hawk genes will rapidly spread through the population as a result. But now each hawk can no longer count on every rival he meets being a dove. To take an extreme example, if the hawk gene spread so successfully that the entire population came to consist of hawks, all fights would now be hawk fights. Things are now very different. When hawk meets hawk, one of them is seriously injured, scoring -100, while the winner scores +50. Each hawk in a population of hawks can expect to win half his fights and lose half his fights. His average expected pay-off per fight is therefore half-way between +50 and -100, which is - 25. Now consider a single dove in a population of hawks. To be sure, he loses all his fights, but on the other hand he never gets hurt. His average pay-off is 0 in a population of hawks, whereas the average pay-off for a hawk in a population of hawks is -25. Dove genes will therefore tend to spread through the population. The way I have told the story it looks as if there will be a continuous oscillation in the population. Hawk genes will sweep to ascendancy; then, as a consequence of the hawk majority, dove genes will gain an advantage and increase in numbers until once again hawk genes start to prosper, and so on. However, it need not be an oscillation like this. There is a stable ratio of hawks to doves. For the particular arbitrary points system we are using, the stable ratio, if you work it out, turns out to be 5/12 doves to 7/12 hawks. When this stable ratio is reached, the average pay-off for hawks is exactly equal to the average pay-off for doves. Therefore selection does not favour either one of them over the other. If the number of hawks in the population started to drift upwards so that the ratio was no longer 7/12 doves would start to gain an extra advantage, and the ratio would swing back to the stable state. Just as we shall find the stable sex ratio to be 50:50, so the stable hawk to dove ratio in this hypothetical example is 7:5. In either case, if there are oscillations about the stable point, they need not be very large ones. Superficially, this sounds a little like group selection, but it is really nothing of the kind. It sounds like group selection because it enables us to think of a population as having a stable equilibrium to which it tends to return when disturbed. But the ESS is a much more subtle concept than group selection. It has nothing to do with some groups being more successful than others. This can be nicely illustrated using the arbitrary points system of our hypothetical example. The average pay-off to an individual in a stable population consisting of 7/12 hawks and 5/12 doves, turns out to be 6 1/4. This is true whether the individual is a hawk or a dove. Now 6 1/4 is much less than the average pay-off for a dove in a population of doves (15). If only everybody would agree to be a dove, every single individual would benefit. By simple group selection, any group in which all individuals mutually agree to be doves would be far more successful than a rival group sitting at the ESS ratio. (As a matter of fact, a conspiracy of nothing but doves is not quite the most successful possible group. In a group consisting of 1/6 hawks and 5/6 doves, the average pay-off per contest is 16 2/3. This is the most successful possible conspiracy, but for present purposes we can ignore it. A simpler all-dove conspiracy, with its average pay-off for each individual of 15, is far better for every single individual than the ESS would be.) Group selection theory would therefore predict a tendency to evolve towards an all-dove conspiracy, since a group that contained a 7/12 proportion of hawks would be less successful. But the trouble with conspiracies, even those that are to everybody's advantage in the long run, is that they are open to abuse. It is true that everybody does better in an all-dove group than he would in an ESS group. But unfortunately, in conspiracies of doves, a single hawk does so extremely well that nothing could stop the evolution of hawks. The conspiracy is therefore bound to be broken by treachery from within. An ESS is stable, not because it is particularly good for the individuals participating in it, but simply because it is immune to treachery from within. It is possible for humans to enter into pacts or conspiracies that are to every individual's advantage, even if these are not stable in the ESS sense. But this is only possible because every individual uses his conscious foresight, and is able to see that it is in his own long-term interests to obey the rules of the pact. Even in human pacts there is a constant danger that individuals will stand to gain so much in the short term by breaking the pact that the temptation to do so will be overwhelming. Perhaps the best example of this is price-fixing. It is in the long-term interests of all individual garage owners to standardize the price of petrol at some artificially high value. Price rings, based on conscious estimation of long-term best interests, can survive for quite long periods. Every so often, however, an individual gives in to the temptation to make a quick killing by cutting his prices. Immediately, his neighbours follow suit, and a wave of price cutting spreads over the country. Unfortunately for the rest of us, the conscious foresight of the garage owners then reasserts itself, and they enter into a new price-fixing pact. So, even in man, a species with the gift of conscious foresight, pacts or conspiracies based on long-term best interests teeter constantly on the brink of collapse due to treachery from within. In wild animals, controlled by the struggling genes, it is even more difficult to see ways in which group benefit or conspiracy strategies could possibly evolve. We must expect to find evolutionarily stable strategies everywhere. In our hypothetical example we made the simple assumption that any one individual was either a hawk or a dove. We ended up with an evolutionarily stable ratio of hawks to doves. In practice, what this means is that a stable ratio of hawk genes to dove genes would be achieved in the gene pool. The genetic technical term for this state is stable polymorphism. As far as the maths are concerned, an exactly equivalent ESS can be achieved without polymorphism as follows. If every individual is capable of behaving either like a hawk or like a dove in each particular contest, an ESS can be achieved in which all individuals have the same probability of behaving like a hawk, namely 7/12 in our particular example. In practice this would mean that each individual enters each contest having made a random decision whether to behave on this occasion like a hawk or like a dove; random, but with a 7:5 bias in favour of hawk. It is very important that the decisions, although biased towards hawk, should be random in the sense that a rival has no way of guessing how his opponent is going to behave in any particular contest. It is no good, for instance, playing hawk seven fights in a row, then dove five fights in a row and so on. If any individual adopted such a simple sequence, his rivals would quickly catch on and take advantage. The way to take advantage of a simple sequence strategist is to play hawk against him only when you know he is going to play dove. The hawk and dove story is, of course, naively simple. It is a 'model', something that does not really happen in nature, but which helps us to understand things that do happen in nature. Models can be very simple, like this one, and still be useful for understanding a point, or getting an idea. Simple models can be elaborated and gradually made more complex. If all goes well, as they get more complex they come to resemble the real world more. One way in which we can begin to develop the hawk and dove model is to introduce some more strategies. Hawk and dove are not the only possibilities. A more complex strategy which Maynard Smith and Price introduced is called Retaliator. A retaliator plays like a dove at the beginning of every fight. That is, he does not mount an all-out savage attack like a hawk, but has a conventional threatening match. If his opponent attacks him, however, he retaliates. In other words, a retaliator behaves like a hawk when he is attacked by a hawk, and like a dove when he meets a dove. When he meets another retaliator he plays like a dove. A retaliator is a conditional strategist. His behaviour depends on the behaviour of his opponent. Another conditional strategist is called Bully. A bully goes around behaving like a hawk until somebody hits back. Then he immediately runs away. Yet another conditional strategist is Prober-retaliator. A prober-retaliator is basically like a retaliator, but he occasionally tries a brief experimental escalation of the contest. He persists in this hawk-like behaviour if his opponent does not fight back. If, on the other hand, his opponent does fight back he reverts to conventional threatening like a dove. If he is attacked, he retaliates just like an ordinary retaliator. If all the five strategies I have mentioned are turned loose upon one another in a computer simulation, only one of them, retaliator, emerges as evolutionarily stable. Prober-retaliator is nearly stable. Dove is not stable, because a population of doves would be invaded by hawks and bullies. Hawk is not stable, because a population of hawks would be invaded by doves and bullies. Bully is not stable, because a population of bullies would be invaded by hawks. In a population of retaliators, no other strategy would invade, since there is no other strategy that does better than retaliator itself. However, dove does equally well in a population of retaliators. This means that, other things being equal, the numbers of doves could slowly drift upwards. Now if the numbers of doves drifted up to any significant extent, prober-retaliators (and, incidentally, hawks and bullies) would start to have an advantage, since they do better against doves than retaliators do. Prober-retaliator itself, unlike hawk and bully, is almost an ESS, in the sense that, in a population of prober-retaliators, only one other strategy, retaliator, does better, and then only slightly. We might expect, therefore, that a mixture of retaliators and prober-retaliators would tend to predominate, with perhaps even a gentle oscillation between the two, in association with an oscillation in the size of a small dove minority. Once again, we don't have to think in terms of a polymorphism in which every individual always plays one strategy or another. Each individual could play a complex mixture between retaliator, prober-retaliator, and dove. This theoretical conclusion is not far from what actually happens in most wild animals. We have in a sense explained the 'gloved fist' aspect of animal aggression. Of course the details depend on the exact numbers of 'points' awarded for winning, being injured, wasting time, and so on. In elephant seals the prize for winning may be near-monopoly rights over a large harem of females. The pay-off for winning must therefore be rated as very high. Small wonder that fights are vicious and the probability of serious injury is also high. The cost of wasting time should presumably be regarded as small in comparison with the cost of being injured and the benefit of winning. For a small bird in a cold climate, on the other hand, the cost of wasting time may be paramount. A great tit when feeding nestlings needs to catch an average of one prey per thirty seconds. Every second of daylight is precious. Even the comparatively short time wasted in a hawk /hawk fight should perhaps be regarded as more serious than the risk of injury to such a bird. Unfortunately, we know too little at present to assign realistic numbers to the costs and benefits of various outcomes in nature. We must be careful not to draw conclusions that result simply from our own arbitrary choice of numbers. The general conclusions which are important are that ESSs will tend to evolve, that an ESS is not the same as the optimum that could be achieved by a group conspiracy, and that common sense can be misleading. Another kind of war game that Maynard Smith has considered is the 'war of attrition'. This can be thought of as arising in a species that never engages in dangerous combat, perhaps a well-armoured species in which injury is very unlikely. All disputes in this species are settled by conventional posturing. A contest always ends in one rival or the other backing down. To win, all you have to do is stand your ground and glare at the opponent until he finally turns tail. Obviously no animal can afford to spend infinite time threatening; there are important things to be done elsewhere. The resource he is competing for may be valuable, but it is not infinitely valuable. It is only worth so much time and, as at an auction sale, each individual is prepared to spend only so much on it. Time is the currency of this two-bidder auction. Suppose all such individuals worked out in advance exactly how much time they thought a particular kind of resource, say a female, was worth. A mutant individual who was prepared to go on just a little bit longer would always win. So the strategy of maintaining a fixed bidding limit is unstable. Even if the value of the resource can be very finely estimated, and all individuals bid exactly the right value, the strategy is unstable. Any two individuals bidding according to this maximum strategy would give up at exactly the same instant, and neither would get the resource! It would then pay an individual to give up right at the start rather than waste any time in contests at all. The important difference between the war of attrition and a real auction sale is, after all, that in the war of attrition both contestants pay the price but only one of them gets the goods. In a population of maximum bidders, therefore, a strategy of giving up at the beginning would be successful and would spread through the population. As a consequence of this some benefit would start to accrue to individuals who did not give up immediately, but waited for a few seconds before giving up. This strategy would pay when played against the immediate retreaters who now predominate in the population. Selection would then favour a progressive extension of the giving-up time until it once more approached the maximum allowed by the true economic worth of the resource under dispute. Once again, by using words, we have talked ourselves into picturing an oscillation in a population. Once again, mathematical analysis shows that this is not correct. There is an evolutionarily stable strategy, which can be expressed as a mathematical formula, but in words what it amounts to is this. Each individual goes on for an unpredictable time. Unpredictable on any particular occasion, that is, but averaging the true value of the resource. For example, suppose the resource is really worth five minutes of display. At the ESS, any particular individual may go on for more than five minutes or he may go on for less than five minutes, or he may even go on for exactly five minutes. The important thing is that his opponent has no way of knowing how long he is prepared to persist on this particular occasion. Obviously, it is vitally important in the war of attrition that individuals should give no inkling of when they are going to give up. Anybody who betrayed, by the merest flicker of a whisker, that he was beginning to think of throwing in the sponge, would be at an instant disadvantage. If, say, whisker-flickering happened to be a reliable sign that retreat would follow within one minute, there would be a very simple winning strategy: if your opponent's whiskers flicker, wait one more minute, regardless of what your own previous plans for giving up might have been. If your opponent's whiskers have not yet flickered, and you are within one minute of the time when you intend to give up anyway, give up immediately and don't waste any more time. Never flicker your own whiskers.' So natural selection would quickly penalize whisker-flickering and any analogous betrayals of future behaviour. The poker face would evolve. Why the poker face rather than out-and-out lies? Once again, because lying is not stable. Suppose it happened to be the case that the majority of individuals raised their hackles only when they were truly intending to go on for a very long time in the war of attrition. The obvious counterploy would evolve: individuals would give up immediately when an opponent raised his hackles. But now, liars might start to evolve. Individuals who really had no intention of going on for a long time would raise their hackles on every occasion, and reap the benefits of easy and quick victory. So liar genes would spread. When liars became the majority, selection would now favour individuals who called their bluff. Therefore liars would decrease in numbers again. In the war of attrition, telling lies is no more evolutionarily stable than telling the truth. The poker face is evolutionarily stable. Surrender, when it finally comes, will be sudden and unpredictable. So far we have considered only what Maynard Smith calls 'symmetric' contests. This means we have assumed that the contestants are identical in all respects except their fighting strategy. Hawks and doves are assumed to be equally strong, to be equally well endowed with weapons and with armour, and to have an equal amount to gain from winning. This is a convenient assumption to make for a model, but it is not very realistic. Parker and Maynard Smith went on to consider asymmetric contests. For example, if individuals vary in size and fighting ability, and each individual is capable of gauging a rival's size in comparison to his own, does this affect the ESS that emerges? It most certainly does. There seem to be three main sorts of asymmetry. The first we have just met: individuals may differ in their size or fighting equipment. Secondly, individuals may differ in how much they have to gain from winning. For instance an old male, who has not long to live anyway, might have less to lose if he is injured than a young male with the bulk of his reproductive life ahead of him. Thirdly, it is a strange consequence of the theory that a purely arbitrary, apparently irrelevant, asymmetry can give rise to an ESS, since it can be used to settle contests quickly. For instance it will usually be the case that one contestant happens to arrive at the location of the contest earlier than the other. Call them 'resident' and 'intruder' respectively. For the sake of argument, I am assuming that there is no general advantage attached to being a resident or an intruder. As we shall see, there are practical reasons why this assumption may not be true, but that is not the point. The point is that even if there were no general reason to suppose that residents have an advantage over intruders, an ESS depending on the asymmetry itself would be likely to evolve. A simple analogy is to humans who settle a dispute quickly and without fuss by tossing a coin. The conditional strategy: 'If you are the resident, attack; if you are the intruder, retreat', could be an ESS. Since the asymmetry is assumed to be arbitrary, the opposite strategy: 'If resident, retreat; if intruder, attack' could also be stable. Which of the two ESSs is adopted in a particular population would depend on which one happens to reach a majority first. Once a majority of individuals is playing one of these two conditional strategies, deviants from it are penalized. Hence, by definition, it is an ESS. For instance, suppose all individuals are playing 'resident wins, intruder runs away'. This means they will win half their fights and lose half their fights. They will never be injured and they will never waste time, since all disputes are instantly settled by arbitrary convention. Now consider a new mutant rebel. Suppose he plays a pure hawk strategy, always attacking and never retreating. He will win when his opponent is an intruder. When his opponent is a resident he will run a grave risk of injury. On average he will have a lower pay-off than individuals playing according to the arbitrary rules of the ESS. A rebel who tries the reverse convention 'if resident run away, if intruder attack', will do even worse. Not only will he frequently be injured, he will also seldom win a contest. Suppose, though, that by some chance events individuals playing this reverse convention managed to become the majority. In this case their strategy would then become the stable norm, and deviation from it would be penalized. Conceivably, if we watched a population for many generations we would see a series of occasional flips from one stable state to the other. However, in real life, truly arbitrary asymmetries probably do not exist. For instance, residents probably tend to have a practical advantage over intruders. They have better knowledge of local terrain. An intruder is perhaps more likely to be out of breath because he moved into the battle area, whereas the resident was there all the time. There is a more abstract reason why, of the two stable states, the 'resident wins, intruder retreats', one is the more probable in nature. This is that the reverse strategy, 'intruder wins, resident retreats' has an inherent tendency to self-destruction-it is what Maynard Smith would call a paradoxical strategy. In any population sitting at this paradoxical ESS, individuals would always be striving never to be caught as residents: they would always be trying to be the intruder in any encounter. They could only achieve this by ceaseless, and otherwise pointless, moving around! Quite apart from the costs in time and energy that would be incurred, this evolutionary trend would, of itself, tend to lead to the category 'resident' ceasing to exist. In a population sitting at the other stable state, 'resident wins, intruder retreats', natural selection would favour individuals who strove to be residents. For each individual, this would mean holding on to a particular piece of ground, leaving it as little as possible, and appearing to 'defend' it. As is now well known, such behaviour is commonly observed in nature, and goes by the name of 'territorial defence'. The neatest demonstration I know of this form of behavioural asymmetry was provided by the great ethologist Niko Tinbergen, in an experiment of characteristically ingenious simplicity. He had a fish-tank containing two male sticklebacks. The males had each built nests, at opposite ends of the tank, and each 'defended' the territory around his own nest. Tinbergen placed each of the two males in a large glass test-tube, and he held the two tubes next to each other and watched the males trying to fight each other through the glass. Now comes the interesting result. When he moved the two tubes into the vicinity of male A's nest, male A assumed an attacking posture, and male B attempted to retreat. But when he moved the two tubes into male B's territory, the tables were turned. By simply moving the two tubes from one end of the tank to the other, Tinbergen was able to dictate which male attacked and which retreated. Both males were evidently playing the simple conditional strategy: 'if resident, attack; if intruder, retreat.' Biologists often ask what the biological 'advantages' of territorial behaviour are. Numerous suggestions have been made, some of which will be mentioned later. But we can now see that the very question may be superfluous. Territorial 'defence' may simply be an ESS which arises because of the asymmetry in time of arrival that usually characterizes the relationship between two individuals and a patch of ground. Presumably the most important kind of non-arbitrary asymmetry is in size and general fighting ability. Large size is not necessarily always the most important quality needed to win fights, but it is probably one of them. If the larger of two fighters always wins, and if each individual knows for certain whether he is larger or smaller than his opponent, only one strategy makes any sense: 'If your opponent is larger than you, run away. Pick fights with people smaller than you are.' Things are a bit more complicated if the importance of size is less certain. If large size confers only a slight advantage, the strategy I have just mentioned is still stable. But if the risk of injury is serious there may also be a second, 'paradoxical strategy'. This is: 'Pick fights with people larger than you are and run away from people smaller than you are'! It is obvious why this is called paradoxical. It seems completely counter to common sense. The reason it can be stable is this. In a population consisting entirely of paradoxical strategists, nobody ever gets hurt. This is because in every contest one of the participants, the larger, always runs away. A mutant of average size who plays the 'sensible' strategy of picking on smaller opponents is involved in a seriously escalated fight with half the people he meets. This is because, if he meets somebody smaller than him, he attacks; the smaller individual fights back fiercely, because he is playing paradoxical; although the sensible strategist is more likely to win than the paradoxical one, he still runs a substantial risk of losing and of being seriously injured. Since the majority of the population are paradoxical, a sensible strategist is more likely to be injured than any single paradoxical strategist. Even though a paradoxical strategy can be stable, it is probably only of academic interest. Paradoxical fighters will only have a higher average pay-off if they very heavily out-number sensible ones. It is hard to imagine how this state of affairs could ever arise in the first place. Even if it did, the ratio of sensibles to paradoxicals in the population only has to drift a little way towards the sensible side before reaching the 'zone of attraction' of the other ESS, the sensible one. The zone of attraction is the set of population ratios at which, in this case, sensible strategists have the advantage: once a population reaches this zone, it will be sucked inevitably towards the sensible stable point. It would be exciting to find an example of a paradoxical ESS in nature, but I doubt if we can really hope to do so. (I spoke too soon. After I had written this last sentence, Professor Maynard Smith called my attention to the following description of the behaviour of the Mexican social spider, Oecobius civitas, by J. W. Burgess: 'If a spider is disturbed and driven out of its retreat, it darts across the rock and, in the absence of a vacant crevice to hide in, may seek refuge in the hiding place of another spider of the same species. If the other spider is in residence when the intruder enters, it does not attack but darts out and seeks a new refuge of its own. Thus once the first spider is disturbed the process of sequential displacement from web to web may continue for several seconds, often causing a majority of the spiders in the aggregation to shift from their home refuge to an alien one (Social Spiders, Scientific American, March 1976). What if individuals retain some memory of the outcome of past fights? This depends on whether the memory is specific or general. Crickets have a general memory of what happened in past fights. A cricket that has recently won a large number of fights becomes more hawkish. A cricket that has recently had a losing streak becomes more dovish. This was neatly shown by R. D. Alexander. He used a model cricket to beat up real crickets. After this treatment the real crickets became more likely to lose fights against other real crickets. Each cricket can be thought of as constantly updating his own estimate of his fighting ability, relative to that of an average individual in his population. If animals such as crickets, who work with a general memory of past fights, are kept together in a closed group for a time, a kind of dominance hierarchy is likely to develop. An observer can rank the individuals in order. Individuals lower in the order tend to give in to individuals higher in the order. There is no need to suppose that the individuals recognize each other. All that happens is that individuals who are accustomed to winning become even more likely to win, while individuals who are accustomed to losing become steadily more likely to lose. Even if the individuals started by winning or losing entirely at random, they would tend to sort themselves out into a rank order. This incidentally has the effect that the number of serious fights in the group gradually dies down. I have to use the phrase 'kind of dominance hierarchy', because many people reserve the term dominance hierarchy for cases in which individual recognition is involved. In these cases, memory of past fights is specific rather than general. Crickets do not recognize each other as individuals, but hens and monkeys do. If you are a monkey, a monkey who has beaten you in the past is likely to beat you in the future. The best strategy for an individual is to be relatively dovish towards an individual who has previously beaten him. If a batch of hens who have never met before are introduced to each other, there is usually a great deal of fighting. After a time the fighting dies down. Not for the same reason as in the crickets, though. In the case of the hens it is because each individual 'learns her place' relative to each other individual. This is incidentally good for the group as a whole. As an indicator of this it has been noticed that in established groups of hens, where fierce fighting is rare, egg production is higher than in groups of hens whose membership is continually being changed, and in which fights are consequently more frequent. Biologists often speak of the biological advantage or 'function' of dominance hierarchies as being to reduce overt aggression in the group. However, this is the wrong way to put it. A dominance hierarchy perse cannot be said to have a 'function' in the evolutionary sense, since it is a property of a group, not of an individual. The individual behaviour patterns that manifest themselves in the form of dominance hierarchies when viewed at the group level may be said to have functions. It is, however, even better to abandon the word 'function' altogether, and to think about the matter in terms of ESSs in asymmetric contests where there is individual recognition and memory. We have been thinking of contests between members of the same species. What about inter-specific contests? As we saw earlier, members of different species are less direct competitors than members of the same species. For this reason we should expect fewer disputes between them over resources, and our expectation is borne out. For instance, robins defend territories against other robins, but not against great tits. One can draw a map of the territories of different individual robins in a wood and one can superimpose a map of the territories of individual great tits. The territories of the two species overlap in an entirely indiscriminate way. They might as well be on different planets. But there are other ways in which the interests of individuals from different species conflict very sharply. For instance a lion wants to eat an antelope's body, but the antelope has very different plans for its body. This is not normally regarded as competition for a resource, but logically it is hard to see why not. The resource in question is meat. The lion genes 'want' the meat as food for their survival machine. The antelope genes want the meat as working muscle and organs for their survival machine. These two uses for the meat are mutually incompatible, therefore there is conflict of interest. Members of one's own species are made of meat too. Why is cannibalism relatively rare? As we saw in the case of black-headed gulls, adults do sometimes eat the young of their own species. Yet adult carnivores are never to be seen actively pursuing other adults of their own species with a view to eating them. Why not? We are still so used to thinking in terms of the 'good of the species' view of evolution that we often forget to ask perfectly reasonable questions like: 'Why don't lions hunt other lions?' Another good question of a type which is seldom asked is: 'Why do antelopes run away from lions instead of hitting back?' The reason lions do not hunt lions is that it would not be an ESS for them to do so. A cannibal strategy would be unstable for the same reason as the hawk strategy in the earlier example. There is too much danger of retaliation. This is less likely to be true in contests between members of different species, which is why so many prey animals run away instead of retaliating. It probably stems originally from the fact that in an interaction between two animals of different species there is a built-in asymmetry which is greater than that between members of the same species. Whenever there is strong asymmetry in a contest, ESSs are likely to be conditional strategies dependent on the asymmetry. Strategies analogous to 'if smaller, run away; if larger, attack' are very likely to evolve in contests between members of different species because there are so many available asymmetries. Lions and antelopes have reached a kind of stability by evolutionary divergence, which has accentuated the original asymmetry of the contest in an ever-increasing fashion. They have become highly proficient in the arts of, respectively, chasing, and running away. A mutant antelope that adopted a 'stand and fight' strategy against lions would be less successful than rival antelopes disappearing over the horizon. I have a hunch that we may come to look back on the invention of the ESS concept as one of the most important advances in evolutionary theory since Darwin. It is applicable wherever we find conflict of interest, and that means almost everywhere. Students of animal behaviour have got into the habit of talking about something called 'social organization'. Too often the social organization of a species is treated as an entity in its own right, with its own biological 'advantage'. An example I have already given is that of the 'dominance hierarchy'. I believe it is possible to discern hidden group-selectionist assumptions lying behind a large number of the statements that biologists make about social organization. Maynard Smith's concept of the ESS will enable us, for the first time, to see clearly how a collection of independent selfish entities can come to resemble a single organized whole. I think this will be true not only of social organizations within species, but also of 'ecosystems' and 'communities' consisting of many species. In the long term, I expect the ESS concept to revolutionize the science of ecology. We can also apply it to a matter that was deferred from Chapter 3, arising from the analogy of oarsmen in a boat (representing genes in a body) needing a good team spirit. Genes are selected, not as 'good' in isolation, but as good at working against the background of the other genes in the gene pool. A good gene must be compatible with, and complementary to, the other genes with whom it has to share a long succession of bodies. A gene for plant-grinding teeth is a good gene in the gene pool of a herbivorous species, but a bad gene in the gene pool of a carnivorous species. It is possible to imagine a compatible combination of genes as being selected together as a unit. In the case of the butterfly mimicry example of Chapter 3, this seems to be exactly what happened. But the power of the ESS concept is that it can now enable us to see how the same kind of result could be achieved by selection purely at the level of the independent gene. The genes do not have to be linked on the same chromosome. The rowing analogy is really not up to explaining this idea. The nearest we can come to it is this. Suppose it is important in a really successful crew that the rowers should coordinate their activities by means of speech. Suppose further that, in the pool of oarsmen at the coach's disposal, some speak only English and some speak only German. The English are not consistently better or worse rowers than the Germans. But because of the importance of communication, a mixed crew will tend to win fewer races than either a pure English crew or a pure German crew. The coach does not realize this. All he does is shuffle his men around, giving credit points to individuals in winning boats, marking down individuals in losing boats. Now if the pool available to him just happens to be dominated by Englishmen it follows that any German who gets into a boat is likely to cause it to lose, because communications break down. Conversely, if the pool happened to be dominated by Germans, an Englishman would tend to cause any boat in which he found himself to lose. What will emerge as the overall best crew will be one of the two stable states-pure English or pure German, but not mixed. Superficially it looks as though the coach is selecting whole language groups as units. This is not what he is doing. He is selecting individual oarsmen for their apparent ability to win races. It so happens that the tendency for an individual to win races depends on which other individuals are present in the pool of candidates. Minority candidates are automatically penalized, not because they are bad rowers, but simply because they are minority candidates. Similarly, the fact that genes are selected for mutual compatibility does not necessarily mean we have to think of groups of genes as being selected as units, as they were in the case of the butterflies. Selection at the low level of the single gene can give the impression of selection at some higher level. In this example, selection favours simple conformity. More interestingly, genes may be selected because they complement each other. In terms of the analogy, suppose an ideally balanced crew would consist of four right-handers and four left-handers. Once again assume that the coach, unaware of this fact, selects blindly on 'merit'. Now if the pool of candidates happens to be dominated by right-handers, any individual left-hander will tend to be at an advantage: he is likely to cause any boat in which he finds himself to win, and he will therefore appear to be a good oarsman. Conversely, in a pool dominated by left-handers, a right-hander would have an advantage. This is similar to the case of a hawk doing well in a population of doves, and a dove doing well in a population of hawks. The difference is that there we were talking about interactions between individual bodies-selfish machines-whereas here we are talking, by analogy, about interactions between genes within bodies. The coach's blind selection of 'good' oarsmen will lead in the end to an ideal crew consisting of four left-handers and four righthanders. It will look as though he selected them all together as a complete, balanced unit. I find it more parsimonious to think of him as selecting at a lower level, the level of the independent candidates. The evolutionarily stable state ('strategy' is misleading in this context) of four left-handers and four right-handers will emerge simply as a consequence of low-level selection on the basis of apparent merit. The gene pool is the long-term environment of the gene. 'Good' genes are blindly selected as those that survive in the gene pool. This is not a theory; it is not even an observed fact: it is a tautology. The interesting question is what makes a gene good. As a first approximation I said that what makes a gene good is the ability to build efficient survival machines-bodies. We must now amend that statement. The gene pool will become an evolutionarily stable set of genes, defined as a gene pool that cannot be invaded by any new gene. Most new genes that arise, either by mutation or reassortment or immigration, are quickly penalized by natural selection: the evolutionarily stable set is restored. Occasionally a new gene does succeed in invading the set: it succeeds in spreading through the gene pool. There is a transitional period of instability, terminating in a new evolutionarily stable set-a little bit of evolution has occurred. By analogy with the aggression strategies, a population might have more than one alternative stable point, and it might occasionally flip from one to another. Progressive evolution may be not so much a steady upward climb as a series of discrete steps from stable plateau to stable plateau. It may look as though the population as a whole is behaving like a single self-regulating unit. But this illusion is produced by selection going on at the level of the single gene. Genes are selected on 'merit'. But merit is judged on the basis of performance against the background of the evolutionarily stable set which is the current gene pool. By focussing on aggressive interactions between whole individuals, Maynard Smith was able to make things very clear. It is easy to think of stable ratios of hawk bodies and dove bodies, because bodies are large things which we can see. But such interactions between genes sitting in different bodies are only the tip of the iceberg. The vast majority of significant interactions between genes in the evolutionarily stable set-the gene pool-go on within individual bodies. These interactions are difficult to see, for they take place within cells, notably the cells of developing embryos. Well-integrated bodies exist because they are the product of an evolutionarily stable set of selfish genes. But I must return to the level of interactions between whole animals which is the main subject of this book. For understanding aggression it was convenient to treat individual animals as independent selfish machines. This model breaks down when the individuals concerned are close relatives-brothers and sisters, cousins, parents and children. This is because relatives share a substantial proportion of their genes. Each selfish gene therefore has its loyalties divided between different bodies. This is explained in the next chapter.",
        "char_count": 55556
      },
      {
        "heading": "Chapter 7",
        "text": "The Selfish Gene 6. Genesmanship. What is the selfish gene? It is not just one single physical bit of DNA. Just as in the primeval soup, it is all replicas of a particular bit of DNA, distributed throughout the world. If we allow ourselves the licence of talking about genes as if they had conscious aims, always reassuring ourselves that we could translate our sloppy language back into respectable terms if we wanted to, we can ask the question, what is a single selfish gene trying to do? It is trying to get more numerous in the gene pool. Basically it does this by helping to program the bodies in which it finds itself to survive and to reproduce. But now we are emphasizing that 'it' is a distributed agency, existing in many different individuals at once. The key point of this chapter is that a gene might be able to assist replicas of itself that are sitting in other bodies. If so, this would appear as individual altruism but it would be brought about by gene selfishness. Consider the gene for being an albino in man. In fact several genes exist that can give rise to albinism, but I am talking about just one of them. It is recessive; that is, it has to be present in double dose in order for the person to be an albino. This is true of about 1 in 20,000 of us. But it is also present, in single dose, in about 1 in 70 of us, and these individuals are not albinos. Since it is distributed in many individuals, a gene such as the albino gene could, in theory, assist its own survival in the gene pool by programming its bodies to behave altruistically towards other albino bodies, since these are known to contain the same gene. The albino gene should be quite happy if some of the bodies that it inhabits die, provided that in doing so they help other bodies containing the same gene to survive. If the albino gene could make one of its bodies save the lives of 10 albino bodies, then even the death of the altruist is amply compensated by the increased numbers of albino genes in the gene pool. Should we then expect albinos to be especially nice to each other? Actually the answer is probably no. In order to see why not, we must temporarily abandon our metaphor of the gene as a conscious agent, because in this context it becomes positively misleading. We must translate back into respectable, if more longwinded terms. Albino genes do not really 'want' to survive or to help other albino genes. But if the albino gene just happened to cause its bodies to behave altruistically towards other albinos, then automatically, willy-nilly, it would tend to become more numerous in the gene pool as a result. But, in order for this to happen, the gene would have to have two independent effects on bodies. Not only must it confer its usual effect of a very pale complexion. It must also confer a tendency to be selectively altruistic towards individuals with a very pale complexion. Such a double-effect gene could, if it existed, be very successful in the population. Now it is true that genes do have multiple effects, as I emphasized in Chapter 3. It is theoretically possible that a gene could arise which conferred an externally visible 'label', say a pale skin, or a green beard, or anything conspicuous, and also a tendency to be specially nice to bearers of that conspicuous label. It is possible, but not particularly likely. Green beardedness is just as likely to be linked to a tendency to develop ingrowing toenails or any other trait, and a fondness for green beards is just as likely to go together with an inability to smell freesias. It is not very probable that one and the same gene would produce both the right label and the right sort of altruism. Nevertheless, what may be called the Green Beard Altruism Effect is a theoretical possibility. An arbitrary label like a green beard is just one way in which a gene might 'recognize' copies of itself in other individuals. Are there any other ways? A particularly direct possible way is the following. The possessor of an altruistic gene might be recognized simply by the fact that he does altruistic acts. A gene could prosper in the gene pool if it 'said' the equivalent of: 'Body, if A is drowning as a result of trying to save someone else from drowning, jump in and rescue A.' The reason such a gene could do well is that there is a greater than average chance that A contains the same life-saving altruistic gene. The fact that A is seen to be trying to rescue somebody else is a label, equivalent to a green beard. It is less arbitrary than a green beard, but it still seems rather implausible. Are there any plausible ways in which genes might 'recognize' their copies in other individuals? The answer is yes. It is easy to show that close relatives-kin-have a greater than average chance of sharing genes. It has long been clear that this must be why altruism by parents towards their young is so common. What R. A. Fisher, J. B. S. Haldane, and especially W. D. Hamilton realized, was that the same applies to other close relations-brothers and sisters, nephews and nieces, close cousins. If an individual dies in order to save ten close relatives, one copy of the kin-altruism gene may be lost, but a larger number of copies of the same gene is saved. 'A larger number' is a bit vague. So is 'close relatives'. We can do better than that, as Hamilton showed. His two papers of 1964 are among the most important contributions to social ethology ever written, and I have never been able to understand why they have been so neglected by ethologists (his name does not even appear in the index of two major text-books of ethology, both published in 1970). Fortunately there are recent signs of a revival of interest in his ideas. Hamilton's papers are rather mathematical, but it is easy to grasp the basic principles intuitively, without rigorous mathematics, though at the cost of some over-simplification. The thing we want to calculate is the probability, or odds, that two individuals, say two sisters, share a particular gene. For simplicity I shall assume that we are talking about genes that are rare in the gene pool as a whole. Most people share 'the gene for not being an albino', whether they are related to each other or not. The reason this gene is so common is that in nature albinos are less likely to survive than non-albinos because, for example, the sun dazzles them and makes them relatively unlikely to see an approaching predator. We are not concerned with explaining the prevalence in the gene pool of such obviously 'good' genes as the gene for not being an albino. We are interested in explaining the success of genes specifically as a result of their altruism. We can therefore assume that, at least in the early stages of this process of evolution, these genes are rare. Now the important point is that even a gene that is rare in the population as a whole is common within a family. I contain a number of genes that are rare in the population as a whole, and you also contain genes that are rare in the population as a whole. The chance that we both contain the same rare genes is very small indeed. But the chances are good that my sister contains a particular rare gene that I contain, and the chances are equally good that your sister contains a rare gene in common with you. The odds are in this case exactly 50 per cent, and it is easy to explain why. Suppose you contain one copy of the gene G. You must have received it either from your father or from your mother (for convenience we can neglect various infrequent possibilities-that G is a new mutation, that both your parents had it, or that either of your parents had two copies of it). Suppose it was your father who gave you the gene. Then every one of his ordinary body cells contained one copy of G. Now you will remember that when a man makes a sperm he doles out half his genes to it. There is therefore a 50 per cent chance that the sperm that begot your sister received the gene G. If, on the other hand, you received G from your mother, exactly parallel reasoning shows that half of her eggs must have contained G; once again, the chances are 50 per cent that your sister contains G. This means that if you had 100 brothers and sisters, approximately 50 of them would contain any particular rare gene that you contain. It also means that if you have 100 rare genes, approximately 50 of them are in the body of any one of your brothers or sisters. You can do the same kind of calculation for any degree of kinship you like. An important relationship is that between parent and child. If you have one copy of gene H, the chance that any particular one of your children has it is 50 per cent, because half your sex cells contain H, and any particular child was made from one of those sex cells. If you have one copy of gene J, the chance that your father also had J is 50 per cent, because you received half your genes from him, and half from your mother. For convenience we use an index of relatedness, which expresses the chance of a gene being shared between two relatives. The relatedness between two brothers is 1/2, since half the genes possessed by one brother will be found in the other. This is an average figure: by the luck of the meiotic draw, it is possible for particular pairs of brothers to share more or fewer genes than this. The relatedness between parent and child is always exactly 1/2. It is rather tedious going through the calculations from first principles every time, so here is a rough and ready rule for working out the relatedness between any two individuals A and B. You may find it useful in making your will, or in interpreting apparent resemblances in your own family. It works for all simple cases, but breaks down where incestuous mating occurs, and in certain insects, as we shall see. First identify all the common ancestors of A and B. For instance, the common ancestors of a pair of first cousins are their shared grandfather and grandmother. Once you have found a common ancestor, it is of course logically true that all his ancestors are common to A and B as well. However, we ignore all but the most recent common ancestors. In this sense, first cousins have only two common ancestors. If B is a lineal descendant of A, for instance his great grandson, then A himself is the 'common ancestor' we are looking for. Having located the common ancestor(s) of A and B, count the generation distance as follows. Starting at A, climb up the family tree until you hit a common ancestor, and then climb down again to B. The total number of steps up the tree and then down again is the generation distance. For instance, if A is B's uncle, the generation distance is 3. The common ancestor is A's father (say) and B's grandfather. Starting at A you have to climb up one generation in order to hit the common ancestor. Then to get down to B you have to descend two generations on the other side. Therefore the generation distance is 1 + 2 = 3. Having found the generation distance between A and B via a particular common ancestor, calculate that part of their relatedness for which that ancestor is responsible. To do this, multiply 1/2 by itself once for each step of the generation distance. If the generation distance is 3, this means calculate 1/2 x 1/2 x 1/2. If the generation distance via a particular ancestor is equal to g steps, the portion of relatedness due to that ancestor is (1/2) to the power g. But this is only part of the relatedness between A and B. If they have more than one common ancestor we have to add on the equivalent figure for each ancestor. It is usually the case that the generation distance is the same for all common ancestors of a pair of individuals. Therefore, having worked out the relatedness between A and B due to any one of the ancestors, all you have to do in practice is to multiply by the number of ancestors. First cousins, for instance, have two common ancestors, and the generation distance via each one is 4. Therefore their relatedness is 1/8. If A is Bs greatgrandchild, the generation distance is 3 and the number of common 'ancestors' is 1 (B himself), so the relatedness is 1/8. Genetically speaking, your first cousin is equivalent to a great grandchild. Similarly, you are just as likely to 'take after' your uncle (relatedness = 1/4) as after your grandfather (relatedness = 1/4). For relationships as distant as third cousin (1/128), we are getting down near the baseline probability that a particular gene possessed by A will be shared by any random individual taken from the population. A third cousin is not far from being equivalent to any old Tom, Dick, or Harry as far as an altruistic gene is concerned. A second cousin (relatedness = 1/32) is only a little bit special; a first cousin somewhat more so (1/8). Full brothers and sisters, and parents and children are very special (1/2), and identical twins (relatedness = 1) just as special as oneself. Uncles and aunts, nephews and nieces, grandparents and grandchildren, and half brothers and half sisters, are intermediate with a relatedness of 3. Now we are in a position to talk about genes for kin-altruism much more precisely. A gene for suicidally saving five cousins would not become more numerous in the population, but a gene for saving five brothers or ten first cousins would. The minimum requirement for a suicidal altruistic gene to be successful is that it should save more than two siblings (or children or parents), or more than four half-siblings (or uncles, aunts, nephews, nieces, grandparents, grandchildren), or more than eight first cousins, etc. Such a gene, on average, tends to live on in the bodies of enough individuals saved by the altruist to compensate for the death of the altruist itself. If an individual could be sure that a particular person was his identical twin, he should be exactly as concerned for his twin's welfare as for his own. Any gene for twin altruism is bound to be carried by both twins, therefore if one dies heroically to save the other the gene lives on. Nine-banded armadillos are born in a litter of identical quadruplets. As far as I know, no feats of heroic self-sacrifice have been reported for young armadillos, but it has been pointed out that some strong altruism is definitely to be expected, and it would be well worth somebody's while going out to South America to have a look. We can now see that parental care is just a special case of kin altruism. Genetically speaking, an adult should devote just as much care and attention to its orphaned baby brother as it does to one of its own children. Its relatedness to both infants is exactly the same, 1/2. In gene selection terms, a gene for big sister altruistic behaviour should have just as good a chance of spreading through the population as a gene for parental altruism. In practice, this is an over-simplification for various reasons which we shall come to later, and brotherly or sisterly care is nothing like so common in nature as parental care. But the point I am making here is that there is nothing special genetically speaking about the parent/child relationship as against the brother/ sister relationship. The fact that parents actually hand on genes to children, but sisters do not hand on genes to each other is irrelevant, since the sisters both receive identical replicas of the same genes from the same parents. Some people use the term kin selection to distinguish this kind of natural selection from group selection (the differential survival of groups) and individual selection (the differential survival of individuals). Kin selection accounts for within-family altruism; the closer the relationship, the stronger the selection. There is nothing wrong with this term, but unfortunately it may have to be abandoned because of recent gross misuses of it, which are likely to muddle and confuse biologists for years to come. E. O. Wilson, in his otherwise admirable Sociobiology: The New Synthesis, defines kin selection as a special case of group selection. He has a diagram which clearly shows that he thinks of it as intermediate between 'individual selection', and 'group selection' in the conventional sense-the sense that I used in Chapter 1. Now group selection-even by Wilson's own definition-means the differential survival of groups of individuals. There is, to be sure, a sense in which a family is a special kind of group. But the whole point of Hamilton's argument is that the distinction between family and non-family is not hard and fast, but a matter of mathematical probability. It is no part of Hamilton's theory that animals should behave altruistically towards all 'members of the family', and selfishly to everybody else. There are no definite lines to be drawn between family and non-family. We do not have to decide whether, say, second cousins should count as inside the family group or outside it: we simply expect that second cousins should be 1/16 as likely to receive altruism as offspring or siblings. Kin selection is emphatically not a special case of group selection. It is a special consequence of gene selection. There is an even more serious shortcoming in Wilson's definition of kin selection. He deliberately excludes offspring: they don't count as kin! Now of course he knows perfectly well that offspring are kin to their parents, but he prefers not to invoke the theory of kin selection in order to explain altruistic care by parents of their own offspring. He is, of course, entitled to define a word however he likes, but this is a most confusing definition, and I hope that Wilson will change it in future editions of his justly influential book. Genetically speaking, parental care and brother/sister altruism evolve for exactly the same reason: in both cases there is a good chance that the altruistic gene is present in the body of the beneficiary. I ask the general reader's indulgence for this little diatribe, and return hastily to the main story. So far, I have over-simplified somewhat, and it is now time to introduce some qualifications. I have talked in elemental terms of suicidal genes for saving the lives of particular numbers of kin of exactly known relatedness. Obviously, in real life, animals cannot be expected to count exactly how many relatives they are saving, nor to perform Hamilton's calculations in their heads even if they had some way of knowing exactly who their brothers and cousins were. In real life, certain suicide and absolute 'saving' of life must be replaced by statistical risks of death, one's own and other people's. Even a third cousin may be worth saving, if the risk to yourself is very small. Then again, both you and the relative you are thinking of saving are going to die one day in any case. Every individual has an 'expectation of life' which an actuary could calculate with a certain probability of error. To save the life of a relative who is soon going to die of old age has less of an impact on the gene pool of the future than to save the life of an equally close relative who has the bulk of his life ahead of him. Our neat symmetrical calculations of relatedness have to be modified by messy actuarial weightings. Grandparents and grandchildren have, genetically speaking, equal reason to behave altruistically to each other, since they share 1/4 of each other's genes. But if the grandchildren have the greater expectation of life, genes for grandparent to grandchild altruism have a higher selective advantage than genes for grandchild to grandparent altruism. It is quite possible for the net benefit of assisting a young distant relative to exceed the net benefit of assisting an old close relative. (Incidentally, it is not, of course, necessarily the case that grandparents have a shorter expectation of life than grandchildren. In species with a high infant-mortality rate, the reverse may be true.) To extend the actuarial analogy, individuals can be thought of as life-insurance underwriters. An individual can be expected to invest or risk a certain proportion of his own assets in the life of another individual. He takes into account his relatedness to the other individual, and also whether the individual is a 'good risk' in terms of his life expectancy compared with the insurer's own. Strictly we should say 'reproduction expectancy' rather than 'life expectancy', or to be even more strict, 'general capacity to benefit own genes in the future expectancy'. Then in order for altruistic behaviour to evolve, the net risk to the altruist must be less than the net benefit to the recipient multiplied by the relatedness. Risks and benefits have to be calculated in the complex actuarial way I have outlined. But what a complicated calculation to expect a poor survival machine to do, especially in a hurry! Even the great mathematical biologist J. B. S. Haldane (in a paper of 1955 in which he anticipated Hamilton by postulating the spread of a gene for saving close relatives from drowning) remarked:'... on the two occasions when I have pulled possibly drowning people out of the water (at an infinitesimal risk to myself) I had no time to make such calculations.' Fortunately, however, as Haldane well knew, it is not necessary to assume that survival machines do the sums consciously in their heads. Just as we may use a slide rule without appreciating that we are, in effect, using logarithms, so an animal may be pre-programmed in such a way that it behaves as if it had made a complicated calculation. This is not so difficult to imagine as it appears. When a man throws a ball high in the air and catches it again, he behaves as if he had solved a set of differential equations in predicting the trajectory of the ball. He may neither know nor care what a differential equation is, but this does not affect his skill with the ball. At some subconscious level, something functionally equivalent to the mathematical calculations is going on. Similarly, when a man takes a difficult decision, after weighing up all the pros and cons, and all the consequences of the decision that he can imagine, he is doing the functional equivalent of a large 'weighted sum' calculation, such as a computer might perform. If we were to program a computer to simulate a model survival machine making decisions about whether to behave altruistically, we should probably proceed roughly as follows. We should make a list of all the alternative things the animal might do. Then for each of these alternative behaviour patterns we program a weighted sum calculation. All the various benefits will have a plus sign; all the risks will have a minus sign; both benefits and risks will be weighted by being multiplied by the appropriate index of relatedness before being added up. For simplicity we can, to begin with, ignore other weightings, such as those for age and health. Since an individual's 'relatedness' with himself is 1 (i.e. he has 100 per cent of his own genes-obviously), risks and benefits to himself will not be devalued at all, but will be given their full weight in the calculation. The whole sum for any one of the alternative behaviour patterns will look like this: Net benefit of behaviour pattern = Benefit to self - Risk to self +1/2 Benefit to brother - 1/2 Risk to brother + 1/2 Benefit to other brother - 1/2 Risk to other brother + 1/8 Benefit to first cousin - 1/8 Risk to first cousin + \\ Benefit to child - \\ Risk to child + etc. The result of the sum will be a number called the net benefit score of that behaviour pattern. Next, the model animal computes the equivalent sum for each alternative behaviour pattern in his repertoire. Finally he chooses to perform the behaviour pattern which emerges with the largest net benefit. Even if all the scores come out negative, he should still choose the action with the highest one, the least of evils. Remember that any positive action involves consumption of energy and time, both of which could have been spent doing other things. If doing nothing emerges as the 'behaviour' with the highest net benefit score, the model animal will do nothing. Here is a very over-simplified example, this time expressed in the form of a subjective soliloquy rather than a computer simulation. I am an animal who has found a clump of eight mushrooms. After taking account of their nutritional value, and subtracting something for the slight risk that they might be poisonous, I estimate that they are worth +6 units each (the units are arbitrary pay-offs as in the previous chapter). The mushrooms are so big I could eat only three of them. Should I inform anybody else about my find, by giving a 'food call'? Who is within earshot? Brother B (his relatedness to me is 2), cousin C (relatedness to me = 1/8), and D (no particular relation: his relatedness to me is some small number which can be treated as zero for practical purposes). The net benefit score to me if I keep quiet about my find will be +6 for each of the three mushrooms I eat, that is +18 in all. My net benefit score if I give the food call needs a bit of figuring. The eight mushrooms will be shared equally between the four of us. The pay-off to me from the two that I eat myself will be the full +6 units each, that is +12 in all. But I shall also get some pay-off when my brother and cousin eat their two mushrooms each, because of our shared genes. The actual score comes to (1 x 12) + (1/2 x 12) + (1/8 x 12) + (0 x 12) = + 19.5. The corresponding net benefit for the selfish behaviour was +18: it is a close-run thing, but the verdict is clear. I should give the food call; altruism on my part would in this case pay my selfish genes. I have made the simplifying assumption that the individual animal works out what is best for his genes. What really happens is that the gene pool becomes filled with genes that influence bodies in such a way that they behave as if they had made such calculations. In any case the calculation is only a very preliminary first approximation to what it ideally should be. It neglects many things, including the ages of the individuals concerned. Also, if I have just had a good meal, so that I can only find room for one mushroom, the net benefit of giving the food call will be greater than it would be if I was famished. There is no end to the progressive refinements of the calculation that could be achieved in the best of all possible worlds. But real life is not lived in the best of all possible worlds. We cannot expect real animals to take every last detail into account in coming to an optimum decision. We shall have to discover, by observation and experiment in the wild, how closely real animals actually come to achieving an ideal cost-benefit analysis. Just to reassure ourselves that we have not become too carried away with subjective examples, let us briefly return to gene language. Living bodies are machines programmed by genes that have survived. The genes that have survived have done so in conditions that tended on average to characterize the environment of the species in the past. Therefore 'estimates' of costs and benefits are based on past 'experience', just as they are in human decision-making. However, experience in this case has the special meaning of gene experience or, more precisely, conditions of past gene survival. (Since genes also endow survival machines with the capacity to learn, some cost-benefit estimates could be said to be taken on the basis of individual experience as well.) So long as conditions do not change too drastically, the estimates will be good estimates, and survival machines will tend to make the right decisions on average. If conditions change radically, survival machines will tend to make erroneous decisions, and their genes will pay the penalty. Just so; human decisions based on outdated information tend to be wrong. Estimates of relatedness are also subject to error and uncertainty. In our over-simplified calculations so far, we have talked as if survival machines know who is related to them, and how closely. In real life such certain knowledge is occasionally possible, but more usually the relatedness can only be estimated as an average number. For example, suppose that A and B could equally well be either half brothers or full brothers. Their relatedness is either 1/4 or 1/2, but since we do not know whether they are half or full brothers, the effectively usable figure is the average, 1. If it is certain that they have the same mother, but the odds that they have the same father are only 1 in 10, then it is 90 per cent certain that they are half brothers, and 10 percent certain that they are full brothers, and the effective relatedness is 1/10 x 1/2 + 9/10 x 1/4 = 0.275. But when we say something like 'it' is 90 per cent certain, what 'it' are we referring to? Do we mean a human naturalist after a long field study is 90 per cent certain, or do we mean the animals are 90 per cent certain? With a bit of luck these two may amount to nearly the same thing. To see this, we have to think how animals might actually go about estimating who their close relations are. We know who our relations are because we are told, because we give them names, because we have formal marriages, and because we have written records and good memories. Many social anthropologists are preoccupied with 'kinship' in the societies which they study. They do not mean real genetic kinship, but subjective and cultural ideas of kinship. Human customs and tribal rituals commonly give great emphasis to kinship; ancestor worship is widespread, family obligations and loyalties dominate much of life. Blood-feuds and inter-clan warfare are easily interpretable in terms of Hamilton's genetic theory. Incest taboos testify to the great kinship-consciousness of man, although the genetical advantage of an incest taboo is nothing to do with altruism; it is presumably concerned with the injurious effects of recessive genes which appear with inbreeding. (For some reason many, anthropologists do not like this explanation.) How could wild animals 'know' who their kin are, or in other words, what behavioural rules could they follow which would have the indirect effect of making them seem to know about kinship? The rule 'be nice to your relations' begs the question of how relations are to be recognized in practice. Animals have to be given by their genes a simple rule for action, a rule that does not involve all-wise cognition of the ultimate purpose of the action, but a rule that works nevertheless, at least in average conditions. We humans are familiar with rules, and so powerful are they that if we are small minded we obey a rule itself, even when we can see perfectly well that it is not doing us, or anybody else, any good. For instance, some orthodox Jews and Muslims would starve rather than break their rule against eating pork. What simple practical rules could animals obey which, under normal conditions, would have the indirect effect of benefiting their close relations? If animals had a tendency to behave altruistically towards individuals who physically resembled them, they might indirectly be doing their kin a bit of good. Much would depend on details of the species concerned. Such a rule would, in any case, only lead to 'right' decisions in a statistical sense. If conditions changed, for example if a species started living in much larger groups, it could lead to wrong decisions. Conceivably, racial prejudice could be interpreted as an irrational generalization of a kin-selected tendency to identify with individuals physically resembling oneself, and to be nasty to individuals different in appearance. In a species whose members do not move around much, or whose members move around in small groups, the chances may be good that any random individual you come across is fairly close kin to you. In this case the rule 'Be nice to any member of the species whom you meet' could have positive survival value, in the sense that a gene predisposing its possessors to obey the rule might become more numerous in the gene pool. This may be why altruistic behaviour is so frequently reported in troops of monkeys and schools of whales. Whales and dolphins drown if they are not allowed to breathe air. Baby whales, and injured individuals who cannot swim to the surface have been seen to be rescued and held up by companions in the school. It is not known whether whales have ways of knowing who their close relatives are, but it is possible that it does not matter. It may be that the overall probability that a random member of the school is a relation is so high that the altruism is worth the cost. Incidentally, there is at least one well-authenticated story of a drowning human swimmer being rescued by a wild dolphin. This could be regarded as a misfiring of the rule for saving drowning members of the school. The rule's 'definition' of a member of the school who is drowning might be something like: 'A long thing thrashing about and choking near the surface.' Adult male baboons have been reported to risk their lives defending the rest of the troop against predators such as leopards. It is quite probable that any adult male has, on average, a fairly large number of genes tied up in other members of the troop. A gene that 'says', in effect: 'Body, if you happen to be an adult male, defend the troop against leopards', could become more numerous in the gene pool. Before leaving this often-quoted example, it is only fair to add that at least one respected authority has reported very different facts. According to her, adult males are the first over the horizon when a leopard appears. Baby chicks feed in family clutches, all following their mother. They have two main calls. In addition to the loud piercing cheep which I have already mentioned, they give short melodious twitters when feeding. The cheeps, which have the effect of summoning the mother's aid, are ignored by the other chicks. The twitters, however, are attractive to chicks. This means that when one chick finds food, its twitters attract other chicks to the food as well: in the terms of the earlier hypothetical example, the twitters are 'food calls'. As in that case, the apparent altruism of the chicks can easily be explained by kin selection. Since, in nature, the chicks would be all full brothers and sisters, a gene for giving the food twitter would spread, provided the cost to the twitterer is less than half the net benefit to the other chicks. As the benefit is shared out between the whole clutch, which normally numbers more than two, it is not difficult to imagine this condition being realized. Of course the rule misfires in domestic or farm situations when a hen is made to sit on eggs not her own, even turkey or duck eggs. But neither the hen nor her chicks can be expected to realize this. Their behaviour has been shaped under the conditions that normally prevail in nature, and in nature strangers are not normally found in your nest. Mistakes of this sort may, however, occasionally happen in nature. In species that live in herds or troops, an orphaned youngster may be adopted by a strange female, most probably one who has lost her own child. Monkey-watchers sometimes use the word 'aunt' for an adopting female. In most cases there is no evidence that she really is an aunt, or indeed any kind of relative: if monkey-watchers were as gene-conscious as they might be, they would not use an important word like 'aunt' so uncritically. In most cases we should probably regard adoption, however touching it may seem, as a misfiring of a built-in rule. This is because the generous female is doing her own genes no good by caring for the orphan. She is wasting time and energy which she could be investing in the lives of her own kin, particularly future children of her own. It is presumably a mistake that happens too seldom for natural selection to have 'bothered' to change the rule by making the maternal instinct more selective. In many cases, by the way, such adoptions do not occur, and an orphan is left to die. There is one example of a mistake which is so extreme that you may prefer to regard it not as a mistake at all, but as evidence against the selfish gene theory. This is the case of bereaved monkey mothers who have been seen to steal a baby from another female, and look after it. I see this as a double mistake, since the adopter not only wastes her own time; she also releases a rival female from the burden of child-rearing, and frees her to have another child more quickly. It seems to me a critical example which deserves some thorough research. We need to know how often it happens; what the average relatedness between adopter and child is likely to be; and what the attitude of the real mother of the child is - it is, after all, to her advantage that her child should be adopted; do mothers deliberately try to deceive naive young females into adopting their children? (It has also been suggested that adopters and baby-snatchers might benefit by gaining valuable practice in the art of child -rearing.) An example of a deliberately engineered misfiring of the maternal instinct is provided by cuckoos, and other 'brood-parasites'-birds that lay their eggs in somebody else's nest. Cuckoos exploit the rule built into bird parents: 'Be nice to any small bird sitting in the nest that you built.' Cuckoos apart, this rule will normally have the desired effect of restricting altruism to immediate kin, because it happens to be a fact that nests are so isolated from each other that the contents of your own nest are almost bound to be your own chicks. Adult herring gulls do not recognize their own eggs, and will happily sit on other gull eggs, and even crude wooden dummies if these are substituted by a human experimenter. In nature, egg recognition is not important for gulls, because eggs do not roll far enough to reach the vicinity of a neighbour's nest, some yards away. Gulls do, however, recognize their own chicks: chicks, unlike eggs, wander, and can easily end up near the nest of a neighbouring adult, often with fatal results, as we saw in Chapter 1. Guillemots, on the other hand, do recognize their own eggs by means of the speckling pattern, and actively discriminate in favour of them when incubating. This is presumably because they nest on flat rocks, where there is a danger of eggs rolling around and getting muddled up. Now, it might be said, why do they bother to discriminate and sit only on their own eggs? Surely if everybody saw to it that she sat on somebody's egg, it would not matter whether each particular mother was sitting on her own or somebody else's. This is the argument of a group selectionist. Just consider what would happen if such a group baby-sitting circle did develop. The average clutch size of the guillemot is one. This means that if the mutual baby-sitting circle is to work successfully, every adult would have to sit on an average of one egg. Now suppose somebody cheated, and refused to sit on an egg. Instead of wasting time sitting, she could spend her time laying more eggs. And the beauty of the scheme is that the other, more altruistic, adults would look after them for her. They would go on faithfully obeying the rule 'If you see a stray egg near your nest, haul it in and sit on it.' So the gene for cheating the system would spread through the population, and the nice friendly baby-sitting circle would break down. 'Well', it might be said, 'what if the honest birds retaliated by refusing to be blackmailed, and resolutely decided to sit on one egg and only one egg? That should foil the cheaters, because they would see their own eggs lying out on the rocks with nobody incubating them. That should soon bring them into line.' Alas, it would not. Since we are postulating that the sitters are not discriminating one egg from another, if the honest birds put into practice this scheme for resisting cheating, the eggs that ended up being neglected would be just as likely to be their own eggs as those of the cheaters. The cheaters would still have the advantage, because they would lay more eggs and have more surviving children. The only way an honest guillemot could beat the cheaters would be to discriminate actively in favour of her own eggs. That is, to cease being altruistic and look after her own interests. To use the language of Maynard Smith, the altruistic adoption 'strategy' is not an evolutionarily stable strategy. It is unstable in the sense that it can be bettered by a rival selfish strategy of laying more than one's fair share of eggs, and then refusing to sit on them. This latter selfish strategy is in its turn unstable, because the altruistic strategy which it exploits is unstable, and will disappear. The only evolutionarily stable strategy for a guillemot is to recognize its own egg, and sit exclusively on its own egg, and this is exactly what happens. The song-bird species that are parasitized by cuckoos have fought back, not in this case by learning the appearance of their own eggs, but by discriminating instinctively in favour of eggs with the species-typical markings. Since they are not in danger of being parasitized by members of their own species, this is effective. But the cuckoos have retaliated in their turn by making their eggs more and more like those of the host species in colour, size, and markings. This is an example of a lie, and it often works. The result of this evolutionary arms race has been a remarkable perfection of mimicry on the part of the cuckoo eggs. We may suppose that a proportion of cuckoo eggs and chicks are 'found out', and those that are not found out are the ones who live to lay the next generation of cuckoo eggs. So genes for more effective deception spread through the cuckoo gene pool. Similarly, those host birds with eyes sharp enough to detect any slight imperfection in the cuckoo eggs' mimicry are the ones that contribute most to their own gene pool. Thus sharp and sceptical eyes are passed on to their next generation. This is a good example of how natural selection can sharpen up active discrimination, in this case discrimination against another species whose members are doing their best to foil the discriminators. Now let us return to the comparison between an animal's 'estimate' of its kinship with other members of its group, and the corresponding estimate of an expert field naturalist. Brian Bertram has spent many years studying the biology of lions in the Serengeti National Park. On the basis of his knowledge of their reproductive habits, he has estimated the average relatedness between individuals in a typical lion pride. The facts that he uses to make his estimates are things like this. A typical pride consists of seven adult females who are its more permanent members, and two adult males who are itinerant. About half the adult females give birth as a batch at the same time, and rear their cubs together so that it is difficult to tell which cub belongs to whom. The typical litter size is three cubs. The fathering of litters is shared equally between the adult males in the pride. Young females remain in the pride and replace old females who die or leave. Young males are driven out when adolescent. When they grow up, they wander around from pride to pride in small related gangs or pairs, and are unlikely to return to their original family. Using these and other assumptions, you can see that it would be possible to compute an average figure for the relatedness of two individuals from a typical lion pride. Bertram arrives at a figure of 0.22 for a pair of randomly chosen males, and 0.15 for a pair of females. That is to say, males within a pride are on average slightly less close than half brothers, and females slightly closer than first cousins. Now, of course, any particular pair of individuals might be full brothers, but Bertram had no way of knowing this, and it is a fair bet that the lions did not know it either. On the other hand, the average figures that Bertram estimated are available to the lions themselves in a certain sense. If these figures really are typical for an average lion pride, then any gene that predisposed males to behave towards other males as if they were nearly half brothers would have positive survival value. Any gene that went too far and made males behave in a friendly way more appropriate to full brothers would on average be penalized, as would a gene for not being friendly enough, say treating other males like second cousins. If the facts of lion life are as Bertram says, and, just as important, if they have been like that for a large number of generations, then we may expect that natural selection will have favoured a degree of altruism appropriate to the average degree of relatedness in a typical pride. This is what I meant when I said that the kinship estimates of animal and of good naturalist might end up rather the same. So we conclude that the 'true' relatedness may be less important in the evolution of altruism than the best estimate of relatedness that animals can get. This fact is probably a key to understanding why parental care is so much more common and more devoted than brother/sister altruism in nature, and also why animals may value themselves more highly even than several brothers. Briefly, what I am saying is that, in addition to the index of relatedness, we should consider something like an index of 'certainty'. Although the parent/ child relationship is no closer genetically than the brother/sister relationship, its certainty is greater. It is normally possible to be much more certain who your children are than who your brothers are. And you can be more certain still who you yourself are! We considered cheaters among guillemots, and we shall have more to say about liars and cheaters and exploiters in following chapters. In a world where other individuals are constantly on the alert for opportunities to exploit kin-selected altruism, and use it for their own ends, a survival machine has to consider who it can trust, who it can be really sure of. If B is really my baby brother, then I should care for him up to half as much as I care for myself, and fully as much as I care for my own child. But can I be as sure of him as I can of my own child? How do I know he is my baby brother? If C is my identical twin, then I should care for him twice as much as I care for any of my children, indeed I should value his life no less than my own. But can I be sure of him? He looks like me to be sure, but it could be that we just happen to share the genes for facial features. No, I will not give up my life for him, because although it is possible that he bears 100 per cent of my genes, I absolutely know that I contain 100 per cent of my genes, so I am worth more to me than he is. I am the only individual that any one of my selfish genes can be sure of. And although ideally a gene for individual selfishness could be displaced by a rival gene for altruistically saving at least one identical twin, two children or brothers, or at least four grandchildren etc., the gene for individual selfishness has the enormous advantage of certainty of individual identity. The rival kin-altruistic gene runs the risk of making mistakes of identity, either genuinely accidental, or deliberately engineered by cheats and parasites. We therefore must expect individual selfishness in nature, to an extent greater than would be predicted by considerations of genetic relatedness alone. In many species a mother can be more sure of her young than a father can. The mother lays the visible, tangible egg, or bears the child. She has a good chance of knowing for certain the bearers of her own genes. The poor father is much more vulnerable to deception. It is therefore to be expected that fathers will put less effort than mothers into caring for young. We shall see that there are other reasons to expect the same thing, in the chapter on the Battle of the Sexes (Chapter 9). Similarly, maternal grandmothers can be more sure of their grandchildren than paternal grandmothers can, and might be expected to show more altruism than paternal grandmothers. This is because they can be sure of their daughter's children, but their son may have been cuckolded. Maternal grandfathers are just as sure of their grandchildren as paternal grandmothers are, since both can reckon on one generation of certainty and one generation of uncertainty. Similarly, uncles on the mother's side should be more interested in the welfare of nephews and nieces than uncles on the father's side, and in general should be just as altruistic as aunts are. Indeed in a society with a high degree of marital infidelity, maternal uncles should be more altruistic than 'fathers' since they have more grounds for confidence in their relatedness to the child. They know that the child's mother is at least their half-sister. The 'legal' father knows nothing. I do not know of any evidence bearing on these predictions, but I offer them in the hope that others may, or may start looking for evidence. In particular, perhaps social anthropologists might have interesting things to say. Returning to the fact that parental altruism is more common than fraternal altruism, it does seem reasonable to explain this in terms of the 'identification problem'. But this does not explain the fundamental asymmetry in the parent/child relationship itself. Parents care more for their children than children do for their parents, although the genetic relationship is symmetrical, and certainty of relatedness is just as great both ways. One reason is that parents are in a better practical position to help their young, being older and more competent at the business of living. Even if a baby wanted to feed its parents, it is not well equipped to do so in practice. There is another asymmetry in the parent/child relationship which does not apply to the brother/sister one. Children are always younger than their parents. This often, though not always means they have a longer expectation of life. As I emphasized above, expectation of life is an important variable which, in the best of all possible worlds, should enter into an animal's 'calculation' when it is 'deciding' whether to behave altruistically or not. In a species in which children have a longer average life expectancy than parents, any gene for child altruism would be labouring under a disadvantage. It would be engineering altruistic self-sacrifice for the benefit of individuals who are nearer to dying of old age than the altruist itself. A gene for parent altruism, on the other hand, would have a corresponding advantage as far as the life-expectancy terms in the equation were concerned. One sometimes hears it said that kin selection is all very well as a theory, but there are few examples of its working in practice. This criticism can only be made by someone who does not understand what kin selection means. The truth is that all examples of child-protection and parental care, and all associated bodily organs, milk-secreting glands, kangaroo pouches, and so on, are examples of the working in nature of the kin-selection principle. The critics are of course familiar with the widespread existence of parental care, but they fail to understand that parental care is no less an example of kin selection than brother/sister altruism. When they say they want examples, they mean that they want examples other than parental care, and it is true that such examples are less common. I have suggested reasons why this might be so. I could have gone out of my way to quote examples of brother/sister altruism-there are in fact quite a few. But I don't want to do this, because it would reinforce the erroneous idea (favoured, as we have seen, by Wilson) that kin selection is specifically about relationships other than the parent/ child relationship.",
        "char_count": 51908
      },
      {
        "heading": "Chapter 8",
        "text": "The Selfish Gene 7. Family planning. It is easy to see why some people have wanted to separate parental care from the other kinds of kin-selected altruism. Parental care looks like an integral part of reproduction whereas, for example, altruism toward a nephew is not. I think there really is an important distinction hidden here, but that people have mistaken what the distinction is. They have put reproduction and parental care on one side, and other sorts of altruism on the other. But I wish to make a distinction between bringing new individuals into the world, on the one hand, and caring for existing individuals on the other. I shall call these two activities respectively child-bearing and child-caring. An individual survival machine has to make two quite different sorts of decisions, caring decisions and bearing decisions. I use the word decision to mean unconscious strategic move. The caring decisions are of this form: 'There is a child; its degree of relatedness to me is so and so; its chances of dying if I do not feed it are such and such; shall I feed it?' Bearing decisions, on the other hand, are like this: 'Shall I take whatever steps are necessary in order to bring a new individual into the world; shall I reproduce?' To some extent, caring and bearing are bound to compete with each other for an individual's time and other resources: the individual may have to make a choice: 'Shall I care for this child or shall I bear a new one?' Depending on the ecological details of the species, various mixes of caring and bearing strategies can be evolutionarily stable. The one thing that cannot be evolutionarily stable is a pure caring strategy. If all individuals devoted themselves to caring for existing children to such an extent that they never brought any new ones into the world, the population would quickly become invaded by mutant individuals who specialized in bearing. Caring can only be evolutionarily stable as part of a mixed strategy-at least some bearing has to go on. The reason this error has grown up is largely historical. The evolutionary advantage of parental care is so obvious that we did not have to wait for Hamilton to point it out It has been understood ever since Darwin. When Hamilton demonstrated the genetic equivalence of other relationships, and their evolutionary significance, he naturally had to lay stress on these other relationships. In particular, he drew examples from the social insects such as ants and bees, in which the sister/sister relationship is particularly important, as we shall see in a later chapter. I have even heard people say that they thought Hamilton's theory applied only to the social insects! If anybody does not want to admit that parental care is an example of kin selection in action, then the onus is on him to formulate a general theory of natural selection that predicts parental altruism, but that does not predict altruism between collateral kin. I think he will fail. The species with which we are most familiar-mammals and birds-tend to be great carers. A decision to bear a new child is usually followed by a decision to care for it. It is because bearing and caring so often go together in practice that people have muddled the two things up. But from the point of view of the selfish genes there is, as we have seen, no distinction in principle between caring for a baby brother and caring for a baby son. Both infants are equally closely related to you. If you have to choose between feeding one or the other, there is no genetic reason why you should choose your own son. But on the other hand you cannot, by definition, bear a baby brother. You can only care for him once somebody else has brought him into the world. In the last chapter we looked at how individual survival machines ideally should decide whether to behave altruistically towards other individuals who already exist. In this chapter we look at how they should decide whether to bring new individuals into the world. It is over this matter that the controversy about 'group selection', which I mentioned in Chapter 1, has chiefly raged. This is because Wynne-Edwards, who has been mainly responsible for promulgating the idea of group selection, did so in the context of a theory of 'population regulation'. He suggested that individual animals deliberately and altruistically reduce their birth rates for the good of the group as a whole. This is a very attractive hypothesis, because it fits so well with what individual humans ought to do. Mankind is having too many children. Population size depends upon four things: births, deaths, immigrations and emigrations. Taking the world population as a whole, immigrations and emigrations do not occur, and we are left with births and deaths. So long as the average number of children per couple is larger than two surviving to reproduce, the numbers of babies born will tend to increase over the years at an ever-accelerating rate. In each generation the population, instead of going up by a fixed amount, increases by something more like a fixed proportion of the size that it has already reached. Since this size is itself getting bigger, the size of the increment gets bigger. If this kind of growth was allowed to go on unchecked, a population would reach astronomical proportions surprisingly quickly. Incidentally, a thing that is sometimes not realized even by people who worry about population problems is that population growth depends on when people have children, as well as on how many they have. Since populations tend to increase by a certain proportion per generation, it follows that if you space the generations out more, the population will grow at a slower rate per year. Banners that read 'Stop at Two' could equally well be changed to 'Start at Thirty'! But in any case, accelerating population growth spells serious trouble. We have probably all seen examples of the startling calculations that can be used to bring this home. For instance, the present population of Latin America is around 300 million, and already many of them are under-nourished. But if the population continued to increase at the present rate, it would take less than 500 years to reach the point where the people, packed in a standing position, formed a solid human carpet over the whole area of the continent. This is so, even if we assume them to be very skinny-a not unrealistic assumption. In 1,000 years from now they would be standing on each other's shoulders more than a million deep. By 2,000 years, the mountain of people, travelling outwards at the speed of light, would have reached the edge of the known universe. It will not have escaped you that this is a hypothetical calculation! It will not really happen like that for some very good practical reasons. The names of some of these reasons are famine, plague, and war; or, if we are lucky, birth control. It is no use appealing to advances in agricultural science-'green revolutions' and the like. Increases in food production may temporarily alleviate the problem, but it is mathematically certain that they cannot be a long-term solution; indeed, like the medical advances that have precipitated the crisis, they may well make the problem worse, by speeding up the rate of the population expansion. It is a simple logical truth that, short of mass emigration into space, with rockets taking off at the rate of several million per second, uncontrolled birth-rates are bound to lead to horribly increased death-rates. It is hard to believe that this simple truth is not understood by those leaders who forbid their followers to use effective contraceptive methods. They express a preference for 'natural' methods of population limitation, and a natural method is exactly what they are going to get. It is called starvation. But of course the unease that such long-term calculations arouse is based on concern for the future welfare of our species as a whole. Humans (some of them) have the conscious foresight to see ahead to the disastrous consequences of over-population. It is the basic assumption of this book that survival machines in general are guided by selfish genes, who most certainly cannot be expected to see into the future, nor to have the welfare of the whole species at heart. This is where Wynne-Edwards parts company with orthodox evolutionary theorists. He thinks there is a way in which genuine altruistic birth-control can evolve. A point that is not emphasized in the writings of Wynne-Edwards, or in Ardrey's popularization of his views, is that there is a large body of agreed facts that are not in dispute. It is an obvious fact that wild animal populations do not grow at the astronomical rates of which they are theoretically capable. Sometimes wild animal populations remain rather stable, with birth-rates and death-rates roughly keeping pace with each other. In many cases, lemmings being a famous example, the population fluctuates widely, with violent explosions alternating with crashes and near extinction. Occasionally the result is outright extinction, at least of the population in a local area. Sometimes, as in the case of the Canadian lynx-where estimates are obtained from the numbers of pelts sold by the Hudson's Bay Company in successive years-the population seems to oscillate rhythmically. The one thing animal populations do not do is go on increasing indefinitely. Wild animals almost never die of old age: starvation, disease, or predators catch up with them long before they become really senile. Until recently this was true of man too. Most animals die in childhood, many never get beyond the egg stage. Starvation and other causes of death are the ultimate reasons why populations cannot increase indefinitely. But as we have seen for our own species, there is no necessary reason why it ever has to come to that. If only animals would regulate their birth-rates, starvation need never happen. It is Wynne-Edwards's thesis that that is exactly what they do. But even here there is less disagreement than you might think from reading his book. Adherents of the selfish gene theory would readily agree that animals do regulate their birth-rates. Any given species tends to have a rather fixed clutch-size or litter-size: no animal has an infinite number of children. The disagreement comes not over whether birth-rates are regulated. The disagreement is over why they are regulated: by what process of natural selection has family-planning evolved? In a nutshell, the disagreement is over whether animal birth-control is altruistic, practised for the good of the group as a whole; or selfish, practised for the good of the individual doing the reproducing. I will deal with the two theories in order. Wynne-Edwards supposed that individuals have fewer children than they are capable of, for the benefit of the group as a whole. He recognized that normal natural selection cannot possibly give rise to the evolution of such altruism: the natural selection of lower-than-average reproductive rates is, on the face of it, a contradiction in terms. He therefore invoked group selection, as we saw in Chapter 1. According to him, groups whose individual members restrain their own birth-rates are less likely to go extinct than rival groups whose individual members reproduce so fast that they endanger the food supply. Therefore the world becomes populated by groups of restrained breeders. The individual restraint that Wynne-Edwards is suggesting amounts in a general sense to birth-control, but he is more specific than this, and indeed comes up with a grand conception in which the whole of social life is seen as a mechanism of population regulation. For instance, two major features of social life in many species of animals are territoriality and dominance hierarchies, already mentioned in Chapter 5. Many animals devote a great deal of time and energy to apparently defending an area of ground which naturalists call a territory. The phenomenon is very widespread in the animal kingdom, not only in birds, mammals, and fish, but in insects and even sea-anemones. The territory may be a large area of woodland which is the principal foraging ground of a breeding pair, as in the case of robins. Or, in herring gulls for instance, it may be a small area containing no food, but with a nest at its centre. Wynne-Edwards believes that animals who fight over territory are fighting over a token prize, rather than an actual prize like a bit of food. In many cases females refuse to mate with males who do not possess a territory. Indeed it often happens that a female whose mate is defeated and his territory conquered promptly attaches herself to the victor. Even in apparently faithful monogamous species, the female may be wedded to a male's territory rather than to him personally. If the population gets too big, some individuals will not get territories, and therefore will not breed. Winning a territory is therefore, to Wynne-Edwards, like winning a ticket or licence to breed. Since there is a finite number of territories available, it is as if a finite number of breeding licences is issued. Individuals may fight over who gets these licences, but the total number of babies that the population can have as a whole is limited by the number of territories available. In some cases, for instance in red grouse, individuals do, at first sight, seem to show restraint, because those who cannot win territories not only do not breed; they also appear to give up the struggle to win a territory. It is as though they all accepted the rules of the game: that if, by the end of the competition season, you have not secured one of the official tickets to breed, you voluntarily refrain from breeding and leave the lucky ones unmolested during the breeding season, so that they can get on with propagating the species. Wynne-Edwards interprets dominance hierarchies in a similar way. In many groups of animals, especially in captivity, but also in some cases in the wild, individuals learn each other's identity, and they learn whom they can beat in a fight, and who usually beats them. As we saw in Chapter 5, they tend to submit without a struggle to individuals who they 'know' are likely to beat them anyway. As a result a naturalist is able to describe a dominance hierarchy or 'peck order' (so called because it was first described for hens)-a rank-ordering of society in which everybody knows his place, and does not get ideas above his station. Of course sometimes real earnest fights do take place, and sometimes individuals can win promotion over their former immediate bosses. But we saw in Chapter 5, the overall effect of the automatic submission by lower-ranking individuals is that few prolonged fights actually take place, and serious injuries seldom occur. Many people think of this as a 'good thing' in some vaguely group-selectionist way. Wynne-Edwards has an altogether more daring interpretation. High-ranking individuals are more likely to breed than low-ranking individuals, either because they are preferred by females, or because they physically prevent low-ranking males from getting near females. Wynne-Edwards sees high social rank as another ticket of entitlement to reproduce. Instead of fighting directly over females themselves, individuals fight over social status, and then accept that if they do not end up high on the social scale they are not entitled to breed. They restrain themselves where females are directly concerned, though they may try even now and then to win higher status, and therefore could be said to compete indirectly over females. But, as in the case of territorial behaviour, the result of this Voluntary acceptance' of the rule that only high-status males should breed is, according to Wynne-Edwards, that populations do not grow too fast. Instead of actually having too many children, and then finding out the hard way that it was a mistake, populations use formal contests over status and territory as a means of limiting their size slightly below the level at which starvation itself actually takes its toll. Perhaps the most startling of Wynne-Edwards's ideas is that of epideictic behaviour, a word that he coined himself. Many animals spend a great deal of time in large flocks, herds, or shoals. Various more or less common-sense reasons why such aggregating behaviour should have been favoured by natural selection have been suggested, and I will talk about some of them in Chapter 10. Wynne-Edwards's idea is quite different. He proposes that when huge flocks of starlings mass at evening, or crowds of midges dance over a gatepost, they are performing a census of their population. Since he is supposing that individuals restrain their birth-rates in the interests of the group as a whole, and have fewer babies when the population density is high, it is reasonable that they should have some way of measuring the population density. Just so; a thermostat needs a thermometer as an integral part of its mechanism. For Wynne-Edwards, epideictic behaviour is deliberate massing in crowds to facilitate population estimation. He is not suggesting conscious population estimation, but an automatic nervous or hormonal mechanism linking the individuals' sensory perception of the density of their population with their reproductive systems. I have tried to do justice to Wynne-Edwards's theory, even if rather briefly. If I have succeeded, you should now be feeling persuaded that it is, on the face of it, rather plausible. But the earlier chapters of this book should have prepared you to be sceptical to the point of saying that, plausible as it may sound, the evidence for Wynne-Edwards's theory had better be good, or else. ... And unfortunately the evidence is not good. It consists of a large number of examples which could be interpreted in his way, but which could equally well be interpreted on more orthodox 'selfish gene' lines. Although he would never have used that name, the chief architect of the selfish gene theory of family planning was the great ecologist David Lack. He worked especially on clutch-size in wild birds, but his theories and conclusions have the merit of being generally applicable. Each bird species tends to have a typical clutch size. For instance, gannets and guillemots incubate one egg at a time, swifts three, great tits half a dozen or more. There is variation in this: some swifts lay only two at a time, great tits may lay twelve. It is reasonable to suppose that the number of eggs a female lays and incubates is at least partly under genetic control, like any other characteristic. That is say there may be a gene for laying two eggs, a rival allele for laying three, another allele for laying four, and so on, although in practice it is unlikely to be quite as simple as this. Now the selfish gene theory requires us to ask which of these genes will become more numerous in the gene pool. Superficially it might seem that the gene for laying four eggs is bound to have an advantage over the genes for laying three or two. A moment's reflection shows that this simple 'more means better' argument cannot be true, however. It leads to the expectation that five eggs should be better than four, ten better still, 100 even better, and infinity best of all. In other words it leads logically to an absurdity. Obviously there are costs as well as benefits in laying a large number of eggs. Increased bearing is bound to be paid for in less efficient caring. Lack's essential point is that for any given species, in any given environmental situation, there must be an optimal clutch size. Where he differs from Wynne-Edwards is in his answer to the question 'optimal from whose point of view?'. Wynne-Edwards would say the important optimum, to which all individuals should aspire, is the optimum for the group as a whole. Lack would say each selfish individual chooses the clutch size that maximizes the number of children she rears. If three is the optimum clutch size for swifts, what this means, for Lack, is that any individual who tries to rear four will probably end up with fewer children than rival, more cautious individuals who only try to rear three. The obvious reason for this would be that the food is so thinly spread between the four babies that few of them survive to adulthood. This would be true both of the original allocation of yolk to the four eggs, and of the food given to the babies after hatching. According to Lack, therefore, individuals regulate their clutch size for reasons that are anything but altruistic. They are not practising birth-control in order to avoid over-exploiting the group's resources. They are practising birth-control in order to maximize the number of surviving children they actually have, an aim which is the very opposite of that which we normally associate with birth-control. Rearing baby birds is a costly business. The mother has to invest a large quantity of food and energy in manufacturing eggs. Possibly with her mate's help, she invests a large effort in building a nest to hold her eggs and protect them. Parents spend weeks patiently sitting on the eggs. Then, when the babies hatch out, the parents work themselves nearly to death fetching food for them, more or less non-stop without resting. As we have already seen, a parent great tit brings an average of one item of food to the nest every 30 seconds of daylight. Mammals such as ourselves do it in a slightly different way, but the basic idea of reproduction being a costly affair, especially for the mother, is no less true. It is obvious that if a parent tries to spread her limited resources of food and effort among too many children, she will end up rearing fewer than if she had set out with more modest ambitions. She has to strike a balance between bearing and caring. The total amount of food and other resources which an individual female, or a mated pair, can muster is the limiting factor determining the number of children they can rear. Natural selection, according to the Lack theory, adjusts initial clutch size (litter size etc.) so as to take maximum advantage of these limited resources. Individuals who have too many children are penalized, not because the whole population goes extinct, but simply because fewer of their children survive. Genes for having too many children are just not passed on to the next generation in large numbers, because few of the children bearing these genes reach adulthood. What has happened in modern civilized man is that family sizes are no longer limited by the finite resources that the individual parents can provide. If a husband and wife have more children than they can feed, the state, which means the rest of the population, simply steps in and keeps the surplus children alive and healthy. There is, in fact, nothing to stop a couple with no material resources at all having and rearing precisely as many children as the woman can physically bear. But the welfare state is a very unnatural thing. In nature, parents who have more children than they can support do not have many grandchildren, and their genes are not passed on to future generations. There is no need for altruistic restraint in the birth-rate, because there is no welfare state in nature. Any gene for overindulgence is promptly punished: the children containing that gene starve. Since we humans do not want to return to the old selfish ways where we let the children of too-large families starve to death, we have abolished the family as a unit of economic self-sufficiency, and substituted the state. But the privilege of guaranteed support for children should not be abused. Contraception is sometimes attacked as 'unnatural'. So it is, very unnatural. The trouble is, so is the welfare state. I think that most of us believe the welfare state is highly desirable. But you cannot have an unnatural welfare state, unless you also have unnatural birth-control, otherwise the end result will be misery even greater than that which obtains in nature. The welfare state is perhaps the greatest altruistic system the animal kingdom has ever known. But any altruistic system is inherently unstable, because it is open to abuse by selfish individuals, ready to exploit it. Individual humans who have more children than they are capable of rearing are probably too ignorant in most cases to be accused of conscious malevolent exploitation. Powerful institutions and leaders who deliberately encourage them to do so seem to me less free from suspicion. Returning to wild animals, the Lack clutch-size argument can be generalized to all the other examples Wynne-Edwards uses: territorial behaviour, dominance hierarchies, and so on. Take, for instance, the red grouse that he and his colleagues have worked on. These birds eat heather, and they parcel out the moors in territories containing apparently more food than the territory owners actually need. Early in the season they fight over territories, but after a while the losers seem to accept that they have failed, and do not fight any more. They become outcasts who never get territories, and by the end of the season they have mostly starved to death. Only territory owners breed. That non-territory owners are physically capable of breeding is shown by the fact that if a territory owner is shot his place is promptly filled by one of the former outcasts, who then breeds. Wynne-Edwards's interpretation of this extreme territorial behaviour is, as we have seen, that the outcasts 'accept' that they have failed to gain a ticket or licence to breed; they do not try to breed. On the face of it, this seems an awkward example for the selfish gene theory to explain. Why don't the outcasts try, try, and try again to oust a territory holder, until they drop from exhaustion? They would seem to have nothing to lose. But wait, perhaps they do have something to lose. We have already seen that if a territory-holder should happen to die, an outcast has a chance of taking his place, and therefore of breeding. If the odds of an outcast's succeeding to a territory in this way are greater than the odds of his gaining one by fighting, then it may pay him, as a selfish individual, to wait in the hope that somebody will die, rather than squander what little energy he has in futile fighting. For Wynne-Edwards, the role of the outcasts in the welfare of the group is to wait in the wings as understudies, ready to step into the shoes of any territory holder who dies or. the main stage of group reproduction. We can now see that this may also be their best strategy purely as selfish individuals. As we saw in Chapter 4, we can regard animals as gamblers. The best strategy for a gambler may sometimes be a wait-and-hope strategy, rather than a bull-at-a-gate strategy. Similarly, the many other examples where animals appear to 'accept' non-reproductive status passively can be explained quite easily by the selfish gene theory. The general form of the explanation is always the same: the individual's best bet is to restrain himself for the moment, in the hope of better chances in the future. A seal who leaves the harem-holders unmolested is not doing it for the good of the group. He is biding his time, waiting for a more propitious moment. Even if the moment never comes and he ends up without descendants, the gamble might have paid off, though, with hindsight we can see that for him it did not. And when lemmings flood in their millions away from the centre of a population explosion, they are not doing it in order to reduce the density of the area they leave behind! They are seeking, every selfish one of them, a less crowded place in which to live. The fact that any particular one may fail to find it, and dies, is something we can see with hindsight. It does not alter the likelihood that to stay behind would have been an even worse gamble. It is a well-documented fact that overcrowding sometimes reduces birth-rates. This is sometimes taken to be evidence for Wynne-Edwards's theory. It is nothing of the kind. It is compatible with his theory, and it is also just as compatible with the selfish gene theory. For example, in one experiment mice were put in an outdoor enclosure with plenty of food, and allowed to breed freely. The population grew up to a point, then levelled off. The reason for the levelling-off turned out to be that the females became less fertile as a consequence of over-crowding: they had fewer babies. This kind of effect has often been reported. Its immediate cause is often called 'stress', although giving it a name like that does not of itself help to explain it. In any case, whatever its immediate cause may be, we still have to ask about its ultimate, or evolutionary explanation. Why does natural selection favour females who reduce their birth-rate when their population is over-crowded? Wynne-Edwards's answer is clear. Group selection favours groups in which the females measure the population and adjust their birth-rates so that food supplies are not over-exploited. In the condition of the experiment, it so happened that food was never going to be scarce, but the mice could not be expected to realize that. They are programmed for life in the wild, and it is likely that in natural conditions over-crowding is a reliable indicator of future famine. What does the selfish gene theory say? Almost exactly the same thing, but with one crucial difference. You will remember that, according to Lack, animals will tend to have the optimum number of children from their own selfish point of view. If they bear too few or too many, they will end up rearing fewer than they would have if they had hit on just the right number. Now, 'just the right number' is likely to be a smaller number in a year when the population is overcrowded than in a year when the population is sparse. We have already agreed that over-crowding is likely to foreshadow famine. Obviously, if a female is presented with reliable evidence that a famine is to be expected, it is in her own selfish interests to reduce her own birth-rate. Rivals who do not respond to the warning signs in this way will end up rearing fewer babies, even if they actually bear more. We therefore end up with almost exactly the same conclusion as Wynne-Edwards, but we get there by an entirely different type of evolutionary reasoning. The selfish gene theory has no trouble even with 'epideictic displays'. You will remember that Wynne-Edwards hypothesized that animals deliberately display together in large crowds in order to make it easy for all the individuals to conduct a census, and regulate their birth-rates accordingly. There is no direct evidence that any aggregations are in fact epideictic, but just suppose some such evidence were found. Would the selfish gene theory be embarrassed? Not a bit. Starlings roost together in huge numbers. Suppose it were shown, not only that over-crowding in winter reduced fertility in the following spring, but that this was directly due to the birds' listening to each other's calls. It might be demonstrated experimentally that individuals exposed to a tape-recording of a dense and very loud starling roost laid fewer eggs than individuals exposed to a recording of a quieter, less dense, roost. By definition, this would indicate that the calls of starlings constituted an epideictic display. The selfish gene theory would explain it in much the same way as it handled the case of the mice. Again, we start from the assumption that genes for having a larger family than you can support are automatically penalized, and become less numerous in the gene pool. The task of an efficient egg-layer is one of predicting what is going to be the optimum clutch size for her, as a selfish individual, in the coming breeding season. You will remember from Chapter 4 the special sense in which we are using the word prediction. Now how can a female bird predict her optimum clutch size? What variables should influence her prediction? It may be that many species make a fixed prediction, which does not change from year to year. Thus on average the optimum clutch size for a gannet is one. It is possible that in particular bumper years for fish the true optimum for an individual might temporarily rise to two eggs. If there is no way for gannets to know in advance whether a particular year is going to be a bumper one, we cannot expect individual females to take the risk of wasting their resources on two eggs, when this would damage their reproductive success in an average year. But there may be other species, perhaps starlings, in which it is in principle possible to predict in winter whether the following spring is going to yield a good crop of some particular food resource. Country people have numerous old sayings suggesting that such clues as the abundance of holly berries may be good predictors of the weather in the coming spring. Whether any particular old wives' tale is accurate or not, it remains logically possible that there are such clues, and that a good prophet could in theory adjust her clutch size from year to year to her own advantage. Holly berries may be reliable predictors or they may not but, as in the case of the mice, it does seem quite likely that population density would be a good predictor. A female starling can in principle know that, when she comes to feed her babies in the coming spring, she will be competing for food with rivals of the same species. If she can somehow estimate the local density of her own species in winter, this could provide her with a powerful means of predicting how difficult it is going to be to get food for babies next spring. If she found the winter population to be particularly high, her prudent policy, from her own selfish point of view, might well be to lay relatively few eggs: her estimate of her own optimum clutch size would have been reduced. Now the moment it becomes true that individuals are reducing their clutch size on the basis of their estimate of population density, it will immediately be to the advantage of each selfish individual to pretend to rivals that the population is large, whether it really is or not. If starlings are estimating population size by the volume of noise in a winter roost, it would pay each individual to shout as loudly as possible, in order to sound more like two starlings than one. This idea of animals pretending to be several animals at once has been suggested in another context by J. R. Krebs, and is named the Beau Geste Effect after the novel in which a similar tactic was used by a unit of the French Foreign Legion. The idea in our case is to try to induce neighbouring starlings to reduce their clutch size to a level lower than the true optimum. If you are a starling who succeeds in doing this, it is to your selfish advantage, since you are reducing the numbers of individuals who do not bear your genes. I therefore conclude that Wynne-Edwards's idea of epideictic displays may actually be a good idea: he may have been right all along, but for the wrong reasons. More generally, the Lack type of hypothesis is powerful enough to account, in selfish gene terms, for all evidence that might seem to support the group-selection theory, should any such evidence turn up. Our conclusion from this chapter is that individual parents practise family planning, but in the sense that they optimize their birth-rates rather than restrict them for public good. They try to maximize the number of surviving children that they have, and this means having neither too many babies nor too few. Genes that make an individual have too many babies tend not to persist in the gene pool, because children containing such genes tend not to survive to adulthood. So much, then, for quantitative considerations of family size. We now come on to conflicts of interest within families. Will it always pay a mother to treat all her children equally, or might she have favourites? Should the family function as a single cooperating whole, or are we to expect selfishness and deception even within the family? Will all members of a family be working towards the same optimum, or will they 'disagree' about what the optimum is? These are the questions we try to answer in the next chapter. The related question of whether there may be conflict of interest between mates, we postpone until Chapter 9.",
        "char_count": 36392
      },
      {
        "heading": "Chapter 9",
        "text": "The Selfish Gene 8. Battle of the generations. Let us begin by tackling the first of the questions posed at the end of the last chapter. Should a mother have favourites, or should she be equally altruistic towards all her children? At the risk of being boring, I must yet again throw in my customary warning. The word 'favourite' carries no subjective connotations, and the word 'should' no moral ones. I am treating a mother as a machine programmed to do everything in its power to propagate copies of the genes which ride inside it. Since you and I are humans who know what it is like to have conscious purposes, it is convenient for me to use the language of purpose as a metaphor in explaining the behaviour of survival machines. In practice, what would it mean to say a mother had a favourite child? It would mean she would invest her resources unequally among her children. The resources that a mother has available to invest consist of a variety of things. Food is the obvious one, together with the effort expended in gathering food, since this in itself costs the mother something. Risk undergone in protecting young from predators is another resource which the mother can 'spend' or refuse to spend. Energy and time devoted to nest or home maintenance, protection from the elements, and, in some species, time spent in teaching children, are valuable resources which a parent can allocate to children, equally or unequally as she 'chooses'. It is difficult to think of a common currency in which to measure all these resources that a parent can invest. Just as human societies use money as a universally convertible currency which can be translated into food or land or labouring time, so we require a currency in which to measure resources that an individual survival machine may invest in another individual's life, in particular a child's life. A measure of energy such as the calorie is tempting, and some ecologists have devoted themselves to the accounting of energy costs in nature. This is inadequate though, because it is only loosely convertible into the currency that really matters, the 'gold-standard' of evolution, gene survival. R. L. Trivers, in 1972, neatly solved the problem with his concept of Parental Investment (although, reading between the close-packed lines, one feels that Sir Ronald Fisher, the greatest biologist of the twentieth century, meant much the same thing in 1930 by his 'parental expenditure'). Parental Investment (P.I.) is defined as 'any investment by the parent in an individual offspring that increases the offspring's chance of surviving (and hence reproductive success) at the cost of the parent's ability to invest in other offspring.' The beauty of Trivers's parental investment is that it is measured in units very close to the units that really matter. When a child uses up some of its mother's milk, the amount of milk consumed is measured not in pints, not in calories, but in units of detriment to other children of the same mother. For instance, if a mother has two babies, X and Y, and X drinks one pint of milk, a major part of the P.I. that this pint represents is measured in units of increased probability that Y will die because he did not drink that pint. P.I. is measured in units of decrease in life expectancy of other children, born or yet to be born. Parental investment is not quite an ideal measure, because it overemphasizes the importance of parentage, as against other genetic relationships. Ideally we should use a generalized altruism investment measure. Individual A may be said to invest in individual B, when A increases it's chance of surviving, at the cost of A's ability to invest in other individuals including herself, all costs being weighted by the appropriate relatedness. Thus a parent's investment in any one child should ideally be measured in terms of detriment to life expectancy not only of other children, but also of nephews, nieces, herself, etc. In many respects, however, this is just a quibble, and Trivers's measure is well worth using in practice. Now any particular adult individual has, in her whole lifetime, a certain total quantity of P.I. available to invest in children (and other relatives and in herself, but for simplicity we consider only children). This represents the sum of all the food she can gather or manufacture in a lifetime of work, all the risks she is prepared to take, and all the energy and effort that she is able to put into the welfare of children. How should a young female, setting out on her adult life, invest her life's resources? What would be a wise investment policy for her to follow? We have already seen from the Lack theory that she should not spread her investment too thinly among too many children. That way she will lose too many genes: she won't have enough grandchildren. On the other hand, she must not devote all her investment to too few children-spoilt brats. She may virtually guarantee herself some grandchildren, but rivals who invest in the optimum number of children will end up with more grandchildren. So much for even-handed investment policies. Our present interest is in whether it could ever pay a mother to invest unequally among her children, i.e. in whether she should have favourites. The answer is that there is no genetic reason for a mother to have favourites. Her relatedness to all her children is the same, 1/2. Her optimal strategy is to invest equally in the largest number of children that she can rear to the age when they have children of their own. But, as we have already seen, some individuals are better life insurance risks than others. An under-sized runt bears just as many of his mother's genes as his more thriving litter mates. But his life expectation is less. Another way to put this is that he needs more than his fair share of parental investment, just to end up equal to his brothers. Depending on the circumstances, it may pay a mother to refuse to feed a runt, and allocate all of his share of her parental investment to his brothers and sisters. Indeed it may pay her to feed him to his brothers and sisters, or to eat him herself, and use him to make milk. Mother pigs do sometimes devour their young, but I do not know whether they pick especially on runts. Runts constitute a particular example. We can make some more general predictions about how a mother's tendency to invest in a child might be affected by his age. If she has a straight choice between saving the life of one child or saving the life of another, and if the one she does not save is bound to die, she should prefer the older one. This is because she stands to lose a higher proportion of her life's parental investment if he dies than if his little brother dies. Perhaps a better way to put this is that if she saves the little brother she will still have to invest some costly resources in him just to get him up to the age of the big brother. On the other hand, if the choice is not such a stark life or death choice, her best bet might be to prefer the younger one. For instance, suppose her dilemma is whether to give a particular morsel of food to a little child or a big one. The big one is likely to be more capable of finding his own food unaided. Therefore if she stopped feeding him he would not necessarily die. On the other hand, the little one who is too young to find food for himself would be more likely to die if his mother gave the food to his big brother. Now, even though the mother would prefer the little brother to die rather than the big brother, she may still give the food to the little one, because the big one is unlikely to die anyway. This is why mammal mothers wean their children, rather than going on feeding them indefinitely throughout their lives. There comes a time in the life of a child when it pays the mother to divert investment from him into future children. When this moment comes, she will want to wean him. A mother who had some way of knowing that she had had her last child might be expected to continue to invest all her resources in him for the rest of her life, and perhaps suckle him well into adulthood. Nevertheless, she should 'weigh up' whether it would not pay her more to invest in grandchildren or nephews and nieces, since although these are half as closely related to her as her own children, their capacity to benefit from her investment may be more than double that of one of her own children. This seems a good moment to mention the puzzling phenomenon known as the menopause, the rather abrupt termination of a human female's reproductive fertility in middle age. This may not have occurred too commonly in our wild ancestors, since not many women would have lived that long anyway. But still, the difference between the abrupt change of life in women and the gradual fading out of fertility in men suggests that there is something genetically 'deliberate' about the menopause-that it is an 'adaptation'. It is rather difficult to explain. At first sight we might expect that a woman should go on having children until she dropped, even if advancing years made it progressively less likely that any individual child would survive. Surely it would seem always worth trying? But we must remember that she is also related to her grandchildren, though half as closely. For various reasons, perhaps connected with the Medawar theory of ageing , women in the natural state became gradually less efficient at bringing up children as they got older. Therefore the life expectancy of a child of an old mother was less than that of a child of a young mother. This means that, if a woman had a child and a grandchild born on the same day, the grandchild could expect to live longer than the child. When a woman reached the age where the average chance of each child reaching adulthood was just less than half the chance of each grandchild of the same age reaching adulthood, any gene for investing in grandchildren in preference to children would tend to prosper. Such a gene is carried by only one in four grandchildren, whereas the rival gene is carried by one in two children, but the greater expectation of life of the grandchildren outweighs this, and the 'grandchild altruism' gene prevails in the gene pool. A woman could not invest fully in her grandchildren if she went on having children of her own. Therefore genes for becoming reproductively infertile in middle age became more numerous, since they were carried in the bodies of grandchildren whose survival was assisted by grandmotherly altruism. This is a possible explanation of the evolution of the menopause in females. The reason why the fertility of males tails off gradually rather than abruptly is probably that males do not invest so much as females in each individual child anyway. Provided he can sire children by young women, it will always pay even a very old man to invest in children rather than in grandchildren. So far, in this chapter and in the last, we have seen everything from the parent's point of view, largely the mother's. We have asked whether parents can be expected to have favourites, and in general what is the best investment policy for a parent. But perhaps each child can influence how much his parents invest in him as against his brothers and sisters. Even if parents do not 'want' to show favouritism among their children, could it be that children grab favoured treatment for themselves? Would it pay them to do so? More strictly, would genes for selfish grabbing among children become more numerous in the gene pool than rival genes for accepting no more than one's fair share? This matter has been brilliantly analysed by Trivers, in a paper of 1974 called Parent-Offspring Conflict. A mother is equally related to all her children, born and to be born. On genetic grounds alone she should have no favourites, as we have seen. If she does show favouritism it should be based on differences in expectation of life, depending on age and other things. The mother, like any individual, is twice as closely 'related' to herself as she is to any of her children. Other things being equal, this means that she should invest most of her resources selfishly in herself, but other things are not equal. She can do her genes more good by investing a fair proportion of her resources in her children. This is because these are younger and more helpless than she is, and they can therefore benefit more from each unit of investment than she can herself. Genes for investing in more helpless individuals in preference to oneself can prevail in the gene pool, even though the beneficiaries may share only a proportion of one's genes. This is why animals show parental altruism, and indeed why they show any kind of kin-selected altruism. Now look at it from the point of view of a particular child. He is just as closely related to each of is brothers and sisters as his mother is to them. The relatedness is 1/2 in all cases. Therefore he 'wants' his mother to invest some of her resources in his brothers and sisters. Genetically speaking, he is just as altruistically disposed to them as his mother is. But again, he is twice as closely related to himself as he is to any brother or sister, and this will dispose him to want his mother to invest in him more than in any particular brother or sister, other things being equal. In this case other things might indeed be equal. If you and your brother are the same age, and both are in a position to benefit equally from a pint of mother's milk, you 'should' try to grab more than your fair share, and he should try to grab more than his fair share. Have you ever heard a litter of piglets squealing to be first on the scene when the mother sow lies down to feed them? Or little boys fighting over the last slice of cake? Selfish greed seems to characterize much of child behaviour. But there is more to it than this. If I am competing with my brother for a morsel of food, and if he is much younger than me so that he could benefit from the food more than I could, it might pay my genes to let him have it. An elder brother may have exactly the same grounds for altruism as a parent: in both cases, as we have seen, the relatedness is 1/2, and in both cases the younger individual can make better use of the resource than the elder. If I possess a gene for giving up food, there is a 50 per cent chance that my baby brother contains the same gene. Although the gene has double the chance of being in my own body-100 per cent, it is in my body-my need of the food maybe less than half as urgent. In general, a child 'should' grab more than his share of parental investment, but only up to a point. Up to what point? Up to the point where the resulting net cost to his brothers and sisters, born and potentially to be born, is just double the benefit of the grabbing to himself. Consider the question of when weaning should take place. A mother wants to stop suckling her present child so that she can prepare for the next one. The present child, on the other hand, does not want to be weaned yet, because milk is a convenient, trouble-free source of food, and he does not want to have to go out and work for his living. To be more exact, he does want eventually to go out and work for his living, but only when he can do his genes more good by leaving his mother free to rear his little brothers and sisters, than by staying behind himself. The older a child is, the less relative benefit does he derive from each pint of milk. This is because he is bigger, and a pint of milk is therefore a smaller proportion of his requirement, and also he is becoming more capable of fending for himself if he is forced to. Therefore when an old child drinks a pint that could have been invested in a younger child, he is taking relatively more parental investment for himself than when a young child drinks a pint. As a child grows older, there will come a moment when it would pay his mother to stop feeding him, and invest in a new child instead. Somewhat later there will come a time when the old child too would benefit his genes most by weaning himself. This is the moment when a pint of milk can do more good to the copies of his genes that may be present in his brothers and sisters than it can to the genes that are present in himself. The disagreement between mother and child is not an absolute one, but a quantitative one, in this case a disagreement over timing. The mother wants to go on suckling her present child up to the moment when investment in him reaches his 'fair' share, taking into account his expectation of life and how much she has already invested in him. Up to this point there is no disagreement. Similarly, both mother and child agree in not wanting him to go on sucking after the point when the cost to future children is more than double the benefit to him. But there is disagreement between mother and child during the intermediate period, the period when the child is getting more than his share as the mother sees it, but when the cost to other children is still less than double the benefit to him. Weaning time is just one example of a matter of dispute between mother and child. It could also be regarded as a dispute between one individual and all his future unborn brothers and sisters, with the mother taking the part of her future unborn children. More directly there may be competition between contemporary rivals for her investment, between litter mates or nest mates. Here, once again, the mother will normally be anxious to see fair play. Many baby birds are fed in the nest by their parents. They all gape and scream, and the parent drops a worm or other morsel in the open mouth of one of them. The loudness with which each baby screams is, ideally, proportional to how hungry he is. Therefore, if the parent always gives the food to the loudest screamer, they should all tend to get their fair share, since when one has had enough he will not scream so loudly. At least that is what would happen in the best of all possible worlds, if individuals did not cheat. But in the light of our selfish gene concept we must expect that individuals will cheat, will tell lies about how hungry they are. This will escalate, apparently rather pointlessly because it might seem that if they are all lying by screaming too loudly, this level of loudness will become the norm, and will cease, in effect, to be a lie. However, it cannot de-escalate, because any individual who takes the first step in decreasing the loudness of his scream will be penalized by being fed less, and is more likely to starve. Baby bird screams do not become infinitely loud, because of other considerations. For example, loud screams tend to attract predators, and they use up energy. Sometimes, as we have seen, one member of a litter is a runt, much smaller than the rest. He is unable to fight for food as strongly as the rest, and runts often die. We have considered the conditions under which it would actually pay a mother to let a runt die. We might suppose intuitively that the runt himself should go on struggling to the last, but the theory does not necessarily predict this. As soon as a runt becomes so small and weak that his expectation of life is reduced to the point where benefit to him due to parental investment is less than half the benefit that the same investment could potentially confer on the other babies, the runt should die gracefully and willingly. He can benefit his genes most by doing so. That is to say, a gene that gives the instruction 'Body, if you are very much smaller than your litter-mates, give up the struggle and die', could be successful in the gene pool, because it has a 50 per cent chance of being in the body of each brother and sister saved, and its chances of surviving in the body of the runt are very small anyway. There should be a point of no return in the career of a runt. Before he reaches this point he should go on struggling. As soon as he reaches it he should give up and preferably let himself be eaten by his litter-mates or his parents. I did not mention it when we were discussing Lack's theory of clutch size, but the following is a reasonable strategy for a parent who is undecided as to what is her optimum clutch size for the current year. She might lay one more egg than she actually 'thinks' is likely to be the true optimum. Then, if the year's food crop should turn out to be a better one than expected, she will rear the extra child. If not, she can cut her losses. By being careful always to feed the young in the same order, say in order of size, she sees to it that one, perhaps a runt, quickly dies, and not too much food is wasted on him, beyond the initial investment of egg yolk or equivalent. From the mother's point of view, this may be the explanation of the runt phenomenon. He represents the hedging of the mother's bets. This has been observed in many birds. Using our metaphor of the individual animal as a survival machine behaving as if it had the 'purpose' of preserving its genes, we can talk about a conflict between parents and young, a battle of the generations. The battle is a subtle one, and no holds are barred on either side. A child will lose no opportunity of cheating. It will pretend to be hungrier than it is, perhaps younger than it is, more in danger than it really is. It is too small and weak to bully its parents physically, but it uses every psychological weapon at its disposal: lying, cheating, deceiving, exploiting, right up to the point where it starts to penalize its relatives more than its genetic relatedness to them should allow. Parents, on the other hand, must be alert to cheating and deceiving, and must try not to be fooled by it. This might seem an easy task. If the parent knows that its child is likely to lie about how hungry it is, it might employ the tactic of feeding it a fixed amount and no more, even though the child goes on screaming. One trouble with this is that the child may not have been lying, and if it dies as a result of not being fed the parent would have lost some of its precious genes. Wild birds can die after being starved for only a few hours. A. Zahavi has suggested a particularly diabolical form of child blackmail: the child screams in such a way as to attract predators deliberately to the nest. The child is 'saying' 'Fox, fox, come and get me.' The only way the parent can stop it screaming is to feed it. So the child gains more than its fair share of food, but at a cost of some risk to itself. The principle of this ruthless tactic is the same as that of the hijacker threatening to blow up an aeroplane, with himself on board, unless he is given a ransom. I am sceptical about whether it could ever be favoured in evolution, not because it is too ruthless, but because I doubt if it could ever pay the blackmailing baby. He has too much to lose if a predator really came. This is clear for an only child, which is the case Zahavi himself considers. No matter how much his mother may already have invested in him, he should still value his own life more than his mother values it, since she has only half of his genes. Moreover, the tactic would not pay even if the blackmailer was one of a clutch of vulnerable babies, all in the nest together, since the blackmailer has a 50 per cent genetic 'stake' in each of his endangered brothers and sisters, as well as a 100 per cent stake in himself. I suppose the theory might conceivably work if the predominant predator had the habit of only taking the largest nestling from a nest. Then it might pay a smaller one to use the threat of summoning a predator, since it would not be greatly endangering itself. This is analogous to holding a pistol to your brother's head rather than threatening to blow yourself up. More plausibly, the blackmail tactic might pay a baby cuckoo. As is well known, cuckoo females lay one egg in each of several 'foster' nests, and then leave the unwitting foster-parents, of a quite different species, to rear the cuckoo young. Therefore a baby cuckoo has no genetic stake in his foster brothers and sisters. (Some species of baby cuckoo will not have any foster brothers and sisters, for a sinister reason which we shall come to. For the moment I assume we are dealing with one of those species in which foster brothers and sisters co-exist alongside the baby cuckoo.) If a baby cuckoo screamed loudly enough to attract predators, it would have a lot to lose-its life-but the foster mother would have even more to lose, perhaps four of her young. It could therefore pay her to feed it more than its share, and the advantage of this to the cuckoo might outweigh the risk. This is one of those occasions when it would be wise to translate back into respectable gene language, just to reassure ourselves that we have not become too carried away with subjective metaphors. What does it really mean to set up the hypothesis that baby cuckoos 'blackmail' their foster parents by screaming 'Predator, predator, come and get me and all my little brothers and sisters'? In gene terms it means the following. Cuckoo genes for screaming loudly became more numerous in the cuckoo gene pool because the loud screams increased the probability that the foster parents would feed the baby cuckoos. The reason the foster parents responded to the screams in this way was that genes for responding to the screams had spread through the gene pool of the foster-species. The reason these genes spread was that individual foster parents who did not feed the cuckoos extra food, reared fewer of their own children-fewer than rival parents who did feed their cuckoos extra. This was because predators were attracted to the nest by the cuckoo cries. Although cuckoo genes for not screaming were less likely to end up in the bellies of predators than screaming genes, the non-screaming cuckoos paid the greater penalty of not being fed extra rations. Therefore the screaming genes spread through the cuckoo gene pool. A similar chain of genetic reasoning, following the more subjective argument given above, would show that although such a blackmailing gene could conceivably spread through a cuckoo gene pool, it is unlikely to spread through the gene pool of an ordinary species, at least not for the specific reason that it attracted predators. Of course, in an ordinary species there could be other reasons for screaming genes to spread, as we have already seen, and these would incidentally have the effect of occasionally attracting predators. But here the selective influence of predation would be, if anything, in the direction of making the cries quieter. In the hypothetical case of the cuckoos, the net influence of predators, paradoxical as it sounds at first, could be to make the cries louder. There is no evidence, one way or the other, on whether cuckoos, and other birds of similar 'brood-parasitic' habit, actually employ the blackmail tactic. But they certainly do not lack ruthlessness. For instance, there are honey-guides who, like cuckoos, lay their eggs in the nests of other species. The baby honey-guide is equipped with a sharp, hooked beak. As soon as he hatches out, while he is still blind, naked, and otherwise helpless, he scythes and slashes his foster brothers and sisters to death: dead brothers do not compete for food! The familiar British cuckoo achieves the same result in a slightly different way. It has a short incubation-time, and so the baby cuckoo manages to hatch out before its foster brothers and sisters. As soon as it hatches, blindly and mechanically, but with devastating effectiveness, it throws the other eggs out of the nest. It gets underneath an egg, fitting it into a hollow in its back. Then it slowly backs up the side of the nest, balancing the egg between its wing-stubs, and topples the egg out on to the ground. It does the same with all the other eggs, until it has the nest, and therefore the attention of its foster parents, entirely to itself. One of the most remarkable facts I have learned in the past year was reported from Spain by F. Alvarez, L. Arias de Reyna, and H. Segura. They were investigating the ability of potential foster parents-potential victims of cuckoos-to detect intruders, cuckoo eggs or chicks. In the course of their experiments they had occasion to introduce into magpie nests the eggs and chicks of cuckoos, and, for comparison, eggs and chicks of other species such as swallows. On one occasion they introduced a baby swallow into a magpie's nest. The next day they noticed one of the magpie eggs lying on the ground under the nest. It had not broken, so they picked it up, replaced it, and watched. What they saw is utterly remarkable. The baby swallow, behaving exactly as if it was a baby cuckoo, threw the egg out. They replaced the egg again, and exactly the same thing happened. The baby swallow used the cuckoo method of balancing the egg on its back between its wing-stubs, and walking backwards up the side of the nest until the egg toppled out. Perhaps wisely, Alvarez and his colleagues made no attempt to explain their astonishing observation. How could such behaviour evolve in the swallow gene pool? It must correspond to something in the normal life of a swallow. Baby swallows are not accustomed to finding themselves in magpie nests. They are never normally found in any nest except their own. Could the behaviour represent an evolved anti-cuckoo adaptation? Has the natural selection been favouring a policy of counter-attack in the swallow gene pool, genes for hitting the cuckoo with his own weapons? It seems to be a fact that swallows' nests are not normally parasitized by cuckoos. Perhaps this is why. According to this theory, the magpie eggs of the experiment would be incidentally getting the same treatment, perhaps because, like cuckoo eggs, they are bigger than swallow eggs. But if baby swallows can tell the difference between a large egg and a normal swallow egg, surely the mother should be able to as well. In this case why is it not the mother who ejects the cuckoo egg, since it would be so much easier for her to do so than the baby? The same objection applies to the theory that the baby swallow's behaviour normally functions to remove addled eggs or other debris from the nest. Once again, this task could be-and is-performed better by the parent. The fact that the difficult and skilled egg-rejecting operation was seen to be performed by a weak and helpless baby swallow, whereas an adult swallow could surely do it much more easily, compels me to the conclusion that, from the parent's point of view, the baby is up to no good. It seems to me just conceivable that the true explanation has nothing to do with cuckoos at all. The blood may chill at the thought, but could this be what baby swallows do to each other? Since the firstborn is going to compete with his yet unhatched brothers and sisters for parental investment, it could be to his advantage to begin his life by throwing out one of the other eggs. The Lack theory of clutch size considered the optimum from the parent's point of view. If I am a mother swallow, the optimum clutch-size from my point of view is, say five. But if I am a baby swallow, the optimum clutch size as I see it may well be a smaller number, provided I am one of them! The parent has a certain amount of parental investment, which she 'wishes' to distribute even-handedly among five young. But each baby wants more than his allotted one fifth share. Unlike a cuckoo, he does not want all of it, because he is related to the other babies. But he does want more than one fifth. He can acquire a 1/4 share simply by tipping out one egg; a 1/3 share by tipping out another. Translating into gene language, a gene for fratricide could conceivably spread through the gene pool, because it has 100 per cent chance of being in the body of the fratricidal individual, and only a 50 per cent chance of being in the body of his victim. The chief objection to this theory is that it is very difficult to believe that nobody would have seen this diabolical behaviour if it really occurred. I have no convincing explanation for this. There are different races of swallow in different parts of the world. It is known that the Spanish race differs from, for example, the British one, in certain respects. The Spanish race has not been subjected to the same degree of intensive observation as the British one, and I suppose it is just conceivable that fratricide occurs but has been overlooked. My reason for suggesting such an improbable idea as the fratricide hypothesis here is that I want to make a general point. This is that the ruthless behaviour of a baby cuckoo is only an extreme case of what must go on in any family. Full brothers are more closely related to each other than a baby cuckoo is to its foster brothers, but the difference is only a matter of degree. Even if we cannot believe that outright fratricide could evolve, there must be numerous lesser examples of selfishness where the cost to the child, in the form of losses to his brothers and sisters, is outweighed, more than two to one, by the benefit to himself. In such cases, as in the example of weaning time, there is a real conflict of interest between parent and child. Who is most likely to win this battle of the generations? R. D. Alexander has written an interesting paper in which he suggests that there is a general answer to this question. According to him the parent will always win. Now if this is the case, you have been wasting your time reading this chapter. If Alexander is right, much that is of interest follows. For instance, altruistic behaviour could evolve, not because of benefit to the genes of the individual himself, but solely because of benefit to his parents' genes. Parental manipulation, to use Alexander's term, becomes an alternative evolutionary cause of altruistic behaviour, independent of straightforward kin selection. It is therefore important that we examine Alexander's reasoning, and convince ourselves that we understand why he is wrong. This should really be done mathematically, but we are avoiding explicit use of mathematics in this book, and it is possible to give an intuitive idea of what is wrong with Alexander's thesis. His fundamental genetic point is contained in the following abridged quotation. 'Suppose that a juvenile ... cause(s) an uneven distribution of parental benefits in its own favor, thereby reducing the mother's own overall reproduction. A gene which in this fashion improves an individual's fitness when it is a juvenile cannot fail to lower its fitness more when it is an adult, for such mutant genes will be present in an increased proportion of the mutant individual's offspring.' The fact that Alexander is considering a newly mutated gene is not fundamental to the argument. It is better to think of a rare gene inherited from one of the parents. 'Fitness' has the special technical meaning of reproductive success. What Alexander is basically saying is this. A gene that made a child grab more than his fair share when he was a child, at the expense of his parent's total reproductive output, might indeed increase his chances of surviving. But he would pay the penalty when he came to be a parent himself, because his own children would tend to inherit the same selfish gene, and this would reduce his overall reproductive success. He would be hoist with his own petard. Therefore the gene cannot succeed, and parents must always win the conflict. Our suspicions should be immediately aroused by this argument, because it rests on the assumption of a genetic asymmetry which is not really there. Alexander is using the words 'parent' and 'offspring' as though there was a fundamental genetic difference between them. As we have seen, although there are practical differences between parent and child, for instance parents are older than children, and children come out of parents' bodies, there is really no fundamental genetic asymmetry. The relatedness is 50 per cent, whichever way round you look at it. To illustrate what I mean, I am going to repeat Alexander's words, but with 'parent', 'juvenile' and other appropriate words reversed. 'Suppose that a parent has a gene that tends to cause an even distribution of parental benefits. A gene which in this fashion improves an individual's fitness when it is a parent could not fail to have lowered its fitness more when it was a juvenile.' We therefore reach the opposite conclusion to Alexander, namely that in any parent/offspring conflict, the child must win! Obviously something is wrong here. Both arguments have been put too simply. The purpose of my reverse quotation is not to prove the opposite point to Alexander, but simply to show that you cannot argue in that kind of artificially asymmetrical way. Both Alexander's argument, and my reversal of it, erred through looking at things from the point of view of an individual - in Alexander's case, the parent, in my case, the child. I believe this kind of error is all too easy to make when we use the technical term 'fitness'. This is why I have avoided using the word in this book. There is really only one entity whose point of view matters in evolution, and that entity is the selfish gene. Genes in juvenile bodies will be selected for their ability to outsmart parental bodies; genes in parental bodies will be selected for their ability to outsmart the young. There is no paradox in the fact that the very same genes successively occupy a juvenile body and a parental body. Genes are selected for their ability to make the best use of the levers of power at their disposal: they will exploit their practical opportunities. When a gene is sitting in a juvenile body its practical opportunities will be different from when it is sitting in a parental body. Therefore its optimum policy will be different in the two stages in its body's life history. There is no reason to suppose, as Alexander does, that the later optimum policy should necessarily overrule the earlier. There is another way of putting the argument against Alexander. He is tacitly assuming a false asymmetry between the parent/child relationship on the one hand, and the brother/sister relationship on the other. You will remember that, according to Trivers, the cost to a selfish child of grabbing more than his share, the reason why he only grabs up to a point, is the danger of loss of his brothers and sisters who each bear half his genes. But brothers and sisters are only a special case of relatives with a 50 per cent relatedness. The selfish child's own future children are no more and no less 'valuable' to him than his brothers and sisters. Therefore the total net cost of grabbing more than your fair share of resources should really be measured, not only in lost brothers and sisters, but also in lost future offspring due to their selfishness among themselves. Alexander's point about the disadvantage of juvenile selfishness spreading to your own children, thereby reducing your own long-term reproductive output, is well taken, but it simply means we must add this in to the cost side of the equation. An individual child will still do well to be selfish so long as the net benefit to him is at least half the net cost to close relatives. But 'close relatives' should be read as including, not just brothers and sisters, but future children of one's own as well. An individual should reckon his own welfare as twice as valuable as that of his brothers, which is the basic assumption Trivers makes. But he should also value himself twice as highly as one of his own future children. Alexander's conclusion that there is a built-in advantage on the parent's side in the conflict of interests is not correct. In addition to his fundamental genetic point, Alexander also has more practical arguments, stemming from undeniable asymmetries in the parent/child relationship. The parent is the active partner, the one who actually does the work to get the food, etc., and is therefore in a position to call the tune. If the parent decides to withdraw its labour, there is not much that the child can do about it, since it is smaller, and cannot hit back. Therefore the parent is in a position to impose its will, regardless of what the child may want. This argument is not obviously wrong, since in this case the asymmetry that it postulates is a real one. Parents really are bigger, stronger and more worldly-wise than children. They seem to hold all the good cards. But the young have a few aces up their sleeves too. For example, it is important for a parent to know how hungry each of its children is, so that it can most efficiently dole out the food. It could of course ration the food exactly equally between them all, but in the best of all possible worlds this would be less efficient than a system of giving a little bit more to those that could genuinely use it best. A system whereby each child told the parent how hungry he was would be ideal for the parent, and, as we have seen, such a system seems to have evolved. But the young are in a strong position to lie, because they know exactly how hungry they are, while the parent can only guess whether they are telling the truth or not. It is almost impossible for a parent to detect a small lie, although it might see through a big one. Then again, it is of advantage to a parent to know when a baby is happy, and it is a good thing for a baby to be able to tell its parents when it is happy. Signals like purring and smiling may have been selected because they enable parents to learn which of their actions are most beneficial to their children. The sight of her child smiling, or the sound of her kitten purring, is rewarding to a mother, in the same sense as food in the stomach is rewarding to a rat in a maze. But once it becomes true that a sweet smile or a loud purr are rewarding, the child is in a position to use the smile or the purr in order to manipulate the parent, and gain more than its fair share of parental investment. There is, then, no general answer to the question of who is more likely to win the battle of the generations. What will finally emerge is a compromise between the ideal situation desired by the child and that desired by the parent. It is a battle comparable to that between cuckoo and foster parent, not such a fierce battle to be sure, for the enemies do have some genetic interests in common-they are only enemies up to a point, or during certain sensitive times. However, many of the tactics used by cuckoos, tactics of deception and exploitation, may be employed by a parent's own young, although the parent's own young will stop short of the total selfishness that is to be expected of a cuckoo. This chapter, and the next in which we discuss conflict between mates, could seem horribly cynical, and might even be distressing to human parents, devoted as they are to their children, and to each other. Once again I must emphasize that I am not talking about conscious motives. Nobody is suggesting that children deliberately and consciously deceive their parents because of the selfish genes within them. And I must repeat that when I say something like 'A child should lose no opportunity of cheating ... lying, deceiving, exploiting...', I am using the word 'should' in a special way. I am not advocating this kind of behaviour as moral or desirable. I am simply saying that natural selection will tend to favour children who do act in this way, and that therefore when we look at wild populations we may expect to see cheating and selfishness within families. The phrase 'the child should cheat' means that genes that tend to make children cheat have an advantage in the gene pool. If there is a human moral to be drawn, it is that we must teach our children altruism, for we cannot expect it to be part of their biological nature.",
        "char_count": 43933
      },
      {
        "heading": "Chapter 10",
        "text": "The Selfish Gene 9. Battle of the sexes. If there is conflict of interest between parents and children, who share 50 per cent of each others' genes, how much more severe must be the conflict between mates, who are not related to each other? All that they have in common is a 50 per cent genetic shareholding in the same children. Since father and mother are both interested in the welfare of different halves of the same children, there may be some advantage for both of them in cooperating with each other in rearing those children. If one parent can get away with investing less than his or her fair share of costly resources in each child, however, he will be better off, since he will have more to spend on other children by other sexual partners, and so propagate more of his genes. Each partner can therefore be thought of as trying to exploit the other, trying to force the other one to invest more. Ideally, what an individual would 'like' (I don't mean physically enjoy, although he might) would be to copulate with as many members of the opposite sex as possible, leaving the partner in each case to bring up the children. As we shall see, this state of affairs is achieved by the males of a number of species, but in other species the males are obliged to share an equal part of the burden of bringing up children. This view of sexual partnership, as a relationship of mutual mistrust and mutual exploitation, has been stressed especially by Trivers. It is a comparatively new one to ethologists. We had usually thought of sexual behaviour, copulation, and the courtship that precedes it, as essentially a cooperative venture undertaken for mutual benefit, or even for the good of the species! Let us go right back to first principles, and inquire into the fundamental nature of maleness and femaleness. In Chapter 3 we discussed sexuality without stressing its basic asymmetry. We simply accepted that some animals are called male, and others female, without asking what these words really meant. But what is the essence of maleness? What, at bottom, defines a female? We as mammals see the sexes defined by whole syndromes of characteristics-possession of a penis, bearing of the young, suckling by means of special milk glands, certain chromosomal features, and so on. These criteria for judging the sex of an individual are all very well for mammals but, for animals and plants generally, they are no more reliable than is the tendency to wear trousers as a criterion for judging human sex. In frogs, for instance, neither sex has a penis. Perhaps, then, the words male and female have no general meaning. They are, after all, only words, and if we do not find them helpful for describing frogs, we are quite at liberty to abandon them. We could arbitrarily divide frogs into Sex 1 and Sex 2 if we wished. However, there is one fundamental feature of the sexes which can be used to label males as males, and females as females, throughout animals and plants. This is that the sex cells or 'gametes' of males are much smaller and more numerous than the gametes of females. This is true whether we are dealing with animals or plants. One group of individuals has large sex cells, and it is convenient to use the word female for them. The other group, which it is convenient to call male, has small sex cells. The difference is especially pronounced in reptiles and in birds, where a single egg cell is big enough and nutritious enough to feed a developing baby for several weeks. Even in humans, where the egg is microscopic, it is still many times larger than the sperm. As we shall see, it is possible to interpret all the other differences between the sexes as stemming from this one basic difference. In certain primitive organisms, for instance some fungi, maleness and femaleness do not occur, although sexual reproduction of a kind does. In the system known as isogamy the individuals are not distinguishable into two sexes. Anybody can mate with anybody else. There are not two different sorts of gametes-sperms and eggs-but all sex cells are the same, called isogametes. New individuals are formed by the fusion of two isogametes, each produced by meiotic division. If we have three isogametes, A, B, and C, A could fuse with B or C, B could fuse with A or C. The same is never true of normal sexual systems. If A is a sperm and it can fuse with B or C, then B and C must be eggs and B cannot fuse with C. When two isogametes fuse, both contribute equal numbers of genes to the new individual, and they also contribute equal amounts of food reserves. Sperms and eggs too contribute equal numbers of genes, but eggs contribute far more in the way of food reserves: indeed , sperms make no contribution at all and are simply concerned with transporting their genes as fast as possible to an egg. At the moment of conception, therefore, the father has invested less than his fair share (i.e. 50 per cent) of resources in the offspring. Since each sperm is so tiny, a male can afford to make many millions of them every day. This means he is potentially able to beget a very large number of children in a very short period of time, using different females. This is only possible because each new embryo is endowed with adequate food by the mother in each case. This therefore places a limit on the number of children a female can have, but the number of children a male can have is virtually unlimited. Female exploitation begins here. Parker and others showed how this asymmetry might have evolved from an originally isogamous state of affairs. In the days when all sex cells were interchangeable and of roughly the same size, there would have been some that just happened to be slightly bigger than others. In some respects a big isogamete would have an advantage over an average-sized one, because it would get its embryo off to a good start by giving it a large initial food supply. There might therefore have been an evolutionary trend towards larger gametes. But there was a catch. The evolution of isogametes that were larger than was strictly necessary would have opened the door to selfish exploitation. Individuals who produced smaller than average gametes could cash in, provided they could ensure that their small gametes fused with extra-big ones. This could be achieved by making the small ones more mobile, and able to seek out large ones actively. The advantage to an individual of producing small, rapidly moving gametes would be that he could afford to make a larger number of gametes, and therefore could potentially have more children. Natural selection favoured the production of sex cells that were small and that actively sought out big ones to fuse with. So we can think of two divergent sexual 'strategies' evolving. There was the large-investment or 'honest' strategy. This automatically opened the way for a small-investment exploitative strategy. Once the divergence between the two strategies had started, it would have continued in runaway fashion. Medium-sized intermediates would have been penalized, because they did not enjoy the advantages of either of the two more extreme strategies. The exploiters would have evolved smaller and smaller size, and faster mobility. The honest ones would have evolved larger and larger size, to compensate for the ever-smaller investment contributed by the exploiters, and they became immobile because they would always be actively chased by the exploiters anyway. Each honest one would 'prefer' to fuse with another honest one. But the selection pressure to lock out exploiters would have been weaker than the pressure on exploiters to duck under the barrier: the exploiters had more to lose, and they therefore won the evolutionary battle. The honest ones became eggs, and the exploiters became sperms. Males, then, seem to be pretty worthless fellows, and on simple 'good of the species' grounds, we might expect that males would become less numerous than females. Since one male can theoretically produce enough sperms to service a harem of 100 females we might suppose that females should outnumber males in animal populations by 100 to 1. Other ways of putting this are that the male is more 'expendable', and the female more 'valuable' to the species. Of course, looked at from the point of view of the species as a whole, this is perfectly true. To take an extreme example, in one study of elephant seals, 4 per cent of the males accounted for 88 per cent of all the copulations observed. In this case, and in many others, there is a large surplus of bachelor males who probably never get a chance to copulate in their whole lives. But these extra males live otherwise normal lives, and they eat up the population's food resources no less hungrily than other adults. From a 'good of the species' point of view this is horribly wasteful; the extra males might be regarded as social parasites. This is just one more example of the difficulties that the group selection theory gets into. The selfish gene theory, on the other hand, has no trouble in explaining the fact that the numbers of males and females tend to be equal, even when the males who actually reproduce may be a small fraction of the total number. The explanation was first offered by R. A. Fisher. The problem of how many males and how many females are born is a special case of a problem in parental strategy. Just as we discussed the optimal family size for an individual parent trying to maximize her gene survival, we can also discuss the optimal sex ratio. Is it better to entrust your precious genes to sons or to daughters? Suppose a mother invested all her resources in sons, and therefore had none left to invest in daughters: would she on average contribute more to the gene pool of the future than a rival mother who invested in daughters? Do genes for preferring sons become more or less numerous than genes for preferring daughters? What Fisher showed is that under normal circumstances the stable sex ratio is 50:50. In order to see why, we must first know a little bit about the mechanics of sex determination. In mammals, sex is determined genetically as follows. All eggs are capable of developing into either a male or a female. It is the sperms that carry the sex-determining chromosomes. Half the sperms produced by a man are female-producing, or X-sperms, and half are male-producing, or Y-sperms. The two sorts of sperms look alike. They differ with respect to one chromosome only. A gene for making a father have nothing but daughters could achieve its object by making him manufacture nothing but X-sperms. A gene for making a mother have nothing but daughters could work by making her secrete a selective spermicide, or by making her abort male embryos. What we seek is something equivalent to an evolutionarily stable strategy (ESS), although here, even more than in the chapter on aggression, strategy is just a figure of speech. An individual cannot literally choose the sex of his children. But genes for tending to have children of one sex or the other are possible. If we suppose that such genes, favouring unequal sex ratios, exist, are any of them likely to become more numerous in the gene pool than their rival alleles, which favour an equal sex ratio? Suppose that in the elephant seals mentioned above, a mutant gene arose that tended to make parents have mostly daughters. Since there is no shortage of males in the population, the daughters would have no trouble finding mates, and the daughter-manufacturing gene could spread. The sex ratio in the population might then start to shift towards a surplus of females. From the point of view of the good of the species, this would be all right, because just a few males are quite capable of providing all the sperms needed for even a huge surplus of females, as we have seen. Superficially, therefore, we might expect the daughter-producing gene to go on spreading until the sex ratio was so unbalanced that the few remaining males, working flat out, could just manage. But now, think what an enormous genetic advantage is enjoyed by those few parents who have sons. Anyone who invests in a son has a very good chance of being the grandparent of hundreds of seals. Those who are producing nothing but daughters are assured of a safe few grandchildren, but this is nothing compared to the glorious genetic possibilities that open up before anyone specializing in sons. Therefore genes for producing sons will tend to become more numerous, and the pendulum will swing back. For simplicity I have talked in terms of a pendulum swing. In practice the pendulum would never have been allowed to swing that far in the direction of female domination, because the pressure to have sons would have started to push it back as soon as the sex ratio became unequal. The strategy of producing equal numbers of sons and daughters is an evolutionarily stable strategy, in the sense that any gene for departing from it makes a net loss. I have told the story in terms of numbers of sons versus numbers of daughters. This is to make it simple, but strictly it should be worked out in terms of parental investment, meaning all the food and other resources that a parent has to offer, measured in the way discussed in the previous chapter. Parents should invest equally in sons and daughters. This usually means they should have numerically as many sons as they have daughters. But there could be unequal sex ratios that were evolutionarily stable, provided correspondingly unequal amounts of resources were invested in sons and daughters. In the case of the elephant seals, a policy of having three times as many daughters as sons, but of making each son a supermale by investing three times as much food and other resources in him, could be stable. By investing more food in a son and making him big and strong, a parent might increase his chances of winning the supreme prize of a harem. But this is a special case. Normally the amount invested in each son will roughly equal the amount invested in each daughter, and the sex ratio, in terms of numbers, is usually one to one. In its long journey down the generations therefore, an average gene will spend approximately half its time sitting in male bodies, and the other half sitting in female bodies. Some gene effects show themselves only in bodies of one sex. These are called sex-limited gene effects. A gene controlling penis-length expresses this effect only in male bodies, but it is carried about in female bodies too and may have some quite different effect on female bodies. There is no reason why a man should not inherit a tendency to develop a long penis from his mother. In whichever of the two sorts of body it finds itself, we can expect a gene to make the best use of the opportunities offered by that sort of body. These opportunities may well differ according to whether the body is male or female. As a convenient approximation, we can once again assume that each individual body is a selfish machine, trying to do the best for all its genes. The best policy for such a selfish machine will often be one thing if it is male, and quite a different thing if it is female. For brevity, we shall again use the convention of thinking of the individual as though it had a conscious purpose. As before, we shall hold in the back of our mind that this is just a figure of speech. A body is really a machine blindly programmed by its selfish genes. Consider again the mated pair with which we began the chapter. Both partners, as selfish machines, 'want' sons and daughters in equal numbers. To this extent they agree. Where they disagree is in who is going to bear the brunt of the cost of rearing each one of those children. Each individual wants as many surviving children as possible. The less he or she is obliged to invest in any one of those children, the more children he or she can have. The obvious way to achieve this desirable state of affairs is to induce your sexual partner to invest more than his or her fair share of resources in each child, leaving you free to have other children with other partners. This would be a desirable strategy for either sex, but it is more difficult for the female to achieve. Since she starts by investing more than the male, in the form of her large, food-rich egg, a mother is already at the moment of conception 'committed' to each child more deeply than the father is. She stands to lose more if the child dies than the father does. More to the point, she would have to invest more than the father in the future in order to bring a new substitute child up to the same level of development. If she tried the tactic of leaving the father holding the baby, while she went off with another male, the father might, at relatively small cost to himself, retaliate by abandoning the baby too. Therefore, at least in the early stages of child development, if any abandoning is going to be done, it is likely to be the father who abandons the mother rather than the other way around. Similarly, females can be expected to invest more in children than males, not only at the outset, but throughout development. So, in mammals for example, it is the female who incubates the foetus in her own body, the female who makes the milk to suckle it when it is born, the female who bears the brunt of the load of bringing it up and protecting it. The female sex is exploited, and the fundamental evolutionary basis for the exploitation is the fact that eggs are larger than sperms. Of course in many species the father does work hard and faithfully at looking after the young. But even so, we must expect that there will normally be some evolutionary pressure on males to invest a little bit less in each child, and to try to have more children by different wives. By this I simply mean that there will be a tendency for genes that say 'Body, if you are male leave your mate a little bit earlier than my rival allele would have you do, and look for another female', to be successful in the gene pool. The extent to which this evolutionary pressure actually prevails in practice varies greatly from species to species. In many, for example in the birds of paradise, the female receives no help at all from any male, and she rears her children on her own. Other species such as kittiwakes form monogamous pairbonds of exemplary fidelity, and both partners cooperate in the work of bringing up children. Here we must suppose that some evolutionary counter-pressure has been at work: there must be a penalty attached to the selfish mate-exploitation strategy as well as a benefit, and in kittiwakes the penalty outweighs the benefit. It will in any case only pay a father to desert his wife and child if the wife has a reasonable chance of rearing the child on her own. Trivers has considered the possible courses of action open to a mother who has been deserted by her mate. Best of all for her would be to try to deceive another male into adopting her child, 'thinking' it is his own. This might not be too difficult if it is still a foetus, not yet born. Of course, while the child bears half her genes, it bears no genes at all from the gullible step-father. Natural selection would severely penalize such gullibility in males and indeed would favour males who took active steps to kill any potential step-children as soon as they mated with a new wife. This is very probably the explanation of the so-called Bruce effect: male mice secrete a chemical which when smelt by a pregnant female can cause her to abort. She only aborts if the smell is different from that of her former mate. In this way. a male mouse destroys his potential step-children, and renders his new wife receptive to his own sexual advances. Ardrey, incidentally, sees the Bruce effect as a population control mechanism! A similar example is that of male lions, who, when newly arrived in a pride, sometimes murder existing cubs, presumably because these are not their own children. A male can achieve the same result without necessarily killing step-children. He can enforce a period of prolonged courtship before he copulates with a female, driving away all other males who approach her, and preventing her from escaping. In this way he can wait and see whether she is harbouring any little step-children in her womb, and desert her if so. We shall see below a reason why a female might want a long 'engagement' period before copulation. Here we have a reason why a male might want one too. Provided he can isolate her from all contact with other males, it helps to avoid being the unwitting benefactor of another male's children. Assuming then that a deserted female cannot fool a new male into adopting her child, what else can she do? Much may depend on how old the child is. If it is only just conceived, it is true that she has invested the whole of one egg in it and perhaps more, but it may still pay her to abort it and find a new mate as quickly as possible. In these circumstances it would be to the mutual advantage both of her and of the potential new husband that she should abort-since we are assuming she has no hope of fooling him into adopting the child. This could explain why the Bruce effect works from the female's point of view. Another option open to a deserted female is to stick it out, and try and rear the child on her own. This will especially pay her if the child is already quite old. The older he is the more has already been invested in him, and the less it will take out of her to finish the job of rearing him. Even if he is still quite young, it might yet pay her to try to salvage something from her initial investment, even if she has to work twice as hard to feed the child, now that the male has gone. It is no comfort to her that the child contains half the male's genes too, and that she could spite him by abandoning it. There is no point in spite for its own sake. The child carries half her genes, and the dilemma is now hers alone. Paradoxically, a reasonable policy for a female who is in danger of being deserted might be to walk out on the male before he walks out on her. This could pay her, even if she has already invested more in the child than the male has. The unpleasant truth is that in some circumstances an advantage accrues to the partner who deserts first, whether it is the father or the mother. As Trivers puts it, the partner who is left behind is placed in a cruel bind. It is a rather horrible but very subtle argument. A parent may be expected to desert, the moment it is possible for him or her to say the following: ' This child is now far enough developed that either of us could finish off rearing it on our own. Therefore it would pay me to desert now, provided I could be sure my partner would not desert as well. If I did desert now, my partner would do whatever is best for her/his genes. He/ she would be forced into making a more drastic decision than I am making now, because I would have already left. My partner would “know” that if he/she left as well, the child would surely die. Therefore, assuming that my partner will take the decision that is best for his/her own selfish genes, I conclude that my own best course of action is to desert first. This is especially so, since my partner may be “thinking” along exactly the same lines, and may seize the initiative at any minute by deserting me!' As always, the subjective soliloquy is intended for illustration only. The point is that genes for deserting first could be favourably selected simply because genes for deserting second would not be. We have looked at some of the things that a female might do if she has been deserted by her mate. But these all have the air of making the best of a bad job. Is there anything a female can do to reduce the extent to which her mate exploits her in the first place? She has a strong card in her hand. She can refuse to copulate. She is in demand, in a seller's market. This is because she brings the dowry of a large, nutritious egg. A male who successfully copulates gains a valuable food reserve for his offspring. The female is potentially in a position to drive a hard bargain before she copulates. Once she has copulated she has played her ace-her egg has been committed to the male. It is all very well to talk about driving hard bargains, but we know very well it is not really like that. Is there any realistic way in which something equivalent to driving a hard bargain could evolve by natural selection? I shall consider two main possibilities, called the domestic-bliss strategy, and the he-man strategy. The simplest version of the domestic-bliss strategy is this. The female looks the males over, and tries to spot signs of fidelity and domesticity in advance. There is bound to be variation in the population of males in their predisposition to be faithful husbands. If females could recognize such qualities in advance, they could benefit themselves by choosing males possessing them. One way for a female to do this is to play hard to get for a long time, to be coy. Any male who is not patient enough to wait until the female eventually consents to copulate is not likely to be a good bet as a faithful husband. By insisting on a long engagement period, a female weeds out casual suitors, and only finally copulates with a male who has proved his qualities of fidelity and perseverance in advance. Feminine coyness is in fact very common among animals, and so are prolonged courtship or engagement periods. As we have already seen, a long engagement can also benefit a male where there is a danger of his being duped into caring for another male's child. Courtship rituals often include considerable pre-copulation investment by the male. The female may refuse to copulate until the male has built her a nest. Or the male may have to feed her quite substantial amounts of food. This, of course, is very good from the female's point of view, but it also suggests another possible version of the domestic-bliss strategy. Could females force males to invest so heavily in their offspring before they allow copulation that it would no longer pay the males to desert after copulation? The idea is appealing. A male who waits for a coy female eventually to copulate with him is paying a cost: he is forgoing the chance to copulate with other females, and he is spending a lot of time and energy in courting her. By the time he is finally allowed to copulate with a particular female, he will inevitably be heavily 'committed' to her. There will be little temptation for him to desert her, if he knows that any future female he approaches will also procrastinate in the same manner before she will get down to business. As I showed in a paper, there is a mistake in Trivers's reasoning here. He thought that prior investment in itself committed an individual to future investment. This is fallacious economics. A business man should never say 'I have already invested so much in the Concorde airliner (for instance) that I cannot afford to scrap it now.' He should always ask instead whether it would pay him in the future, to cut his losses, and abandon the project now, even though he has already invested heavily in it. Similarly, it is no use a female forcing a male to invest heavily in her in the hope that this, on its own, will deter the male from subsequently deserting. This version of the domestic-bliss strategy depends upon one further crucial assumption. This is that a majority of the females can be relied upon to play the same game. If there are loose females in the population, prepared to welcome males who have deserted their wives, then it could pay a male to desert his wife, no matter how much he has already invested in her children. Much therefore depends on how the majority of females behave. If we were allowed to think in terms of a conspiracy of females there would be no problem. But a conspiracy of females can no more evolve than the conspiracy of doves which we considered in Chapter 5. Instead, we must look for evolutionarily stable strategies. Let us take Maynard Smith's method of analysing aggressive contests, and apply it to sex. It will be a little bit more complicated than the case of the hawks and doves, because we shall have two female strategies and two male strategies. As in Maynard Smith's studies, the word 'strategy' refers to a blind unconscious behaviour program. Our two female strategies will be called coy and fast, and the two male strategies will be called faithful and philanderer. The behavioural rules of the four types are as follows. Coy females will not copulate with a male until he has gone through a long and expensive courtship period lasting several weeks. Fast females will copulate immediately with anybody. Faithful males are prepared to go on courting for a long time, and after copulation they stay with the female and help her to rear the young. Philanderer males lose patience quickly if a female will not copulate with them straight away: they go off and look for another female; after copulation too they do not stay and act as good fathers, but go off in search of fresh females. As in the case of the hawks and doves, these are not the only possible strategies, but it is illuminating to study their fates nevertheless. Like Maynard Smith, we shall use some arbitrary hypothetical values for the various costs and benefits. To be more general it can be done with algebraic symbols, but numbers are easier to understand. Suppose that the genetic pay-off gained by each parent when a child is reared successfully is +15 units. The cost of rearing one child, the cost of all its food, all the time spent looking after it, and all the risks taken on its behalf, is -20 units. The cost is expressed as negative, because it is 'paid out' by the parents. Also negative is the cost of wasting time in prolonged courtship. Let this cost be -3 units. Imagine we have a population in which all the females are coy, and all the males are faithful. It is an ideal monogamous society. In each couple, the male and the female both get the same average pay-off. They get +15 for each child reared; they share the cost of rearing it (-20) equally between the two of them, an average of -10 each. They both pay the -3 point penalty for wasting time in prolonged courtship. The average pay-off for each is therefore + 15 - 10 - 3 = + 2. Now suppose a single fast female enters the population. She does very well. She does not pay the cost of delay, because she does not indulge in prolonged courtship. Since all the males in the population are faithful, she can reckon on finding a good father for her children whoever she mates with. Her average pay-off per child is + 15 - 10 = + 5. She is 3 units better off than her coy rivals. Therefore fast genes will start to spread. If the success of fast females is so great that they come to predominate in the population, things will start to change in the male camp too. So far, faithful males have had a monopoly. But now if a philanderer male arises in the population, he starts to do better than his faithful rivals. In a population where all the females are fast, the pickings for a philanderer male are rich indeed. He gets the +15 points if a child is successfully reared, and he pays neither of the two costs. What this lack of cost mainly means to him is that he is free to go off and mate with new females. Each of his unfortunate wives struggles on alone with the child, paying the entire -20 point cost, although she does not pay anything for wasting time in courting. The net pay-off for a fast female when she encounters a philanderer male is + 15 - 20 = -5; the pay-off to the philanderer himself is +15. In a population in which all the females are fast, philanderer genes will spread like wildfire. If the philanderers increase so successfully that they come to dominate the male part of the population, the fast females will be in dire straits. Any coy female would have a strong advantage. If a coy female encounters a philanderer male, no business results. She insists on prolonged courtship; he refuses and goes off in search of another female. Neither partner pays the cost of wasting time. Neither gains anything either, since no child is produced. This gives a net pay-off of zero for a coy female in a population where all the males are philanderers. Zero may not seem much, but it is better than the -5 which is the average score for a fast female. Even if a fast female decided to leave her young after being deserted by a philanderer, she would still have paid the considerable cost of an egg. So, coy genes start to spread through the population again. To complete the hypothetical cycle, when coy females increase in numbers so much that they predominate, the philanderer males, who had such an easy time with the fast females, start to feel the pinch. Female after female insists on a long and arduous courtship. The philanderers flit from female to female, and always the story is the same. The net pay-off for a philanderer male when all the females are coy is zero. Now if a single faithful male should turn up, he is the only one with whom the coy females will mate. His net pay-off is + 2, better than that of the philanderers. So, faithful genes start to increase, and we come full circle. As in the case of the aggression analysis, I have told the story as though it was an endless oscillation. But, as in that case, it can be shown that really there would be no oscillation. The system would converge to a stable state. If you do the sums, it turns out that a population in which 5/6 of the females are coy, and 5/8 of the males are faithful, is evolutionarily stable. This is, of course, just for the particular arbitrary numbers that we started out with, but it is easy to work out what the stable ratios would be for any other arbitrary assumptions. As in Maynard Smith's analyses, we do not have to think of there being two different sorts of male and two different sorts of female. The ESS could equally well be achieved if each male spends 5/8 of his time being faithful and the rest of his time philandering; and each female spends 5/6 of her time being coy and 1/6 of her time being fast. Whichever way we think of the ESS, what it means is this. Any tendency for members of either sex to deviate from their appropriate stable ratio will be penalized by a consequent change in the ratio of strategies of the other sex, which is, in turn, to the disadvantage of the original deviant. Therefore the ESS will be preserved. We can conclude that it is certainly possible for a population consisting largely of coy females and faithful males to evolve. In these circumstances the domestic-bliss strategy for females really does seem to work. We do not have to think in terms of a conspiracy of coy females. Coyness can actually pay a female's selfish genes. There are various ways in which females can put this type of strategy into practice. I have already suggested that a female might refuse to copulate with a male who has not already built her a nest, or at least helped her to build a nest. It is indeed the case that in many monogamous birds copulation does not take place until after the nest is built. The effect of this is that at the moment of conception the male has invested a good deal more in the child than just his cheap sperms. Demanding that a prospective mate should build a nest is one effective way for a female to trap him. It might be thought that almost anything that costs the male a great deal would do in theory, even if that cost is not directly paid in the form of benefit to the unborn children. If all females of a population forced males to do some difficult and costly deed, like slaying a dragon or climbing a mountain, before they would consent to copulate with them, they could in theory be reducing the temptation for the males to desert after copulation. Any male tempted to desert his mate and try to spread more of his genes by another female, would be put off by the thought that he would have to kill another dragon. In practice, however, it is unlikely that females would impose such arbitrary tasks as dragon-killing, or Holy-Grail-seeking on their suitors. The reason is that a rival female who imposed a task no less arduous, but more useful to her and her children, would have an advantage over more romantically minded females who demanded a pointless labour of love. Building a nest may be less romantic than slaying a dragon or swimming the Hellespont, but it is much more useful. Also useful to the female is the practice I have already mentioned of courtship feeding by the male. In birds this has usually been regarded as a kind of regression to juvenile behaviour on the part of the female. She begs from the male, using the same gestures as a young bird would use. It has been supposed that this is automatically attractive to the male, in the same way as a man finds a lisp or pouting lips attractive in an adult woman. The female bird at this time needs all the extra food she can get, for she is building up her reserves for the effort of manufacturing her enormous eggs. Courtship feeding by the male probably represents direct investment by him in the eggs themselves. It therefore has the effect of reducing the disparity between the two parents in their initial investment in the young. Several insects and spiders also demonstrate the phenomenon of courtship feeding. Here an alternative interpretation has sometimes been only too obvious. Since, as in the case of the praying mantis, the male may be in danger of being eaten by the larger female, anything that he can do to reduce her appetite may be to his advantage. There is a macabre sense in which the unfortunate male mantis can be said to invest in his children. He is used as food to help make the eggs which will then be fertilized, posthumously, by his own stored sperms. A female, playing the domestic-bliss strategy, who simply looks the males over and tries to recognize qualities of fidelity in advance, lays herself open to deception. Any male who can pass himself off as a good loyal domestic type, but who in reality is concealing a strong tendency towards desertion and unfaithfulness, could have a great advantage. As long as his deserted former wives have any chance of bringing up some of the children, the philanderer stands to pass on more genes than a rival male who is an honest husband and father. Genes for effective deception by males will tend to be favoured in the gene pool. Conversely, natural selection will tend to favour females who become good at seeing through such deception. One way they can do this is to play especially hard to get when they are courted by a new male, but in successive breeding seasons to be increasingly ready to accept quickly the advances of last year's mate. This will automatically penalize young males embarking on their first breeding season, whether they are deceivers or not. The brood of naive first year females would tend to contain a relatively high proportion of genes from unfaithful fathers, but faithful fathers have the advantage in the second and subsequent years of a mother's life, for they do not have to go through the same prolonged energy-wasting and time-consuming courtship rituals. If the majority of individuals in a population are the children of experienced rather than naive mothers-a reasonable assumption in any long-lived species- genes for honest, good fatherhood will come to prevail in the gene pool. For simplicity, I have talked as though a male were either purely honest or thoroughly deceitful. In reality it is more probable that all males, indeed all individuals, are a little bit deceitful, in that they are programmed to take advantage of opportunities to exploit their mates. Natural selection, by sharpening up the ability of each partner to detect dishonesty in the other, has kept large-scale deceit down to a fairly low level. Males have more to gain from dishonesty than females, and we must expect that, even in those species where males show considerable parental altruism, they will usually tend to do a bit less work than the females, and to be a bit more ready to abscond. In birds and mammals this is certainly normally the case. There are species, however, in which the male actually does more work in caring for the children than the female does. Among birds and mammals these cases of paternal devotion are exceptionally rare, but they are common among fish. Why? This is a challenge for the selfish gene theory which has puzzled me for a long time. An ingenious solution was recently suggested to me in a tutorial by Miss T. R. Carlisle. She makes use of Trivers's 'cruel bind' idea, referred to above, as follows. Many fish do not copulate, but instead simply spew out their sex cells into the water. Fertilization takes place in the open water, not inside the body of one of the partners. This is probably how sexual reproduction first began. Land animals like birds, mammals and reptiles, on the other hand, cannot afford this kind of external fertilization, because their sex cells are too vulnerable to drying-up. The gametes of one sex-the male, since sperms are mobile-are introduced into the wet interior of a member of the other sex-the female. So much is just fact. Now comes the idea. After copulation, the land-dwelling female is left in physical possession of the embryo. It is inside her body. Even if she lays the fertilized egg almost immediately, the male still has time to vanish, thereby forcing the female into Trivers's 'cruel bind'. The male is inevitably provided with an opportunity to take the prior decision to desert, closing the female's options, and forcing her to decide whether to leave the young to certain death, or whether to stay with it and rear it. Therefore, maternal care is more common among land animals than paternal care. But for fish and other water-dwelling animals things are very different. If the male does not physically introduce his sperms into the female's body there is no necessary sense in which the female is left 'holding the baby'. Either partner might make a quick getaway and leave the other one in possession of the newly fertilized eggs. But there is even a possible reason why it might often be the male who is most vulnerable to being deserted. It seems probable that an evolutionary battle will develop over who sheds their sex cells first. The partner who does so has the advantage that he or she can then leave the other one in possession of the new embryos. On the other hand, the partner who spawns first runs the risk that his prospective partner may subsequently fail to follow suit. Now the male is more vulnerable here, if only because sperms are lighter and more likely to diffuse than eggs. If a female spawns too early, i.e. before the male is ready, it will not greatly matter because the eggs, being relatively large and heavy, are likely to stay together as a coherent clutch for some time. Therefore a female fish can afford to take the 'risk' of spawning early. The male dare not take this risk, since if he spawns too early his sperms will have diffused away before the female is ready, and she will then not spawn herself, because it will not be worth her while to do so. Because of the diffusion problem, the male must wait until the female spawns, and then he must shed his sperms over the eggs. But she has had a precious few seconds in which to disappear, leaving the male in possession, and forcing him on to the horns of Trivers's dilemma. So this theory neatly explains why paternal care is common in water but rare on dry land. Leaving fish, I now turn to the other main female strategy, the he-man strategy. In species where this policy is adopted the females, in effect, resign themselves to getting no help from the father of their children, and go all-out for good genes instead. Once again they use their weapon of withholding copulation. They refuse to mate with just any male, but exercise the utmost care and discrimination before they will allow a male to copulate with them. Some males undoubtedly do contain a larger number of good genes than other males, genes that would benefit the survival prospects of both sons and daughters. If a female can somehow detect good genes in males, using externally visible clues, she can benefit her own genes by allying them with good paternal genes. To use our analogy of the rowing crews, a female can minimize the chance that her genes will be dragged down through getting into bad company. She can try to hand-pick good crew-mates for her own genes. The chances are that most of the females will agree with each other on which are the best males, since they all have the same information to go on. Therefore these few lucky males will do most of the copulating. This they are quite capable of doing, since all they must give to each female is some cheap sperms. This is presumably what has happened in elephant seals and in birds of paradise. The females are allowing just a few males to get away with the ideal selfish-exploitation strategy which all males aspire to, but they are making sure that only the best males are allowed this luxury. From the point of view of a female trying to pick good genes with which to ally her own, what is she looking for? One thing she wants is evidence of ability to survive. Obviously any potential mate who is courting her has proved his ability to survive at least into adulthood, but he has not necessarily proved that he can survive much longer. Quite a good policy for a female might be to go for old men. Whatever their shortcomings, they have at least proved they can survive, and she is likely to be allying her genes with genes for longevity. However, there is no point in ensuring that her children live long lives if they do not also give her lots of grandchildren. Longevity is not prima facie evidence of virility. Indeed a long-lived male may have survived precisely because he does not take risks in order to reproduce. A female who selects an old male is not necessarily going to have more descendants than a rival female who chooses a young one who shows some other evidence of good genes. What other evidence? There are many possibilities. Perhaps strong muscles as evidence of ability to catch food, perhaps long legs as evidence of ability to run away from predators. A female might benefit her genes by allying them with such traits, since they might be useful qualities in both her sons and her daughters. To begin with, then, we have to imagine females choosing males on the basis of perfectly genuine labels or indicators which tend to be evidence of good underlying genes. But now here is a very interesting point realized by Darwin, and clearly enunciated by Fisher. In a society where males compete with each other to be chosen as he-men by females, one of the best things a mother can do for her genes is to make a son who will turn out in his turn to be an attractive he-man. If she can ensure that her son is one of the fortunate few males who wins most of the copulations in the society when he grows up, she will have an enormous number of grandchildren. The result of this is that one of the most desirable qualities a male can have in the eyes of a female is, quite simply, sexual attractiveness itself. A female who mates with a super-attractive he-man is more likely to have sons who are attractive to females of the next generation, and who will make lots of grandchildren for her. Originally, then, females may be thought of as selecting males on the basis of obviously useful qualities like big muscles, but once such qualities became widely accepted as attractive among the females of the species, natural selection would continue to favour them simply because they were attractive. Extravagances such as the tails of male birds of paradise may therefore have evolved by a kind of unstable, runaway process. In the early days, a slightly longer tail than usual may have been selected by females as a desirable quality in males, perhaps because it betokened a fit and healthy constitution. A short tail on a male might have been an indicator of some vitamin deficiency-evidence of poor food-getting ability. Or perhaps short-tailed males were not very good at running away from predators, and so had had their tails bitten off. Notice that we don't have to assume that the short tail was in itself genetically inherited, only that it served as an indicator of some genetic inferiority. Anyway, for whatever reason, let us suppose that females in the ancestral bird of paradise species preferentially went for males with longer than average tails. Provided there was some genetic contribution to the natural variation in male tail-length, this would in time cause the average tail-length of males in the population to increase. Females followed a simple rule: look all the males over, and go for the one with the longest tail. Any female who departed from this rule was penalized, even if tails had already become so long that they actually encumbered males possessing them. This was because any female who did not produce long-tailed sons had little chance of one of her sons being regarded as attractive. Like a fashion in women's clothes, or in American car design, the trend toward longer tails took off and gathered its own momentum. It was stopped only when tails became so grotesquely long that their manifest disadvantages started to outweigh the advantage of sexual attractiveness. This is a hard idea to swallow, and it has attracted its sceptics ever since Darwin first proposed it, under the name of sexual selection. One person who does not believe it is A. Zahavi, whose 'Fox, fox' theory we have already met. He puts forward his own maddeningly contrary 'handicap principle' as a rival explanation. He points out that the very fact that females are trying to select for good genes among males opens the door to deception by the males. Strong muscles may be a genuinely good quality for a female to select, but then what is to stop males from growing dummy muscles with no more real substance than human padded shoulders? If it costs a male less to grow false muscles than real ones, sexual selection should favour genes for producing false muscles. It will not be long, however, before counter-selection leads to the evolution of females capable of seeing through the deception. Zahavi's basic premise is that false sexual advertisement will eventually be seen through by females. He therefore concludes that really successful males will be those who do not advertise falsely, those who palpably demonstrate that they are not deceiving. If it is strong muscles we are talking about, then males who merely assume the visual appearance of strong muscles will soon be detected by the females. But a male who demonstrates, by the equivalent of lifting weights or ostentatiously doing press-ups, that he really has strong muscles, will succeed in convincing the females. In other words Zahavi believes that a he-man must not only seem to be a good quality male: he must really be a good quality male, otherwise he will not be accepted as such by sceptical females. Displays will therefore evolve that only a genuine he-man is capable of doing. So far so good. Now comes the part of Zahavi's theory that really sticks in the throat. He suggests that the tails of birds of paradise and peacocks, the huge antlers of deer, and the other sexually-selected features which have always seemed paradoxical because they appear to be handicaps to their possessors, evolve precisely because they are handicaps. A male bird with a long and cumbersome tail is showing off to females that he is such a strong he-man that he can survive in spite of his tail. Think of a woman watching two men run a race. If both arrive at the finishing post at the same time, but one has deliberately encumbered himself with a sack of coal on his back, the women will naturally draw the conclusion that the man with the burden is really the faster runner. I do not believe this theory, although I am not quite so confident in my scepticism as I was when I first heard it. I pointed out then that the logical conclusion to it should be the evolution of males with only one leg and only one eye. Zahavi, who comes from Israel, instantly retorted: 'Some of our best generals have only one eye!' Nevertheless, the problem remains that the handicap theory seems to contain a basic contradiction. If the handicap is a genuine one-and it is of the essence of the theory that it has to be a genuine one-then the handicap itself will penalize the offspring just as surely as it may attract females. It is, in any case, important that the handicap must not be passed on to daughters. If we rephrase the handicap theory in terms of genes, we have something like this. A gene that makes males develop a handicap, such as a long tail, becomes more numerous in the gene pool because females choose males who have handicaps. Females choose males who have handicaps, because genes that make females so choose also become frequent in the gene pool. This is because females with a taste for handicapped males will automatically tend to be selecting males with good genes in other respects, since those males have survived to adulthood in spite of the handicap. These good 'other' genes will benefit the bodies of the children, which therefore survive to propagate the genes for the handicap itself, and also the genes for choosing handicapped males. Provided the genes for the handicap itself exert their effect only in sons, just as the genes for a sexual preference for the handicap affect only daughters, the theory just might be made to work. So long as it is formulated only in words, we cannot be sure whether it will work or not. We get a better idea of how feasible such a theory is when it is rephrased in terms of a mathematical model. So far mathematical geneticists who have tried to make the handicap principle into a workable model have failed. This may be because it is not a workable principle, or it may be because they are not clever enough. One of them is Maynard Smith, and my hunch favours the former possibility. If a male can demonstrate his superiority over other males in a way that does not involve deliberately handicapping himself, nobody would doubt that he could increase his genetic success in that way. Thus elephant seals win and hold on to their harems, not by being aesthetically attractive to females, but by the simple expedient of beating up any male who tries to move in on the harem. Harem holders tend to win these fights against would-be usurpers, if only for the obvious reason that that is why they are harem-holders. Usurpers do not often win fights, because if they were capable of winning they would have done so before! Any female who mates only with a harem holder is therefore allying her genes with a male who is strong enough to beat off successive challenges from the large surplus of desperate bachelor males. With luck her sons will inherit their father's ability to hold a harem. In practice a female elephant seal does not have much option, because the harem-owner beats her up if she tries to stray. The principle remains, however, that females who choose to mate with males who win fights may benefit their genes by so doing. As we have seen, there are examples of females preferring to mate with males who hold territories and with males who have high status in the dominance hierarchy. To sum up this chapter so far, the various different kinds of breeding system that we find among animals-monogamy, promiscuity, harems, and so on-can be understood in terms of conflicting interests between males and females. Individuals of either sex 'want' to maximize their total reproductive output during their lives. Because of a fundamental difference between the size and numbers of sperms and eggs, males are in general likely to be biased towards promiscuity and lack of paternal care. Females have two main available counter-ploys, which I have called the he-man and the domestic-bliss strategies. The ecological circumstances of a species will determine whether the females are biased towards one or the other of these counter-ploys, and will also determine how the males respond. In practice all intermediates between he-man and domestic-bliss are found and, as we have seen, there are cases in which the father does even more child-care than the mother. This book is not concerned with the details of particular animals species, so I will not discuss what might predispose a species towards one form of breeding system rather than another. Instead I will consider the differences that are commonly observed between males and females in general, and show how these may be interpreted. I shall therefore not be emphasizing those species in which the differences between the sexes are slight, these being in general the ones whose females have favoured the domestic-bliss strategy. Firstly, it tends to be the males who go in for sexually attractive, gaudy colours, and the females who tend to be more drab. Individuals of both sexes want to avoid being eaten by predators, and there will be some evolutionary pressure on both sexes to be drably coloured. Bright colours attract predators no less than they attract sexual partners. In gene terms, this means that genes for bright colours are more likely to meet their end in the stomachs of predators than are genes for drab colours. On the other hand, genes for drab colours may be less likely than genes for bright colours to find themselves in the next generation, because drab individuals have difficulty in attracting a mate. There are therefore two conflicting selection pressures: predators tending to remove bright-colour genes from the gene pool, and sexual partners tending to remove genes for drabness. As in so many other cases, efficient survival machines can be regarded as a compromise between conflicting selection pressures. What interests us at the moment is that the optimal compromise for a male seems to be different from the optimal compromise for a female. This is of course fully compatible with our view of males as high-risk, high-reward gamblers. Because a male produces many millions of sperms to every egg produced by a female, sperms heavily outnumber eggs in the population. Any given egg is therefore much more likely to enter into sexual fusion than any given sperm is. Eggs are a relatively valuable resource, and therefore a female does not need to be so sexually attractive as a male does in order to ensure that her eggs are fertilized. A male is perfectly capable of siring all the children born to a large population of females. Even if a male has a short life because his gaudy tail attracts predators, or gets tangled in the bushes, he may have fathered a very large number of children before he dies. An unattractive or drab male may live even as long as a female, but he has few children, and his genes are not passed on. What shall it profit a male if he shall gain the whole world, and lose his immortal genes? Another common sexual difference is that females are more fussy than males about whom they mate with. One of the reasons for fussiness by an individual of either sex is the need to avoid mating with a member of another species. Such hybridizations are a bad thing for a variety of reasons. Sometimes, as in the case of a man copulating with a sheep, the copulation does not lead to an embryo being formed, so not much is lost. When more closely related species like horses and donkeys cross-breed, however, the cost, at least to the female partner, can be considerable. An embryo mule is likely to be formed and it then clutters up her womb for eleven months. It takes a large quantity of her total parental investment, not only in the form of food absorbed through the placenta, and then later in the form of milk, but above all in time which could have been spent in rearing other children. Then when the mule reaches adulthood it turns out to be sterile. This is presumably because, although horse chromosomes and donkey chromosomes are sufficiently similar to cooperate in the building of a good strong mule body, they are not similar enough to work together properly in meiosis. Whatever the exact reason, the very considerable investment by the mother in the rearing of a mule is totally wasted from the point of view of her genes. Female horses should be very, very careful that the individual they copulate with is another horse, and not a donkey. In gene terms, any horse gene that says 'Body, if you are female, copulate with any old male, whether he is a donkey or a horse', is a gene which may next find itself in the dead-end body of a mule, and the mother's parental investment in that baby mule detracts heavily from her capacity to rear fertile horses. A male, on the other hand, has less to lose if he mates with a member of the wrong species, and, although he may have nothing to gain either, we should expect males to be less fussy in their choice of sexual partners. Where this has been looked at, it has been found to be true. Even within a species, there may be reasons for fussiness. Incestuous mating, like hybridization, is likely to have damaging genetic consequences, in this case because lethal and semi-lethal recessive genes are brought out into the open. Once again, females have more to lose than males, since their investment in any particular child tends to be greater. Where incest taboos exist, we should expect females to be more rigid in their adherence to the taboos than males. If we assume that the older partner in an incestuous relationship is relatively likely to be the active initiator, we should expect that incestuous unions in which the male is older than the female should be more common than unions in which the female is older. For instance father/daughter incest should be commoner than mother/ son. Brother/sister incest should be intermediate in commonness. In general, males should tend to be more promiscuous than females. Since a female produces a limited number of eggs at a relatively slow rate, she has little to gain from having a large number of copulations with different males. A male on the other hand, who can produce millions of sperms every day, has everything to gain from as many promiscuous matings as he can snatch. Excess copulations may not actually cost a female much, other than a little lost time and energy, but they do not do her positive good. A male on the other hand can never get enough copulations with as many different females as possible: the word excess has no meaning for a male. I have not explicitly talked about man but inevitably, when we think about evolutionary arguments such as those in this chapter, we cannot help reflecting about our own species and our own experience. Notions of females withholding copulation until a male shows some evidence of long-term fidelity may strike a familiar chord. This might suggest that human females play the domestic-bliss rather than the he-man strategy. Many human societies are indeed monogamous. In our own society, parental investment by both parents is large and not obviously unbalanced. Mothers certainly do more direct work for children than fathers do, but fathers often work hard in a more indirect sense to provide the material resources that are poured into the children. On the other hand, some human societies are promiscuous, and many are harem-based. What this astonishing variety suggests is that man's way of life is largely determined by culture rather than by genes. However, it is still possible that human males in general have a tendency towards promiscuity, and females a tendency towards monogamy, as we would predict on evolutionary grounds. Which of these two tendencies wins in particular societies depends on details of cultural circumstance, just as in different animal species it depends on ecological details. One feature of our own society that seems decidedly anomalous is the matter of sexual advertisement. As we have seen, it is strongly to be expected on evolutionary grounds that, where the sexes differ, it should be the males that advertise and the females that are drab. Modern western man is undoubtedly exceptional in this respect. It is of course true that some men dress flamboyantly and some women dress drably but, on average, there can be no doubt that in our society the equivalent of the peacock's tail is exhibited by the female, not by the male. Women paint their faces and glue on false eyelashes. Apart from special cases, like actors, men do not. Women seem to be interested in their own personal appearance and they are encouraged in this by their magazines and journals. Men's magazines are less preoccupied with male sexual attractiveness, and a man who is unusually interested in his own dress and appearance is apt to arouse suspicion, both among men and among women. When a woman is described in conversation, it is quite likely that her sexual attractiveness, or lack of it, will be prominently mentioned. This is true, whether the speaker is a man or a woman. When a man is described, the adjectives used are much more likely to have nothing to do with sex. Faced with these facts, a biologist would be forced to suspect that he was looking at a society in which females compete for males, rather than vice versa. In the case of birds of paradise, we decided that females are drab because they do not need to compete for males. Males are bright and ostentatious because females are in demand and can afford to be choosy. The reason female birds of paradise are in demand is that eggs are a more scarce resource than sperms. What has happened in modern western man? Has the male really become the sought-after sex, the one that is in demand, the sex that can afford to be choosy? If so, why?",
        "char_count": 65999
      },
      {
        "heading": "Chapter 11",
        "text": "The Selfish Gene 10. You scratch my back, I'll ride on yours. We have considered parental, sexual, and aggressive interactions between survival machines belonging to the same species. There are striking aspects of animal interactions which do not seem to be obviously covered by any of these headings. One of these is the propensity that so many animals have for living in groups. Birds flock, insects swarm, fish and whales school, plains-dwelling mammals herd together or hunt in packs. These aggregations usually consist of members of a single species only, but there are exceptions. Zebras often herd together with gnus, and mixed-species flocks of birds are sometimes seen. The suggested benefits that a selfish individual can wrest from living in a group constitute rather a miscellaneous list. I am not going to trot out the catalogue, but will mention just a few suggestions. In the course of this I shall return to the remaining examples of apparently altruistic behaviour that I gave in Chapter 1, and which I promised to explain. This will lead into a consideration of the social insects, without which no account of animal altruism would be complete. Finally in this rather miscellaneous chapter, I shall mention the important idea of reciprocal altruism, the principle of 'You scratch my back, I'll scratch yours'. If animals live together in groups their genes must get more benefit out of the association than they put in. A pack of hyenas can catch prey so much larger than a lone hyena can bring down that it pays each selfish individual to hunt in a pack, even though this involves sharing food. It is probably for similar reasons that some spiders cooperate in building a huge communal web. Emperor penguins conserve heat by huddling together. Each one gains by presenting a smaller surface area to the elements than he would on his own. A fish who swims obliquely behind another fish may gain a hydrodynamic advantage from the turbulence produced by the fish in front. This could be partly why fish school. A related trick concerned with air turbulence is known to racing cyclists, and it may account for the V-formation of flying birds. There is probably competition to avoid the disadvantageous position at the head of the flock. Possibly the birds take turns as unwilling leader-a form of the delayed reciprocal-altruism to be discussed at the end of the chapter. Many of the suggested benefits of group living have been concerned with avoiding being eaten by predators. An elegant formulation of such a theory was given by W. D. Hamilton, in a paper called Geometry for the selfish herd. Lest this lead to misunderstanding, I must stress that by 'selfish herd' he meant 'herd of selfish individuals'. Once again we start with a simple 'model' which, though abstract, helps us to understand the real world. Suppose a species of animal is hunted by a predator that always tends to attack the nearest prey individual. From the predator's point of view this is a reasonable strategy, since it tends to cut down energy expenditure. From the prey's point of view it has an interesting consequence. It means that each prey individual will constantly try to avoid being the nearest to a predator. If the prey can detect the predator at a distance, it will simply run away. But if the predator is apt to turn up suddenly without warning, say it lurks concealed in long grass, then each prey individual can still take steps to minimize its chance of being the nearest to a predator. We can picture each prey individual as being surrounded by a 'domain of danger'. This is defined as that area of ground in which any point is nearer to that individual than it is to any other individual. For instance, if the prey individuals march spaced out in a regular geometric formation, the domain of danger round each one (unless he is on the edge) might be roughly hexagonal in shape. If a predator happens to be lurking in the hexagonal domain of danger surrounding individual A, then individual A is likely to be eaten. Individuals on the edge of the herd are especially vulnerable, since their domain of danger is not a relatively small hexagon, but includes a wide area on the open side. Now clearly a sensible individual will try to keep his domain of danger as small as possible. In particular, he will try to avoid being on the edge of the herd. If he finds himself on the edge he will take immediate steps to move towards the centre. Unfortunately somebody has to be on the edge, but as far as each individual is concerned it is not going to be him! There will be a ceaseless migration in from the edges of an aggregation towards the centre. If the herd was previously loose and straggling, it will soon become tightly bunched as a result of the inward migration. Even if we start our model with no tendency towards aggregation at all, and the prey animals start by being randomly dispersed, the selfish urge of each individual will be to reduce his domain of danger by trying to position himself in a gap between other individuals. This will quickly lead to the formation of aggregations which will become ever more densely bunched. Obviously, in real life the bunching tendency will be limited by opposing pressures: otherwise all individuals would collapse in a writhing heap! But still, the model is interesting as it shows us that even very simple assumptions can predict aggregation. Other, more elaborate models have been proposed. The fact that they are more realistic does not detract from the value of the simpler Hamilton model in helping us to think about the problem of animal aggregation. The selfish-herd model in itself has no place for cooperative interactions. There is no altruism here, only selfish exploitation by each individual of every other individual. But in real life there are cases where individuals seem to take active steps to preserve fellow members of the group from predators. Bird alarm calls spring to mind. These certainly function as alarm signals in that they cause individuals who hear them to take immediate evasive action. There is no suggestion that the caller is 'trying to draw the predator's fire' away from his colleagues. He is simply informing them of the predator's existence-warning them. Nevertheless the act of calling seems, at least at first sight, to be altruistic, because it has the effect of calling the predator's attention to the caller. We can infer this indirectly from a fact which was noticed by P. R. Marler. The physical characteristics of the calls seem to be ideally shaped to be difficult to locate. If an acoustic engineer were asked to design a sound that a predator would find it hard to approach, he would produce something very like the real alarm calls of many small songbirds. Now in nature this shaping of the calls must have been produced by natural selection, and we know what that means. It means that large numbers of individuals have died because their alarm calls were not quite perfect. Therefore there seems to be danger attached to giving alarm calls. The selfish gene theory has to come up with a convincing advantage of giving alarm calls which is big enough to counteract this danger. In fact this is not very difficult. Bird alarm calls have been held up so many times as 'awkward' for the Darwinian theory that it has become a kind of sport to dream up explanations for them. As a result, we now have so many good explanations that it is hard to remember what all the fuss was about. Obviously, if there is a chance that the flock contains some close relatives, a gene for giving an alarm call can prosper in the gene pool because it has a good chance of being in the bodies of some of the individuals saved. This is true, even if the caller pays dearly for his altruism by attracting the predator's attention to himself. If you are not satisfied with this kin-selection idea, there are plenty of other theories to choose from. There are many ways in which the caller could gain selfish benefit from warning his fellows. Trivers reels off five good ideas, but I find the following two of my own rather more convincing. The first I call the cave theory, from the Latin for 'beware', still used (pronounced 'kay-vee') by schoolboys to warn of approaching authority. This theory is suitable for camouflaged birds that crouch frozen in the undergrowth when danger threatens. Suppose a flock of such birds is feeding in a field. A hawk flies past in the distance. He has not yet seen the flock and he is not flying directly towards them, but there is a danger that his keen eyes will spot them at any moment and he will race into the attack. Suppose one member of the flock sees the hawk, but the rest have not yet done so. This one sharp-eyed individual could immediately freeze and crouch in the grass. But this would do him little good, because his companions are still walking around conspicuously and noisily. Any one of them could attract the hawk's attention and then the whole flock is in peril. From a purely selfish point of view the best policy for the individual who spots the hawk first is to hiss a quick warning to his companions, and so shut them up and reduce the chance that they will inadvertently summon the hawk into his own vicinity. The other theory I want to mention may be called the 'never break ranks' theory. This one is suitable for species of birds that fly off when a predator approaches, perhaps up into a tree. Once again, imagine that one individual in a flock of feeding birds has spotted a predator. What is he to do? He could simply fly off himself, without warning his colleagues. But now he would be a bird on his own, no longer part of a relatively anonymous flock, but an odd man out. Hawks are actually known to go for odd pigeons out, but even if this were not so there are plenty of theoretical reasons for thinking that breaking ranks might be a suicidal policy. Even if his companions eventually follow him, the individual who first flies up off the ground temporarily increases his domain of danger. Whether Hamilton's particular theory is right or wrong, there must be some important advantage in living in flocks, otherwise the birds would not do it. Whatever that advantage may be, the individual who leaves the flock ahead of the others will, at least in part, forfeit that advantage. If he must not break ranks, then, what is the observant bird to do? Perhaps he should just carry on as if nothing had happened and rely on the protection afforded by his membership of the flock. But this too carries grave risks. He is still out in the open, highly vulnerable. He would be much safer up in a tree. The best policy is indeed to fly up into a tree, but to make sure everybody else does too. That way, he will not become an odd man out and he will not forfeit the advantages of being part of a crowd, but he will gain the advantage of flying off into cover. Once again, uttering a warning call is seen to have a purely selfish advantage. E. L. Charnov and J. R. Krebs have proposed a similar theory in which they go so far as to use the word 'manipulation' to describe what the calling bird does to the rest of his flock. We have come a long way from pure, disinterested altruism! Superficially, these theories may seem incompatible with the statement that the individual who gives the alarm call endangers himself. Really there is no incompatibility. He would endanger himself even more by not calling. Some individuals have died because they gave alarm calls, especially the ones whose calls were easy to locate. Other individuals have died because they did not give alarm calls. The cave theory and the 'never break ranks' theory are just two out of many ways of explaining why. What of the stotting Thomson's gazelle, which I mentioned in Chapter 1, and whose apparently suicidal altruism moved Ardrey to state categorically that it could be explained only by group selection? Here the selfish gene theory has a more exacting challenge. Alarm calls in birds do work, but they are clearly designed to be as inconspicuous and discreet as possible. Not so the stotting high-jumps. They are ostentatious to the point of downright provocation. The gazelles look as if they are deliberately inviting the predator's attention, almost as if they are teasing the predator. This observation has led to a delightfully daring theory. The theory was originally foreshadowed by N. Smythe but, pushed to its logical conclusion, it bears the unmistakeable signature of A. Zahavi. Zahavi's theory can be put like this. The crucial bit of lateral thinking is the idea that stotting, far from being a signal to the other gazelles, is really aimed at the predators. It is noticed by the other gazelles and it affects their behaviour, but this is incidental, for it is primarily selected as a signal to the predator. Translated roughly into English it means: 'Look how high I can jump, I am obviously such a fit and healthy gazelle, you can't catch me, you would be much wiser to try and catch my neighbour who is not jumping so high!' In less anthropomorphic terms, genes for jumping high and ostentatiously are unlikely to be eaten by predators because predators tend to choose prey who look easy to catch. In particular, many mammal predators are known to go for the old and the unhealthy. An individual who jumps high is advertising, in an exaggerated way, the fact that he is neither old nor unhealthy. According to this theory, the display is far from altruistic. If anything it is selfish, since its object is to persuade the predator to chase somebody else. In a way there is a competition to see who can jump the highest, the loser being the one chosen by the predator. The other example that I said I would return to is the case of the kamikaze bees, who sting honey-raiders but commit almost certain suicide in the process. The honey bee is just one example of a highly social insect. Others are wasps, ants, and termites or 'white ants'. I want to discuss social insects generally, not just suicidal bees. The exploits of the social insects are legendary, in particular their astonishing feats of cooperation and apparent altruism. Suicidal stinging missions typify their prodigies of self-abnegation. In the 'honey-pot' ants there is a caste of workers with grotesquely swollen, food-packed abdomens, whose sole function in life is to hang motionless from the ceiling like bloated light-bulbs, being used as food stores by the other workers. In the human sense they do not live as individuals at all; their individuality is subjugated, apparently to the welfare of the community. A society of ants, bees, or termites achieves a kind of individuality at a higher level. Food is shared to such an extent that one may speak of a communal stomach. Information is shared so efficiently by chemical signals and by the famous 'dance' of the bees that the community behaves almost as if it were a unit with a nervous system and sense organs of its own. Foreign intruders are recognized and repelled with something of the selectivity of a body's immune reaction system. The rather high temperature inside a beehive is regulated nearly as precisely as that of the human body, even though an individual bee is not a 'warm blooded' animal. Finally and most importantly, the analogy extends to reproduction. The majority of individuals in a social insect colony are sterile workers. The 'germ line'-the line of immortal gene continuity-flows through the bodies of a minority of individuals, the reproductives. These are the analogues of our own reproductive cells in our testes and ovaries. The sterile workers are the analogy of our liver, muscle, and nerve cells. Kamikaze behaviour and other forms of altruism and cooperation by workers are not astonishing once we accept the fact that they are sterile. The body of a normal animal is manipulated to ensure the survival of its genes both through bearing offspring and through caring for other individuals containing the same genes. Suicide in the interests of caring for other individuals is incompatible with future bearing of one's own offspring. Suicidal self-sacrifice therefore seldom evolves. But a worker bee never bears offspring of its own. All its efforts are directed to preserving its genes by caring for relatives other than its own offspring. The death of a single sterile worker bee is no more serious to its genes than is the shedding of a leaf in autumn to the genes of a tree. There is a temptation to wax mystical about the social insects, but there is really no need for this. It is worth looking in some detail at how the selfish gene theory deals with them, and in particular at how it explains the evolutionary origin of that extraordinary phenomenon of worker sterility from which so much seems to follow. A social insect colony is a huge family, usually all descended from the same mother. The workers, who seldom or never reproduce themselves, are often divided into a number of distinct castes, including small workers, large workers, soldiers, and highly specialized castes like the honey-pots. Reproductive females are called queens. Reproductive males are sometimes called drones or kings. In the more advanced societies, the reproductives never work at anything except procreation, but at this one task they are extremely good. They rely on the workers for their food and protection, and the workers are also responsible for looking after the brood. In some ant and termite species the queen has swollen into a gigantic egg factory, scarcely recognizable as an insect at all, hundreds of times the size of a worker and quite incapable of moving. She is constantly tended by workers who groom her, feed her, and transport her ceaseless flow of eggs to the communal nurseries. If such a monstrous queen ever has to move from the royal cell she rides in state on the backs of squadrons of toiling workers. In Chapter 7 I introduced the distinction between bearing and caring. I said that mixed strategies, combining bearing and caring, would normally evolve. In Chapter 5 we saw that mixed evolutionarily stable strategies could be of two general types. Either each individual in the population could behave in a mixed way: thus individuals usually achieve a judicious mixture of bearing and caring; or, the population may be divided into two different types of individual: this was how we first pictured the balance between hawks and doves. Now it is theoretically possible for an evolutionarily stable balance between bearing and caring to be achieved in the latter kind of way: the population could be divided into bearers and carers. But this can only be evolutionarily stable if the carers are close kin to the individuals for whom they care, at least as close as they would be to their own offspring if they had any. Although it is theoretically possible for evolution to proceed in this direction, it seems to be only in the social insects that it has actually happened. Social insect individuals are divided into two main classes, bearers and carers. The bearers are the reproductive males and females. The carers are the workers-infertile males and females in the termites, infertile females in all other social insects. Both types do their job more efficiently because they do not have to cope with the other. But from whose point of view is it efficient? The question which will be hurled at the Darwinian theory is the familiar cry: 'What's in it for the workers?' Some people have answered 'Nothing.' They feel that the queen is having it all her own way, manipulating the workers by chemical means to her own selfish ends, making them care for her own teeming brood. This is a version of Alexander's 'parental manipulation' theory which we met in Chapter 8. The opposite idea is that the workers 'farm' the reproductives, manipulating them to increase their productivity in propagating replicas of the workers' genes. To be sure, the survival machines that the queen makes are not offspring to the workers, but they are close relatives nevertheless. It was Hamilton who brilliantly realized that, at least in the ants, bees, and wasps, the workers may actually be more closely related to the brood than the queen herself is! This led him, and later Trivers and Hare, on to one of the most spectacular triumphs of the selfish gene theory. The reasoning goes like this. Insects of the group known as the Hymenoptera, including ants, bees, and wasps, have a very odd system of sex determination. Termites do not belong to this group and they do not share the same peculiarity. A hymenopteran nest typically has only one mature queen. She made one mating flight when young and stored up the sperms for the rest of her long life-ten years or even longer. She rations the sperms out to her eggs over the years, allowing the eggs to be fertilized as they pass out through her tubes. But not all the eggs are fertilized. The unfertilized ones develop into males. A male therefore has no father, and all the cells of his body contain just a single set of chromosomes (all obtained from his mother) instead of a double set (one from the father and one from the mother) as in ourselves. In terms of the analogy of Chapter 3, a male hymenopteran has only one copy of each 'volume' in each of his cells, instead of the usual two. A female hymenopteran, on the other hand, is normal in that she does have a father, and she has the usual double set of chromosomes in each of her body cells. Whether a female develops into a worker or a queen depends not on her genes but on how she is brought up. That is to say, each female has a complete set of queen-making genes, and a complete set of worker-making genes (or, rather, sets of genes for making each specialized caste of worker, soldier, etc.). Which set of genes is 'turned on' depends on how the female is reared, in particular on the food she receives. Although there are many complications, this is essentially how things are. We do not know why this extraordinary system of sexual reproduction evolved. No doubt there were good reasons, but for the moment we must just treat it as a curious fact about the Hymenoptera. Whatever the original reason for the oddity, it plays havoc with Chapter 6's neat rules for calculating relatedness. It means that the sperms of a single male, instead of all being different as they are in ourselves, are all exactly the same. A male has only a single set of genes in each of his body cells, not a double set Every sperm must therefore receive the full set of genes rather than a 50 per cent sample, and all sperms from a given male are therefore identical. Let us now try to calculate the relatedness between a mother and son. If a male is known to possess a gene A, what are the chances that his mother shares it? The answer must be 100 per cent, since the male had no father and obtained all his genes from his mother. But now suppose a queen is known to have the gene B. The chance that her son shares the gene is only 50 per cent, since he contains only half her genes. This sounds like a contradiction, but it is not. A male gets all his genes from his mother, but a mother only gives half her genes to her son. The solution to the apparent paradox lies in the fact that a male has only half the usual number of genes. There is no point in puzzling over whether the 'true' index of relatedness is 1/2 or 1. The index is only a man-made measure, and if it leads to difficulties in particular cases, we may have to abandon it and go back to first principles. From the point of view of a gene A in the body of a queen, the chance that the gene is shared by a son is 1/2, just as it is for a daughter. From a queen's point of view therefore, her offspring, of either sex, are as closely related to her as human children are to their mother. Things start to get intriguing when we come to sisters. Full sisters not only share the same father: the two sperms that conceived them were identical in every gene. The sisters are therefore equivalent to identical twins as far as their paternal genes are concerned. If one female has a gene A, she must have got it from either her father or her mother. If she got it from her mother then there is a 50 per cent chance that her sister shares it. But if she got it from her father, the chances are 100 per cent that her sister shares it. Therefore the relatedness between hymenopteran full sisters is not 1/2 as it would be for normal sexual animals, but 3/4. It follows that a hymenopteran female is more closely related to her full sisters than she is to her offspring of either sex. As Hamilton realized (though he did not put it in quite the same way) this might well predispose a female to farm her own mother as an efficient sister-making machine. A gene for vicariously making sisters replicates itself more rapidly than a gene for making offspring directly. Hence worker sterility evolved. It is presumably no accident that true sociality, with worker sterility, seems to have evolved no fewer than eleven times independently in the Hymenoptera and only once in the whole of the rest of the animal kingdom, namely in the termites. However, there is a catch. If the workers are successfully to farm their mother as a sister-producing machine, they must somehow curb her natural tendency to give them an equal number of little brothers as well. From the point of view of a worker, the chance of any one brother containing a particular one of her genes is only 1/4. Therefore, if the queen were allowed to produce male and female reproductive offspring in equal proportions, the farm would not show a profit as far as the workers are concerned. They would not be maximizing the propagation of their precious genes. Trivers and Hare realized that the workers must try to bias the sex ratio in favour of females. They took the Fisher calculations on optimal sex ratios (which we looked at in the previous chapter) and re-worked them for the special case of the Hymenoptera. It turned out that the stable ratio of investment for a mother is, as usual, 1:1. But the stable ratio for a sister is 3:1 in favour of sisters rather than brothers. If you are a hymenopteran female, the most efficient way for you to propagate your genes is to refrain from breeding yourself, and to make your mother provide you with reproductive sisters and brothers in the ratio 3:1. But if you must have offspring of your own, you can benefit your genes best by having reproductive sons and daughters in equal proportions. As we have seen, the difference between queens and workers is not a genetic one. As far as her genes are concerned, an embryo female might be destined to become either a worker, who 'wants' a 3 :1 sex ratio, or a queen, who 'wants' a 1:1 ratio. So what does this 'wanting' mean? It means that a gene that finds itself in a queen's body can propagate itself best if that body invests equally in reproductive sons and daughters. But the same gene finding itself in a worker's body can propagate itself best by making the mother of that body have more daughters than sons. There is no real paradox here. A gene must take best advantage of the levers of power that happen to be at its disposal. If it finds itself in a position to influence the development of a body that is destined to turn into a queen, its optimal strategy to exploit that control is one thing. If it finds itself in a position to influence the way a worker's body develops, its optimal strategy to exploit that power is different. This means there is a conflict of interests down on the farm. The queen is 'trying' to invest equally in males and females. The workers are trying to shift the ratio of reproductives in the direction of three females to every one male. If we are right to picture the workers as the farmers and the queen as their brood mare, presumably the workers will be successful in achieving their 3 :1 ratio. If not, if the queen really lives up to her name and the workers are her slaves and the obedient tenders of the royal nurseries, then we should expect the 1:1 ratio which the queen 'prefers' to prevail. Who wins in this special case of a battle of the generations? This is a matter that can be put to the test and that is what Trivers and Hare did, using a large number of species of ants. The sex ratio that is of interest is the ratio of male to female reproductives. These are the large winged forms which emerge from the ants' nest in periodic bursts for mating flights, after which the young queens may try to found new colonies. It is these winged forms that have to be counted to obtain an estimate of the sex ratio. Now the male and female reproductives are, in many species, very unequal in size. This complicates things since, as we saw in the previous chapter, the Fisher calculations about optimal sex ratio strictly apply, not to numbers of males and females, but to quantity of investment in males and females. Trivers and Hare made allowance for this by weighing them. They took 20 species of ant and estimated the sex ratio in terms of investment in reproductives. They found a rather convincingly close fit to the 3:1 female to male ratio predicted by the theory that the workers are running the show for their own benefit. It seems then that in the ants studied, the conflict of interests is 'won' by the workers. This is not too surprising since worker bodies, being the guardians of the nurseries, have more power in practical terms than queen bodies. Genes trying to manipulate the world through queen bodies are outmanoeuvred by genes manipulating the world through worker bodies. It is interesting to look around for some special circumstances in which we might expect queens to have more practical power than workers. Trivers and Hare realized that there was just such a circumstance which could be used as a critical test of the theory. This arises from the fact that there are some species of ant that take slaves. The workers of a slave-making species either do no ordinary work at all or are rather bad at it. What they are good at is going on slaving raids. True warfare in which large rival armies fight to the death is known only in man and in social insects. In many species of ants the specialized caste of workers known as soldiers have formidable fighting jaws, and devote their time to fighting for the colony against other ant armies. Slaving raids are just a particular kind of war effort. The slavers mount an attack on a nest of ants belonging to a different species, attempt to kill the defending workers or soldiers, and carry off the unhatched young. These young ones hatch out in the nest of their captors. They do not 'realize' that they are slaves and they set to work following their built-in nervous programs, doing all the duties that they would normally perform in their own nest. The slave-making workers or soldiers go on further slaving expeditions while the slaves stay at home and get on with the everyday business of running an ants' nest, cleaning, foraging, and caring for the brood. The slaves are, of course, blissfully ignorant of the fact that they are unrelated to the queen and to the brood that they are tending. Unwittingly they are rearing new platoons of slave-makers. No doubt natural selection, acting on the genes of the slave species, tends to favour anti-slavery adaptations. However, these are evidently not fully effective because slavery is a wide spread phenomenon. The consequence of slavery that is interesting from our present point of view is this. The queen of the slave-making species is now in a position to bend the sex ratio in the direction she 'prefers'. This is because her own true-born children, the slavers, no longer hold the practical power in the nurseries. This power is now held by the slaves. The slaves 'think' they are looking after their own siblings and they are presumably doing whatever would be appropriate in their own nests to achieve their desired 3:1 bias in favour of sisters. But the queen of the slave-making species is able to get away with countermeasures and there is no selection operating on the slaves to neutralize these counter-measures, since the slaves are totally unrelated to the brood. For example, suppose that in any ant species, queens 'attempt' to disguise male eggs by making them smell like female ones. Natural selection will normally favour any tendency by workers to 'see through' the disguise. We may picture an evolutionary battle in which queens continually 'change the code', and workers 'break the code'. The war will be won by whoever manages to get more of her genes into the next generation, via the bodies of the reproductives. This will normally be the workers, as we have seen. But when the queen of a slave-making species changes the code, the slave workers cannot evolve any ability to break the code. This is because any gene in a slave worker 'for breaking the code' is not represented in the body of any reproductive individual, and so is not passed on. The reproductives all belong to the slave-making species, and are kin to the queen but not to the slaves. If the genes of the slaves find their way into any reproductives at all, it will be into the reproductives that emerge from the original nest from which they were kidnapped. The slave workers will, if anything, be busy breaking the wrong code! Therefore, queens of a slave-making species can get away with changing their code freely, without there being any danger that genes for breaking the code will be propagated into the next generation. The upshot of this involved argument is that we should expect in slave-making species that the ratio of investment in reproductives of the two sexes should approach 1:1 rather than 3:1. For once, the queen will have it all her own way. This is just what Trivers and Hare found, although they only looked at two slave-making species. I must stress that I have told the story in an idealized way. Real life is not so neat and tidy. For instance, the most familiar social insect species of all, the honey bee, seems to do entirely the 'wrong' thing. There is a large surplus of investment in males over queens- something that does not appear to make sense from either the workers' or the mother queen's point of view. Hamilton has offered a possible solution to this puzzle. He points out that when a queen bee leaves the hive she goes with a large swarm of attendant workers, who help her to start a new colony. These workers are lost to the parent hive, and the cost of making them must be reckoned as part of the cost of reproduction: for every queen who leaves, many extra workers have to be made. Investment in these extra workers should be counted as part of the investment in reproductive females. The extra workers should be weighed in the balance against the males when the sex ratio is computed. So this was not a serious difficulty for the theory after all. A more awkward spanner in the elegant works of the theory is the fact that, in some species, the young queen on her mating flight mates with several males instead of one. This means that the average relatedness among her daughters is less than 3/4, and may even approach 1/4 in extreme cases. It is tempting, though probably not very logical, to regard this as a cunning blow struck by queens against workers! Incidentally, this might seem to suggest that workers should chaperone a queen on her mating flight, to prevent her from mating more than once. But this would in no way help the workers' own genes-only the genes of the coming generation of workers. There is no trade-union spirit among the workers as a class. All that each one of them 'cares' about is her own genes. A worker might have 'liked' to have chaperoned her own mother, but she lacked the opportunity, not having been conceived in those days. A young queen on her mating flight is the sister of the present generation of workers, not the mother. Therefore they are on her side rather than on the side of the next generation of workers, who are merely their nieces. My head is now spinning, and it is high time to bring this topic to a close. I have used the analogy of farming for what hymenopteran workers do to their mothers. The farm is a gene farm. The workers use their mother as a more efficient manufacturer of copies of their own genes than they would be themselves. The genes come off the production line in packages called reproductive individuals. This farming analogy should not be confused with a quite different sense in which the social insects may be said to farm. Social insects discovered, as man did long after, that settled cultivation of food can be more efficient than hunting and gathering. For example, several species of ants in the New World, and, quite independently, termites in Africa, cultivate 'fungus gardens'. The best known are the so-called parasol ants of South America. These are immensely successful. Single colonies with more than two million individuals have been found. Their nests consist of huge spreading underground complexes of passages and galleries going down to a depth of ten feet or more, made by the excavation of as much as 40 tons of soil. The underground chambers contain the fungus gardens. The ants deliberately sow fungus of a particular species in special compost beds which they prepare by chewing leaves into fragments. Instead of foraging directly for their own food, the workers forage for leaves to make compost. The 'appetite' of a colony of parasol ants for leaves is gargantuan. This makes them a major economic pest, but the leaves are not food for themselves but food for their fungi. The ants eventually harvest and eat the fungi and feed them to their brood. The fungi are more efficient at breaking down leaf material than the ants' own stomachs would be, which is how the ants benefit by the arrangement. It is possible that the fungi benefit too, even though they are cropped: the ants propagate them more efficiently than their own spore dispersal mechanism might achieve. Furthermore, the ants 'weed' the fungus gardens, keeping them clear of alien species of fungi. By removing competition, this may benefit the ants' own domestic fungi. A kind of relationship of mutual altruism could be said to exist between ants and fungi. It is remarkable that a very similar system of fungus farming has evolved independently, among the quite unrelated termites. Ants have their own domestic animals as well as their crop plants. Aphids-greenfly and similar bugs-are highly specialized for sucking the juice out of plants. They pump the sap up out of the plants' veins more efficiently than they subsequently digest it. The result is that they excrete a liquid that has had only some of its nutritious value extracted. Droplets of sugar-rich 'honeydew' pass out of the back end at a great rate, in some cases more than the insect's own body-weight every hour. The honeydew normally rains down on to the ground-it may well have been the providential food known as 'manna' in the Old Testament. But ants of several species intercept it as soon as it leaves the bug. The ants 'milk' the aphids by stroking their hind-quarters with their feelers and legs. Aphids respond to this, in some cases apparently holding back their droplets until an ant strokes them, and even withdrawing a droplet if an ant is not ready to accept it. It has been suggested that some aphids have evolved a backside that looks and feels like an ant's face, the better to attract ants. What the aphids have to gain from the relationship is apparently protection from their natural enemies. Like our own dairy cattle they lead a sheltered life, and aphid species that are much cultivated by ants have lost their normal defensive mechanisms. In some cases ants care for the aphid eggs inside their own underground nests, feed the young aphids, and finally, when they are grown, gently carry them up to the protected grazing grounds. A relationship of mutual benefit between members of different species is called mutualism or symbiosis. Members of different species often have much to offer each other because they can bring different 'skills' to the partnership. This kind of fundamental asymmetry can lead to evolutionarily stable strategies of mutual cooperation. Aphids have the right sort of mouthparts for pumping up plant sap, but such sucking mouthparts are no good for self-defence. Ants are no good at sucking sap from plants, but they are good at fighting. Ant genes for cultivating and protecting aphids have been favoured in ant gene-pools. Aphid genes for cooperating with the ants have been favoured in aphid gene-pools. Symbiotic relationships of mutual benefit are common among animals and plants. A lichen appears superficially to be an individual plant like any other. But it is really an intimate symbiotic union between a fungus and a green alga. Neither partner could live without the other. If their union had become just a bit more intimate we would no longer have been able to tell that a lichen was a double organism at all. Perhaps then there are other double or multiple organisms which we have not recognized as such. Perhaps even we ourselves? Within each one of our cells there are numerous tiny bodies called mitochondria. The mitochondria are chemical factories, responsible for providing most of the energy we need. If we lost our mitochondria we would be dead within seconds. Recently it has been plausibly argued that mitochondria are, in origin, symbiotic bacteria who joined forces with our type of cell very early in evolution. Similar suggestions have been made for other small bodies within our cells. This is one of those revolutionary ideas which it takes time to get used to, but it is an idea whose time has come. I speculate that we shall come to accept the more radical idea that each one of our genes is a symbiotic unit. We are gigantic colonies of symbiotic genes. One cannot really speak of 'evidence' for this idea, but, as I tried to suggest in earlier chapters, it is really inherent in the very way we think about how genes work in sexual species. The other side of this coin is that viruses may be genes who have broken loose from 'colonies' such as ourselves. Viruses consist of pure DNA (or a related self-replicating molecule) surrounded by a protein jacket. They are all parasitic. The suggestion is that they have evolved from 'rebel' genes who escaped, and now travel from body to body directly through the air, rather than via the more conventional vehicles-sperms and eggs. If this is true, we might just as well regard ourselves as colonies of viruses! Some of them cooperate symbiotically, and travel from body to body in sperms and eggs. These are the conventional 'genes'. Others live parasitically, and travel by whatever means they can. If the parasitic DNA travels in sperms and eggs, it perhaps forms the 'paradoxical' surplus of DNA which I mentioned in Chapter 3. If it travels through the air, or by other direct means, it is called 'virus' in the usual sense. But these are speculations for the future. At present we are concerned with symbiosis at the higher level of relationships between many-celled organisms, rather than within them. The word symbiosis is conventionally used for associations between members of different species. But, now that we have eschewed the 'good of the species' view of evolution, there seems no logical reason to distinguish associations between members of different species as things apart from associations between members of the same species. In general, associations of mutual benefit will evolve if each partner can get more out than he puts in. This is true whether we are speaking of members of the same hyena pack, or of widely distinct creatures such as ants and aphids, or bees and flowers. In practice it may be difficult to distinguish cases of genuine two-way mutual benefit from cases of one-sided exploitation. The evolution of associations of mutual benefit is theoretically easy to imagine if the favours are given and received simultaneously, as in the case of the partners who make up a lichen. But problems arise if there is a delay between the giving of a favour and its repayment. This is because the first recipient of a favour may be tempted to cheat and refuse to pay it back when his turn comes. The resolution of this problem is interesting and is worth discussing in detail. I can do this best in terms of a hypothetical example. Suppose a species of bird is parasitized by a particularly nasty kind of tick which carries a dangerous disease. It is very important that these ticks should be removed as soon as possible. Normally an individual bird can pull off its owns ticks when preening itself. There is one place, however-the top of the head-which it cannot reach with its own bill. The solution to the problem quickly occurs to any human. An individual may not be able to reach his own head, but nothing is easier than for a friend to do it for him. Later, when the friend is parasitized himself, the good deed can be paid back. Mutual grooming is in fact very common in both birds and mammals. This makes immediate intuitive sense. Anybody with conscious foresight can see that it is sensible to enter into mutual back-scratching arrangements. But we have learnt to beware of what seems intuitively sensible. The gene has no foresight. Can the theory of selfish genes account for mutual back-scratching, or 'reciprocal altruism', where there is a delay between good deed and repayment? Williams briefly discussed the problem in his 1966 book, to which I have already referred. He concluded, as had Darwin, that delayed reciprocal altruism can evolve in species that are capable of recognizing and remembering each other as individuals. Trivers, in 1971, took the matter further. When he wrote, he did not have available to him Maynard Smith's concept of the evolutionarily stable strategy. If he had, my guess is that he would have made use of it, for it provides a natural way to express his ideas. His reference to the 'Prisoner's Dilemma'-a favourite puzzle in game theory- shows that he was already thinking along the same lines. Suppose B has a parasite on the top of his head. A pulls it off him. Later, the time comes when A has a parasite on his head. He naturally seeks out B in order that B may pay back his good deed. B simply turns up his nose and walks off. B is a cheat, an individual who accepts the benefit of other individuals' altruism, but who does not pay it back, or who pays it back insufficiently. Cheats do better than indiscriminate altruists because they gain the benefits without paying the costs. To be sure, the cost of grooming another individual's head seems small compared with the benefit of having a dangerous parasite removed, but it is not negligible. Some valuable energy and time has to be spent. Let the population consist of individuals who adopt one of two strategies. As in Maynard Smith's analyses, we are not talking about conscious strategies, but about unconscious behaviour programs laid down by genes. Call the two strategies Sucker and Cheat. Suckers groom anybody who needs it, indiscriminately. Cheats accept altruism from suckers, but they never groom anybody else, not even somebody who has previously groomed them. As in the case of the hawks and doves, we arbitrarily assign pay-off points. It does not matter what the exact values are, so long as the benefit of being groomed exceeds the cost of grooming. If the incidence of parasites is high, any individual sucker in a population of suckers can reckon on being groomed about as often as he grooms. The average pay-off for a sucker among suckers is therefore positive. They all do quite nicely in fact, and the word sucker seems inappropriate. But now suppose a cheat arises in the population. Being the only cheat, he can count on being groomed by everybody else, but he pays nothing in return. His average pay-off is better than the average for a sucker. Cheat genes will therefore start to spread through the population. Sucker genes will soon be driven to extinction. This is because, no matter what the ratio in the population, cheats will always do better than suckers. For instance, consider the case when the population consists of 50 per cent suckers and 50 per cent cheats. The average pay-off for both suckers and cheats will be less than that for any individual in a population of 100 per cent suckers. But still, cheats will be doing better than suckers because they are getting all the benefits-such as they are-and paying nothing back. When the proportion of cheats reaches 90 per cent, the average pay-off for all individuals will be very low: many of both types may by now be dying of the infection carried by the ticks. But still the cheats will be doing better than the suckers. Even if the whole population declines toward extinction, there will never be any time when suckers do better than cheats. Therefore, as long as we consider only these two strategies, nothing can stop the extinction of the suckers and, very probably, the extinction of the whole population too. But now, suppose there is a third strategy called Grudger. Grudgers groom strangers and individuals who have previously groomed them. However, if any individual cheats them, they remember the incident and bear a grudge: they refuse to groom that individual in the future. In a population of grudgers and suckers it is impossible to tell which is which. Both types behave altruistically towards everybody else, and both earn an equal and high average pay-off. In a population consisting largely of cheats, a single grudger would not be very successful. He would expend a great deal of energy grooming most of the individuals he met-for it would take time for him to build up grudges against all of them. On the other hand, nobody would groom him in return. If grudgers are rare in comparison with cheats, the grudger gene will go extinct. Once the grudgers manage to build up in numbers so that they reach a critical proportion, however, their chance of meeting each other becomes sufficiently great to off-set their wasted effort in grooming cheats. When this critical proportion is reached they will start to average a higher pay-off than cheats, and the cheats will be driven at an accelerating rate towards extinction. When the cheats are nearly extinct their rate of decline will become slower, and they may survive as a minority for quite a long time. This is because for any one rare cheat there is only a small chance of his encountering the same grudger twice: therefore the proportion of individuals in the population who bear a grudge against any given cheat will be small. I have told the story of these strategies as though it were intuitively obvious what would happen. In fact it is not all that obvious, and I did take the precaution of simulating it on a computer to check that intuition was right. Grudger does indeed turn out to be an evolutionarily stable strategy against sucker and cheat, in the sense that, in a population consisting largely of grudgers, neither cheat nor sucker will invade. Cheat is also an ESS, however, because a population consisting largely of cheats will not be invaded by either grudger or sucker. A population could sit at either of these two ESSs. In the long term it might flip from one to the other. Depending on the exact values of the pay-offs-the assumptions in the simulation were of course completely arbitrary-one or other of the two stable states will have a larger 'zone of attraction' and will be more likely to be attained. Note incidentally that, although a population of cheats may be more likely to go extinct than a population of grudgers, this in no way affects its status as an ESS. If a population arrives at an ESS that drives it extinct, then it goes extinct, and that is just too bad. It is quite entertaining to watch a computer simulation that starts with a strong majority of suckers, a minority of grudgers that is just above the critical frequency, and about the same-sized minority of cheats. The first thing that happens is a dramatic crash in the population of suckers as the cheats ruthlessly exploit them. The cheats enjoy a soaring population explosion, reaching their peak just as the last sucker perishes. But the cheats still have the grudgers to reckon with. During the precipitous decline of the suckers, the grudgers have been slowly decreasing in numbers, taking a battering from the prospering cheats, but just managing to hold their own. After the last sucker has gone and the cheats can no longer get away with selfish exploitation so easily, the grudgers slowly begin to increase at the cheats' expense. Steadily their population rise gathers momentum. It accelerates steeply, the cheat population crashes to near extinction, then levels out as they enjoy the privileges of rarity and the comparative freedom from grudges which this brings. However, slowly and inexorably the cheats are driven out of existence, and the grudgers are left in sole possession. Paradoxically, the presence of the suckers actually endangered the grudgers early on in the story because they were responsible for the temporary prosperity of the cheats. By the way, my hypothetical example about the dangers of not being groomed is quite plausible. Mice kept in isolation tend to develop unpleasant sores on those parts of their heads that they cannot reach. In one study, mice kept in groups did not suffer in this way, because they licked each others' heads. It would be interesting to test the theory of reciprocal altruism experimentally and it seems that mice might be suitable subjects for the work. Trivers discusses the remarkable symbiosis of the cleaner-fish. Some fifty species, including small fish and shrimps, are known to make their living by picking parasites off the surface of larger fish of other species. The large fish obviously benefit from being cleaned, and the cleaners get a good supply of food. The relationship is symbiotic. In many cases the large fish open their mouths and allow cleaners right inside to pick their teeth, and then to swim out through the gills which they also clean. One might expect that a large fish would craftily wait until he had been thoroughly cleaned, and then gobble up the cleaner. Yet instead he usually lets the cleaner swim off unmolested. This is a considerable feat of apparent altruism because in many cases the cleaner is of the same size as the large fish's normal prey. Cleaner-fish have special stripy patterns and special dancing displays which label them as cleaners. Large fish tend to refrain from eating small fish who have the right kind of stripes, and who approach them with the right kind of dance. Instead they go into a trance-like state and allow the cleaner free access to their exterior and interior. Selfish genes being what they are, it is not surprising that ruthless, exploiting cheats have cashed in. There are species of small fish that look just like cleaners and dance in the same kind of way in order to secure safe conduct into the vicinity of large fish. When the large fish has gone into its expectant trance the cheat, instead of pulling off a parasite, bites a chunk out of the large fish's fin and beats a hasty retreat. But in spite of the cheats, the relationship between fish cleaners and their clients is mainly amicable and stable. The profession of cleaner plays an important part in the daily life of the coral reef community. Each cleaner has his own territory', and large fish have been seen queuing up for attention like customers at a barber's shop. It is probably this site-tenacity that makes possible the evolution of delayed reciprocal-altruism in this case. The benefit to a large fish of being able to return repeatedly to the same 'barber's shop', rather than continually searching for a new one, must outweigh the cost of refraining from eating the cleaner. Since cleaners are small, this is not hard to believe. The presence of cheating cleaner-mimics probably indirectly endangers the bonafide cleaners by setting up a minor pressure on large fish to eat stripy dancers. Site-tenacity on the part of genuine cleaners enables customers to find them and to avoid cheats. A long memory and a capacity for individual recognition are well developed in man. We might therefore expect reciprocal altruism to have played an important part in human evolution. Trivers goes so far as to suggest that many of our psychological characteristics- envy, guilt, gratitude, sympathy etc.-have been shaped by natural selection for improved ability to cheat, to detect cheats, and to avoid being thought to be a cheat. Of particular interest are 'subtle cheats' who appear to be reciprocating, but who consistently pay back slightly less than they receive. It is even possible that man's swollen brain, and his predisposition to reason mathematically, evolved as a mechanism of ever more devious cheating, and ever more penetrating detection of cheating in others. Money is a formal token of delayed reciprocal altruism. There is no end to the fascinating speculation that the idea of reciprocal altruism engenders when we apply it to our own species. Tempting as it is, I am no better at such speculation than the next man, and I leave the reader to entertain himself.",
        "char_count": 57449
      },
      {
        "heading": "Chapter 12",
        "text": "The Selfish Gene 11. Memes: the new replicators. So far, I have not talked much about man in particular, though I have not deliberately excluded him either. Part of the reason I have used the term 'survival machine' is that 'animal' would have left out plants and, in some people's minds, humans. The arguments I have put forward should, prima facie, apply to any evolved being. If a species is to be excepted, it must be for good particular reasons. Are there any good reasons for supposing our own species to be unique? I believe the answer is yes. Most of what is unusual about man can be summed up in one word: 'culture'. I use the word not in its snobbish sense, but as a scientist uses it. Cultural transmission is analogous to genetic transmission in that, although basically conservative, it can give rise to a form of evolution. Geoffrey Chaucer could not hold a conversation with a modern Englishman, even though they are linked to each other by an unbroken chain of some twenty generations of Englishmen, each of whom could speak to his immediate neighbours in the chain as a son speaks to his father. Language seems to 'evolve' by non-genetic means, and at a rate which is orders of magnitude faster than genetic evolution. Cultural transmission is not unique to man. The best non-human example that I know has recently been described by P. F.Jenkins in the song of a bird called the saddleback which lives on islands off New Zealand. On the island where he worked there was a total repertoire of about nine distinct songs. Any given male sang only one or a few of these songs. The males could be classified into dialect groups. For example, one group of eight males with neighbouring territories sang a particular song called the CC song. Other dialect groups sang different songs. Sometimes the members of a dialect group shared more than one distinct song. By comparing the songs of fathers and sons, Jenkins showed that song patterns were not inherited genetically. Each young male was likely to adopt songs from his territorial neighbours by imitation, in an analogous way to human language. During most of the time Jenkins was there, there was a fixed number of songs on the island, a kind of 'song pool' from which each young male drew his own small repertoire. But occasionally Jenkins was privileged to witness the 'invention' of a new song, which occurred by a mistake in the imitation of an old one. He writes: 'New song forms have been shown to arise variously by change of pitch of a note, repetition of a note, the elision of notes and the combination of parts of other existing songs . . . The appearance of the new form was an abrupt event and the product was quite stable over a period of years. Further, in a number of cases the variant was transmitted accurately in its new form to younger recruits so that a recognizably coherent group of like singers developed.' Jenkins refers to the origins of new songs as 'cultural mutations'. Song in the saddleback truly evolves by non-genetic means. There are other examples of cultural evolution in birds and monkeys, but these are just interesting oddities. It is our own species that really shows what cultural evolution can do. Language is only one example out of many. Fashions in dress and diet, ceremonies and customs, art and architecture, engineering and technology, all evolve in historical time in a way that looks like highly speeded up genetic evolution, but has really nothing to do with genetic evolution. As in genetic evolution though, the change may be progressive. There is a sense in which modern science is actually better than ancient science. Not only does our understanding of the universe change as the centuries go by: it improves. Admittedly the current burst of improvement dates back only to the Renaissance, which was preceded by a dismal period of stagnation, in which European scientific culture was frozen at the level achieved by the Greeks. But, as we saw in Chapter 5, genetic evolution too may proceed as a series of brief spurts between stable plateaux. The analogy between cultural and genetic evolution has frequently been pointed out, sometimes in the context of quite unnecessary mystical overtones. The analogy between scientific progress and genetic evolution by natural selection has been illuminated especially by Sir Karl Popper. I want to go even further into directions which are also being explored by, for example, the geneticist L. L. Cavalli-Sforza, the anthropologist F. T. Cloak, and the ethologist J. M. Cullen. As an enthusiastic Darwinian, I have been dissatisfied with explanations that my fellow-enthusiasts have offered for human behaviour. They have tried to look for 'biological advantages' in various attributes of human civilization. For instance, tribal religion has been seen as a mechanism for solidifying group identity, valuable for a pack-hunting species whose individuals rely on cooperation to catch large and fast prey. Frequently the evolutionary preconception in terms of which such theories are framed is implicitly group-selectionist, but it is possible to rephrase the theories in terms of orthodox gene selection. Man may well have spent large portions of the last several million years living in small kin groups. Kin selection and selection in favour of reciprocal altruism may have acted on human genes to produce many of our basic psychological attributes and tendencies. These ideas are plausible as far as they go, but I find that they do not begin to square up to the formidable challenge of explaining culture, cultural evolution, and the immense differences between human cultures around the world, from the utter selfishness of the Ik of Uganda, as described by Colin Turnbull, to the gentle altruism of Margaret Mead's Arapesh. I think we have got to start again and go right back to first principles. The argument I shall advance, surprising as it may seem coming from the author of the earlier chapters, is that, for an understanding of the evolution of modern man, we must begin by throwing out the gene as the sole basis of our ideas on evolution. I am an enthusiastic Darwinian, but I think Darwinism is too big a theory to be confined to the narrow context of the gene. The gene will enter my thesis as an analogy, nothing more. What, after all, is so special about genes? The answer is that they are replicators. The laws of physics are supposed to be true all over the accessible universe. Are there any principles of biology that are likely to have similar universal validity? When astronauts voyage to distant planets and look for life, they can expect to find creatures too strange and unearthy for us to imagine. But is there anything that must be true of all life, wherever it is found, and whatever the basis of its chemistry? If forms of life exist whose chemistry is based on silicon rather than carbon, or ammonia rather than water, if creatures are discovered that boil to death at -100 degrees centigrade, if a form of life is found that is not based on chemistry at all but on electronic reverberating circuits, will there still be any general principle that is true of all life? Obviously I do not know but, if I had to bet, I would put my money on one fundamental principle. This is the law that all life evolves by the differential survival of replicating entities. The gene, the DNA molecule, happens to be the replicating entity that prevails on our own planet. There may be others. If there are, provided certain other conditions are met, they will almost inevitably tend to become the basis for an evolutionary process. But do we have to go to distant worlds to find other kinds of replicator and other, consequent, kinds of evolution? I think that a new kind of replicator has recently emerged on this very planet. It is staring us in the face. It is still in its infancy, still drifting clumsily about in its primeval soup, but already it is achieving evolutionary change at a rate that leaves the old gene panting far behind. The new soup is the soup of human culture. We need a name for the new replicator, a noun that conveys the idea of a unit of cultural transmission, or a unit of imitation. 'Mimeme' comes from a suitable Greek root, but I want a monosyllable that sounds a bit like 'gene'. I hope my classicist friends will forgive me if I abbreviate mimeme to meme. If it is any consolation, it could alternatively be thought of as being related to 'memory', or to the French word meme. It should be pronounced to rhyme with 'cream'. Examples of memes are tunes, ideas, catch-phrases, clothes fashions, ways of making pots or of building arches. Just as genes propagate themselves in the gene pool by leaping from body to body via sperms or eggs, so memes propagate themselves in the meme pool by leaping from brain to brain via a process which, in the broad sense, can be called imitation. If a scientist hears, or reads about, a good idea, he passes it on to his colleagues and students. He mentions it in his articles and his lectures. If the idea catches on, it can be said to propagate itself, spreading from brain to brain. As my colleague N. K. Humphrey neatly summed up an earlier draft of this chapter:'... memes should be regarded as living structures, not just metaphorically but technically. When you plant a fertile meme in my mind you literally parasitize my brain, turning it into a vehicle for the meme's propagation in just the way that a virus may parasitize the genetic mechanism of a host cell. And this isn't just a way of talking-the meme for, say, “belief in life after death” is actually realized physically, millions of times over, as a structure in the nervous systems of individual men the world over.' Consider the idea of God. We do not know how it arose in the meme pool. Probably it originated many times by independent 'mutation'. In any case, it is very old indeed. How does it replicate itself? By the spoken and written word, aided by great music and great art. Why does it have such high survival value? Remember that 'survival value' here does not mean value for a gene in a gene pool, but value for a meme in a meme pool. The question really means: What is it about the idea of a god that gives it its stability and penetrance in the cultural environment? The survival value of the god meme in the meme pool results from its great psychological appeal. It provides a superficially plausible answer to deep and troubling questions about existence. It suggests that injustices in this world may be rectified in the next. The 'everlasting arms' hold out a cushion against our own inadequacies which, like a doctor's placebo, is none the less effective for being imaginary. These are some of the reasons why the idea of God is copied so readily by successive generations of individual brains. God exists, if only in the form of a meme with high survival value, or infective power, in the environment provided by human culture. Some of my colleagues have suggested to me that this account of the survival value of the god meme begs the question. In the last analysis they wish always to go back to 'biological advantage'. To them it is not good enough to say that the idea of a god has 'great psychological appeal'. They want to know why it has great psychological appeal. Psychological appeal means appeal to brains, and brains are shaped by natural selection of genes in gene-pools. They want to find some way in which having a brain like that improves gene survival. I have a lot of sympathy with this attitude, and I do not doubt that there are genetic advantages in our having brains of the kind that we have. But nevertheless I think that these colleagues, if they look carefully at the fundamentals of their own assumptions, will find that they are begging just as many questions as I am. Fundamentally, the reason why it is good policy for us to try to explain biological phenomena in terms of gene advantage is that genes are replicators. As soon as the primeval soup provided conditions in which molecules could make copies of themselves, the replicators themselves took over. For more than three thousand million years, DNA has been the only replicator worth talking about in the world. But it does not necessarily hold these monopoly rights for all time. Whenever conditions arise in which a new kind of replicator can make copies of itself, the new replicators will tend to take over, and start a new kind of evolution of their own. Once this new evolution begins, it will in no necessary sense be subservient to the old. The old gene-selected evolution, by making brains, provided the soup' in which the first memes arose. Once self-copying memes had arisen, their own, much faster, kind of evolution took off. We biologists have assimilated the idea of genetic evolution so deeply that we tend to forget that it is only one of many possible kinds of evolution. Imitation, in the broad sense, is how memes can replicate. But just as not all genes that can replicate do so successfully, so some memes are more successful in the meme-pool than others. This is the analogue of natural selection. I have mentioned particular examples of qualities that make for high survival value among memes. But in general they must be the same as those discussed for the replicators of Chapter 2: longevity, fecundity, and copying-fidelity. The longevity of any one copy of a meme is probably relatively unimportant, as it is for any one copy of a gene. The copy of the tune 'Auld Lang Syne' that exists in my brain will last only for the rest of my life. The copy of the same tune that is printed in my volume of The Scottish Student's Song Book is unlikely to last much longer. But I expect there will be copies of the same tune on paper and in peoples' brains for centuries to come. As in the case of genes, fecundity is much more important than longevity of particular copies. If the meme is a scientific idea, its spread will depend on how acceptable it is to the population of individual scientists; a rough measure of its survival value could be obtained by counting the number of times it is referred to in successive years in scientific journals. If it is a popular tune, its spread through the meme pool may be gauged by the number of people heard whistling it in the streets. If it is a style of women's shoe, the population memeticist may use sales statistics from shoe shops. Some memes, like some genes, achieve brilliant short-term success in spreading rapidly, but do not last long in the meme pool. Popular songs and stiletto heels are examples. Others, such as the Jewish religious laws, may continue to propagate themselves for thousands of years, usually because of the great potential permanence of written records. This brings me to the third general quality of successful replicators: copying-fidelity. Here I must admit that I am on shaky ground. At first sight it looks as if memes are not high-fidelity replicators at all. Every time a scientist hears an idea and passes it on to somebody else, he is likely to change it somewhat. I have made no secret of my debt in this book to the ideas of R. L. Trivers, Yet I have not repeated them in his own words. I have twisted them round for my own purposes, changing the emphasis, blending them with ideas of my own and of other people. The memes are being passed on to you in altered form. This looks quite unlike the particulate, all-or-none quality of gene transmission. It looks as though meme transmission is subject to continuous mutation, and also to blending. It is possible that this appearance of non-particulateness is illusory, and that the analogy with genes does not break down. After all, if we look at the inheritance of many genetic characters such as human height or skin-colouring, it does not look like the work of indivisible and unblendable genes. If a black and a white person mate, their children do not come out either black or white: they are intermediate. This does not mean the genes concerned are not particulate. It is just that there are so many of them concerned with skin colour, each one having such a small effect, that they seem to blend. So far I have talked of memes as though it was obvious what a single unit-meme consisted of. But of course it is far from obvious. I have said a tune is one meme, but what about a symphony: how many memes is that? Is each movement one meme, each recognizable phrase of melody, each bar, each chord, or what? I appeal to the same verbal trick as I used in Chapter 3. There I divided the 'gene complex' into large and small genetic units, and units within units. The 'gene' was defined, not in a rigid all-or-none way, but as a unit of convenience, a length of chromosome with just sufficient copying-fidelity to serve as a viable unit of natural selection. If a single phrase of Beethoven's ninth symphony is sufficiently distinctive and memorable to be abstracted from the context of the whole symphony, and used as the call-sign of a maddeningly intrusive European broadcasting station, then to that extent it deserves to be called one meme. It has, incidentally, materially diminished my capacity to enjoy the original symphony. Similarly, when we say that all biologists nowadays believe in Darwin's theory, we do not mean that every biologist has, graven in his brain, an identical copy of the exact words of Charles Darwin himself. Each individual has his own way of interpreting Darwin's ideas. He probably learned them not from Darwin's own writings, but from more recent authors. Much of what Darwin said is, in detail, wrong. Darwin if he read this book would scarcely recognize his own original theory in it, though I hope he would like the way I put it. Yet, in spite of all this, there is something, some essence of Darwinism, which is present in the head of every individual who understands the theory. If this were not so, then almost any statement about two people agreeing with each other would be meaningless. An 'idea-meme' might be defined as an entity that is capable of being transmitted from one brain to another. The meme of Darwin's theory is therefore that essential basis of the idea which is held in common by all brains that understand the theory. The differences in the ways that people represent the theory are then, by definition, not part of the meme. If Darwin's theory can be subdivided into components, such that some people believe component A but not component B, while others believe B but not A, then A and B should be regarded as separate memes. If almost everybody who believes in A also believes in B-if the memes are closely 'linked' to use the genetic term-then it is convenient to lump them together as one meme. Let us pursue the analogy between memes and genes further. Throughout this book, I have emphasized that we must not think of genes as conscious, purposeful agents. Blind natural selection, however, makes them behave rather as if they were purposeful, and it has been convenient, as a shorthand, to refer to genes in the language of purpose. For example, when we say 'genes are trying to increase their numbers in future gene pools', what we really mean is 'those genes that behave in such a way as to increase their numbers in future gene pools tend to be the genes whose effects we see in the world'. Just as we have found it convenient to think of genes as active agents, working purposefully for their own survival, perhaps it might be convenient to think of memes in the same way. In neither case must we get mystical about it. In both cases the idea of purpose is only a metaphor, but we have already seen what a fruitful metaphor it is in the case of genes. We have even used words like 'selfish' and 'ruthless' of genes, knowing full well it is only a figure of speech. Can we, in exactly the same spirit, look for selfish or ruthless memes? There is a problem here concerning the nature of competition. Where there is sexual reproduction, each gene is competing particularly with its own alleles-rivals for the same chromosomal slot. Memes seem to have nothing equivalent to chromosomes, and nothing equivalent to alleles. I suppose there is a trivial sense in which many ideas can be said to have 'opposites'. But in general memes resemble the early replicating molecules, floating chaotically free in the primeval soup, rather than modern genes in their neatly paired, chromosomal regiments. In what sense then are memes competing with each other? Should we expect them to be 'selfish' or 'ruthless', if they have no alleles? The answer is that we might, because there is a sense in which they must indulge in a kind of competition with each other. Any user of a digital computer knows how precious computer time and memory storage space are. At many large computer centres they are literally costed in money; or each user may be allotted a ration of time, measured in seconds, and a ration of space, measured in 'words'. The computers in which memes live are human brains. Time is possibly a more important limiting factor than storage space, and it is the subject of heavy competition. The human brain, and the body that it controls, cannot do more than one or a few things at once. If a meme is to dominate the attention of a human brain, it must do so at the expense of 'rival' memes. Other commodities for which memes compete are radio and television time, billboard space, newspaper column-inches, and library' shelf-space. In the case of genes, we saw in Chapter 3 that co-adapted gene complexes may arise in the gene pool. A large set of genes concerned with mimicry in butterflies became tightly linked together on the same chromosome, so tightly that they can be treated as one gene. In Chapter 5 we met the more sophisticated idea of the evolutionarily stable set of genes. Mutually suitable teeth, claws, guts, and sense organs evolved in carnivore gene pools, while a different stable set of characteristics emerged from herbivore gene pools. Does anything analogous occur in meme pools? Has the god meme, say, become associated with any other particular memes, and does this association assist the survival of each of the participating memes? Perhaps we could regard an organized church, with its architecture, rituals, laws, music, art, and written tradition, as a co-adapted stable set of mutually-assisting memes. To take a particular example, an aspect of doctrine that has been very effective in enforcing religious observance is the threat of hell fire. Many children and even some adults believe that they will suffer ghastly torments after death if they do not obey the priestly rules. This is a peculiarly nasty technique of persuasion, causing great psychological anguish throughout the middle ages and even today. But it is highly effective. It might almost have been planned deliberately by a machiavellian priesthood trained in deep psychological indoctrination techniques. However, I doubt if the priests were that clever. Much more probably, unconscious memes have ensured their own survival by virtue of those same qualities of pseudo-ruthlessness that successful genes display. The idea of hell fire is, quite simply, self perpetuating, because of its own deep psychological impact. It has become linked with the god meme because the two reinforce each other, and assist each other's survival in the meme pool. Another member of the religious meme complex is called faith. It means blind trust, in the absence of evidence, even in the teeth of evidence. The story of Doubting Thomas is told, not so that we shall admire Thomas, but so that we can admire the other apostles in comparison. Thomas demanded evidence. Nothing is more lethal for certain kinds of meme than a tendency to look for evidence. The other apostles, whose faith was so strong that they did not need evidence, are held up to us as worthy of imitation. The meme for blind faith secures its own perpetuation by the simple unconscious expedient of discouraging rational inquiry. Blind faith can justify anything. If a man believes in a different god, or even if he uses a different ritual for worshipping the same god, blind faith can decree that he should die-on the cross, at the stake, skewered on a Crusader's sword, shot in a Beirut street, or blown up in a bar in Belfast. Memes for blind faith have their own ruthless ways of propagating themselves. This is true of patriotic and political as well as religious blind faith. Memes and genes may often reinforce each other, but they sometimes come into opposition. For example, the habit of celibacy is presumably not inherited genetically. A gene for celibacy is doomed to failure in the gene pool, except under very special circumstances such as we find in the social insects. But still, a meme for celibacy can be successful in the meme pool. For example, suppose the success of a meme depends critically on how much time people spend in actively transmitting it to other people. Any time spent in doing other things than attempting to transmit the meme may be regarded as time wasted from the meme's point of view. The meme for celibacy is transmitted by priests to young boys who have not yet decided what they want to do with their lives. The medium of transmission is human influence of various kinds, the spoken and written word, personal example and so on. Suppose, for the sake of argument, it happened to be the case that marriage weakened the power of a priest to influence his flock, say because it occupied a large proportion of his time and attention. This has, indeed, been advanced as an official reason for the enforcement of celibacy among priests. If this were the case, it would follow that the meme for celibacy could have greater survival value than the meme for marriage. Of course, exactly the opposite would be true for a gene for celibacy. If a priest is a survival machine for memes, celibacy is a useful attribute to build into him. Celibacy is just a minor partner in a large complex of mutually-assisting religious memes. I conjecture that co-adapted meme-complexes evolve in the same kind of way as co-adapted gene-complexes. Selection favours memes that exploit their cultural environment to their own advantage. This cultural environment consists of other memes which are also being selected. The meme pool therefore comes to have the attributes of an evolutionarily stable set, which new memes find it hard to invade. I have been a bit negative about memes, but they have their cheerful side as well. When we die there are two things we can leave behind us: genes and memes. We were built as gene machines, created to pass on our genes. But that aspect of us will be forgotten in three generations. Your child, even your grandchild, may bear a resemblance to you, perhaps in facial features, in a talent for music, in the colour of her hair. But as each generation passes, the contribution of your genes is halved. It does not take long to reach negligible proportions. Our genes may be immortal but the collection of genes that is any one of us is bound to crumble away. Elizabeth II is a direct descendant of William the Conqueror. Yet it is quite probable that she bears not a single one of the old king's genes. We should not seek immortality in reproduction. But if you contribute to the world's culture, if you have a good idea, compose a tune, invent a sparking plug, write a poem, it may live on, intact, long after your genes have dissolved in the common pool. Socrates may or may not have a gene or two alive in the world today, as G. C. Williams has remarked, but who cares? The meme-complexes of Socrates, Leonardo, Copernicus and Marconi are still going strong. However speculative my development of the theory of memes may be, there is one serious point which I would like to emphasize once again. This is that when we look at the evolution of cultural traits and at their survival value, we must be clear whose survival we are talking about. Biologists, as we have seen, are accustomed to looking for advantages at the gene level (or the individual, the group, or the species level according to taste). What we have not previously considered is that a cultural trait may have evolved in the way that it has, simply because it is advantageous to itself. We do not have to look for conventional biological survival values of traits like religion, music, and ritual dancing, though these may also be present. Once the genes have provided their survival machines with brains that are capable of rapid imitation, the memes will automatically take over. We do not even have to posit a genetic advantage in imitation, though that would certainly help. All that is necessary is that the brain should be capable of imitation: memes will then evolve that exploit the capability to the full. I now close the topic of the new replicators, and end the chapter on a note of qualified hope. One unique feature of man, which may or may not have evolved memically, is his capacity for conscious foresight. Selfish genes (and, if you allow the speculation of this chapter, memes too) have no foresight. They are unconscious, blind, replicators. The fact that they replicate, together with certain further conditions means, willy nilly, that they will tend towards the evolution of qualities which, in the special sense of this book, can be called selfish. A simple replicator, whether gene or meme, cannot be expected to forgo short-term selfish advantage even if it would really pay it, in the long term, to do so. We saw this in the chapter on aggression. Even though a 'conspiracy of doves' would be better for every single individual than the evolutionarily stable strategy, natural selection is bound to favour the ESS. It is possible that yet another unique quality of man is a capacity for genuine, disinterested, true altruism. I hope so, but I am not going to argue the case one way or the other, nor to speculate over its possible memic evolution. The point I am making now is that, even if we look on the dark side and assume that individual man is fundamentally selfish, our conscious foresight-our capacity to simulate the future in imagination-could save us from the worst selfish excesses of the blind replicators. We have at least the mental equipment to foster our long-term selfish interests rather than merely our short-term selfish interests. We can see the long-term benefits of participating in a 'conspiracy of doves', and we can sit down together to discuss ways of making the conspiracy work. We have the power to defy the selfish genes of our birth and, if necessary, the selfish memes of our indoctrination. We can even discuss ways of deliberately cultivating and nurturing pure, disinterested altruism- something that has no place in nature, something that has never existed before in the whole history of the world. We are built as gene machines and cultured as meme machines, but we have the power to turn against our creators. We, alone on earth, can rebel against the tyranny of the selfish replicators.",
        "char_count": 31066
      }
    ]
  },
  "rights_of_man": {
    "meta": {
      "key": "rights_of_man",
      "title": "Rights of Man",
      "creator": "Thomas Paine",
      "filepath": "G:/My Drive/15_E-BOOKS/file004129.epub",
      "subject": "History"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Editor’s Introduction WHEN Thomas Paine sailed from America for France, in April, 1787, he was perhaps as happy a man as any in the world. His most intimate friend, Jefferson, was Minister at Paris, and his friend Lafayette was the idol of France. His fame had preceded him, and he at once became, in Paris, the centre of the same circle of savants and philosophers that had surrounded Franklin. His main reason for proceeding at once to Paris was that he might submit to the Academy of Sciences his invention of an iron bridge, and with its favorable verdict he came to England, in September. He at once went to his aged mother at Thetford, leaving with a publisher (Ridgway), his \"Prospects on the Rubicon.\" He next made arrangements to patent his bridge, and to construct at Rotherham the large model of it exhibited on Paddington Green, London. He was welcomed in England by leading statesmen, such as Lansdowne and Fox, and above all by Edmund Burke, who for some time had him as a guest at Beaconsfield, and drove him about in various parts of the country. He had not the slightest revolutionary purpose, either as regarded England or France. Towards Louis XVI. he felt only gratitude for the services he had rendered America, and towards George III. he felt no animosity whatever. His four months' sojourn in Paris had convinced him that there was approaching a reform of that country after the American model, except that the Crown would be preserved, a compromise he approved, provided the throne should not be hereditary. Events in France travelled more swiftly than he had anticipated, and Paine was summoned by Lafayette, Condorcet, and others, as an adviser in the formation of a new constitution. Such was the situation immediately preceding the political and literary duel between Paine and Burke, which in the event turned out a tremendous war between Royalism and Republicanism in Europe. Paine was, both in France and in England, the inspirer of moderate counsels. Samuel Rogers relates that in early life he dined at a friend’s house in London with Thomas Paine, when one of the toasts given was the \"memory of Joshua,\"—in allusion to the Hebrew leader’s conquest of the kings of Canaan, and execution of them. Paine observed that he would not treat kings like Joshua. \"I 'm of the Scotch parson’s opinion,\" he said, \"when he prayed against Louis XIV.—`Lord, shake him over the mouth of hell, but don’t let him drop!'\" Paine then gave as his toast, \"The Republic of the World,\"—which Samuel Rogers, aged twenty–nine, noted as a sublime idea. This was Paine’s faith and hope, and with it he confronted the revolutionary storms which presently burst over France and England. Until Burke’s arraignment of France in his parliamentary speech (February 9, 1790), Paine had no doubt whatever that he would sympathize with the movement in France, and wrote to him from that country as if conveying glad tidings. Burke’s \"Reflections on the Revolution in France\" appeared November 1, 1790, and Paine at once set himself to answer it. He was then staying at the Angel Inn, Islington. The inn has been twice rebuilt since that time, and from its contents there is preserved only a small image, which perhaps was meant to represent \"Liberty,\"—possibly brought from Paris by Paine as an ornament for his study. From the Angel he removed to a house in Harding Street, Fetter Lane. Rickman says Part First of \"Rights of Man\" was finished at Versailles, but probably this has reference to the preface only, as I cannot find Paine in France that year until April 8. The book had been printed by Johnson, in time for the opening of Parliament, in February; but this publisher became frightened after a few copies were out (there is one in the British Museum), and the work was transferred to J. S. Jordan, 166 Fleet Street, with a preface sent from Paris (not contained in Johnson’s edition, nor in the American editions). The pamphlet, though sold at the same price as Burke’s, three shillings, had a vast circulation, and Paine gave the proceeds to the Constitutional Societies which sprang up under his teachings in various parts of the country. Soon after appeared Burke’s \"Appeal from the New to the Old Whigs.\" In this Burke quoted a good deal from \"Rights of Man,\" but replied to it only with exclamation points, saying that the only answer such ideas merited was \"criminal justice.\" Paine’s Part Second followed, published February 17, 1792. In Part First Paine had mentioned a rumor that Burke was a masked pensioner (a charge that will be noticed in connection with its detailed statement in a further publication); and as Burke had been formerly arraigned in Parliament, while Paymaster, for a very questionable proceeding, this charge no doubt hurt a good deal. Although the government did not follow Burke’s suggestion of a prosecution at that time, there is little doubt that it was he who induced the prosecution of Part Second. Before the trial came on, December 18, 1792, Paine was occupying his seat in the French Convention, and could only be outlawed. Burke humorously remarked to a friend of Paine and himself, \"We hunt in pairs.\" The severally representative character and influence of these two men in the revolutionary era, in France and England, deserve more adequate study than they have received. While Paine maintained freedom of discussion, Burke first proposed criminal prosecution for sentiments by no means libellous (such as Paine’s Part First). While Paine was endeavoring to make the movement in France peaceful, Burke fomented the league of monarchs against France which maddened its people, and brought on the Reign of Terror. While Paine was endeavoring to preserve the French throne (\"phantom\" though he believed it), to prevent bloodshed, Burke was secretly writing to the Queen of France, entreating her not to compromise, and to \"trust to the support of foreign armies\" (\"Histoire de France depuis 1789.\" Henri Martin, i., 151). While Burke thus helped to bring the King and Queen to the guillotine, Paine pleaded for their lives to the last moment. While Paine maintained the right of mankind to improve their condition, Burke held that \"the awful Author of our being is the author of our place in the order of existence; and that, having disposed and marshalled us by a divine tactick, not according to our will, but according to his, he has, in and by that disposition, virtually subjected us to act the part which belongs to the place assigned us.\" Paine was a religious believer in eternal principles; Burke held that \"political problems do not primarily concern truth or falsehood. They relate to good or evil. What in the result is likely to produce evil is politically false, that which is productive of good politically is true.\" Assuming thus the visionary’s right to decide before the result what was \"likely to produce evil,\" Burke vigorously sought to kindle war against the French Republic which might have developed itself peacefully, while Paine was striving for an international Congress in Europe in the interest of peace. Paine had faith in the people, and believed that, if allowed to choose representatives, they would select their best and wisest men; and that while reforming government the people would remain orderly, as they had generally remained in America during the transition from British rule to selfgovernment. Burke maintained that if the existing political order were broken up there would be no longer a people, but \"a number of vague, loose individuals, and nothing more.\"\"Alas!\" he exclaims, \"they little know how many a weary step is to be taken before they can form themselves into a mass, which has a true personality.\" For the sake of peace Paine wished the revolution to be peaceful as the advance of summer; he used every endeavor to reconcile English radicals to some modus vivendi with the existing order, as he was willing to retain Louis XVI. as head of the executive in France: Burke resisted every tendency of English statesmanship to reform at home, or to negotiate with the French Republic, and was mainly responsible for the King’s death and the war that followed between England and France in February, 1793. Burke became a royal favorite, Paine was outlawed by a prosecution originally proposed by Burke. While Paine was demanding religious liberty, Burke was opposing the removal of penal statutes from Unitarians, on the ground that but for those statutes Paine might some day set up a church in England. When Burke was retiring on a large royal pension, Paine was in prison, through the devices of Burke’s confederate, the American Minister in Paris. So the two men, as Burke said, \"hunted in pairs.\" So far as Burke attempts to affirm any principle he is fairly quoted in Paine’s work, and nowhere misrepresented. As for Paine’s own ideas, the reader should remember that \"Rights of Man\" was the earliest complete statement of republican principles. They were pronounced to be the fundamental principles of the American Republic by Jefferson, Madison, and Jackson,–the three Presidents who above all others represented the republican idea which Paine first allied with American Independence. Those who suppose that Paine did but reproduce the principles of Rousseau and Locke will find by careful study of his well–weighed language that such is not the case. Paine’s political principles were evolved out of his early Quakerism. He was potential in George Fox. The belief that every human soul was the child of God, and capable of direct inspiration from the Father of all, without mediator or priestly intervention, or sacramental instrumentality, was fatal to all privilege and rank. The universal Fatherhood implied universal Brotherhood, or human equality. But the fate of the Quakers proved the necessity of protecting the individual spirit from oppression by the majority as well as by privileged classes. For this purpose Paine insisted on surrounding the individual right with the security of the Declaration of Rights, not to be invaded by any government; and would reduce government to an association limited in its operations to the defence of those rights which the individual is unable, alone, to maintain. From the preceding chapter it will be seen that Part Second of \"Rights of Man\" was begun by Paine in the spring of 1791. At the close of that year, or early in 1792, he took up his abode with his friend Thomas \"Clio\" Rickman, at No. 7 Upper Marylebone Street. Rickman was a radical publisher; the house remains still a book–binding establishment, and seems little changed since Paine therein revised the proofs of Part Second on a table which Rickman marked with a plate, and which is now in possession of Mr. Edward Truelove. As the plate states, Paine wrote on the same table other works which appeared in England in 1792. In 1795 D. I. Eaton published an edition of \"Rights of Man,\" with a preface purporting to have been written by Paine while in Luxembourg prison. It is manifestly spurious. The genuine English and French prefaces are given.",
        "char_count": 11069
      },
      {
        "heading": "Chapter 2",
        "text": "An Introductory Letter To GEORGE WASHINGTON P RESIDENT O F T HE U NITED S TATES O F A MERICA Sir, I present you a small treatise in defence of those principles of freedom which your exemplary virtue hath so eminently contributed to establish. That the Rights of Man may become as universal as your benevolence can wish, and that you may enjoy the happiness of seeing the New World regenerate the Old, is the prayer of Sir, Your much obliged, and Obedient humble Servant, Thomas Paine",
        "char_count": 483
      },
      {
        "heading": "Chapter 3",
        "text": "Dedication to M. de la Fayette After an acquaintance of nearly fifteen years in difficult situations in America, and various consultations in Europe, I feel a pleasure in presenting to you this small treatise, in gratitude for your services to my beloved America, and as a testimony of my esteem for the virtues, public and private, which I know you to possess. The only point upon which I could ever discover that we differed was not as to principles of government, but as to time. For my own part I think it equally as injurious to good principles to permit them to linger, as to push them on too fast. That which you suppose accomplishable in fourteen or fifteen years, I may believe practicable in a much shorter period. Mankind, as it appears to me, are always ripe enough to understand their true interest, provided it be presented clearly to their understanding, and that in a manner not to create suspicion by anything like self–design, nor offend by assuming too much. Where we would wish to reform we must not reproach. When the American revolution was established I felt a disposition to sit serenely down and enjoy the calm. It did not appear to me that any object could afterwards arise great enough to make me quit tranquility and feel as I had felt before. But when principle, and not place, is the energetic cause of action, a man, I find, is everywhere the same. I am now once more in the public world; and as I have not a right to contemplate on so many years of remaining life as you have, I have resolved to labour as fast as I can; and as I am anxious for your aid and your company, I wish you to hasten your principles and overtake me. If you make a campaign the ensuing spring, which it is most probable there will be no occasion for, I will come and join you. Should the campaign commence, I hope it will terminate in the extinction of German despotism, and in establishing the freedom of all Germany. When France shall be surrounded with revolutions she will be in peace and safety, and her taxes, as well as those of Germany, will consequently become less. Your sincere, Affectionate Friend, Thomas Paine London, Feb. 9, 1792",
        "char_count": 2151
      },
      {
        "heading": "Chapter 4",
        "text": "The Author’s Preface to the English Edition From the part Mr. Burke took in the American Revolution, it was natural that I should consider him a friend to mankind; and as our acquaintance commenced on that ground, it would have been more agreeable to me to have had cause to continue in that opinion than to change it. At the time Mr. Burke made his violent speech last winter in the English Parliament against the French Revolution and the National Assembly, I was in Paris, and had written to him but a short time before to inform him how prosperously matters were going on. Soon after this I saw his advertisement of the Pamphlet he intended to publish: As the attack was to be made in a language but little studied, and less understood in France, and as everything suffers by translation, I promised some of the friends of the Revolution in that country that whenever Mr. Burke’s Pamphlet came forth, I would answer it. This appeared to me the more necessary to be done, when I saw the flagrant misrepresentations which Mr. Burke’s Pamphlet contains; and that while it is an outrageous abuse on the French Revolution, and the principles of Liberty, it is an imposition on the rest of the world. I am the more astonished and disappointed at this conduct in Mr. Burke, as (from the circumstances I am going to mention) I had formed other expectations. I had seen enough of the miseries of war, to wish it might never more have existence in the world, and that some other mode might be found out to settle the differences that should occasionally arise in the neighbourhood of nations. This certainly might be done if Courts were disposed to set honesty about it, or if countries were enlightened enough not to be made the dupes of Courts. The people of America had been bred up in the same prejudices against France, which at that time characterised the people of England; but experience and an acquaintance with the French Nation have most effectually shown to the Americans the falsehood of those prejudices; and I do not believe that a more cordial and confidential intercourse exists between any two countries than between America and France. When I came to France, in the spring of 1787, the Archbishop of Thoulouse was then Minister, and at that time highly esteemed. I became much acquainted with the private Secretary of that Minister, a man of an enlarged benevolent heart; and found that his sentiments and my own perfectly agreed with respect to the madness of war, and the wretched impolicy of two nations, like England and France, continually worrying each other, to no other end than that of a mutual increase of burdens and taxes. That I might be assured I had not misunderstood him, nor he me, I put the substance of our opinions into writing and sent it to him; subjoining a request, that if I should see among the people of England, any disposition to cultivate a better understanding between the two nations than had hitherto prevailed, how far I might be authorised to say that the same disposition prevailed on the part of France? He answered me by letter in the most unreserved manner, and that not for himself only, but for the Minister, with whose knowledge the letter was declared to be written. I put this letter into the, hands of Mr. Burke almost three years ago, and left it with him, where it still remains; hoping, and at the same time naturally expecting, from the opinion I had conceived of him, that he would find some opportunity of making good use of it, for the purpose of removing those errors and prejudices which two neighbouring nations, from the want of knowing each other, had entertained, to the injury of both. When the French Revolution broke out, it certainly afforded to Mr. Burke an opportunity of doing some good, had he been disposed to it; instead of which, no sooner did he see the old prejudices wearing away, than he immediately began sowing the seeds of a new inveteracy, as if he were afraid that England and France would cease to be enemies. That there are men in all countries who get their living by war, and by keeping up the quarrels of Nations, is as shocking as it is true; but when those who are concerned in the government of a country, make it their study to sow discord and cultivate prejudices between Nations, it becomes the more unpardonable. With respect to a paragraph in this work alluding to Mr. Burke’s having a pension, the report has been some time in circulation, at least two months; and as a person is often the last to hear what concerns him the most to know, I have mentioned it, that Mr. Burke may have an opportunity of contradicting the rumour, if he thinks proper. Thomas Paine",
        "char_count": 4666
      },
      {
        "heading": "Chapter 5",
        "text": "French Translator’s Preface (1792) THE work of which we offer a translation to the public has created the greatest sensation in England. Paine, that man of freedom, who seems born to preach \"Common Sense\" to the whole world with the same success as in America, explains in it to the people of England the theory of the practice of the Rights of Man. Owing to the prejudices that still govern that nation, the author has been obliged to condescend to answer Mr. Burke. He has done so more especially in an extended preface which is nothing but a piece of very tedious controversy, in which he shows himself very sensitive to criticisms that do not really affect him. To translate it seemed an insult to the free French people, and similar reasons have led the editors to suppress also a dedicatory epistle addressed by Paine to Lafayette. The French can no longer endure dedicatory epistles. A man should write privately to those he esteems: when he publishes a book his thoughts should be offered to the public alone. Paine, that uncorrupted friend of freedom, believed too in the sincerity of Lafayette. So easy is it to deceive men of single–minded purpose! Bred at a distance from courts, that austere American does not seem any more on his guard against the artful ways and speech of courtiers than some Frenchmen who resemble him.",
        "char_count": 1335
      },
      {
        "heading": "Chapter 6",
        "text": "The Author’s Preface to the French Edition The astonishment which the French Revolution has caused throughout Europe should be considered from two different points of view: first as it affects foreign peoples, secondly as it affects their governments. The cause of the French people is that of all Europe, or rather of the whole world; but the governments of all those countries are by no means favorable to it. It is important that we should never lose sight of this distinction. We must not confuse the peoples with their governments; especially not the English people with its government. The government of England is no friend of the revolution of France. Of this we have sufficient proofs in the thanks given by that weak and witless person, the Elector of Hanover, sometimes called the King of England, to Mr. Burke for the insults heaped on it in his book, and in the malevolent comments of the English Minister, Pitt, in his speeches in Parliament. In spite of the professions of sincerest friendship found in the official correspondence of the English government with that of France, its conduct gives the lie to all its declarations, and shows us clearly that it is not a court to be trusted, but an insane court, plunging in all the quarrels and intrigues of Europe, in quest of a war to satisfy its folly and countenance its extravagance. The English nation, on the contrary, is very favorably disposed towards the French Revolution, and to the progress of liberty in the whole world; and this feeling will become more general in England as the intrigues and artifices of its government are better known, and the principles of the revolution better understood. The French should know that most English newspapers are directly in the pay of government, or, if indirectly connected with it, always under its orders; and that those papers constantly distort and attack the revolution in France in order to deceive the nation. But, as it is impossible long to prevent the prevalence of truth, the daily falsehoods of those papers no longer have the desired effect. To be convinced that the voice of truth has been stifled in England, the world needs only to be told that the government regards and prosecutes as a libel that which it should protect. [1] This outrage on morality is called law, and judges are found wicked enough to inflict penalties on truth. The English government presents, just now, a curious phenomenon. Seeing that the French and English nations are getting rid of the prejudices and false notions formerly entertained against each other, and which have cost them so much money, that government seems to be placarding its need of a foe; for unless it finds one somewhere, no pretext exists for the enormous revenue and taxation now deemed necessary. Therefore it seeks in Russia the enemy it has lost in France, and appears to say to the universe, or to say to itself. \"If nobody will be so kind as to become my foe, I shall need no more fleets nor armies, and shall be forced to reduce my taxes. The American war enabled me to double the taxes; the Dutch business to add more; the Nootka humbug gave me a pretext for raising three millions sterling more; but unless I can make an enemy of Russia the harvest from wars will end. I was the first to incite Turk against Russian, and now I hope to reap a fresh crop of taxes.\" If the miseries of war, and the flood of evils it spreads over a country, did not check all inclination to mirth, and turn laughter into grief, the frantic conduct of the government of England would only excite ridicule. But it is impossible to banish from one’s mind the images of suffering which the contemplation of such vicious policy presents. To reason with governments, as they have existed for ages, is to argue with brutes. It is only from the nations themselves that reforms can be expected. There ought not now to exist any doubt that the peoples of France, England, and America, enlightened and enlightening each other, shall henceforth be able, not merely to give the world an example of good government, but by their united influence enforce its practice. (Translated from the French)",
        "char_count": 4152
      },
      {
        "heading": "Chapter 7",
        "text": "Combining Principle and Practice Introduction What Archimedes said of the mechanical powers, may be applied to Reason and Liberty. \"Had we,\" said he, \"a place to stand upon, we might raise the world.\" The revolution of America presented in politics what was only theory in mechanics. So deeply rooted were all the governments of the old world, and so effectually had the tyranny and the antiquity of habit established itself over the mind, that no beginning could be made in Asia, Africa, or Europe, to reform the political condition of man. Freedom had been hunted round the globe; reason was considered as rebellion; and the slavery of fear had made men afraid to think. But such is the irresistible nature of truth, that all it asks,—and all it wants,—is the liberty of appearing. The sun needs no inscription to distinguish him from darkness; and no sooner did the American governments display themselves to the world, than despotism felt a shock and man began to contemplate redress. The independence of America, considered merely as a separation from England, would have been a matter but of little importance, had it not been accompanied by a revolution in the principles and practice of governments. She made a stand, not for herself only, but for the world, and looked beyond the advantages herself could receive. Even the Hessian, though hired to fight against her, may live to bless his defeat; and England, condemning the viciousness of its government, rejoice in its miscarriage. As America was the only spot in the political world where the principle of universal reformation could begin, so also was it the best in the natural world. An assemblage of circumstances conspired, not only to give birth, but to add gigantic maturity to its principles. The scene which that country presents to the eye of a spectator, has something in it which generates and encourages great ideas. Nature appears to him in magnitude. The mighty objects he beholds, act upon his mind by enlarging it, and he partakes of the greatness he contemplates.—Its first settlers were emigrants from different European nations, and of diversified professions of religion, retiring from the governmental persecutions of the old world, and meeting in the new, not as enemies, but as brothers. The wants which necessarily accompany the cultivation of a wilderness produced among them a state of society, which countries long harassed by the quarrels and intrigues of governments, had neglected to cherish. In such a situation man becomes what he ought. He sees his species, not with the inhuman idea of a natural enemy, but as kindred; and the example shows to the artificial world, that man must go back to Nature for information. From the rapid progress which America makes in every species of improvement, it is rational to conclude that, if the governments of Asia, Africa, and Europe had begun on a principle similar to that of America, or had not been very early corrupted therefrom, those countries must by this time have been in a far superior condition to what they are. Age after age has passed away, for no other purpose than to behold their wretchedness. Could we suppose a spectator who knew nothing of the world, and who was put into it merely to make his observations, he would take a great part of the old world to be new, just struggling with the difficulties and hardships of an infant settlement. He could not suppose that the hordes of miserable poor with which old countries abound could be any other than those who had not yet had time to provide for themselves. Little would he think they were the consequence of what in such countries they call government. If, from the more wretched parts of the old world, we look at those which are in an advanced stage of improvement we still find the greedy hand of government thrusting itself into every corner and crevice of industry, and grasping the spoil of the multitude. Invention is continually exercised to furnish new pretences for revenue and taxation. It watches prosperity as its prey, and permits none to escape without a tribute. As revolutions have begun (and as the probability is always greater against a thing beginning, than of proceeding after it has begun), it is natural to expect that other revolutions will follow. The amazing and still increasing expenses with which old governments are conducted, the numerous wars they engage in or provoke, the embarrassments they throw in the way of universal civilisation and commerce, and the oppression and usurpation acted at home, have wearied out the patience, and exhausted the property of the world. In such a situation, and with such examples already existing, revolutions are to be looked for. They are become subjects of universal conversation, and may be considered as the Order of the day. If systems of government can be introduced less expensive and more productive of general happiness than those which have existed, all attempts to oppose their progress will in the end be fruitless. Reason, like time, will make its own way, and prejudice will fall in a combat with interest. If universal peace, civilisation, and commerce are ever to be the happy lot of man, it cannot be accomplished but by a revolution in the system of governments. All the monarchical governments are military. War is their trade, plunder and revenue their objects. While such governments continue, peace has not the absolute security of a day. What is the history of all monarchical governments but a disgustful picture of human wretchedness, and the accidental respite of a few years' repose? Wearied with war, and tired with human butchery, they sat down to rest, and called it peace. This certainly is not the condition that heaven intended for man; and if this be monarchy, well might monarchy be reckoned among the sins of the Jews. The revolutions which formerly took place in the world had nothing in them that interested the bulk of mankind. They extended only to a change of persons and measures, but not of principles, and rose or fell among the common transactions of the moment. What we now behold may not improperly be called a \"counter–revolution.\" Conquest and tyranny, at some earlier period, dispossessed man of his rights, and he is now recovering them. And as the tide of all human affairs has its ebb and flow in directions contrary to each other, so also is it in this. Government founded on a moral theory, on a system of universal peace, on the indefeasible hereditary Rights of Man, is now revolving from west to east by a stronger impulse than the government of the sword revolved from east to west. It interests not particular individuals, but nations in its progress, and promises a new era to the human race. The danger to which the success of revolutions is most exposed is that of attempting them before the principles on which they proceed, and the advantages to result from them, are sufficiently seen and understood. Almost everything appertaining to the circumstances of a nation, has been absorbed and confounded under the general and mysterious word government. Though it avoids taking to its account the errors it commits, and the mischiefs it occasions, it fails not to arrogate to itself whatever has the appearance of prosperity. It robs industry of its honours, by pedantically making itself the cause of its effects; and purloins from the general character of man, the merits that appertain to him as a social being. It may therefore be of use in this day of revolutions to discriminate between those things which are the effect of government, and those which are not. This will best be done by taking a review of society and civilisation, and the consequences resulting therefrom, as things distinct from what are called governments. By beginning with this investigation, we shall be able to assign effects to their proper causes and analyse the mass of common errors.",
        "char_count": 7906
      },
      {
        "heading": "Chapter 8",
        "text": "Combining Principle and Practice Preface When I began the chapter entitled the \"Conclusion\" in the former part of the RIGHTS OF MAN, published last year, it was my intention to have extended it to a greater length; but in casting the whole matter in my mind, which I wish to add, I found that it must either make the work too bulky, or contract my plan too much. I therefore brought it to a close as soon as the subject would admit, and reserved what I had further to say to another opportunity. Several other reasons contributed to produce this determination. I wished to know the manner in which a work, written in a style of thinking and expression different to what had been customary in England, would be received before I proceeded farther. A great field was opening to the view of mankind by means of the French Revolution. Mr. Burke’s outrageous opposition thereto brought the controversy into England. He attacked principles which he knew (from information) I would contest with him, because they are principles I believe to be good, and which I have contributed to establish, and conceive myself bound to defend. Had he not urged the controversy, I had most probably been a silent man. Another reason for deferring the remainder of the work was, that Mr. Burke promised in his first publication to renew the subject at another opportunity, and to make a comparison of what he called the English and French Constitutions. I therefore held myself in reserve for him. He has published two works since, without doing this: which he certainly would not have omitted, had the comparison been in his favour. In his last work, his \"Appeal from the New to the Old Whigs,\" he has quoted about ten pages from the RIGHTS OF MAN, and having given himself the trouble of doing this, says he \"shall not attempt in the smallest degree to refute them,\" meaning the principles therein contained. I am enough acquainted with Mr. Burke to know that he would if he could. But instead of contesting them, he immediately after consoles himself with saying that \"he has done his part.\"—He has not done his part. He has not performed his promise of a comparison of constitutions. He started the controversy, he gave the challenge, and has fled from it; and he is now a case in point with his own opinion that \"the age of chivalry is gone!\" The title, as well as the substance of his last work, his \"Appeal,\" is his condemnation. Principles must stand on their own merits, and if they are good they certainly will. To put them under the shelter of other men’s authority, as Mr. Burke has done, serves to bring them into suspicion. Mr. Burke is not very fond of dividing his honours, but in this case he is artfully dividing the disgrace. But who are those to whom Mr. Burke has made his appeal? A set of childish thinkers, and half–way politicians born in the last century, men who went no farther with any principle than as it suited their purposes as a party; the nation was always left out of the question; and this has been the character of every party from that day to this. The nation sees nothing of such works, or such politics, worthy its attention. A little matter will move a party, but it must be something great that moves a nation. Though I see nothing in Mr. Burke’s \"Appeal\" worth taking much notice of, there is, however, one expression upon which I shall offer a few remarks. After quoting largely from the RIGHTS OF MAN, and declining to contest the principles contained in that work, he says: \"This will most probably be done (if such writings shall be thought to deserve any other refutation than that of criminal justice) by others, who may think with Mr. Burke and with the same zeal.\" In the first place, it has not yet been done by anybody. Not less, I believe, than eight or ten pamphlets intended as answers to the former part of the RIGHTS OF MAN have been published by different persons, and not one of them to my knowledge, has extended to a second edition, nor are even the titles of them so much as generally remembered. As I am averse to unnecessary multiplying publications, I have answered none of them. And as I believe that a man may write himself out of reputation when nobody else can do it, I am careful to avoid that rock. But as I would decline unnecessary publications on the one hand, so would I avoid everything that might appear like sullen pride on the other. If Mr. Burke, or any person on his side the question, will produce an answer to the RIGHTS OF MAN that shall extend to a half, or even to a fourth part of the number of copies to which the Rights Of Man extended, I will reply to his work. But until this be done, I shall so far take the sense of the public for my guide (and the world knows I am not a flatterer) that what they do not think worth while to read, is not worth mine to answer. I suppose the number of copies to which the first part of the RIGHTS OF MAN extended, taking England, Scotland, and Ireland, is not less than between forty and fifty thousand. I now come to remark on the remaining part of the quotation I have made from Mr. Burke. \"If,\" says he, \"such writings shall be thought to deserve any other refutation than that of criminal justice.\" Pardoning the pun, it must be criminal justice indeed that should condemn a work as a substitute for not being able to refute it. The greatest condemnation that could be passed upon it would be a refutation. But in proceeding by the method Mr. Burke alludes to, the condemnation would, in the final event, pass upon the criminality of the process and not upon the work, and in this case, I had rather be the author, than be either the judge or the jury that should condemn it. But to come at once to the point. I have differed from some professional gentlemen on the subject of prosecutions, and I since find they are falling into my opinion, which I will here state as fully, but as concisely as I can. I will first put a case with respect to any law, and then compare it with a government, or with what in England is, or has been, called a constitution. It would be an act of despotism, or what in England is called arbitrary power, to make a law to prohibit investigating the principles, good or bad, on which such a law, or any other is founded. If a law be bad it is one thing to oppose the practice of it, but it is quite a different thing to expose its errors, to reason on its defects, and to show cause why it should be repealed, or why another ought to be substituted in its place. I have always held it an opinion (making it also my practice) that it is better to obey a bad law, making use at the same time of every argument to show its errors and procure its repeal, than forcibly to violate it; because the precedent of breaking a bad law might weaken the force, and lead to a discretionary violation, of those which are good. The case is the same with respect to principles and forms of government, or to what are called constitutions and the parts of which they are, composed. It is for the good of nations and not for the emolument or aggrandisement of particular individuals, that government ought to be established, and that mankind are at the expense of supporting it. The defects of every government and constitution both as to principle and form, must, on a parity of reasoning, be as open to discussion as the defects of a law, and it is a duty which every man owes to society to point them out. When those defects, and the means of remedying them, are generally seen by a nation, that nation will reform its government or its constitution in the one case, as the government repealed or reformed the law in the other. The operation of government is restricted to the making and the administering of laws; but it is to a nation that the right of forming or reforming, generating or regenerating constitutions and governments belong; and consequently those subjects, as subjects of investigation, are always before a country as a matter of right, and cannot, without invading the general rights of that country, be made subjects for prosecution. On this ground I will meet Mr. Burke whenever he please. It is better that the whole argument should come out than to seek to stifle it. It was himself that opened the controversy, and he ought not to desert it. I do not believe that monarchy and aristocracy will continue seven years longer in any of the enlightened countries in Europe. If better reasons can be shown for them than against them, they will stand; if the contrary, they will not. Mankind are not now to be told they shall not think, or they shall not read; and publications that go no farther than to investigate principles of government, to invite men to reason and to reflect, and to show the errors and excellences of different systems, have a right to appear. If they do not excite attention, they are not worth the trouble of a prosecution; and if they do, the prosecution will amount to nothing, since it cannot amount to a prohibition of reading. This would be a sentence on the public, instead of the author, and would also be the most effectual mode of making or hastening revolution. On all cases that apply universally to a nation, with respect to systems of government, a jury of twelve men is not competent to decide. Where there are no witnesses to be examined, no facts to be proved, and where the whole matter is before the whole public, and the merits or demerits of it resting on their opinion; and where there is nothing to be known in a court, but what every body knows out of it, every twelve men is equally as good a jury as the other, and would most probably reverse each other’s verdict; or, from the variety of their opinions, not be able to form one. It is one case, whether a nation approve a work, or a plan; but it is quite another case, whether it will commit to any such jury the power of determining whether that nation have a right to, or shall reform its government or not. I mention those cases that Mr. Burke may see I have not written on Government without reflecting on what is Law, as well as on what are Rights.—The only effectual jury in such cases would be a convention of the whole nation fairly elected; for in all such cases the whole nation is the vicinage. If Mr. Burke will propose such a jury, I will waive all privileges of being the citizen of another country, and, defending its principles, abide the issue, provided he will do the same; for my opinion is, that his work and his principles would be condemned instead of mine. As to the prejudices which men have from education and habit, in favour of any particular form or system of government, those prejudices have yet to stand the test of reason and reflection. In fact, such prejudices are nothing. No man is prejudiced in favour of a thing, knowing it to be wrong. He is attached to it on the belief of its being right; and when he sees it is not so, the prejudice will be gone. We have but a defective idea of what prejudice is. It might be said, that until men think for themselves the whole is prejudice, and not opinion; for that only is opinion which is the result of reason and reflection. I offer this remark, that Mr. Burke may not confide too much in what have been the customary prejudices of the country. I do not believe that the people of England have ever been fairly and candidly dealt by. They have been imposed upon by parties, and by men assuming the character of leaders. It is time that the nation should rise above those trifles. It is time to dismiss that inattention which has so long been the encouraging cause of stretching taxation to excess. It is time to dismiss all those songs and toasts which are calculated to enslave, and operate to suffocate reflection. On all such subjects men have but to think, and they will neither act wrong nor be misled. To say that any people are not fit for freedom, is to make poverty their choice, and to say they had rather be loaded with taxes than not. If such a case could be proved, it would equally prove that those who govern are not fit to govern them, for they are a part of the same national mass. But admitting governments to be changed all over Europe; it certainly may be done without convulsion or revenge. It is not worth making changes or revolutions, unless it be for some great national benefit: and when this shall appear to a nation, the danger will be, as in America and France, to those who oppose; and with this reflection I close my Preface. THOMAS PAINE London, Feb. 9, 1792",
        "char_count": 12510
      },
      {
        "heading": "Chapter 9",
        "text": "BEING AN ANSWER TO MR. BURKE’S ATTACK ON THE FRENCH REVOLUTION Among the incivilities by which nations or individuals provoke and irritate each other, Mr. Burke’s pamphlet on the French Revolution is an extraordinary instance. Neither the People of France, nor the National Assembly, were troubling themselves about the affairs of England, or the English Parliament; and that Mr. Burke should commence an unprovoked attack upon them, both in Parliament and in public, is a conduct that cannot be pardoned on the score of manners, nor justified on that of policy. There is scarcely an epithet of abuse to be found in the English language, with which Mr. Burke has not loaded the French Nation and the National Assembly. Everything which rancour, prejudice, ignorance or knowledge could suggest, is poured forth in the copious fury of near four hundred pages. In the strain and on the plan Mr. Burke was writing, he might have written on to as many thousands. When the tongue or the pen is let loose in a frenzy of passion, it is the man, and not the subject, that becomes exhausted. Hitherto Mr. Burke has been mistaken and disappointed in the opinions he had formed of the affairs of France; but such is the ingenuity of his hope, or the malignancy of his despair, that it furnishes him with new pretences to go on. There was a time when it was impossible to make Mr. Burke believe there would be any Revolution in France. His opinion then was, that the French had neither spirit to undertake it nor fortitude to support it; and now that there is one, he seeks an escape by condemning it. Not sufficiently content with abusing the National Assembly, a great part of his work is taken up with abusing Dr. Price (one of the best–hearted men that lives) and the two societies in England known by the name of the Revolution Society and the Society for Constitutional Information. Dr. Price had preached a sermon on the 4th of November, 1789, being the anniversary of what is called in England the Revolution, which took place 1688. Mr. Burke, speaking of this sermon, says: \"The political Divine proceeds dogmatically to assert, that by the principles of the Revolution, the people of England have acquired three fundamental rights:\" To choose our own governors. To cashier them for misconduct. To frame a government for ourselves. Dr. Price does not say that the right to do these things exists in this or in that person, or in this or in that description of persons, but that it exists in the whole; that it is a right resident in the nation. Mr. Burke, on the contrary, denies that such a right exists in the nation, either in whole or in part, or that it exists anywhere; and, what is still more strange and marvellous, he says: \"that the people of England utterly disclaim such a right, and that they will resist the practical assertion of it with their lives and fortunes.\" That men should take up arms and spend their lives and fortunes, not to maintain their rights, but to maintain they have not rights, is an entirely new species of discovery, and suited to the paradoxical genius of Mr. Burke. The method which Mr. Burke takes to prove that the people of England have no such rights, and that such rights do not now exist in the nation, either in whole or in part, or anywhere at all, is of the same marvellous and monstrous kind with what he has already said; for his arguments are that the persons, or the generation of persons, in whom they did exist, are dead, and with them the right is dead also. To prove this, he quotes a declaration made by Parliament about a hundred years ago, to William and Mary, in these words: \"The Lords Spiritual and Temporal, and Commons, do, in the name of the people aforesaid\" (meaning the people of England then living) \"most humbly and faithfully submit themselves, their heirs and posterities, for Ever.\" He quotes a clause of another Act of Parliament made in the same reign, the terms of which he says, \"bind us\" (meaning the people of their day), \"our heirs and our posterity, to them, their heirs and posterity, to the end of time.\" Mr. Burke conceives his point sufficiently established by producing those clauses, which he enforces by saying that they exclude the right of the nation for ever. And not yet content with making such declarations, repeated over and over again, he farther says, \"that if the people of England possessed such a right before the Revolution\" (which he acknowledges to have been the case, not only in England, but throughout Europe, at an early period), \"yet that the English Nation did, at the time of the Revolution, most solemnly renounce and abdicate it, for themselves, and for all their posterity, for ever.\" As Mr. Burke occasionally applies the poison drawn from his horrid principles, not only to the English nation, but to the French Revolution and the National Assembly, and charges that august, illuminated and illuminating body of men with the epithet of usurpers, I shall, sans ceremonie, place another system of principles in opposition to his. The English Parliament of 1688 did a certain thing, which, for themselves and their constituents, they had a right to do, and which it appeared right should be done. But, in addition to this right, which they possessed by delegation, they set up another right by assumption, that of binding and controlling posterity to the end of time. The case, therefore, divides itself into two parts; the right which they possessed by delegation, and the right which they set up by assumption. The first is admitted; but with respect to the second, I reply: There never did, there never will, and there never can, exist a Parliament, or any description of men, or any generation of men, in any country, possessed of the right or the power of binding and controlling posterity to the \"end of time,\" or of commanding for ever how the world shall be governed, or who shall govern it; and therefore all such clauses, acts or declarations by which the makers of them attempt to do what they have neither the right nor the power to do, nor the power to execute, are in themselves null and void. Every age and generation must be as free to act for itself in all cases as the age and generations which preceded it. The vanity and presumption of governing beyond the grave is the most ridiculous and insolent of all tyrannies. Man has no property in man; neither has any generation a property in the generations which are to follow. The Parliament or the people of 1688, or of any other period, had no more right to dispose of the people of the present day, or to bind or to control them in any shape whatever, than the parliament or the people of the present day have to dispose of, bind or control those who are to live a hundred or a thousand years hence. Every generation is, and must be, competent to all the purposes which its occasions require. It is the living, and not the dead, that are to be accommodated. When man ceases to be, his power and his wants cease with him; and having no longer any participation in the concerns of this world, he has no longer any authority in directing who shall be its governors, or how its government shall be organised, or how administered. I am not contending for nor against any form of government, nor for nor against any party, here or elsewhere. That which a whole nation chooses to do it has a right to do. Mr. Burke says, No. Where, then, does the right exist? I am contending for the rights of the living, and against their being willed away and controlled and contracted for by the manuscript assumed authority of the dead, and Mr. Burke is contending for the authority of the dead over the rights and freedom of the living. There was a time when kings disposed of their crowns by will upon their death–beds, and consigned the people, like beasts of the field, to whatever successor they appointed. This is now so exploded as scarcely to be remembered, and so monstrous as hardly to be believed. But the Parliamentary clauses upon which Mr. Burke builds his political church are of the same nature. The laws of every country must be analogous to some common principle. In England no parent or master, nor all the authority of Parliament, omnipotent as it has called itself, can bind or control the personal freedom even of an individual beyond the age of twenty–one years. On what ground of right, then, could the Parliament of 1688, or any other Parliament, bind all posterity for ever? Those who have quitted the world, and those who have not yet arrived at it, are as remote from each other as the utmost stretch of mortal imagination can conceive. What possible obligation, then, can exist between them—what rule or principle can be laid down that of two nonentities, the one out of existence and the other not in, and who never can meet in this world, the one should control the other to the end of time? In England it is said that money cannot be taken out of the pockets of the people without their consent. But who authorised, or who could authorise, the Parliament of 1688 to control and take away the freedom of posterity (who were not in existence to give or to withhold their consent) and limit and confine their right of acting in certain cases for ever? A greater absurdity cannot present itself to the understanding of man than what Mr. Burke offers to his readers. He tells them, and he tells the world to come, that a certain body of men who existed a hundred years ago made a law, and that there does not exist in the nation, nor ever will, nor ever can, a power to alter it. Under how many subtilties or absurdities has the divine right to govern been imposed on the credulity of mankind? Mr. Burke has discovered a new one, and he has shortened his journey to Rome by appealing to the power of this infallible Parliament of former days, and he produces what it has done as of divine authority, for that power must certainly be more than human which no human power to the end of time can alter. But Mr. Burke has done some service—not to his cause, but to his country—by bringing those clauses into public view. They serve to demonstrate how necessary it is at all times to watch against the attempted encroachment of power, and to prevent its running to excess. It is somewhat extraordinary that the offence for which James II. was expelled, that of setting up power by assumption, should be re–acted, under another shape and form, by the Parliament that expelled him. It shows that the Rights of Man were but imperfectly understood at the Revolution, for certain it is that the right which that Parliament set up by assumption (for by the delegation it had not, and could not have it, because none could give it) over the persons and freedom of posterity for ever was of the same tyrannical unfounded kind which James attempted to set up over the Parliament and the nation, and for which he was expelled. The only difference is (for in principle they differ not) that the one was an usurper over living, and the other over the unborn; and as the one has no better authority to stand upon than the other, both of them must be equally null and void, and of no effect. From what, or from whence, does Mr. Burke prove the right of any human power to bind posterity for ever? He has produced his clauses, but he must produce also his proofs that such a right existed, and show how it existed. If it ever existed it must now exist, for whatever appertains to the nature of man cannot be annihilated by man. It is the nature of man to die, and he will continue to die as long as he continues to be born. But Mr. Burke has set up a sort of political Adam, in whom all posterity are bound for ever. He must, therefore, prove that his Adam possessed such a power, or such a right. The weaker any cord is, the less will it bear to be stretched, and the worse is the policy to stretch it, unless it is intended to break it. Had anyone proposed the overthrow of Mr. Burke’s positions, he would have proceeded as Mr. Burke has done. He would have magnified the authorities, on purpose to have called the right of them into question; and the instant the question of right was started, the authorities must have been given up. It requires but a very small glance of thought to perceive that although laws made in one generation often continue in force through succeeding generations, yet they continue to derive their force from the consent of the living. A law not repealed continues in force, not because it cannot be repealed, but because it is not repealed; and the non–repealing passes for consent. But Mr. Burke’s clauses have not even this qualification in their favour. They become null, by attempting to become immortal. The nature of them precludes consent. They destroy the right which they might have, by grounding it on a right which they cannot have. Immortal power is not a human right, and therefore cannot be a right of Parliament. The Parliament of 1688 might as well have passed an act to have authorised themselves to live for ever, as to make their authority live for ever. All, therefore, that can be said of those clauses is that they are a formality of words, of as much import as if those who used them had addressed a congratulation to themselves, and in the oriental style of antiquity had said: O Parliament, live for ever! The circumstances of the world are continually changing, and the opinions of men change also; and as government is for the living, and not for the dead, it is the living only that has any right in it. That which may be thought right and found convenient in one age may be thought wrong and found inconvenient in another. In such cases, who is to decide, the living or the dead? As almost one hundred pages of Mr. Burke’s book are employed upon these clauses, it will consequently follow that if the clauses themselves, so far as they set up an assumed usurped dominion over posterity for ever, are unauthoritative, and in their nature null and void; that all his voluminous inferences, and declamation drawn therefrom, or founded thereon, are null and void also; and on this ground I rest the matter. We now come more particularly to the affairs of France. Mr. Burke’s book has the appearance of being written as instruction to the French nation; but if I may permit myself the use of an extravagant metaphor, suited to the extravagance of the case, it is darkness attempting to illuminate light. While I am writing this there are accidentally before me some proposals for a declaration of rights by the Marquis de la Fayette (I ask his pardon for using his former address, and do it only for distinction’s sake) to the National Assembly, on the 11th of July, 1789, three days before the taking of the Bastille, and I cannot but remark with astonishment how opposite the sources are from which that gentleman and Mr. Burke draw their principles. Instead of referring to musty records and mouldy parchments to prove that the rights of the living are lost, \"renounced and abdicated for ever,\" by those who are now no more, as Mr. Burke has done, M. de la Fayette applies to the living world, and emphatically says: \"Call to mind the sentiments which nature has engraved on the heart of every citizen, and which take a new force when they are solemnly recognised by all:—For a nation to love liberty, it is sufficient that she knows it; and to be free, it is sufficient that she wills it.\" How dry, barren, and obscure is the source from which Mr. Burke labors! and how ineffectual, though gay with flowers, are all his declamation and his arguments compared with these clear, concise, and soul–animating sentiments! Few and short as they are, they lead on to a vast field of generous and manly thinking, and do not finish, like Mr. Burke’s periods, with music in the ear, and nothing in the heart. As I have introduced M. de la Fayette, I will take the liberty of adding an anecdote respecting his farewell address to the Congress of America in 1783, and which occurred fresh to my mind, when I saw Mr. Burke’s thundering attack on the French Revolution. M. de la Fayette went to America at the early period of the war, and continued a volunteer in her service to the end. His conduct through the whole of that enterprise is one of the most extraordinary that is to be found in the history of a young man, scarcely twenty years of age. Situated in a country that was like the lap of sensual pleasure, and with the means of enjoying it, how few are there to be found who would exchange such a scene for the woods and wildernesses of America, and pass the flowery years of youth in unprofitable danger and hardship! but such is the fact. When the war ended, and he was on the point of taking his final departure, he presented himself to Congress, and contemplating in his affectionate farewell the Revolution he had seen, expressed himself in these words: \"May this great monument raised to liberty serve as a lesson to the oppressor, and an example to the oppressed!\" When this address came to the hands of Dr. Franklin, who was then in France, he applied to Count Vergennes to have it inserted in the French Gazette, but never could obtain his consent. The fact was that Count Vergennes was an aristocratical despot at home, and dreaded the example of the American Revolution in France, as certain other persons now dread the example of the French Revolution in England, and Mr. Burke’s tribute of fear (for in this light his book must be considered) runs parallel with Count Vergennes' refusal. But to return more particularly to his work. \"We have seen,\" says Mr. Burke, \"the French rebel against a mild and lawful monarch, with more fury, outrage, and insult, than any people has been known to rise against the most illegal usurper, or the most sanguinary tyrant.\" This is one among a thousand other instances, in which Mr. Burke shows that he is ignorant of the springs and principles of the French Revolution. It was not against Louis XVI. but against the despotic principles of the Government, that the nation revolted. These principles had not their origin in him, but in the original establishment, many centuries back: and they were become too deeply rooted to be removed, and the Augean stables of parasites and plunderers too abominably filthy to be cleansed by anything short of a complete and universal Revolution. When it becomes necessary to do anything, the whole heart and soul should go into the measure, or not attempt it. That crisis was then arrived, and there remained no choice but to act with determined vigor, or not to act at all. The king was known to be the friend of the nation, and this circumstance was favorable to the enterprise. Perhaps no man bred up in the style of an absolute king, ever possessed a heart so little disposed to the exercise of that species of power as the present King of France. But the principles of the Government itself still remained the same. The Monarch and the Monarchy were distinct and separate things; and it was against the established despotism of the latter, and not against the person or principles of the former, that the revolt commenced, and the Revolution has been carried. Mr. Burke does not attend to the distinction between men and principles, and, therefore, he does not see that a revolt may take place against the despotism of the latter, while there lies no charge of despotism against the former. The natural moderation of Louis XVI. contributed nothing to alter the hereditary despotism of the monarchy. All the tyrannies of former reigns, acted under that hereditary despotism, were still liable to be revived in the hands of a successor. It was not the respite of a reign that would satisfy France, enlightened as she was then become. A casual discontinuance of the practice of despotism, is not a discontinuance of its principles: the former depends on the virtue of the individual who is in immediate possession of the power; the latter, on the virtue and fortitude of the nation. In the case of Charles I. and James II. of England, the revolt was against the personal despotism of the men; whereas in France, it was against the hereditary despotism of the established Government. But men who can consign over the rights of posterity for ever on the authority of a mouldy parchment, like Mr. Burke, are not qualified to judge of this Revolution. It takes in a field too vast for their views to explore, and proceeds with a mightiness of reason they cannot keep pace with. But there are many points of view in which this Revolution may be considered. When despotism has established itself for ages in a country, as in France, it is not in the person of the king only that it resides. It has the appearance of being so in show, and in nominal authority; but it is not so in practice and in fact. It has its standard everywhere. Every office and department has its despotism, founded upon custom and usage. Every place has its Bastille, and every Bastille its despot. The original hereditary despotism resident in the person of the king, divides and sub–divides itself into a thousand shapes and forms, till at last the whole of it is acted by deputation. This was the case in France; and against this species of despotism, proceeding on through an endless labyrinth of office till the source of it is scarcely perceptible, there is no mode of redress. It strengthens itself by assuming the appearance of duty, and tyrannies under the pretence of obeying. When a man reflects on the condition which France was in from the nature of her government, he will see other causes for revolt than those which immediately connect themselves with the person or character of Louis XVI. There were, if I may so express it, a thousand despotisms to be reformed in France, which had grown up under the hereditary despotism of the monarchy, and became so rooted as to be in a great measure independent of it. Between the Monarchy, the Parliament, and the Church there was a rivalship of despotism; besides the feudal despotism operating locally, and the ministerial despotism operating everywhere. But Mr. Burke, by considering the king as the only possible object of a revolt, speaks as if France was a village, in which everything that passed must be known to its commanding officer, and no oppression could be acted but what he could immediately control. Mr. Burke might have been in the Bastille his whole life, as well under Louis XVI. as Louis XIV., and neither the one nor the other have known that such a man as Burke existed. The despotic principles of the government were the same in both reigns, though the dispositions of the men were as remote as tyranny and benevolence. What Mr. Burke considers as a reproach to the French Revolution (that of bringing it forward under a reign more mild than the preceding ones) is one of its highest honors. The Revolutions that have taken place in other European countries, have been excited by personal hatred. The rage was against the man, and he became the victim. But, in the instance of France we see a Revolution generated in the rational contemplation of the Rights of Man, and distinguishing from the beginning between persons and principles. But Mr. Burke appears to have no idea of principles when he is contemplating Governments. \"Ten years ago,\" says he, \"I could have felicitated France on her having a Government, without inquiring what the nature of that Government was, or how it was administered.\" Is this the language of a rational man? Is it the language of a heart feeling as it ought to feel for the rights and happiness of the human race? On this ground, Mr. Burke must compliment all the Governments in the world, while the victims who suffer under them, whether sold into slavery, or tortured out of existence, are wholly forgotten. It is power, and not principles, that Mr. Burke venerates; and under this abominable depravity he is disqualified to judge between them. Thus much for his opinion as to the occasions of the French Revolution. I now proceed to other considerations. I know a place in America called Point–no–Point, because as you proceed along the shore, gay and flowery as Mr. Burke’s language, it continually recedes and presents itself at a distance before you; but when you have got as far as you can go, there is no point at all. Just thus it is with Mr. Burke’s three hundred and sixty–six pages. It is therefore difficult to reply to him. But as the points he wishes to establish may be inferred from what he abuses, it is in his paradoxes that we must look for his arguments. As to the tragic paintings by which Mr. Burke has outraged his own imagination, and seeks to work upon that of his readers, they are very well calculated for theatrical representation, where facts are manufactured for the sake of show, and accommodated to produce, through the weakness of sympathy, a weeping effect. But Mr. Burke should recollect that he is writing history, and not plays, and that his readers will expect truth, and not the spouting rant of high–toned exclamation. When we see a man dramatically lamenting in a publication intended to be believed that \"The age of chivalry is gone! that The glory of Europe is extinguished for ever! that The unbought grace of life (if anyone knows what it is), the cheap defence of nations, the nurse of manly sentiment and heroic enterprise is gone!\" and all this because the Quixot age of chivalry nonsense is gone, what opinion can we form of his judgment, or what regard can we pay to his facts? In the rhapsody of his imagination he has discovered a world of wind mills, and his sorrows are that there are no Quixots to attack them. But if the age of aristocracy, like that of chivalry, should fall (and they had originally some connection) Mr. Burke, the trumpeter of the Order, may continue his parody to the end, and finish with exclaiming: \"Othello’s occupation’s gone!\" Notwithstanding Mr. Burke’s horrid paintings, when the French Revolution is compared with the Revolutions of other countries, the astonishment will be that it is marked with so few sacrifices; but this astonishment will cease when we reflect that principles, and not persons, were the meditated objects of destruction. The mind of the nation was acted upon by a higher stimulus than what the consideration of persons could inspire, and sought a higher conquest than could be produced by the downfall of an enemy. Among the few who fell there do not appear to be any that were intentionally singled out. They all of them had their fate in the circumstances of the moment, and were not pursued with that long, cold–blooded unabated revenge which pursued the unfortunate Scotch in the affair of 1745. Through the whole of Mr. Burke’s book I do not observe that the Bastille is mentioned more than once, and that with a kind of implication as if he were sorry it was pulled down, and wished it were built up again. \"We have rebuilt Newgate,\" says he, \"and tenanted the mansion; and we have prisons almost as strong as the Bastille for those who dare to libel the queens of France.\" [2] As to what a madman like the person called Lord George Gordon might say, and to whom Newgate is rather a bedlam than a prison, it is unworthy a rational consideration. It was a madman that libelled, and that is sufficient apology; and it afforded an opportunity for confining him, which was the thing that was wished for. But certain it is that Mr. Burke, who does not call himself a madman (whatever other people may do), has libelled in the most unprovoked manner, and in the grossest style of the most vulgar abuse, the whole representative authority of France, and yet Mr. Burke takes his seat in the British House of Commons! From his violence and his grief, his silence on some points and his excess on others, it is difficult not to believe that Mr. Burke is sorry, extremely sorry, that arbitrary power, the power of the Pope and the Bastille, are pulled down. Not one glance of compassion, not one commiserating reflection that I can find throughout his book, has he bestowed on those who lingered out the most wretched of lives, a life without hope in the most miserable of prisons. It is painful to behold a man employing his talents to corrupt himself. Nature has been kinder to Mr. Burke than he is to her. He is not affected by the reality of distress touching his heart, but by the showy resemblance of it striking his imagination. He pities the plumage, but forgets the dying bird. Accustomed to kiss the aristocratical hand that hath purloined him from himself, he degenerates into a composition of art, and the genuine soul of nature forsakes him. His hero or his heroine must be a tragedy–victim expiring in show, and not the real prisoner of misery, sliding into death in the silence of a dungeon. As Mr. Burke has passed over the whole transaction of the Bastille (and his silence is nothing in his favour), and has entertained his readers with refections on supposed facts distorted into real falsehoods, I will give, since he has not, some account of the circumstances which preceded that transaction. They will serve to show that less mischief could scarcely have accompanied such an event when considered with the treacherous and hostile aggravations of the enemies of the Revolution. The mind can hardly picture to itself a more tremendous scene than what the city of Paris exhibited at the time of taking the Bastille, and for two days before and after, nor perceive the possibility of its quieting so soon. At a distance this transaction has appeared only as an act of heroism standing on itself, and the close political connection it had with the Revolution is lost in the brilliancy of the achievement. But we are to consider it as the strength of the parties brought man to man, and contending for the issue. The Bastille was to be either the prize or the prison of the assailants. The downfall of it included the idea of the downfall of despotism, and this compounded image was become as figuratively united as Bunyan’s Doubting Castle and Giant Despair. The National Assembly, before and at the time of taking the Bastille, was sitting at Versailles, twelve miles distant from Paris. About a week before the rising of the Partisans, and their taking the Bastille, it was discovered that a plot was forming, at the head of which was the Count D’Artois, the king’s youngest brother, for demolishing the National Assembly, seizing its members, and thereby crushing, by a coup de main, all hopes and prospects of forming a free government. For the sake of humanity, as well as freedom, it is well this plan did not succeed. Examples are not wanting to show how dreadfully vindictive and cruel are all old governments, when they are successful against what they call a revolt. This plan must have been some time in contemplation; because, in order to carry it into execution, it was necessary to collect a large military force round Paris, and cut off the communication between that city and the National Assembly at Versailles. The troops destined for this service were chiefly the foreign troops in the pay of France, and who, for this particular purpose, were drawn from the distant provinces where they were then stationed. When they were collected to the amount of between twenty–five and thirty thousand, it was judged time to put the plan into execution. The ministry who were then in office, and who were friendly to the Revolution, were instantly dismissed and a new ministry formed of those who had concerted the project, among whom was Count de Broglio, and to his share was given the command of those troops. The character of this man as described to me in a letter which I communicated to Mr. Burke before he began to write his book, and from an authority which Mr. Burke well knows was good, was that of \"a high–flying aristocrat, cool, and capable of every mischief.\" While these matters were agitating, the National Assembly stood in the most perilous and critical situation that a body of men can be supposed to act in. They were the devoted victims, and they knew it. They had the hearts and wishes of their country on their side, but military authority they had none. The guards of Broglio surrounded the hall where the Assembly sat, ready, at the word of command, to seize their persons, as had been done the year before to the Parliament of Paris. Had the National Assembly deserted their trust, or had they exhibited signs of weakness or fear, their enemies had been encouraged and their country depressed. When the situation they stood in, the cause they were engaged in, and the crisis then ready to burst, which should determine their personal and political fate and that of their country, and probably of Europe, are taken into one view, none but a heart callous with prejudice or corrupted by dependence can avoid interesting itself in their success. The Archbishop of Vienne was at this time President of the National Assembly—a person too old to undergo the scene that a few days or a few hours might bring forth. A man of more activity and bolder fortitude was necessary, and the National Assembly chose (under the form of a Vice–President, for the Presidency still resided in the Archbishop) M. de la Fayette; and this is the only instance of a Vice–President being chosen. It was at the moment that this storm was pending (July 11th) that a declaration of rights was brought forward by M. de la Fayette, and is the same which is alluded to earlier. It was hastily drawn up, and makes only a part of the more extensive declaration of rights agreed upon and adopted afterwards by the National Assembly. The particular reason for bringing it forward at this moment (M. de la Fayette has since informed me) was that, if the National Assembly should fall in the threatened destruction that then surrounded it, some trace of its principles might have the chance of surviving the wreck. Everything now was drawing to a crisis. The event was freedom or slavery. On one side, an army of nearly thirty thousand men; on the other, an unarmed body of citizens—for the citizens of Paris, on whom the National Assembly must then immediately depend, were as unarmed and as undisciplined as the citizens of London are now. The French guards had given strong symptoms of their being attached to the national cause; but their numbers were small, not a tenth part of the force that Broglio commanded, and their officers were in the interest of Broglio. Matters being now ripe for execution, the new ministry made their appearance in office. The reader will carry in his mind that the Bastille was taken the 14th July; the point of time I am now speaking of is the 12th. Immediately on the news of the change of ministry reaching Paris, in the afternoon, all the playhouses and places of entertainment, shops and houses, were shut up. The change of ministry was considered as the prelude of hostilities, and the opinion was rightly founded. The foreign troops began to advance towards the city. The Prince de Lambesc, who commanded a body of German cavalry, approached by the Place of Louis Xv., which connects itself with some of the streets. In his march, he insulted and struck an old man with a sword. The French are remarkable for their respect to old age; and the insolence with which it appeared to be done, uniting with the general fermentation they were in, produced a powerful effect, and a cry of \"To arms! to arms!\" spread itself in a moment over the city. Arms they had none, nor scarcely anyone who knew the use of them; but desperate resolution, when every hope is at stake, supplies, for a while, the want of arms. Near where the Prince de Lambesc was drawn up, were large piles of stones collected for building the new bridge, and with these the people attacked the cavalry. A party of French guards upon hearing the firing, rushed from their quarters and joined the people; and night coming on, the cavalry retreated. The streets of Paris, being narrow, are favourable for defence, and the loftiness of the houses, consisting of many stories, from which great annoyance might be given, secured them against nocturnal enterprises; and the night was spent in providing themselves with every sort of weapon they could make or procure: guns, swords, blacksmiths' hammers, carpenters' axes, iron crows, pikes, halberts, pitchforks, spits, clubs, etc., etc. The incredible numbers in which they assembled the next morning, and the still more incredible resolution they exhibited, embarrassed and astonished their enemies. Little did the new ministry expect such a salute. Accustomed to slavery themselves, they had no idea that liberty was capable of such inspiration, or that a body of unarmed citizens would dare to face the military force of thirty thousand men. Every moment of this day was employed in collecting arms, concerting plans, and arranging themselves into the best order which such an instantaneous movement could afford. Broglio continued lying round the city, but made no further advances this day, and the succeeding night passed with as much tranquility as such a scene could possibly produce. But defence only was not the object of the citizens. They had a cause at stake, on which depended their freedom or their slavery. They every moment expected an attack, or to hear of one made on the National Assembly; and in such a situation, the most prompt measures are sometimes the best. The object that now presented itself was the Bastille; and the eclat of carrying such a fortress in the face of such an army, could not fail to strike terror into the new ministry, who had scarcely yet had time to meet. By some intercepted correspondence this morning, it was discovered that the Mayor of Paris, M. Defflesselles, who appeared to be in the interest of the citizens, was betraying them; and from this discovery, there remained no doubt that Broglio would reinforce the Bastille the ensuing evening. It was therefore necessary to attack it that day; but before this could be done, it was first necessary to procure a better supply of arms than they were then possessed of. There was, adjoining to the city a large magazine of arms deposited at the Hospital of the Invalids, which the citizens summoned to surrender; and as the place was neither defensible, nor attempted much defence, they soon succeeded. Thus supplied, they marched to attack the Bastille; a vast mixed multitude of all ages, and of all degrees, armed with all sorts of weapons. Imagination would fail in describing to itself the appearance of such a procession, and of the anxiety of the events which a few hours or a few minutes might produce. What plans the ministry were forming, were as unknown to the people within the city, as what the citizens were doing was unknown to the ministry; and what movements Broglio might make for the support or relief of the place, were to the citizens equally as unknown. All was mystery and hazard. That the Bastille was attacked with an enthusiasm of heroism, such only as the highest animation of liberty could inspire, and carried in the space of a few hours, is an event which the world is fully possessed of. I am not undertaking the detail of the attack, but bringing into view the conspiracy against the nation which provoked it, and which fell with the Bastille. The prison to which the new ministry were dooming the National Assembly, in addition to its being the high altar and castle of despotism, became the proper object to begin with. This enterprise broke up the new ministry, who began now to fly from the ruin they had prepared for others. The troops of Broglio dispersed, and himself fled also. Mr. Burke has spoken a great deal about plots, but he has never once spoken of this plot against the National Assembly, and the liberties of the nation; and that he might not, he has passed over all the circumstances that might throw it in his way. The exiles who have fled from France, whose case he so much interests himself in, and from whom he has had his lesson, fled in consequence of the miscarriage of this plot. No plot was formed against them; they were plotting against others; and those who fell, met, not unjustly, the punishment they were preparing to execute. But will Mr. Burke say that if this plot, contrived with the subtilty of an ambuscade, had succeeded, the successful party would have restrained their wrath so soon? Let the history of all governments answer the question. Whom has the National Assembly brought to the scaffold? None. They were themselves the devoted victims of this plot, and they have not retaliated; why, then, are they charged with revenge they have not acted? In the tremendous breaking forth of a whole people, in which all degrees, tempers and characters are confounded, delivering themselves, by a miracle of exertion, from the destruction meditated against them, is it to be expected that nothing will happen? When men are sore with the sense of oppressions, and menaced with the prospects of new ones, is the calmness of philosophy or the palsy of insensibility to be looked for? Mr. Burke exclaims against outrage; yet the greatest is that which himself has committed. His book is a volume of outrage, not apologised for by the impulse of a moment, but cherished through a space of ten months; yet Mr. Burke had no provocation—no life, no interest, at stake. More of the citizens fell in this struggle than of their opponents: but four or five persons were seized by the populace, and instantly put to death; the Governor of the Bastille, and the Mayor of Paris, who was detected in the act of betraying them; and afterwards Foulon, one of the new ministry, and Berthier, his son–in–law, who had accepted the office of intendant of Paris. Their heads were stuck upon spikes, and carried about the city; and it is upon this mode of punishment that Mr. Burke builds a great part of his tragic scene. Let us therefore examine how men came by the idea of punishing in this manner. They learn it from the governments they live under; and retaliate the punishments they have been accustomed to behold. The heads stuck upon spikes, which remained for years upon Temple Bar, differed nothing in the horror of the scene from those carried about upon spikes at Paris; yet this was done by the English Government. It may perhaps be said that it signifies nothing to a man what is done to him after he is dead; but it signifies much to the living; it either tortures their feelings or hardens their hearts, and in either case it instructs them how to punish when power falls into their hands. Lay then the axe to the root, and teach governments humanity. It is their sanguinary punishments which corrupt mankind. In England the punishment in certain cases is by hanging, drawing and quartering; the heart of the sufferer is cut out and held up to the view of the populace. In France, under the former Government, the punishments were not less barbarous. Who does not remember the execution of Damien, torn to pieces by horses? The effect of those cruel spectacles exhibited to the populace is to destroy tenderness or excite revenge; and by the base and false idea of governing men by terror, instead of reason, they become precedents. It is over the lowest class of mankind that government by terror is intended to operate, and it is on them that it operates to the worst effect. They have sense enough to feel they are the objects aimed at; and they inflict in their turn the examples of terror they have been instructed to practise. There is in all European countries a large class of people of that description, which in England is called the \"mob.\" Of this class were those who committed the burnings and devastations in London in 1780, and of this class were those who carried the heads on iron spikes in Paris. Foulon and Berthier were taken up in the country, and sent to Paris, to undergo their examination at the Hotel de Ville; for the National Assembly, immediately on the new ministry coming into office, passed a decree, which they communicated to the King and Cabinet, that they (the National Assembly) would hold the ministry, of which Foulon was one, responsible for the measures they were advising and pursuing; but the mob, incensed at the appearance of Foulon and Berthier, tore them from their conductors before they were carried to the Hotel de Ville, and executed them on the spot. Why then does Mr. Burke charge outrages of this kind on a whole people? As well may he charge the riots and outrages of 1780 on all the people of London, or those in Ireland on all his countrymen. But everything we see or hear offensive to our feelings and derogatory to the human character should lead to other reflections than those of reproach. Even the beings who commit them have some claim to our consideration. How then is it that such vast classes of mankind as are distinguished by the appellation of the vulgar, or the ignorant mob, are so numerous in all old countries? The instant we ask ourselves this question, reflection feels an answer. They rise, as an unavoidable consequence, out of the ill construction of all old governments in Europe, England included with the rest. It is by distortedly exalting some men, that others are distortedly debased, till the whole is out of nature. A vast mass of mankind are degradedly thrown into the back–ground of the human picture, to bring forward, with greater glare, the puppet–show of state and aristocracy. In the commencement of a revolution, those men are rather the followers of the camp than of the standard of liberty, and have yet to be instructed how to reverence it. I give to Mr. Burke all his theatrical exaggerations for facts, and I then ask him if they do not establish the certainty of what I here lay down? Admitting them to be true, they show the necessity of the French Revolution, as much as any one thing he could have asserted. These outrages were not the effect of the principles of the Revolution, but of the degraded mind that existed before the Revolution, and which the Revolution is calculated to reform. Place them then to their proper cause, and take the reproach of them to your own side. It is the honour of the National Assembly and the city of Paris that, during such a tremendous scene of arms and confusion, beyond the control of all authority, they have been able, by the influence of example and exhortation, to restrain so much. Never were more pains taken to instruct and enlighten mankind, and to make them see that their interest consisted in their virtue, and not in their revenge, than have been displayed in the Revolution of France. I now proceed to make some remarks on Mr. Burke’s account of the expedition to Versailles, October the 5th and 6th. I can consider Mr. Burke’s book in scarcely any other light than a dramatic performance; and he must, I think, have considered it in the same light himself, by the poetical liberties he has taken of omitting some facts, distorting others, and making the whole machinery bend to produce a stage effect. Of this kind is his account of the expedition to Versailles. He begins this account by omitting the only facts which as causes are known to be true; everything beyond these is conjecture, even in Paris; and he then works up a tale accommodated to his own passions and prejudices. It is to be observed throughout Mr. Burke’s book that he never speaks of plots against the Revolution; and it is from those plots that all the mischiefs have arisen. It suits his purpose to exhibit the consequences without their causes. It is one of the arts of the drama to do so. If the crimes of men were exhibited with their sufferings, stage effect would sometimes be lost, and the audience would be inclined to approve where it was intended they should commiserate. After all the investigations that have been made into this intricate affair (the expedition to Versailles), it still remains enveloped in all that kind of mystery which ever accompanies events produced more from a concurrence of awkward circumstances than from fixed design. While the characters of men are forming, as is always the case in revolutions, there is a reciprocal suspicion, and a disposition to misinterpret each other; and even parties directly opposite in principle will sometimes concur in pushing forward the same movement with very different views, and with the hopes of its producing very different consequences. A great deal of this may be discovered in this embarrassed affair, and yet the issue of the whole was what nobody had in view. The only things certainly known are that considerable uneasiness was at this time excited at Paris by the delay of the King in not sanctioning and forwarding the decrees of the National Assembly, particularly that of the Declaration of the Rights of Man, and the decrees of the fourth of August, which contained the foundation principles on which the constitution was to be erected. The kindest, and perhaps the fairest conjecture upon this matter is, that some of the ministers intended to make remarks and observations upon certain parts of them before they were finally sanctioned and sent to the provinces; but be this as it may, the enemies of the Revolution derived hope from the delay, and the friends of the Revolution uneasiness. During this state of suspense, the Garde du Corps, which was composed as such regiments generally are, of persons much connected with the Court, gave an entertainment at Versailles (October 1) to some foreign regiments then arrived; and when the entertainment was at the height, on a signal given, the Garde du Corps tore the national cockade from their hats, trampled it under foot, and replaced it with a counter–cockade prepared for the purpose. An indignity of this kind amounted to defiance. It was like declaring war; and if men will give challenges they must expect consequences. But all this Mr. Burke has carefully kept out of sight. He begins his account by saying: \"History will record that on the morning of the 6th October, 1789, the King and Queen of France, after a day of confusion, alarm, dismay, and slaughter, lay down under the pledged security of public faith to indulge nature in a few hours of respite, and troubled melancholy repose.\" This is neither the sober style of history, nor the intention of it. It leaves everything to be guessed at and mistaken. One would at least think there had been a battle; and a battle there probably would have been had it not been for the moderating prudence of those whom Mr. Burke involves in his censures. By his keeping the Garde du Corps out of sight Mr. Burke has afforded himself the dramatic licence of putting the King and Queen in their places, as if the object of the expedition was against them. But to return to my account this conduct of the Garde du Corps, as might well be expected, alarmed and enraged the Partisans. The colors of the cause, and the cause itself, were become too united to mistake the intention of the insult, and the Partisans were determined to call the Garde du Corps to an account. There was certainly nothing of the cowardice of assassination in marching in the face of the day to demand satisfaction, if such a phrase may be used, of a body of armed men who had voluntarily given defiance. But the circumstance which serves to throw this affair into embarrassment is, that the enemies of the Revolution appear to have encouraged it as well as its friends. The one hoped to prevent a civil war by checking it in time, and the other to make one. The hopes of those opposed to the Revolution rested in making the King of their party, and getting him from Versailles to Metz, where they expected to collect a force and set up a standard. We have, therefore, two different objects presenting themselves at the same time, and to be accomplished by the same means: the one to chastise the Garde du Corps, which was the object of the Partisans; the other to render the confusion of such a scene an inducement to the King to set off for Metz. On the 5th of October a very numerous body of women, and men in the disguise of women, collected around the Hotel de Ville or town–hall at Paris, and set off for Versailles. Their professed object was the Garde du Corps; but prudent men readily recollect that mischief is more easily begun than ended; and this impressed itself with the more force from the suspicions already stated, and the irregularity of such a cavalcade. As soon, therefore, as a sufficient force could be collected, M. de la Fayette, by orders from the civil authority of Paris, set off after them at the head of twenty thousand of the Paris militia. The Revolution could derive no benefit from confusion, and its opposers might. By an amiable and spirited manner of address he had hitherto been fortunate in calming disquietudes, and in this he was extraordinarily successful; to frustrate, therefore, the hopes of those who might seek to improve this scene into a sort of justifiable necessity for the King’s quitting Versailles and withdrawing to Metz, and to prevent at the same time the consequences that might ensue between the Garde du Corps and this phalanx of men and women, he forwarded expresses to the King, that he was on his march to Versailles, by the orders of the civil authority of Paris, for the purpose of peace and protection, expressing at the same time the necessity of restraining the Garde du Corps from firing upon the people. [3] He arrived at Versailles between ten and eleven at night. The Garde du Corps was drawn up, and the people had arrived some time before, but everything had remained suspended. Wisdom and policy now consisted in changing a scene of danger into a happy event. M. de la Fayette became the mediator between the enraged parties; and the King, to remove the uneasiness which had arisen from the delay already stated, sent for the President of the National Assembly, and signed the Declaration of the Rights of Man, and such other parts of the constitution as were in readiness. It was now about one in the morning. Everything appeared to be composed, and a general congratulation took place. By the beat of a drum a proclamation was made that the citizens of Versailles would give the hospitality of their houses to their fellow–citizens of Paris. Those who could not be accommodated in this manner remained in the streets, or took up their quarters in the churches; and at two o’clock the King and Queen retired. In this state matters passed till the break of day, when a fresh disturbance arose from the censurable conduct of some of both parties, for such characters there will be in all such scenes. One of the Garde du Corps appeared at one of the windows of the palace, and the people who had remained during the night in the streets accosted him with reviling and provocative language. Instead of retiring, as in such a case prudence would have dictated, he presented his musket, fired, and killed one of the Paris militia. The peace being thus broken, the people rushed into the palace in quest of the offender. They attacked the quarters of the Garde du Corps within the palace, and pursued them throughout the avenues of it, and to the apartments of the King. On this tumult, not the Queen only, as Mr. Burke has represented it, but every person in the palace, was awakened and alarmed; and M. de la Fayette had a second time to interpose between the parties, the event of which was that the Garde du Corps put on the national cockade, and the matter ended as by oblivion, after the loss of two or three lives. During the latter part of the time in which this confusion was acting, the King and Queen were in public at the balcony, and neither of them concealed for safety’s sake, as Mr. Burke insinuates. Matters being thus appeased, and tranquility restored, a general acclamation broke forth of Le Roi a Paris—Le Roi a Paris—The King to Paris. It was the shout of peace, and immediately accepted on the part of the King. By this measure all future projects of trapanning the King to Metz, and setting up the standard of opposition to the constitution, were prevented, and the suspicions extinguished. The King and his family reached Paris in the evening, and were congratulated on their arrival by M. Bailly, the Mayor of Paris, in the name of the citizens. Mr. Burke, who throughout his book confounds things, persons, and principles, as in his remarks on M. Bailly’s address, confounded time also. He censures M. Bailly for calling it \"un bon jour,\" a good day. Mr. Burke should have informed himself that this scene took up the space of two days, the day on which it began with every appearance of danger and mischief, and the day on which it terminated without the mischiefs that threatened; and that it is to this peaceful termination that M. Bailly alludes, and to the arrival of the King at Paris. Not less than three hundred thousand persons arranged themselves in the procession from Versailles to Paris, and not an act of molestation was committed during the whole march. Mr. Burke on the authority of M. Lally Tollendal, a deserter from the National Assembly, says that on entering Paris, the people shouted \"Tous les eveques a la lanterne.\" All Bishops to be hanged at the lanthorn or lamp–posts. It is surprising that nobody could hear this but Lally Tollendal, and that nobody should believe it but Mr. Burke. It has not the least connection with any part of the transaction, and is totally foreign to every circumstance of it. The Bishops had never been introduced before into any scene of Mr. Burke’s drama: why then are they, all at once, and altogether, tout a coup, et tous ensemble, introduced now? Mr. Burke brings forward his Bishops and his lanthorn–like figures in a magic lanthorn, and raises his scenes by contrast instead of connection. But it serves to show, with the rest of his book what little credit ought to be given where even probability is set at defiance, for the purpose of defaming; and with this reflection, instead of a soliloquy in praise of chivalry, as Mr. Burke has done, I close the account of the expedition to Versailles. [4] I have now to follow Mr. Burke through a pathless wilderness of rhapsodies, and a sort of descant upon governments, in which he asserts whatever he pleases, on the presumption of its being believed, without offering either evidence or reasons for so doing. Before anything can be reasoned upon to a conclusion, certain facts, principles, or data, to reason from, must be established, admitted, or denied. Mr. Burke with his usual outrage, abused the Declaration of the Rights of Man, published by the National Assembly of France, as the basis on which the constitution of France is built. This he calls \"paltry and blurred sheets of paper about the rights of man.\" Does Mr. Burke mean to deny that man has any rights? If he does, then he must mean that there are no such things as rights anywhere, and that he has none himself; for who is there in the world but man? But if Mr. Burke means to admit that man has rights, the question then will be: What are those rights, and how man came by them originally? The error of those who reason by precedents drawn from antiquity, respecting the rights of man, is that they do not go far enough into antiquity. They do not go the whole way. They stop in some of the intermediate stages of an hundred or a thousand years, and produce what was then done, as a rule for the present day. This is no authority at all. If we travel still farther into antiquity, we shall find a direct contrary opinion and practice prevailing; and if antiquity is to be authority, a thousand such authorities may be produced, successively contradicting each other; but if we proceed on, we shall at last come out right; we shall come to the time when man came from the hand of his Maker. What was he then? Man. Man was his high and only title, and a higher cannot be given him. But of titles I shall speak hereafter. We are now got at the origin of man, and at the origin of his rights. As to the manner in which the world has been governed from that day to this, it is no farther any concern of ours than to make a proper use of the errors or the improvements which the history of it presents. Those who lived an hundred or a thousand years ago, were then moderns, as we are now. They had their ancients, and those ancients had others, and we also shall be ancients in our turn. If the mere name of antiquity is to govern in the affairs of life, the people who are to live an hundred or a thousand years hence, may as well take us for a precedent, as we make a precedent of those who lived an hundred or a thousand years ago. The fact is, that portions of antiquity, by proving everything, establish nothing. It is authority against authority all the way, till we come to the divine origin of the rights of man at the creation. Here our enquiries find a resting–place, and our reason finds a home. If a dispute about the rights of man had arisen at the distance of an hundred years from the creation, it is to this source of authority they must have referred, and it is to this same source of authority that we must now refer. Though I mean not to touch upon any sectarian principle of religion, yet it may be worth observing, that the genealogy of Christ is traced to Adam. Why then not trace the rights of man to the creation of man? I will answer the question. Because there have been upstart governments, thrusting themselves between, and presumptuously working to un–make man. If any generation of men ever possessed the right of dictating the mode by which the world should be governed for ever, it was the first generation that existed; and if that generation did it not, no succeeding generation can show any authority for doing it, nor can set any up. The illuminating and divine principle of the equal rights of man (for it has its origin from the Maker of man) relates, not only to the living individuals, but to generations of men succeeding each other. Every generation is equal in rights to generations which preceded it, by the same rule that every individual is born equal in rights with his contemporary. Every history of the creation, and every traditionary account, whether from the lettered or unlettered world, however they may vary in their opinion or belief of certain particulars, all agree in establishing one point, the unity of man; by which I mean that men are all of one degree, and consequently that all men are born equal, and with equal natural right, in the same manner as if posterity had been continued by creation instead of generation, the latter being the only mode by which the former is carried forward; and consequently every child born into the world must be considered as deriving its existence from God. The world is as new to him as it was to the first man that existed, and his natural right in it is of the same kind. The Mosaic account of the creation, whether taken as divine authority or merely historical, is full to this point, the unity or equality of man. The expression admits of no controversy. \"And God said, Let us make man in our own image. In the image of God created he him; male and female created he them.\" The distinction of sexes is pointed out, but no other distinction is even implied. If this be not divine authority, it is at least historical authority, and shows that the equality of man, so far from being a modern doctrine, is the oldest upon record. It is also to be observed that all the religions known in the world are founded, so far as they relate to man, on the unity of man, as being all of one degree. Whether in heaven or in hell, or in whatever state man may be supposed to exist hereafter, the good and the bad are the only distinctions. Nay, even the laws of governments are obliged to slide into this principle, by making degrees to consist in crimes and not in persons. It is one of the greatest of all truths, and of the highest advantage to cultivate. By considering man in this light, and by instructing him to consider himself in this light, it places him in a close connection with all his duties, whether to his Creator or to the creation, of which he is a part; and it is only when he forgets his origin, or, to use a more fashionable phrase, his birth and family, that he becomes dissolute. It is not among the least of the evils of the present existing governments in all parts of Europe that man, considered as man, is thrown back to a vast distance from his Maker, and the artificial chasm filled up with a succession of barriers, or sort of turnpike gates, through which he has to pass. I will quote Mr. Burke’s catalogue of barriers that he has set up between man and his Maker. Putting himself in the character of a herald, he says: \"We fear God—we look with awe to kings—with affection to Parliaments with duty to magistrates—with reverence to priests, and with respect to nobility.\" Mr. Burke has forgotten to put in \"'chivalry.\" He has also forgotten to put in Peter. The duty of man is not a wilderness of turnpike gates, through which he is to pass by tickets from one to the other. It is plain and simple, and consists but of two points. His duty to God, which every man must feel; and with respect to his neighbor, to do as he would be done by. If those to whom power is delegated do well, they will be respected: if not, they will be despised; and with regard to those to whom no power is delegated, but who assume it, the rational world can know nothing of them. Hitherto we have spoken only (and that but in part) of the natural rights of man. We have now to consider the civil rights of man, and to show how the one originates from the other. Man did not enter into society to become worse than he was before, nor to have fewer rights than he had before, but to have those rights better secured. His natural rights are the foundation of all his civil rights. But in order to pursue this distinction with more precision, it will be necessary to mark the different qualities of natural and civil rights. A few words will explain this. Natural rights are those which appertain to man in right of his existence. Of this kind are all the intellectual rights, or rights of the mind, and also all those rights of acting as an individual for his own comfort and happiness, which are not injurious to the natural rights of others. Civil rights are those which appertain to man in right of his being a member of society. Every civil right has for its foundation some natural right pre–existing in the individual, but to the enjoyment of which his individual power is not, in all cases, sufficiently competent. Of this kind are all those which relate to security and protection. From this short review it will be easy to distinguish between that class of natural rights which man retains after entering into society and those which he throws into the common stock as a member of society. The natural rights which he retains are all those in which the Power to execute is as perfect in the individual as the right itself. Among this class, as is before mentioned, are all the intellectual rights, or rights of the mind; consequently religion is one of those rights. The natural rights which are not retained, are all those in which, though the right is perfect in the individual, the power to execute them is defective. They answer not his purpose. A man, by natural right, has a right to judge in his own cause; and so far as the right of the mind is concerned, he never surrenders it. But what availeth it him to judge, if he has not power to redress? He therefore deposits this right in the common stock of society, and takes the ann of society, of which he is a part, in preference and in addition to his own. Society grants him nothing. Every man is a proprietor in society, and draws on the capital as a matter of right. From these premisses two or three certain conclusions will follow: First, That every civil right grows out of a natural right; or, in other words, is a natural right exchanged. Secondly, That civil power properly considered as such is made up of the aggregate of that class of the natural rights of man, which becomes defective in the individual in point of power, and answers not his purpose, but when collected to a focus becomes competent to the Purpose of every one. Thirdly, That the power produced from the aggregate of natural rights, imperfect in power in the individual, cannot be applied to invade the natural rights which are retained in the individual, and in which the power to execute is as perfect as the right itself. We have now, in a few words, traced man from a natural individual to a member of society, and shown, or endeavoured to show, the quality of the natural rights retained, and of those which are exchanged for civil rights. Let us now apply these principles to governments. In casting our eyes over the world, it is extremely easy to distinguish the governments which have arisen out of society, or out of the social compact, from those which have not; but to place this in a clearer light than what a single glance may afford, it will be proper to take a review of the several sources from which governments have arisen and on which they have been founded. They may be all comprehended under three heads. First, Superstition. Secondly, Power. Thirdly, The common interest of society and the common rights of man. The first was a government of priestcraft, the second of conquerors, and the third of reason. When a set of artful men pretended, through the medium of oracles, to hold intercourse with the Deity, as familiarly as they now march up the back–stairs in European courts, the world was completely under the government of superstition. The oracles were consulted, and whatever they were made to say became the law; and this sort of government lasted as long as this sort of superstition lasted. After these a race of conquerors arose, whose government, like that of William the Conqueror, was founded in power, and the sword assumed the name of a sceptre. Governments thus established last as long as the power to support them lasts; but that they might avail themselves of every engine in their favor, they united fraud to force, and set up an idol which they called Divine Right, and which, in imitation of the Pope, who affects to be spiritual and temporal, and in contradiction to the Founder of the Christian religion, twisted itself afterwards into an idol of another shape, called Church and State. The key of St. Peter and the key of the Treasury became quartered on one another, and the wondering cheated multitude worshipped the invention. When I contemplate the natural dignity of man, when I feel (for Nature has not been kind enough to me to blunt my feelings) for the honour and happiness of its character, I become irritated at the attempt to govern mankind by force and fraud, as if they were all knaves and fools, and can scarcely avoid disgust at those who are thus imposed upon. We have now to review the governments which arise out of society, in contradistinction to those which arose out of superstition and conquest. It has been thought a considerable advance towards establishing the principles of Freedom to say that Government is a compact between those who govern and those who are governed; but this cannot be true, because it is putting the effect before the cause; for as man must have existed before governments existed, there necessarily was a time when governments did not exist, and consequently there could originally exist no governors to form such a compact with. The fact therefore must be that the individuals themselves, each in his own personal and sovereign right, entered into a compact with each other to produce a government: and this is the only mode in which governments have a right to arise, and the only principle on which they have a right to exist. To possess ourselves of a clear idea of what government is, or ought to be, we must trace it to its origin. In doing this we shall easily discover that governments must have arisen either out of the people or over the people. Mr. Burke has made no distinction. He investigates nothing to its source, and therefore he confounds everything; but he has signified his intention of undertaking, at some future opportunity, a comparison between the constitution of England and France. As he thus renders it a subject of controversy by throwing the gauntlet, I take him upon his own ground. It is in high challenges that high truths have the right of appearing; and I accept it with the more readiness because it affords me, at the same time, an opportunity of pursuing the subject with respect to governments arising out of society. But it will be first necessary to define what is meant by a Constitution. It is not sufficient that we adopt the word; we must fix also a standard signification to it. A constitution is not a thing in name only, but in fact. It has not an ideal, but a real existence; and wherever it cannot be produced in a visible form, there is none. A constitution is a thing antecedent to a government, and a government is only the creature of a constitution. The constitution of a country is not the act of its government, but of the people constituting its government. It is the body of elements, to which you can refer, and quote article by article; and which contains the principles on which the government shall be established, the manner in which it shall be organised, the powers it shall have, the mode of elections, the duration of Parliaments, or by what other name such bodies may be called; the powers which the executive part of the government shall have; and in fine, everything that relates to the complete organisation of a civil government, and the principles on which it shall act, and by which it shall be bound. A constitution, therefore, is to a government what the laws made afterwards by that government are to a court of judicature. The court of judicature does not make the laws, neither can it alter them; it only acts in conformity to the laws made: and the government is in like manner governed by the constitution. Can, then, Mr. Burke produce the English Constitution? If he cannot, we may fairly conclude that though it has been so much talked about, no such thing as a constitution exists, or ever did exist, and consequently that the people have yet a constitution to form. Mr. Burke will not, I presume, deny the position I have already advanced—namely, that governments arise either out of the people or over the people. The English Government is one of those which arose out of a conquest, and not out of society, and consequently it arose over the people; and though it has been much modified from the opportunity of circumstances since the time of William the Conqueror, the country has never yet regenerated itself, and is therefore without a constitution. I readily perceive the reason why Mr. Burke declined going into the comparison between the English and French constitutions, because he could not but perceive, when he sat down to the task, that no such a thing as a constitution existed on his side the question. His book is certainly bulky enough to have contained all he could say on this subject, and it would have been the best manner in which people could have judged of their separate merits. Why then has he declined the only thing that was worth while to write upon? It was the strongest ground he could take, if the advantages were on his side, but the weakest if they were not; and his declining to take it is either a sign that he could not possess it or could not maintain it. Mr. Burke said, in a speech last winter in Parliament, \"that when the National Assembly first met in three Orders (the Tiers Etat, the Clergy, and the Noblesse), France had then a good constitution.\" This shows, among numerous other instances, that Mr. Burke does not understand what a constitution is. The persons so met were not a constitution, but a convention, to make a constitution. The present National Assembly of France is, strictly speaking, the personal social compact. The members of it are the delegates of the nation in its original character; future assemblies will be the delegates of the nation in its organised character. The authority of the present Assembly is different from what the authority of future Assemblies will be. The authority of the present one is to form a constitution; the authority of future assemblies will be to legislate according to the principles and forms prescribed in that constitution; and if experience should hereafter show that alterations, amendments, or additions are necessary, the constitution will point out the mode by which such things shall be done, and not leave it to the discretionary power of the future government. A government on the principles on which constitutional governments arising out of society are established, cannot have the right of altering itself. If it had, it would be arbitrary. It might make itself what it pleased; and wherever such a right is set up, it shows there is no constitution. The act by which the English Parliament empowered itself to sit seven years, shows there is no constitution in England. It might, by the same self–authority, have sat any great number of years, or for life. The bill which the present Mr. Pitt brought into Parliament some years ago, to reform Parliament, was on the same erroneous principle. The right of reform is in the nation in its original character, and the constitutional method would be by a general convention elected for the purpose. There is, moreover, a paradox in the idea of vitiated bodies reforming themselves. From these preliminaries I proceed to draw some comparisons. I have already spoken of the declaration of rights; and as I mean to be as concise as possible, I shall proceed to other parts of the French Constitution. The constitution of France says that every man who pays a tax of sixty sous per annum (2s. 6d. English) is an elector. What article will Mr. Burke place against this? Can anything be more limited, and at the same time more capricious, than the qualification of electors is in England? Limited—because not one man in an hundred (I speak much within compass) is admitted to vote. Capricious—because the lowest character that can be supposed to exist, and who has not so much as the visible means of an honest livelihood, is an elector in some places: while in other places, the man who pays very large taxes, and has a known fair character, and the farmer who rents to the amount of three or four hundred pounds a year, with a property on that farm to three or four times that amount, is not admitted to be an elector. Everything is out of nature, as Mr. Burke says on another occasion, in this strange chaos, and all sorts of follies are blended with all sorts of crimes. William the Conqueror and his descendants parcelled out the country in this manner, and bribed some parts of it by what they call charters to hold the other parts of it the better subjected to their will. This is the reason why so many of those charters abound in Cornwall; the people were averse to the Government established at the Conquest, and the towns were garrisoned and bribed to enslave the country. All the old charters are the badges of this conquest, and it is from this source that the capriciousness of election arises. The French Constitution says that the number of representatives for any place shall be in a ratio to the number of taxable inhabitants or electors. What article will Mr. Burke place against this? The county of York, which contains nearly a million of souls, sends two county members; and so does the county of Rutland, which contains not an hundredth part of that number. The old town of Sarum, which contains not three houses, sends two members; and the town of Manchester, which contains upward of sixty thousand souls, is not admitted to send any. Is there any principle in these things? It is admitted that all this is altered, but there is much to be done yet, before we have a fair representation of the people. Is there anything by which you can trace the marks of freedom, or discover those of wisdom? No wonder then Mr. Burke has declined the comparison, and endeavored to lead his readers from the point by a wild, unsystematical display of paradoxical rhapsodies. The French Constitution says that the National Assembly shall be elected every two years. What article will Mr. Burke place against this? Why, that the nation has no right at all in the case; that the government is perfectly arbitrary with respect to this point; and he can quote for his authority the precedent of a former Parliament. The French Constitution says there shall be no game laws, that the farmer on whose lands wild game shall be found (for it is by the produce of his lands they are fed) shall have a right to what he can take; that there shall be no monopolies of any kind—that all trades shall be free and every man free to follow any occupation by which he can procure an honest livelihood, and in any place, town, or city throughout the nation. What will Mr. Burke say to this? In England, game is made the property of those at whose expense it is not fed; and with respect to monopolies, the country is cut up into monopolies. Every chartered town is an aristocratical monopoly in itself, and the qualification of electors proceeds out of those chartered monopolies. Is this freedom? Is this what Mr. Burke means by a constitution? In these chartered monopolies, a man coming from another part of the country is hunted from them as if he were a foreign enemy. An Englishman is not free of his own country; every one of those places presents a barrier in his way, and tells him he is not a freeman—that he has no rights. Within these monopolies are other monopolies. In a city, such for instance as Bath, which contains between twenty and thirty thousand inhabitants, the right of electing representatives to Parliament is monopolised by about thirty–one persons. And within these monopolies are still others. A man even of the same town, whose parents were not in circumstances to give him an occupation, is debarred, in many cases, from the natural right of acquiring one, be his genius or industry what it may. Are these things examples to hold out to a country regenerating itself from slavery, like France? Certainly they are not, and certain am I, that when the people of England come to reflect upon them they will, like France, annihilate those badges of ancient oppression, those traces of a conquered nation. Had Mr. Burke possessed talents similar to the author of \"On the Wealth of Nations.\" he would have comprehended all the parts which enter into, and, by assemblage, form a constitution. He would have reasoned from minutiae to magnitude. It is not from his prejudices only, but from the disorderly cast of his genius, that he is unfitted for the subject he writes upon. Even his genius is without a constitution. It is a genius at random, and not a genius constituted. But he must say something. He has therefore mounted in the air like a balloon, to draw the eyes of the multitude from the ground they stand upon. Much is to be learned from the French Constitution. Conquest and tyranny transplanted themselves with William the Conqueror from Normandy into England, and the country is yet disfigured with the marks. May, then, the example of all France contribute to regenerate the freedom which a province of it destroyed! The French Constitution says that to preserve the national representation from being corrupt, no member of the National Assembly shall be an officer of the government, a placeman or a pensioner. What will Mr. Burke place against this? I will whisper his answer: Loaves and Fishes. Ah! this government of loaves and fishes has more mischief in it than people have yet reflected on. The National Assembly has made the discovery, and it holds out the example to the world. Had governments agreed to quarrel on purpose to fleece their countries by taxes, they could not have succeeded better than they have done. Everything in the English government appears to me the reverse of what it ought to be, and of what it is said to be. The Parliament, imperfectly and capriciously elected as it is, is nevertheless supposed to hold the national purse in trust for the nation; but in the manner in which an English Parliament is constructed it is like a man being both mortgagor and mortgagee, and in the case of misapplication of trust it is the criminal sitting in judgment upon himself. If those who vote the supplies are the same persons who receive the supplies when voted, and are to account for the expenditure of those supplies to those who voted them, it is themselves accountable to themselves, and the Comedy of Errors concludes with the pantomime of Hush. Neither the Ministerial party nor the Opposition will touch upon this case. The national purse is the common hack which each mounts upon. It is like what the country people call \"Ride and tie—you ride a little way, and then I.\" [5] They order these things better in France. The French Constitution says that the right of war and peace is in the nation. Where else should it reside but in those who are to pay the expense? In England this right is said to reside in a metaphor shown at the Tower for sixpence or a shilling a piece: so are the lions; and it would be a step nearer to reason to say it resided in them, for any inanimate metaphor is no more than a hat or a cap. We can all see the absurdity of worshipping Aaron’s molten calf, or Nebuchadnezzar’s golden image; but why do men continue to practise themselves the absurdities they despise in others? It may with reason be said that in the manner the English nation is represented it signifies not where the right resides, whether in the Crown or in the Parliament. War is the common harvest of all those who participate in the division and expenditure of public money, in all countries. It is the art of conquering at home; the object of it is an increase of revenue; and as revenue cannot be increased without taxes, a pretence must be made for expenditure. In reviewing the history of the English Government, its wars and its taxes, a bystander, not blinded by prejudice nor warped by interest, would declare that taxes were not raised to carry on wars, but that wars were raised to carry on taxes. Mr. Burke, as a member of the House of Commons, is a part of the English Government; and though he professes himself an enemy to war, he abuses the French Constitution, which seeks to explode it. He holds up the English Government as a model, in all its parts, to France; but he should first know the remarks which the French make upon it. They contend in favor of their own, that the portion of liberty enjoyed in England is just enough to enslave a country more productively than by despotism, and that as the real object of all despotism is revenue, a government so formed obtains more than it could do either by direct despotism, or in a full state of freedom, and is, therefore on the ground of interest, opposed to both. They account also for the readiness which always appears in such governments for engaging in wars by remarking on the different motives which produced them. In despotic governments wars are the effect of pride; but in those governments in which they become the means of taxation, they acquire thereby a more permanent promptitude. The French Constitution, therefore, to provide against both these evils, has taken away the power of declaring war from kings and ministers, and placed the right where the expense must fall. When the question of the right of war and peace was agitating in the National Assembly, the people of England appeared to be much interested in the event, and highly to applaud the decision. As a principle it applies as much to one country as another. William the Conqueror, as a conqueror, held this power of war and peace in himself, and his descendants have ever since claimed it under him as a right. Although Mr. Burke has asserted the right of the Parliament at the Revolution to bind and control the nation and posterity for ever, he denies at the same time that the Parliament or the nation had any right to alter what he calls the succession of the crown in anything but in part, or by a sort of modification. By his taking this ground he throws the case back to the Norman Conquest, and by thus running a line of succession springing from William the Conqueror to the present day, he makes it necessary to enquire who and what William the Conqueror was, and where he came from, and into the origin, history and nature of what are called prerogatives. Everything must have had a beginning, and the fog of time and antiquity should be penetrated to discover it. Let, then, Mr. Burke bring forward his William of Normandy, for it is to this origin that his argument goes. It also unfortunately happens, in running this line of succession, that another line parallel thereto presents itself, which is that if the succession runs in the line of the conquest, the nation runs in the line of being conquered, and it ought to rescue itself from this reproach. But it will perhaps be said that though the power of declaring war descends in the heritage of the conquest, it is held in check by the right of Parliament to withhold the supplies. It will always happen when a thing is originally wrong that amendments do not make it right, and it often happens that they do as much mischief one way as good the other, and such is the case here, for if the one rashly declares war as a matter of right, and the other peremptorily withholds the supplies as a matter of right, the remedy becomes as bad, or worse, than the disease. The one forces the nation to a combat, and the other ties its hands; but the more probable issue is that the contest will end in a collusion between the parties, and be made a screen to both. On this question of war, three things are to be considered. First, the right of declaring it: secondly, the expense of supporting it: thirdly, the mode of conducting it after it is declared. The French Constitution places the right where the expense must fall, and this union can only be in the nation. The mode of conducting it after it is declared, it consigns to the executive department. Were this the case in all countries, we should hear but little more of wars. Before I proceed to consider other parts of the French Constitution, and by way of relieving the fatigue of argument, I will introduce an anecdote which I had from Dr. Franklin. While the Doctor resided in France as Minister from America, during the war, he had numerous proposals made to him by projectors of every country and of every kind, who wished to go to the land that floweth with milk and honey, America; and among the rest, there was one who offered himself to be king. He introduced his proposal to the Doctor by letter, which is now in the hands of M. Beaumarchais, of Paris—stating, first, that as the Americans had dismissed or sent away [6] their King, that they would want another. Secondly, that himself was a Norman. Thirdly, that he was of a more ancient family than the Dukes of Normandy, and of a more honorable descent, his line having never been bastardised. Fourthly, that there was already a precedent in England of kings coming out of Normandy, and on these grounds he rested his offer, enjoining that the Doctor would forward it to America. But as the Doctor neither did this, nor yet sent him an answer, the projector wrote a second letter, in which he did not, it is true, threaten to go over and conquer America, but only with great dignity proposed that if his offer was not accepted, an acknowledgment of about £30,000 might be made to him for his generosity! Now, as all arguments respecting succession must necessarily connect that succession with some beginning, Mr. Burke’s arguments on this subject go to show that there is no English origin of kings, and that they are descendants of the Norman line in right of the Conquest. It may, therefore, be of service to his doctrine to make this story known, and to inform him, that in case of that natural extinction to which all mortality is subject, Kings may again be had from Normandy, on more reasonable terms than William the Conqueror; and consequently, that the good people of England, at the revolution of 1688, might have done much better, had such a generous Norman as this known their wants, and they had known his. The chivalric character which Mr. Burke so much admires, is certainly much easier to make a bargain with than a hard dealing Dutchman. But to return to the matters of the constitution: The French Constitution says, There shall be no titles; and, of consequence, all that class of equivocal generation which in some countries is called \"aristocracy\" and in others \"nobility,\" is done away, and the peer is exalted into the Man. Titles are but nicknames, and every nickname is a title. The thing is perfectly harmless in itself, but it marks a sort of foppery in the human character, which degrades it. It reduces man into the diminutive of man in things which are great, and the counterfeit of women in things which are little. It talks about its fine blue ribbon like a girl, and shows its new garter like a child. A certain writer, of some antiquity, says: \"When I was a child, I thought as a child; but when I became a man, I put away childish things.\" It is, properly, from the elevated mind of France that the folly of titles has fallen. It has outgrown the baby clothes of Count and Duke, and breeched itself in manhood. France has not levelled, it has exalted. It has put down the dwarf, to set up the man. The punyism of a senseless word like Duke, Count or Earl has ceased to please. Even those who possessed them have disowned the gibberish, and as they outgrew the rickets, have despised the rattle. The genuine mind of man, thirsting for its native home, society, contemns the gewgaws that separate him from it. Titles are like circles drawn by the magician’s wand, to contract the sphere of man’s felicity. He lives immured within the Bastille of a word, and surveys at a distance the envied life of man. Is it, then, any wonder that titles should fall in France? Is it not a greater wonder that they should be kept up anywhere? What are they? What is their worth, and \"what is their amount?\" When we think or speak of a Judge or a General, we associate with it the ideas of office and character; we think of gravity in one and bravery in the other; but when we use the word merely as a title, no ideas associate with it. Through all the vocabulary of Adam there is not such an animal as a Duke or a Count; neither can we connect any certain ideas with the words. Whether they mean strength or weakness, wisdom or folly, a child or a man, or the rider or the horse, is all equivocal. What respect then can be paid to that which describes nothing, and which means nothing? Imagination has given figure and character to centaurs, satyrs, and down to all the fairy tribe; but titles baffle even the powers of fancy, and are a chimerical nondescript. But this is not all. If a whole country is disposed to hold them in contempt, all their value is gone, and none will own them. It is common opinion only that makes them anything, or nothing, or worse than nothing. There is no occasion to take titles away, for they take themselves away when society concurs to ridicule them. This species of imaginary consequence has visibly declined in every part of Europe, and it hastens to its exit as the world of reason continues to rise. There was a time when the lowest class of what are called nobility was more thought of than the highest is now, and when a man in armour riding throughout Christendom in quest of adventures was more stared at than a modern Duke. The world has seen this folly fall, and it has fallen by being laughed at, and the farce of titles will follow its fate. The patriots of France have discovered in good time that rank and dignity in society must take a new ground. The old one has fallen through. It must now take the substantial ground of character, instead of the chimerical ground of titles; and they have brought their titles to the altar, and made of them a burnt–offering to Reason. If no mischief had annexed itself to the folly of titles they would not have been worth a serious and formal destruction, such as the National Assembly have decreed them; and this makes it necessary to enquire farther into the nature and character of aristocracy. That, then, which is called aristocracy in some countries and nobility in others arose out of the governments founded upon conquest. It was originally a military order for the purpose of supporting military government (for such were all governments founded in conquest); and to keep up a succession of this order for the purpose for which it was established, all the younger branches of those families were disinherited and the law of primogenitureship set up. The nature and character of aristocracy shows itself to us in this law. It is the law against every other law of nature, and Nature herself calls for its destruction. Establish family justice, and aristocracy falls. By the aristocratical law of primogenitureship, in a family of six children five are exposed. Aristocracy has never more than one child. The rest are begotten to be devoured. They are thrown to the cannibal for prey, and the natural parent prepares the unnatural repast. As everything which is out of nature in man affects, more or less, the interest of society, so does this. All the children which the aristocracy disowns (which are all except the eldest) are, in general, cast like orphans on a parish, to be provided for by the public, but at a greater charge. Unnecessary offices and places in governments and courts are created at the expense of the public to maintain them. With what kind of parental reflections can the father or mother contemplate their younger offspring? By nature they are children, and by marriage they are heirs; but by aristocracy they are bastards and orphans. They are the flesh and blood of their parents in the one line, and nothing akin to them in the other. To restore, therefore, parents to their children, and children to their parents relations to each other, and man to society—and to exterminate the monster aristocracy, root and branch—the French Constitution has destroyed the law of Primogenitureship. Here then lies the monster; and Mr. Burke, if he pleases, may write its epitaph. Hitherto we have considered aristocracy chiefly in one point of view. We have now to consider it in another. But whether we view it before or behind, or sideways, or any way else, domestically or publicly, it is still a monster. In France aristocracy had one feature less in its countenance than what it has in some other countries. It did not compose a body of hereditary legislators. It was not \"a corporation of aristocracy,\" for such I have heard M. de la Fayette describe an English House of Peers. Let us then examine the grounds upon which the French Constitution has resolved against having such a House in France. Because, in the first place, as is already mentioned, aristocracy is kept up by family tyranny and injustice. Secondly. Because there is an unnatural unfitness in an aristocracy to be legislators for a nation. Their ideas of distributive justice are corrupted at the very source. They begin life by trampling on all their younger brothers and sisters, and relations of every kind, and are taught and educated so to do. With what ideas of justice or honour can that man enter a house of legislation, who absorbs in his own person the inheritance of a whole family of children or doles out to them some pitiful portion with the insolence of a gift? Thirdly. Because the idea of hereditary legislators is as inconsistent as that of hereditary judges, or hereditary juries; and as absurd as an hereditary mathematician, or an hereditary wise man; and as ridiculous as an hereditary poet laureate. Fourthly. Because a body of men, holding themselves accountable to nobody, ought not to be trusted by anybody. Fifthly. Because it is continuing the uncivilised principle of governments founded in conquest, and the base idea of man having property in man, and governing him by personal right. Sixthly. Because aristocracy has a tendency to deteriorate the human species. By the universal economy of nature it is known, and by the instance of the Jews it is proved, that the human species has a tendency to degenerate, in any small number of persons, when separated from the general stock of society, and inter–marrying constantly with each other. It defeats even its pretended end, and becomes in time the opposite of what is noble in man. Mr. Burke talks of nobility; let him show what it is. The greatest characters the world have known have arisen on the democratic floor. Aristocracy has not been able to keep a proportionate pace with democracy. The artificial Noble shrinks into a dwarf before the Noble of Nature; and in the few instances of those (for there are some in all countries) in whom nature, as by a miracle, has survived in aristocracy, Those Men Despise It.—But it is time to proceed to a new subject. The French Constitution has reformed the condition of the clergy. It has raised the income of the lower and middle classes, and taken from the higher. None are now less than twelve hundred livres (fifty pounds sterling), nor any higher than two or three thousand pounds. What will Mr. Burke place against this? Hear what he says. He says: \"That the people of England can see without pain or grudging, an archbishop precede a duke; they can see a Bishop of Durham, or a Bishop of Winchester in possession of £10,000 a–year; and cannot see why it is in worse hands than estates to a like amount, in the hands of this earl or that squire.\" And Mr. Burke offers this as an example to France. As to the first part, whether the archbishop precedes the duke, or the duke the bishop, it is, I believe, to the people in general, somewhat like Sternhold and Hopkins, or Hopkins and Sternhold; you may put which you please first; and as I confess that I do not understand the merits of this case, I will not contest it with Mr. Burke. But with respect to the latter, I have something to say. Mr. Burke has not put the case right. The comparison is out of order, by being put between the bishop and the earl or the squire. It ought to be put between the bishop and the curate, and then it will stand thus:—\"The people of England can see without pain or grudging, a Bishop of Durham, or a Bishop of Winchester, in possession of ten thousand pounds a–year, and a curate on thirty or forty pounds a–year, or less.\" No, sir, they certainly do not see those things without great pain or grudging. It is a case that applies itself to every man’s sense of justice, and is one among many that calls aloud for a constitution. In France the cry of \"the church! the church!\" was repeated as often as in Mr. Burke’s book, and as loudly as when the Dissenters' Bill was before the English Parliament; but the generality of the French clergy were not to be deceived by this cry any longer. They knew that whatever the pretence might be, it was they who were one of the principal objects of it. It was the cry of the high beneficed clergy, to prevent any regulation of income taking place between those of ten thousand pounds a–year and the parish priest. They therefore joined their case to those of every other oppressed class of men, and by this union obtained redress. The French Constitution has abolished tythes, that source of perpetual discontent between the tythe–holder and the parishioner. When land is held on tythe, it is in the condition of an estate held between two parties; the one receiving one–tenth, and the other nine–tenths of the produce: and consequently, on principles of equity, if the estate can be improved, and made to produce by that improvement double or treble what it did before, or in any other ratio, the expense of such improvement ought to be borne in like proportion between the parties who are to share the produce. But this is not the case in tythes: the farmer bears the whole expense, and the tythe–holder takes a tenth of the improvement, in addition to the original tenth, and by this means gets the value of two–tenths instead of one. This is another case that calls for a constitution. The French Constitution hath abolished or renounced Toleration and Intolerance also, and hath established Universal Right Of Conscience. Toleration is not the opposite of Intolerance, but is the counterfeit of it. Both are despotisms. The one assumes to itself the right of withholding Liberty of Conscience, and the other of granting it. The one is the Pope armed with fire and faggot, and the other is the Pope selling or granting indulgences. The former is church and state, and the latter is church and traffic. But Toleration may be viewed in a much stronger light. Man worships not himself, but his Maker; and the liberty of conscience which he claims is not for the service of himself, but of his God. In this case, therefore, we must necessarily have the associated idea of two things; the mortal who renders the worship, and the Immortal Being who is worshipped. Toleration, therefore, places itself, not between man and man, nor between church and church, nor between one denomination of religion and another, but between God and man; between the being who worships, and the Being who is worshipped; and by the same act of assumed authority which it tolerates man to pay his worship, it presumptuously and blasphemously sets itself up to tolerate the Almighty to receive it. Were a bill brought into any Parliament, entitled, \"An Act to tolerate or grant liberty to the Almighty to receive the worship of a Jew or Turk,\" or \"to prohibit the Almighty from receiving it,\" all men would startle and call it blasphemy. There would be an uproar. The presumption of toleration in religious matters would then present itself unmasked; but the presumption is not the less because the name of \"Man\" only appears to those laws, for the associated idea of the worshipper and the worshipped cannot be separated. Who then art thou, vain dust and ashes! by whatever name thou art called, whether a King, a Bishop, a Church, or a State, a Parliament, or anything else, that obtrudest thine insignificance between the soul of man and its Maker? Mind thine own concerns. If he believes not as thou believest, it is a proof that thou believest not as he believes, and there is no earthly power can determine between you. With respect to what are called denominations of religion, if every one is left to judge of its own religion, there is no such thing as a religion that is wrong; but if they are to judge of each other’s religion, there is no such thing as a religion that is right; and therefore all the world is right, or all the world is wrong. But with respect to religion itself, without regard to names, and as directing itself from the universal family of mankind to the Divine object of all adoration, it is man bringing to his Maker the fruits of his heart; and though those fruits may differ from each other like the fruits of the earth, the grateful tribute of every one is accepted. A Bishop of Durham, or a Bishop of Winchester, or the archbishop who heads the dukes, will not refuse a tythe–sheaf of wheat because it is not a cock of hay, nor a cock of hay because it is not a sheaf of wheat; nor a pig, because it is neither one nor the other; but these same persons, under the figure of an established church, will not permit their Maker to receive the varied tythes of man’s devotion. One of the continual choruses of Mr. Burke’s book is \"Church and State.\" He does not mean some one particular church, or some one particular state, but any church and state; and he uses the term as a general figure to hold forth the political doctrine of always uniting the church with the state in every country, and he censures the National Assembly for not having done this in France. Let us bestow a few thoughts on this subject. All religions are in their nature kind and benign, and united with principles of morality. They could not have made proselytes at first by professing anything that was vicious, cruel, persecuting, or immoral. Like everything else, they had their beginning; and they proceeded by persuasion, exhortation, and example. How then is it that they lose their native mildness, and become morose and intolerant? It proceeds from the connection which Mr. Burke recommends. By engendering the church with the state, a sort of mule–animal, capable only of destroying, and not of breeding up, is produced, called the Church established by Law. It is a stranger, even from its birth, to any parent mother, on whom it is begotten, and whom in time it kicks out and destroys. The inquisition in Spain does not proceed from the religion originally professed, but from this mule–animal, engendered between the church and the state. The burnings in Smithfield proceeded from the same heterogeneous production; and it was the regeneration of this strange animal in England afterwards, that renewed rancour and irreligion among the inhabitants, and that drove the people called Quakers and Dissenters to America. Persecution is not an original feature in any religion; but it is alway the strongly–marked feature of all law–religions, or religions established by law. Take away the law–establishment, and every religion re–assumes its original benignity. In America, a catholic priest is a good citizen, a good character, and a good neighbour; an episcopalian minister is of the same description: and this proceeds independently of the men, from there being no law–establishment in America. If also we view this matter in a temporal sense, we shall see the ill effects it has had on the prosperity of nations. The union of church and state has impoverished Spain. The revoking the edict of Nantes drove the silk manufacture from that country into England; and church and state are now driving the cotton manufacture from England to America and France. Let then Mr. Burke continue to preach his antipolitical doctrine of Church and State. It will do some good. The National Assembly will not follow his advice, but will benefit by his folly. It was by observing the ill effects of it in England, that America has been warned against it; and it is by experiencing them in France, that the National Assembly have abolished it, and, like America, have established Universal Right Of Conscience, And Universal Right Of Citizenship. [7] I will here cease the comparison with respect to the principles of the French Constitution, and conclude this part of the subject with a few observations on the organisation of the formal parts of the French and English governments. The executive power in each country is in the hands of a person styled the King; but the French Constitution distinguishes between the King and the Sovereign: It considers the station of King as official, and places Sovereignty in the nation. The representatives of the nation, who compose the National Assembly, and who are the legislative power, originate in and from the people by election, as an inherent right in the people.—In England it is otherwise; and this arises from the original establishment of what is called its monarchy; for, as by the conquest all the rights of the people or the nation were absorbed into the hands of the Conqueror, and who added the title of King to that of Conqueror, those same matters which in France are now held as rights in the people, or in the nation, are held in England as grants from what is called the crown. The Parliament in England, in both its branches, was erected by patents from the descendants of the Conqueror. The House of Commons did not originate as a matter of right in the people to delegate or elect, but as a grant or boon. By the French Constitution the nation is always named before the king. The third article of the declaration of rights says: \"The nation is essentially the source (or fountain) of all sovereignty.\" Mr. Burke argues that in England a king is the fountain—that he is the fountain of all honour. But as this idea is evidently descended from the conquest I shall make no other remark upon it, than that it is the nature of conquest to turn everything upside down; and as Mr. Burke will not be refused the privilege of speaking twice, and as there are but two parts in the figure, the fountain and the spout, he will be right the second time. The French Constitution puts the legislative before the executive, the law before the king; la loi, le roi. This also is in the natural order of things, because laws must have existence before they can have execution. A king in France does not, in addressing himself to the National Assembly, say, \"My Assembly,\" similar to the phrase used in England of my \"Parliament\"; neither can he use it consistently with the constitution, nor could it be admitted. There may be propriety in the use of it in England, because as is before mentioned, both Houses of Parliament originated from what is called the crown by patent or boon—and not from the inherent rights of the people, as the National Assembly does in France, and whose name designates its origin. The President of the National Assembly does not ask the King to grant to the Assembly liberty of speech, as is the case with the English House of Commons. The constitutional dignity of the National Assembly cannot debase itself. Speech is, in the first place, one of the natural rights of man always retained; and with respect to the National Assembly the use of it is their duty, and the nation is their authority. They were elected by the greatest body of men exercising the right of election the European world ever saw. They sprung not from the filth of rotten boroughs, nor are they the vassal representatives of aristocratical ones. Feeling the proper dignity of their character they support it. Their Parliamentary language, whether for or against a question, is free, bold and manly, and extends to all the parts and circumstances of the case. If any matter or subject respecting the executive department or the person who presides in it (the king) comes before them it is debated on with the spirit of men, and in the language of gentlemen; and their answer or their address is returned in the same style. They stand not aloof with the gaping vacuity of vulgar ignorance, nor bend with the cringe of sycophantic insignificance. The graceful pride of truth knows no extremes, and preserves, in every latitude of life, the right–angled character of man. Let us now look to the other side of the question. In the addresses of the English Parliaments to their kings we see neither the intrepid spirit of the old Parliaments of France, nor the serene dignity of the present National Assembly; neither do we see in them anything of the style of English manners, which border somewhat on bluntness. Since then they are neither of foreign extraction, nor naturally of English production, their origin must be sought for elsewhere, and that origin is the Norman Conquest. They are evidently of the vassalage class of manners, and emphatically mark the prostrate distance that exists in no other condition of men than between the conqueror and the conquered. That this vassalage idea and style of speaking was not got rid of even at the Revolution of 1688, is evident from the declaration of Parliament to William and Mary in these words: \"We do most humbly and faithfully submit ourselves, our heirs and posterities, for ever.\" Submission is wholly a vassalage term, repugnant to the dignity of freedom, and an echo of the language used at the Conquest. As the estimation of all things is given by comparison, the Revolution of 1688, however from circumstances it may have been exalted beyond its value, will find its level. It is already on the wane, eclipsed by the enlarging orb of reason, and the luminous revolutions of America and France. In less than another century it will go, as well as Mr. Burke’s labours, \"to the family vault of all the Capulets.\" Mankind will then scarcely believe that a country calling itself free would send to Holland for a man, and clothe him with power on purpose to put themselves in fear of him, and give him almost a million sterling a year for leave to submit themselves and their posterity, like bondmen and bondwomen, for ever. But there is a truth that ought to be made known; I have had the opportunity of seeing it; which is, that notwithstanding appearances, there is not any description of men that despise monarchy so much as courtiers. But they well know, that if it were seen by others, as it is seen by them, the juggle could not be kept up; they are in the condition of men who get their living by a show, and to whom the folly of that show is so familiar that they ridicule it; but were the audience to be made as wise in this respect as themselves, there would be an end to the show and the profits with it. The difference between a republican and a courtier with respect to monarchy, is that the one opposes monarchy, believing it to be something; and the other laughs at it, knowing it to be nothing. As I used sometimes to correspond with Mr. Burke believing him then to be a man of sounder principles than his book shows him to be, I wrote to him last winter from Paris, and gave him an account how prosperously matters were going on. Among other subjects in that letter, I referred to the happy situation the National Assembly were placed in; that they had taken ground on which their moral duty and their political interest were united. They have not to hold out a language which they do not themselves believe, for the fraudulent purpose of making others believe it. Their station requires no artifice to support it, and can only be maintained by enlightening mankind. It is not their interest to cherish ignorance, but to dispel it. They are not in the case of a ministerial or an opposition party in England, who, though they are opposed, are still united to keep up the common mystery. The National Assembly must throw open a magazine of light. It must show man the proper character of man; and the nearer it can bring him to that standard, the stronger the National Assembly becomes. In contemplating the French Constitution, we see in it a rational order of things. The principles harmonise with the forms, and both with their origin. It may perhaps be said as an excuse for bad forms, that they are nothing more than forms; but this is a mistake. Forms grow out of principles, and operate to continue the principles they grow from. It is impossible to practise a bad form on anything but a bad principle. It cannot be ingrafted on a good one; and wherever the forms in any government are bad, it is a certain indication that the principles are bad also. I will here finally close this subject. I began it by remarking that Mr. Burke had voluntarily declined going into a comparison of the English and French Constitutions. He apologises (in page 241) for not doing it, by saying that he had not time. Mr. Burke’s book was upwards of eight months in hand, and is extended to a volume of three hundred and sixty–six pages. As his omission does injury to his cause, his apology makes it worse; and men on the English side of the water will begin to consider, whether there is not some radical defect in what is called the English constitution, that made it necessary for Mr. Burke to suppress the comparison, to avoid bringing it into view. As Mr. Burke has not written on constitutions so neither has he written on the French Revolution. He gives no account of its commencement or its progress. He only expresses his wonder. \"It looks,\" says he, \"to me, as if I were in a great crisis, not of the affairs of France alone, but of all Europe, perhaps of more than Europe. All circumstances taken together, the French Revolution is the most astonishing that has hitherto happened in the world.\" As wise men are astonished at foolish things, and other people at wise ones, I know not on which ground to account for Mr. Burke’s astonishment; but certain it is, that he does not understand the French Revolution. It has apparently burst forth like a creation from a chaos, but it is no more than the consequence of a mental revolution priorily existing in France. The mind of the nation had changed beforehand, and the new order of things has naturally followed the new order of thoughts. I will here, as concisely as I can, trace out the growth of the French Revolution, and mark the circumstances that have contributed to produce it. The despotism of Louis XIV., united with the gaiety of his Court, and the gaudy ostentation of his character, had so humbled, and at the same time so fascinated the mind of France, that the people appeared to have lost all sense of their own dignity, in contemplating that of their Grand Monarch; and the whole reign of Louis XV., remarkable only for weakness and effeminacy, made no other alteration than that of spreading a sort of lethargy over the nation, from which it showed no disposition to rise. The only signs which appeared to the spirit of Liberty during those periods, are to be found in the writings of the French philosophers. Montesquieu, President of the Parliament of Bordeaux, went as far as a writer under a despotic government could well proceed; and being obliged to divide himself between principle and prudence, his mind often appears under a veil, and we ought to give him credit for more than he has expressed. Voltaire, who was both the flatterer and the satirist of despotism, took another line. His forte lay in exposing and ridiculing the superstitions which priest–craft, united with state–craft, had interwoven with governments. It was not from the purity of his principles, or his love of mankind (for satire and philanthropy are not naturally concordant), but from his strong capacity of seeing folly in its true shape, and his irresistible propensity to expose it, that he made those attacks. They were, however, as formidable as if the motive had been virtuous; and he merits the thanks rather than the esteem of mankind. On the contrary, we find in the writings of Rousseau, and the Abbe Raynal, a loveliness of sentiment in favour of liberty, that excites respect, and elevates the human faculties; but having raised this animation, they do not direct its operation, and leave the mind in love with an object, without describing the means of possessing it. The writings of Quesnay, Turgot, and the friends of those authors, are of the serious kind; but they laboured under the same disadvantage with Montesquieu; their writings abound with moral maxims of government, but are rather directed to economise and reform the administration of the government, than the government itself. But all those writings and many others had their weight; and by the different manner in which they treated the subject of government, Montesquieu by his judgment and knowledge of laws, Voltaire by his wit, Rousseau and Raynal by their animation, and Quesnay and Turgot by their moral maxims and systems of economy, readers of every class met with something to their taste, and a spirit of political inquiry began to diffuse itself through the nation at the time the dispute between England and the then colonies of America broke out. In the war which France afterwards engaged in, it is very well known that the nation appeared to be before–hand with the French ministry. Each of them had its view; but those views were directed to different objects; the one sought liberty, and the other retaliation on England. The French officers and soldiers who after this went to America, were eventually placed in the school of Freedom, and learned the practice as well as the principles of it by heart. As it was impossible to separate the military events which took place in America from the principles of the American Revolution, the publication of those events in France necessarily connected themselves with the principles which produced them. Many of the facts were in themselves principles; such as the declaration of American Independence, and the treaty of alliance between France and America, which recognised the natural rights of man, and justified resistance to oppression. The then Minister of France, Count Vergennes, was not the friend of America; and it is both justice and gratitude to say, that it was the Queen of France who gave the cause of America a fashion at the French Court. Count Vergennes was the personal and social friend of Dr. Franklin; and the Doctor had obtained, by his sensible gracefulness, a sort of influence over him; but with respect to principles Count Vergennes was a despot. The situation of Dr. Franklin, as Minister from America to France, should be taken into the chain of circumstances. The diplomatic character is of itself the narrowest sphere of society that man can act in. It forbids intercourse by the reciprocity of suspicion; and a diplomatic is a sort of unconnected atom, continually repelling and repelled. But this was not the case with Dr. Franklin. He was not the diplomatic of a Court, but of Man. His character as a philosopher had been long established, and his circle of society in France was universal. Count Vergennes resisted for a considerable time the publication in France of American constitutions, translated into the French language: but even in this he was obliged to give way to public opinion, and a sort of propriety in admitting to appear what he had undertaken to defend. The American constitutions were to liberty what a grammar is to language: they define its parts of speech, and practically construct them into syntax. The peculiar situation of the then Marquis de la Fayette is another link in the great chain. He served in America as an American officer under a commission of Congress, and by the universality of his acquaintance was in close friendship with the civil government of America, as well as with the military line. He spoke the language of the country, entered into the discussions on the principles of government, and was always a welcome friend at any election. When the war closed, a vast reinforcement to the cause of Liberty spread itself over France, by the return of the French officers and soldiers. A knowledge of the practice was then joined to the theory; and all that was wanting to give it real existence was opportunity. Man cannot, properly speaking, make circumstances for his purpose, but he always has it in his power to improve them when they occur, and this was the case in France. M. Neckar was displaced in May, 1781; and by the ill–management of the finances afterwards, and particularly during the extravagant administration of M. Calonne, the revenue of France, which was nearly twenty–four millions sterling per year, was become unequal to the expenditure, not because the revenue had decreased, but because the expenses had increased; and this was a circumstance which the nation laid hold of to bring forward a Revolution. The English Minister, Mr. Pitt, has frequently alluded to the state of the French finances in his budgets, without understanding the subject. Had the French Parliaments been as ready to register edicts for new taxes as an English Parliament is to grant them, there had been no derangement in the finances, nor yet any Revolution; but this will better explain itself as I proceed. It will be necessary here to show how taxes were formerly raised in France. The King, or rather the Court or Ministry acting under the use of that name, framed the edicts for taxes at their own discretion, and sent them to the Parliaments to be registered; for until they were registered by the Parliaments they were not operative. Disputes had long existed between the Court and the Parliaments with respect to the extent of the Parliament’s authority on this head. The Court insisted that the authority of Parliaments went no farther than to remonstrate or show reasons against the tax, reserving to itself the right of determining whether the reasons were well or ill–founded; and in consequence thereof, either to withdraw the edict as a matter of choice, or to order it to be unregistered as a matter of authority. The Parliaments on their part insisted that they had not only a right to remonstrate, but to reject; and on this ground they were always supported by the nation. But to return to the order of my narrative. M. Calonne wanted money: and as he knew the sturdy disposition of the Parliaments with respect to new taxes, he ingeniously sought either to approach them by a more gentle means than that of direct authority, or to get over their heads by a manoeuvre; and for this purpose he revived the project of assembling a body of men from the several provinces, under the style of an \"Assembly of the Notables,\" or men of note, who met in 1787, and who were either to recommend taxes to the Parliaments, or to act as a Parliament themselves. An Assembly under this name had been called in 1617. As we are to view this as the first practical step towards the Revolution, it will be proper to enter into some particulars respecting it. The Assembly of the Notables has in some places been mistaken for the States–General, but was wholly a different body, the States–General being always by election. The persons who composed the Assembly of the Notables were all nominated by the king, and consisted of one hundred and forty members. But as M. Calonne could not depend upon a majority of this Assembly in his favour, he very ingeniously arranged them in such a manner as to make forty–four a majority of one hundred and forty; to effect this he disposed of them into seven separate committees, of twenty members each. Every general question was to be decided, not by a majority of persons, but by a majority of committee, and as eleven votes would make a majority in a committee, and four committees a majority of seven, M. Calonne had good reason to conclude that as forty–four would determine any general question he could not be outvoted. But all his plans deceived him, and in the event became his overthrow. The then Marquis de la Fayette was placed in the second committee, of which the Count D’Artois was president, and as money matters were the object, it naturally brought into view every circumstance connected with it. M. de la Fayette made a verbal charge against Calonne for selling crown lands to the amount of two millions of livres, in a manner that appeared to be unknown to the king. The Count D’Artois (as if to intimidate, for the Bastille was then in being) asked the Marquis if he would render the charge in writing? He replied that he would. The Count D’Artois did not demand it, but brought a message from the king to that purport. M. de la Fayette then delivered in his charge in writing, to be given to the king, undertaking to support it. No farther proceedings were had upon this affair, but M. Calonne was soon after dismissed by the king and set off to England. As M. de la Fayette, from the experience of what he had seen in America, was better acquainted with the science of civil government than the generality of the members who composed the Assembly of the Notables could then be, the brunt of the business fell considerably to his share. The plan of those who had a constitution in view was to contend with the Court on the ground of taxes, and some of them openly professed their object. Disputes frequently arose between Count D’Artois and M. de la Fayette upon various subjects. With respect to the arrears already incurred the latter proposed to remedy them by accommodating the expenses to the revenue instead of the revenue to the expenses; and as objects of reform he proposed to abolish the Bastille and all the State prisons throughout the nation (the keeping of which was attended with great expense), and to suppress Lettres de Cachet; but those matters were not then much attended to, and with respect to Lettres de Cachet, a majority of the Nobles appeared to be in favour of them. On the subject of supplying the Treasury by new taxes the Assembly declined taking the matter on themselves, concurring in the opinion that they had not authority. In a debate on this subject M. de la Fayette said that raising money by taxes could only be done by a National Assembly, freely elected by the people, and acting as their representatives. Do you mean, said the Count D’Artois, the States–General? M. de la Fayette replied that he did. Will you, said the Count D’Artois, sign what you say to be given to the king? The other replied that he would not only do this but that he would go farther, and say that the effectual mode would be for the king to agree to the establishment of a constitution. As one of the plans had thus failed, that of getting the Assembly to act as a Parliament, the other came into view, that of recommending. On this subject the Assembly agreed to recommend two new taxes to be unregistered by the Parliament: the one a stamp–tax and the other a territorial tax, or sort of land–tax. The two have been estimated at about five millions sterling per annum. We have now to turn our attention to the Parliaments, on whom the business was again devolving. The Archbishop of Thoulouse (since Archbishop of Sens, and now a Cardinal), was appointed to the administration of the finances soon after the dismission of Calonne. He was also made Prime Minister, an office that did not always exist in France. When this office did not exist, the chief of each of the principal departments transacted business immediately with the King, but when a Prime Minister was appointed they did business only with him. The Archbishop arrived to more state authority than any minister since the Duke de Choiseul, and the nation was strongly disposed in his favour; but by a line of conduct scarcely to be accounted for he perverted every opportunity, turned out a despot, and sunk into disgrace, and a Cardinal. The Assembly of the Notables having broken up, the minister sent the edicts for the two new taxes recommended by the Assembly to the Parliaments to be unregistered. They of course came first before the Parliament of Paris, who returned for answer: \"that with such a revenue as the nation then supported the name of taxes ought not to be mentioned but for the purpose of reducing them\"; and threw both the edicts out. [8] On this refusal the Parliament was ordered to Versailles, where, in the usual form, the King held what under the old government was called a Bed of justice; and the two edicts were unregistered in presence of the Parliament by an order of State, in the manner mentioned, earlier. On this the Parliament immediately returned to Paris, renewed their session in form, and ordered the enregistering to be struck out, declaring that everything done at Versailles was illegal. All the members of the Parliament were then served with Lettres de Cachet, and exiled to Troyes; but as they continued as inflexible in exile as before, and as vengeance did not supply the place of taxes, they were after a short time recalled to Paris. The edicts were again tendered to them, and the Count D’Artois undertook to act as representative of the King. For this purpose he came from Versailles to Paris, in a train of procession; and the Parliament were assembled to receive him. But show and parade had lost their influence in France; and whatever ideas of importance he might set off with, he had to return with those of mortification and disappointment. On alighting from his carriage to ascend the steps of the Parliament House, the crowd (which was numerously collected) threw out trite expressions, saying: \"This is Monsieur D’Artois, who wants more of our money to spend.\" The marked disapprobation which he saw impressed him with apprehensions, and the word Aux armes! (To arms!) was given out by the officer of the guard who attended him. It was so loudly vociferated, that it echoed through the avenues of the house, and produced a temporary confusion. I was then standing in one of the apartments through which he had to pass, and could not avoid reflecting how wretched was the condition of a disrespected man. He endeavoured to impress the Parliament by great words, and opened his authority by saying, \"The King, our Lord and Master.\" The Parliament received him very coolly, and with their usual determination not to register the taxes: and in this manner the interview ended. After this a new subject took place: In the various debates and contests which arose between the Court and the Parliaments on the subject of taxes, the Parliament of Paris at last declared that although it had been customary for Parliaments to enregister edicts for taxes as a matter of convenience, the right belonged only to the States–General; and that, therefore, the Parliament could no longer with propriety continue to debate on what it had not authority to act. The King after this came to Paris and held a meeting with the Parliament, in which he continued from ten in the morning till about six in the evening, and, in a manner that appeared to proceed from him as if unconsulted upon with the Cabinet or Ministry, gave his word to the Parliament that the States–General should be convened. But after this another scene arose, on a ground different from all the former. The Minister and the Cabinet were averse to calling the States–General. They well knew that if the States–General were assembled, themselves must fall; and as the King had not mentioned any time, they hit on a project calculated to elude, without appearing to oppose. For this purpose, the Court set about making a sort of constitution itself. It was principally the work of M. Lamoignon, the Keeper of the Seals, who afterwards shot himself. This new arrangement consisted in establishing a body under the name of a Cour Pleniere, or Full Court, in which were invested all the powers that the Government might have occasion to make use of. The persons composing this Court were to be nominated by the King; the contended right of taxation was given up on the part of the King, and a new criminal code of laws and law proceedings was substituted in the room of the former. The thing, in many points, contained better principles than those upon which the Government had hitherto been administered; but with respect to the Cour Pleniere, it was no other than a medium through which despotism was to pass, without appearing to act directly from itself. The Cabinet had high expectations from their new contrivance. The people who were to compose the Cour Pleniere were already nominated; and as it was necessary to carry a fair appearance, many of the best characters in the nation were appointed among the number. It was to commence on May 8, 1788; but an opposition arose to it on two grounds the one as to principle, the other as to form. On the ground of Principle it was contended that Government had not a right to alter itself, and that if the practice was once admitted it would grow into a principle and be made a precedent for any future alterations the Government might wish to establish: that the right of altering the Government was a national right, and not a right of Government. And on the ground of form it was contended that the Cour Pleniere was nothing more than a larger Cabinet. The then Duke de la Rochefoucault, Luxembourg, De Noailles, and many others, refused to accept the nomination, and strenuously opposed the whole plan. When the edict for establishing this new court was sent to the Parliaments to be unregistered and put into execution, they resisted also. The Parliament of Paris not only refused, but denied the authority; and the contest renewed itself between the Parliament and the Cabinet more strongly than ever. While the Parliament were sitting in debate on this subject, the Ministry ordered a regiment of soldiers to surround the House and form a blockade. The members sent out for beds and provisions, and lived as in a besieged citadel: and as this had no effect, the commanding officer was ordered to enter the Parliament House and seize them, which he did, and some of the principal members were shut up in different prisons. About the same time a deputation of persons arrived from the province of Brittany to remonstrate against the establishment of the Cour Pleniere, and those the archbishop sent to the Bastille. But the spirit of the nation was not to be overcome, and it was so fully sensible of the strong ground it had taken—that of withholding taxes—that it contented itself with keeping up a sort of quiet resistance, which effectually overthrew all the plans at that time formed against it. The project of the Cour Pleniere was at last obliged to be given up, and the Prime Minister not long afterwards followed its fate, and M. Neckar was recalled into office. The attempt to establish the Cour Pleniere had an effect upon the nation which itself did not perceive. It was a sort of new form of government that insensibly served to put the old one out of sight and to unhinge it from the superstitious authority of antiquity. It was Government dethroning Government; and the old one, by attempting to make a new one, made a chasm. The failure of this scheme renewed the subject of convening the State–General; and this gave rise to a new series of politics. There was no settled form for convening the States–General: all that it positively meant was a deputation from what was then called the Clergy, the Noblesse, and the Commons; but their numbers or their proportions had not been always the same. They had been convened only on extraordinary occasions, the last of which was in 1614; their numbers were then in equal proportions, and they voted by orders. It could not well escape the sagacity of M. Neckar, that the mode of 1614 would answer neither the purpose of the then government nor of the nation. As matters were at that time circumstanced it would have been too contentious to agree upon anything. The debates would have been endless upon privileges and exemptions, in which neither the wants of the Government nor the wishes of the nation for a Constitution would have been attended to. But as he did not choose to take the decision upon himself, he summoned again the Assembly of the Notables and referred it to them. This body was in general interested in the decision, being chiefly of aristocracy and high–paid clergy, and they decided in favor of the mode of 1614. This decision was against the sense of the Nation, and also against the wishes of the Court; for the aristocracy opposed itself to both and contended for privileges independent of either. The subject was then taken up by the Parliament, who recommended that the number of the Commons should be equal to the other two: and they should all sit in one house and vote in one body. The number finally determined on was 1,200; 600 to be chosen by the Commons (and this was less than their proportion ought to have been when their worth and consequence is considered on a national scale), 300 by the Clergy, and 300 by the Aristocracy; but with respect to the mode of assembling themselves, whether together or apart, or the manner in which they should vote, those matters were referred. [9] The election that followed was not a contested election, but an animated one. The candidates were not men, but principles. Societies were formed in Paris, and committees of correspondence and communication established throughout the nation, for the purpose of enlightening the people, and explaining to them the principles of civil government; and so orderly was the election conducted, that it did not give rise even to the rumour of tumult. The States–General were to meet at Versailles in April 1789, but did not assemble till May. They situated themselves in three separate chambers, or rather the Clergy and Aristocracy withdrew each into a separate chamber. The majority of the Aristocracy claimed what they called the privilege of voting as a separate body, and of giving their consent or their negative in that manner; and many of the bishops and the high–beneficed clergy claimed the same privilege on the part of their Order. The Tiers Etat (as they were then called) disowned any knowledge of artificial orders and artificial privileges; and they were not only resolute on this point, but somewhat disdainful. They began to consider the Aristocracy as a kind of fungus growing out of the corruption of society, that could not be admitted even as a branch of it; and from the disposition the Aristocracy had shown by upholding Lettres de Cachet, and in sundry other instances, it was manifest that no constitution could be formed by admitting men in any other character than as National Men. After various altercations on this head, the Tiers Etat or Commons (as they were then called) declared themselves (on a motion made for that purpose by the Abbe Sieyes) \"The Representative Of The Nation; and that the two Orders could be considered but as deputies of corporations, and could only have a deliberate voice when they assembled in a national character with the national representatives.\" This proceeding extinguished the style of Etats Generaux, or States–General, and erected it into the style it now bears, that of L’Assemblee Nationale, or National Assembly. This motion was not made in a precipitate manner. It was the result of cool deliberation, and concerned between the national representatives and the patriotic members of the two chambers, who saw into the folly, mischief, and injustice of artificial privileged distinctions. It was become evident, that no constitution, worthy of being called by that name, could be established on anything less than a national ground. The Aristocracy had hitherto opposed the despotism of the Court, and affected the language of patriotism; but it opposed it as its rival (as the English Barons opposed King John) and it now opposed the nation from the same motives. On carrying this motion, the national representatives, as had been concerted, sent an invitation to the two chambers, to unite with them in a national character, and proceed to business. A majority of the clergy, chiefly of the parish priests, withdrew from the clerical chamber, and joined the nation; and forty–five from the other chamber joined in like manner. There is a sort of secret history belonging to this last circumstance, which is necessary to its explanation; it was not judged prudent that all the patriotic members of the chamber styling itself the Nobles, should quit it at once; and in consequence of this arrangement, they drew off by degrees, always leaving some, as well to reason the case, as to watch the suspected. In a little time the numbers increased from forty–five to eighty, and soon after to a greater number; which, with the majority of the clergy, and the whole of the national representatives, put the malcontents in a very diminutive condition. The King, who, very different from the general class called by that name, is a man of a good heart, showed himself disposed to recommend a union of the three chambers, on the ground the National Assembly had taken; but the malcontents exerted themselves to prevent it, and began now to have another project in view. Their numbers consisted of a majority of the aristocratical chamber, and the minority of the clerical chamber, chiefly of bishops and high–beneficed clergy; and these men were determined to put everything to issue, as well by strength as by stratagem. They had no objection to a constitution; but it must be such a one as themselves should dictate, and suited to their own views and particular situations. On the other hand, the Nation disowned knowing anything of them but as citizens, and was determined to shut out all such up–start pretensions. The more aristocracy appeared, the more it was despised; there was a visible imbecility and want of intellects in the majority, a sort of je ne sais quoi, that while it affected to be more than citizen, was less than man. It lost ground from contempt more than from hatred; and was rather jeered at as an ass, than dreaded as a lion. This is the general character of aristocracy, or what are called Nobles or Nobility, or rather No–ability, in all countries. The plan of the malcontents consisted now of two things; either to deliberate and vote by chambers (or orders), more especially on all questions respecting a Constitution (by which the aristocratical chamber would have had a negative on any article of the Constitution); or, in case they could not accomplish this object, to overthrow the National Assembly entirely. To effect one or other of these objects they began to cultivate a friendship with the despotism they had hitherto attempted to rival, and the Count D’Artois became their chief. The king (who has since declared himself deceived into their measures) held, according to the old form, a Bed of Justice, in which he accorded to the deliberation and vote par tete (by head) upon several subjects; but reserved the deliberation and vote upon all questions respecting a constitution to the three chambers separately. This declaration of the king was made against the advice of M. Neckar, who now began to perceive that he was growing out of fashion at Court, and that another minister was in contemplation. As the form of sitting in separate chambers was yet apparently kept up, though essentially destroyed, the national representatives immediately after this declaration of the King resorted to their own chambers to consult on a protest against it; and the minority of the chamber (calling itself the Nobles), who had joined the national cause, retired to a private house to consult in like manner. The malcontents had by this time concerted their measures with the court, which the Count D’Artois undertook to conduct; and as they saw from the discontent which the declaration excited, and the opposition making against it, that they could not obtain a control over the intended constitution by a separate vote, they prepared themselves for their final object—that of conspiring against the National Assembly, and overthrowing it. The next morning the door of the chamber of the National Assembly was shut against them, and guarded by troops; and the members were refused admittance. On this they withdrew to a tennis–ground in the neighbourhood of Versailles, as the most convenient place they could find, and, after renewing their session, took an oath never to separate from each other, under any circumstance whatever, death excepted, until they had established a constitution. As the experiment of shutting up the house had no other effect than that of producing a closer connection in the members, it was opened again the next day, and the public business recommenced in the usual place. We are now to have in view the forming of the new ministry, which was to accomplish the overthrow of the National Assembly. But as force would be necessary, orders were issued to assemble thirty thousand troops, the command of which was given to Broglio, one of the intended new ministry, who was recalled from the country for this purpose. But as some management was necessary to keep this plan concealed till the moment it should be ready for execution, it is to this policy that a declaration made by Count D’Artois must be attributed, and which is here proper to be introduced. It could not but occur while the malcontents continued to resort to their chambers separate from the National Assembly, more jealousy would be excited than if they were mixed with it, and that the plot might be suspected. But as they had taken their ground, and now wanted a pretence for quitting it, it was necessary that one should be devised. This was effectually accomplished by a declaration made by the Count D’Artois: \"That if they took not a Part in the National Assembly, the life of the king would be endangered\": on which they quitted their chambers, and mixed with the Assembly, in one body. At the time this declaration was made, it was generally treated as a piece of absurdity in Count D’Artois calculated merely to relieve the outstanding members of the two chambers from the diminutive situation they were put in; and if nothing more had followed, this conclusion would have been good. But as things best explain themselves by their events, this apparent union was only a cover to the machinations which were secretly going on; and the declaration accommodated itself to answer that purpose. In a little time the National Assembly found itself surrounded by troops, and thousands more were daily arriving. On this a very strong declaration was made by the National Assembly to the King, remonstrating on the impropriety of the measure, and demanding the reason. The King, who was not in the secret of this business, as himself afterwards declared, gave substantially for answer, that he had no other object in view than to preserve the public tranquility, which appeared to be much disturbed. But in a few days from this time the plot unravelled itself M. Neckar and the ministry were displaced, and a new one formed of the enemies of the Revolution; and Broglio, with between twenty–five and thirty thousand foreign troops, was arrived to support them. The mask was now thrown off, and matters were come to a crisis. The event was that in a space of three days the new ministry and their abettors found it prudent to fly the nation; the Bastille was taken, and Broglio and his foreign troops dispersed, as is already related in the former part of this work. There are some curious circumstances in the history of this short–lived ministry, and this short–lived attempt at a counter–revolution. The Palace of Versailles, where the Court was sitting, was not more than four hundred yards distant from the hall where the National Assembly was sitting. The two places were at this moment like the separate headquarters of two combatant armies; yet the Court was as perfectly ignorant of the information which had arrived from Paris to the National Assembly, as if it had resided at an hundred miles distance. The then Marquis de la Fayette, who (as has been already mentioned) was chosen to preside in the National Assembly on this particular occasion, named by order of the Assembly three successive deputations to the king, on the day and up to the evening on which the Bastille was taken, to inform and confer with him on the state of affairs; but the ministry, who knew not so much as that it was attacked, precluded all communication, and were solacing themselves how dextrously they had succeeded; but in a few hours the accounts arrived so thick and fast that they had to start from their desks and run. Some set off in one disguise, and some in another, and none in their own character. Their anxiety now was to outride the news, lest they should be stopt, which, though it flew fast, flew not so fast as themselves. It is worth remarking that the National Assembly neither pursued those fugitive conspirators, nor took any notice of them, nor sought to retaliate in any shape whatever. Occupied with establishing a constitution founded on the Rights of Man and the Authority of the People, the only authority on which Government has a right to exist in any country, the National Assembly felt none of those mean passions which mark the character of impertinent governments, founding themselves on their own authority, or on the absurdity of hereditary succession. It is the faculty of the human mind to become what it contemplates, and to act in unison with its object. The conspiracy being thus dispersed, one of the first works of the National Assembly, instead of vindictive proclamations, as has been the case with other governments, was to publish a declaration of the Rights of Man, as the basis on which the new constitution was to be built, and which is here subjoined: Declaration Of The Rights Of Man And Of Citizens By The National Assembly Of France The representatives of the people of France, formed into a National Assembly, considering that ignorance, neglect, or contempt of human rights, are the sole causes of public misfortunes and corruptions of Government, have resolved to set forth in a solemn declaration, these natural, imprescriptible, and inalienable rights: that this declaration being constantly present to the minds of the members of the body social, they may be forever kept attentive to their rights and their duties; that the acts of the legislative and executive powers of Government, being capable of being every moment compared with the end of political institutions, may be more respected; and also, that the future claims of the citizens, being directed by simple and incontestable principles, may always tend to the maintenance of the Constitution, and the general happiness. For these reasons the National Assembly doth recognize and declare, in the presence of the Supreme Being, and with the hope of his blessing and favour, the following sacred rights of men and of citizens: One: Men are born, and always continue, free and equal in respect of their Rights. Civil distinctions, therefore, can be founded only on Public Utility. Two: The end of all Political associations is the Preservation of the Natural and Imprescriptible Rights of Man; and these rights are Liberty, Property, Security, and Resistance of Oppression. Three: The Nation is essentially the source of all Sovereignty; nor can any individual, or any body of Men, be entitled to any authority which is not expressly derived from it. Four: Political Liberty consists in the power of doing whatever does not Injure another. The exercise of the Natural Rights of every Man, has no other limits than those which are necessary to secure to every other Man the Free exercise of the same Rights; and these limits are determinable only by the Law. Five: The Law ought to Prohibit only actions hurtful to Society. What is not Prohibited by the Law should not be hindered; nor should anyone be compelled to that which the Law does not Require. Six: the Law is an expression of the Will of the Community. All Citizens have a right to concur, either personally or by their Representatives, in its formation. It Should be the same to all, whether it protects or punishes; and all being equal in its sight, are equally eligible to all Honours, Places, and employments, according to their different abilities, without any other distinction than that created by their Virtues and talents. Seven: No Man should be accused, arrested, or held in confinement, except in cases determined by the Law, and according to the forms which it has prescribed. All who promote, solicit, execute, or cause to be executed, arbitrary orders, ought to be punished, and every Citizen called upon, or apprehended by virtue of the Law, ought immediately to obey, and renders himself culpable by resistance. Eight: The Law ought to impose no other penalties but such as are absolutely and evidently necessary; and no one ought to be punished, but in virtue of a Law promulgated before the offence, and Legally applied. Nine: Every Man being presumed innocent till he has been convicted, whenever his detention becomes indispensable, all rigour to him, more than is necessary to secure his person, ought to be provided against by the Law. Ten: No Man ought to be molested on account of his opinions, not even on account of his Religious opinions, provided his avowal of them does not disturb the Public Order established by the Law. Eleven: The unrestrained communication of thoughts and opinions being one of the Most Precious Rights of Man, every Citizen may speak, write, and publish freely, provided he is responsible for the abuse of this Liberty, in cases determined by the Law. Twelve: A Public force being necessary to give security to the Rights of Men and of Citizens, that force is instituted for the benefit of the Community and not for the particular benefit of the persons to whom it is intrusted. Thirteen: A common contribution being necessary for the support of the Public force, and for defraying the other expenses of Government, it ought to be divided equally among the Members of the Community, according to their abilities. Fourteen: every Citizen has a Right, either by himself or his Representative, to a free voice in determining the necessity of Public Contributions, the appropriation of them, and their amount, mode of assessment, and duration. Fifteen: every Community has a Right to demand of all its agents an account of their conduct. Sixteen: every Community in which a Separation of Powers and a Security of Rights is not Provided for, wants a Constitution. Seventeen: The Right to Property being inviolable and sacred, no one ought to be deprived of it, except in cases of evident Public necessity, legally ascertained, and on condition of a previous just Indemnity.",
        "char_count": 161429
      },
      {
        "heading": "Chapter 10",
        "text": "OBSERVATIONS ON THE DECLARATION OF RIGHTS The first three articles comprehend in general terms the whole of a Declaration of Rights, all the succeeding articles either originate from them or follow as elucidations. The 4th, 5th, and 6th define more particularly what is only generally expressed in the 1st, 2nd, and 3rd. The 7th, 8th, 9th, 10th, and 11th articles are declaratory of principles upon which laws shall be constructed, conformable to rights already declared. But it is questioned by some very good people in France, as well as in other countries, whether the 10th article sufficiently guarantees the right it is intended to accord with; besides which it takes off from the divine dignity of religion, and weakens its operative force upon the mind, to make it a subject of human laws. It then presents itself to man like light intercepted by a cloudy medium, in which the source of it is obscured from his sight, and he sees nothing to reverence in the dusky ray. [10] The remaining articles, beginning with the twelfth, are substantially contained in the principles of the preceding articles; but in the particular situation in which France then was, having to undo what was wrong, as well as to set up what was right, it was proper to be more particular than what in another condition of things would be necessary. While the Declaration of Rights was before the National Assembly some of its members remarked that if a declaration of rights were published it should be accompanied by a Declaration of Duties. The observation discovered a mind that reflected, and it only erred by not reflecting far enough. A Declaration of Rights is, by reciprocity, a Declaration of Duties also. Whatever is my right as a man is also the right of another; and it becomes my duty to guarantee as well as to possess. The three first articles are the base of Liberty, as well individual as national; nor can any country be called free whose government does not take its beginning from the principles they contain, and continue to preserve them pure; and the whole of the Declaration of Rights is of more value to the world, and will do more good, than all the laws and statutes that have yet been promulgated. In the declaratory exordium which prefaces the Declaration of Rights we see the solemn and majestic spectacle of a nation opening its commission, under the auspices of its Creator, to establish a Government, a scene so new, and so transcendantly unequalled by anything in the European world, that the name of a Revolution is diminutive of its character, and it rises into a Regeneration of man. What are the present Governments of Europe but a scene of iniquity and oppression? What is that of England? Do not its own inhabitants say it is a market where every man has his price, and where corruption is common traffic at the expense of a deluded people? No wonder, then, that the French Revolution is traduced. Had it confined itself merely to the destruction of flagrant despotism perhaps Mr. Burke and some others had been silent. Their cry now is, \"It has gone too far\"—that is, it has gone too far for them. It stares corruption in the face, and the venal tribe are all alarmed. Their fear discovers itself in their outrage, and they are but publishing the groans of a wounded vice. But from such opposition the French Revolution, instead of suffering, receives an homage. The more it is struck the more sparks it will emit; and the fear is it will not be struck enough. It has nothing to dread from attacks; truth has given it an establishment, and time will record it with a name as lasting as his own. Having now traced the progress of the French Revolution through most of its principal stages, from its commencement to the taking of the Bastille, and its establishment by the Declaration of Rights, I will close the subject with the energetic apostrophe of M. de la Fayette, \"May this great monument, raised to Liberty, serve as a lesson to the oppressor, and an example to the oppressed!\" [11]",
        "char_count": 4010
      },
      {
        "heading": "Chapter 11",
        "text": "MISCELLANEOUS CHAPTER To prevent interrupting the argument in the preceding part of this work, or the narrative that follows it, I reserved some observations to be thrown together in a Miscellaneous Chapter; by which variety might not be censured for confusion. Mr. Burke’s book is all Miscellany. His intention was to make an attack on the French Revolution; but instead of proceeding with an orderly arrangement, he has stormed it with a mob of ideas tumbling over and destroying one another. But this confusion and contradiction in Mr. Burke’s Book is easily accounted for.—When a man in a wrong cause attempts to steer his course by anything else than some polar truth or principle, he is sure to be lost. It is beyond the compass of his capacity to keep all the parts of an argument together, and make them unite in one issue, by any other means than having this guide always in view. Neither memory nor invention will supply the want of it. The former fails him, and the latter betrays him. Notwithstanding the nonsense, for it deserves no better name, that Mr. Burke has asserted about hereditary rights, and hereditary succession, and that a Nation has not a right to form a Government of itself; it happened to fall in his way to give some account of what Government is. \"Government,\" says he, \"is a contrivance of human wisdom.\" Admitting that government is a contrivance of human wisdom, it must necessarily follow, that hereditary succession, and hereditary rights (as they are called), can make no part of it, because it is impossible to make wisdom hereditary; and on the other hand, that cannot be a wise contrivance, which in its operation may commit the government of a nation to the wisdom of an idiot. The ground which Mr. Burke now takes is fatal to every part of his cause. The argument changes from hereditary rights to hereditary wisdom; and the question is, Who is the wisest man? He must now show that every one in the line of hereditary succession was a Solomon, or his title is not good to be a king. What a stroke has Mr. Burke now made! To use a sailor’s phrase, he has swabbed the deck, and scarcely left a name legible in the list of Kings; and he has mowed down and thinned the House of Peers, with a scythe as formidable as Death and Time. But Mr. Burke appears to have been aware of this retort; and he has taken care to guard against it, by making government to be not only a contrivance of human wisdom, but a monopoly of wisdom. He puts the nation as fools on one side, and places his government of wisdom, all wise men of Gotham, on the other side; and he then proclaims, and says that \"Men have a Right that their Wants should be provided for by this wisdom.\" Having thus made proclamation, he next proceeds to explain to them what their wants are, and also what their rights are. In this he has succeeded dextrously, for he makes their wants to be a want of wisdom; but as this is cold comfort, he then informs them, that they have a right (not to any of the wisdom) but to be governed by it; and in order to impress them with a solemn reverence for this monopoly–government of wisdom, and of its vast capacity for all purposes, possible or impossible, right or wrong, he proceeds with astrological mysterious importance, to tell to them its powers in these words: \"The rights of men in government are their advantages; and these are often in balance between differences of good; and in compromises sometimes between good and evil, and sometimes between evil and evil. Political reason is a computing principle; adding—subtracting—multiplying—and dividing, morally and not metaphysically or mathematically, true moral denominations.\" As the wondering audience, whom Mr. Burke supposes himself talking to, may not understand all this learned jargon, I will undertake to be its interpreter. The meaning, then, good people, of all this, is: That government is governed by no principle whatever; that it can make evil good, or good evil, just as it pleases. In short, that government is arbitrary power. But there are some things which Mr. Burke has forgotten. First, he has not shown where the wisdom originally came from: and secondly, he has not shown by what authority it first began to act. In the manner he introduces the matter, it is either government stealing wisdom, or wisdom stealing government. It is without an origin, and its powers without authority. In short, it is usurpation. Whether it be from a sense of shame, or from a consciousness of some radical defect in a government necessary to be kept out of sight, or from both, or from any other cause, I undertake not to determine, but so it is, that a monarchical reasoner never traces government to its source, or from its source. It is one of the shibboleths by which he may be known. A thousand years hence, those who shall live in America or France, will look back with contemplative pride on the origin of their government, and say, This was the work of our glorious ancestors! But what can a monarchical talker say? What has he to exult in? Alas he has nothing. A certain something forbids him to look back to a beginning, lest some robber, or some Robin Hood, should rise from the long obscurity of time and say, I am the origin. Hard as Mr. Burke laboured at the Regency Bill and Hereditary Succession two years ago, and much as he dived for precedents, he still had not boldness enough to bring up William of Normandy, and say, There is the head of the list! there is the fountain of honour! the son of a prostitute, and the plunderer of the English nation. The opinions of men with respect to government are changing fast in all countries. The Revolutions of America and France have thrown a beam of light over the world, which reaches into man. The enormous expense of governments has provoked people to think, by making them feel; and when once the veil begins to rend, it admits not of repair. Ignorance is of a peculiar nature: once dispelled, it is impossible to re–establish it. It is not originally a thing of itself, but is only the absence of knowledge; and though man may be kept ignorant, he cannot be made ignorant. The mind, in discovering truth, acts in the same manner as it acts through the eye in discovering objects; when once any object has been seen, it is impossible to put the mind back to the same condition it was in before it saw it. Those who talk of a counter–revolution in France, show how little they understand of man. There does not exist in the compass of language an arrangement of words to express so much as the means of effecting a counter–revolution. The means must be an obliteration of knowledge; and it has never yet been discovered how to make man unknow his knowledge, or unthink his thoughts. Mr. Burke is labouring in vain to stop the progress of knowledge; and it comes with the worse grace from him, as there is a certain transaction known in the city which renders him suspected of being a pensioner in a fictitious name. This may account for some strange doctrine he has advanced in his book, which though he points it at the Revolution Society, is effectually directed against the whole nation. \"The King of England,\" says he, \"holds his crown (for it does not belong to the Nation, according to Mr. Burke) in contempt of the choice of the Revolution Society, who have not a single vote for a king among them either individually or collectively; and his Majesty’s heirs each in their time and order, will come to the Crown with the same contempt of their choice, with which his Majesty has succeeded to that which he now wears.\" As to who is King in England, or elsewhere, or whether there is any King at all, or whether the people choose a Cherokee chief, or a Hessian hussar for a King, it is not a matter that I trouble myself about—be that to themselves; but with respect to the doctrine, so far as it relates to the Rights of Men and Nations, it is as abominable as anything ever uttered in the most enslaved country under heaven. Whether it sounds worse to my ear, by not being accustomed to hear such despotism, than what it does to another person, I am not so well a judge of; but of its abominable principle I am at no loss to judge. It is not the Revolution Society that Mr. Burke means; it is the Nation, as well in its original as in its representative character; and he has taken care to make himself understood, by saying that they have not a vote either collectively or individually. The Revolution Society is composed of citizens of all denominations, and of members of both the Houses of Parliament; and consequently, if there is not a right to a vote in any of the characters, there can be no right to any either in the nation or in its Parliament. This ought to be a caution to every country how to import foreign families to be kings. It is somewhat curious to observe, that although the people of England had been in the habit of talking about kings, it is always a Foreign House of Kings; hating Foreigners yet governed by them.—It is now the House of Brunswick, one of the petty tribes of Germany. It has hitherto been the practice of the English Parliaments to regulate what was called the succession (taking it for granted that the Nation then continued to accord to the form of annexing a monarchical branch of its government; for without this the Parliament could not have had authority to have sent either to Holland or to Hanover, or to impose a king upon the nation against its will). And this must be the utmost limit to which Parliament can go upon this case; but the right of the Nation goes to the whole case, because it has the right of changing its whole form of government. The right of a Parliament is only a right in trust, a right by delegation, and that but from a very small part of the Nation; and one of its Houses has not even this. But the right of the Nation is an original right, as universal as taxation. The nation is the paymaster of everything, and everything must conform to its general will. I remember taking notice of a speech in what is called the English House of Peers, by the then Earl of Shelburne, and I think it was at the time he was Minister, which is applicable to this case. I do not directly charge my memory with every particular; but the words and the purport, as nearly as I remember, were these: \"That the form of a Government was a matter wholly at the will of the Nation at all times, that if it chose a monarchical form, it had a right to have it so; and if it afterwards chose to be a Republic, it had a right to be a Republic, and to say to a King, 'We have no longer any occasion for you.'\" When Mr. Burke says that \"His Majesty’s heirs and successors, each in their time and order, will come to the crown with the same content of their choice with which His Majesty had succeeded to that he wears,\" it is saying too much even to the humblest individual in the country; part of whose daily labour goes towards making up the million sterling a–year, which the country gives the person it styles a king. Government with insolence is despotism; but when contempt is added it becomes worse; and to pay for contempt is the excess of slavery. This species of government comes from Germany; and reminds me of what one of the Brunswick soldiers told me, who was taken prisoner by, the Americans in the late war: \"Ah!\" said he, \"America is a fine free country, it is worth the people’s fighting for; I know the difference by knowing my own: in my country, if the prince says eat straw, we eat straw.\" God help that country, thought I, be it England or elsewhere, whose liberties are to be protected by German principles of government, and Princes of Brunswick! As Mr. Burke sometimes speaks of England, sometimes of France, and sometimes of the world, and of government in general, it is difficult to answer his book without apparently meeting him on the same ground. Although principles of Government are general subjects, it is next to impossible, in many cases, to separate them from the idea of place and circumstance, and the more so when circumstances are put for arguments, which is frequently the case with Mr. Burke. In the former part of his book, addressing himself to the people of France, he says: \"No experience has taught us (meaning the English), that in any other course or method than that of a hereditary crown, can our liberties be regularly perpetuated and preserved sacred as our hereditary right.\" I ask Mr. Burke, who is to take them away? M. de la Fayette, in speaking to France, says: \"For a Nation to be free, it is sufficient that she wills it.\" But Mr. Burke represents England as wanting capacity to take care of itself, and that its liberties must be taken care of by a King holding it in \"contempt.\" If England is sunk to this, it is preparing itself to eat straw, as in Hanover, or in Brunswick. But besides the folly of the declaration, it happens that the facts are all against Mr. Burke. It was by the government being hereditary, that the liberties of the people were endangered. Charles I. and James II. are instances of this truth; yet neither of them went so far as to hold the Nation in contempt. As it is sometimes of advantage to the people of one country to hear what those of other countries have to say respecting it, it is possible that the people of France may learn something from Mr. Burke’s book, and that the people of England may also learn something from the answers it will occasion. When Nations fall out about freedom, a wide field of debate is opened. The argument commences with the rights of war, without its evils, and as knowledge is the object contended for, the party that sustains the defeat obtains the prize. Mr. Burke talks about what he calls an hereditary crown, as if it were some production of Nature; or as if, like Time, it had a power to operate, not only independently, but in spite of man; or as if it were a thing or a subject universally consented to. Alas! it has none of those properties, but is the reverse of them all. It is a thing in imagination, the propriety of which is more than doubted, and the legality of which in a few years will be denied. But, to arrange this matter in a clearer view than what general expression can heads under which (what is called) an hereditary crown, or more properly speaking, an hereditary succession to the Government of a Nation, can be considered; which are: First, The right of a particular Family to establish itself. Secondly, The right of a Nation to establish a particular Family. With respect to the first of these heads, that of a Family establishing itself with hereditary powers on its own authority, and independent of the consent of a Nation, all men will concur in calling it despotism; and it would be trespassing on their understanding to attempt to prove it. But the second head, that of a Nation establishing a particular Family with hereditary powers, does not present itself as despotism on the first reflection; but if men will permit it a second reflection to take place, and carry that reflection forward but one remove out of their own persons to that of their offspring, they will then see that hereditary succession becomes in its consequences the same despotism to others, which they reprobated for themselves. It operates to preclude the consent of the succeeding generations; and the preclusion of consent is despotism. When the person who at any time shall be in possession of a Government, or those who stand in succession to him, shall say to a Nation, I hold this power in \"contempt\" of you, it signifies not on what authority he pretends to say it. It is no relief, but an aggravation to a person in slavery, to reflect that he was sold by his parent; and as that which heightens the criminality of an act cannot be produced to prove the legality of it, hereditary succession cannot be established as a legal thing. In order to arrive at a more perfect decision on this head, it will be proper to consider the generation which undertakes to establish a Family with hereditary powers, apart and separate from the generations which are to follow; and also to consider the character in which the first generation acts with respect to succeeding generations. The generation which first selects a person, and puts him at the head of its Government, either with the title of King, or any other distinction, acts on its own choice, be it wise or foolish, as a free agent for itself The person so set up is not hereditary, but selected and appointed; and the generation who sets him up, does not live under a hereditary government, but under a government of its own choice and establishment. Were the generation who sets him up, and the person so set up, to live for ever, it never could become hereditary succession; and of consequence hereditary succession can only follow on the death of the first parties. As, therefore, hereditary succession is out of the question with respect to the first generation, we have now to consider the character in which that generation acts with respect to the commencing generation, and to all succeeding ones. It assumes a character, to which it has neither right nor title. It changes itself from a Legislator to a Testator, and effects to make its Will, which is to have operation after the demise of the makers, to bequeath the Government; and it not only attempts to bequeath, but to establish on the succeeding generation, a new and different form of Government under which itself lived. Itself, as already observed, lived not under a hereditary Government but under a Government of its own choice and establishment; and it now attempts, by virtue of a will and testament (and which it has not authority to make), to take from the commencing generation, and all future ones, the rights and free agency by which itself acted. But, exclusive of the right which any generation has to act collectively as a testator, the objects to which it applies itself in this case, are not within the compass of any law, or of any will or testament. The rights of men in society, are neither devisable or transferable, nor annihilable, but are descendable only, and it is not in the power of any generation to intercept finally, and cut off the descent. If the present generation, or any other, are disposed to be slaves, it does not lessen the right of the succeeding generation to be free. Wrongs cannot have a legal descent. When Mr. Burke attempts to maintain that the English nation did at the Revolution of 1688, most solemnly renounce and abdicate their rights for themselves, and for all their posterity for ever, he speaks a language that merits not reply, and which can only excite contempt for his prostitute principles, or pity for his ignorance. In whatever light hereditary succession, as growing out of the will and testament of some former generation, presents itself, it is an absurdity. A cannot make a will to take from B the property of B, and give it to C; yet this is the manner in which (what is called) hereditary succession by law operates. A certain former generation made a will, to take away the rights of the commencing generation, and all future ones, and convey those rights to a third person, who afterwards comes forward, and tells them, in Mr. Burke’s language, that they have no rights, that their rights are already bequeathed to him and that he will govern in contempt of them. From such principles, and such ignorance, good Lord deliver the world! But, after all, what is this metaphor called a crown, or rather what is monarchy? Is it a thing, or is it a name, or is it a fraud? Is it a \"contrivance of human wisdom,\" or of human craft to obtain money from a nation under specious pretences? Is it a thing necessary to a nation? If it is, in what does that necessity consist, what service does it perform, what is its business, and what are its merits? Does the virtue consist in the metaphor, or in the man? Doth the goldsmith that makes the crown, make the virtue also? Doth it operate like Fortunatus’s wishing–cap, or Harlequin’s wooden sword? Doth it make a man a conjurer? In fine, what is it? It appears to be something going much out of fashion, falling into ridicule, and rejected in some countries, both as unnecessary and expensive. In America it is considered as an absurdity; and in France it has so far declined, that the goodness of the man, and the respect for his personal character, are the only things that preserve the appearance of its existence. If government be what Mr. Burke describes it, \"a contrivance of human wisdom\" I might ask him, if wisdom was at such a low ebb in England, that it was become necessary to import it from Holland and from Hanover? But I will do the country the justice to say, that was not the case; and even if it was it mistook the cargo. The wisdom of every country, when properly exerted, is sufficient for all its purposes; and there could exist no more real occasion in England to have sent for a Dutch Stadtholder, or a German Elector, than there was in America to have done a similar thing. If a country does not understand its own affairs, how is a foreigner to understand them, who knows neither its laws, its manners, nor its language? If there existed a man so transcendently wise above all others, that his wisdom was necessary to instruct a nation, some reason might be offered for monarchy; but when we cast our eyes about a country, and observe how every part understands its own affairs; and when we look around the world, and see that of all men in it, the race of kings are the most insignificant in capacity, our reason cannot fail to ask us—What are those men kept for? If there is anything in monarchy which we people of America do not understand, I wish Mr. Burke would be so kind as to inform us. I see in America, a government extending over a country ten times as large as England, and conducted with regularity, for a fortieth part of the expense which Government costs in England. If I ask a man in America if he wants a King, he retorts, and asks me if I take him for an idiot? How is it that this difference happens? are we more or less wise than others? I see in America the generality of people living in a style of plenty unknown in monarchical countries; and I see that the principle of its government, which is that of the equal Rights of Man, is making a rapid progress in the world. If monarchy is a useless thing, why is it kept up anywhere? and if a necessary thing, how can it be dispensed with? That civil government is necessary, all civilized nations will agree; but civil government is republican government. All that part of the government of England which begins with the office of constable, and proceeds through the department of magistrate, quarter–sessions, and general assize, including trial by jury, is republican government. Nothing of monarchy appears in any part of it, except in the name which William the Conqueror imposed upon the English, that of obliging them to call him \"Their Sovereign Lord the King.\" It is easy to conceive that a band of interested men, such as Placemen, Pensioners, Lords of the bed–chamber, Lords of the kitchen, Lords of the necessary–house, and the Lord knows what besides, can find as many reasons for monarchy as their salaries, paid at the expense of the country, amount to; but if I ask the farmer, the manufacturer, the merchant, the tradesman, and down through all the occupations of life to the common labourer, what service monarchy is to him? he can give me no answer. If I ask him what monarchy is, he believes it is something like a sinecure. Notwithstanding the taxes of England amount to almost seventeen millions a year, said to be for the expenses of Government, it is still evident that the sense of the Nation is left to govern itself, and does govern itself, by magistrates and juries, almost at its own charge, on republican principles, exclusive of the expense of taxes. The salaries of the judges are almost the only charge that is paid out of the revenue. Considering that all the internal government is executed by the people, the taxes of England ought to be the lightest of any nation in Europe; instead of which, they are the contrary. As this cannot be accounted for on the score of civil government, the subject necessarily extends itself to the monarchical part. When the people of England sent for George the First (and it would puzzle a wiser man than Mr. Burke to discover for what he could be wanted, or what service he could render), they ought at least to have conditioned for the abandonment of Hanover. Besides the endless German intrigues that must follow from a German Elector being King of England, there is a natural impossibility of uniting in the same person the principles of Freedom and the principles of Despotism, or as it is usually called in England Arbitrary Power. A German Elector is in his electorate a despot; how then could it be expected that he should be attached to principles of liberty in one country, while his interest in another was to be supported by despotism? The union cannot exist; and it might easily have been foreseen that German Electors would make German Kings, or in Mr. Burke’s words, would assume government with \"contempt.\" The English have been in the habit of considering a King of England only in the character in which he appears to them; whereas the same person, while the connection lasts, has a home–seat in another country, the interest of which is different to their own, and the principles of the governments in opposition to each other. To such a person England will appear as a town–residence, and the Electorate as the estate. The English may wish, as I believe they do, success to the principles of liberty in France, or in Germany; but a German Elector trembles for the fate of despotism in his electorate; and the Duchy of Mecklenburgh, where the present Queen’s family governs, is under the same wretched state of arbitrary power, and the people in slavish vassalage. There never was a time when it became the English to watch continental intrigues more circumspectly than at the present moment, and to distinguish the politics of the Electorate from the politics of the Nation. The Revolution of France has entirely changed the ground with respect to England and France, as nations; but the German despots, with Prussia at their head, are combining against liberty; and the fondness of Mr. Pitt for office, and the interest which all his family connections have obtained, do not give sufficient security against this intrigue. As everything which passes in the world becomes matter for history, I will now quit this subject, and take a concise review of the state of parties and politics in England, as Mr. Burke has done in France. Whether the present reign commenced with contempt, I leave to Mr. Burke: certain, however, it is, that it had strongly that appearance. The animosity of the English nation, it is very well remembered, ran high; and, had the true principles of Liberty been as well understood then as they now promise to be, it is probable the Nation would not have patiently submitted to so much. George the First and Second were sensible of a rival in the remains of the Stuarts; and as they could not but consider themselves as standing on their good behaviour, they had prudence to keep their German principles of government to themselves; but as the Stuart family wore away, the prudence became less necessary. The contest between rights, and what were called prerogatives, continued to heat the nation till some time after the conclusion of the American War, when all at once it fell a calm—Execration exchanged itself for applause, and Court popularity sprung up like a mushroom in a night. To account for this sudden transition, it is proper to observe that there are two distinct species of popularity; the one excited by merit, and the other by resentment. As the Nation had formed itself into two parties, and each was extolling the merits of its parliamentary champions for and against prerogative, nothing could operate to give a more general shock than an immediate coalition of the champions themselves. The partisans of each being thus suddenly left in the lurch, and mutually heated with disgust at the measure, felt no other relief than uniting in a common execration against both. A higher stimulus or resentment being thus excited than what the contest on prerogatives occasioned, the nation quitted all former objects of rights and wrongs, and sought only that of gratification. The indignation at the Coalition so effectually superseded the indignation against the Court as to extinguish it; and without any change of principles on the part of the Court, the same people who had reprobated its despotism united with it to revenge themselves on the Coalition Parliament. The case was not, which they liked best, but which they hated most; and the least hated passed for love. The dissolution of the Coalition Parliament, as it afforded the means of gratifying the resentment of the Nation, could not fail to be popular; and from hence arose the popularity of the Court. Transitions of this kind exhibit a Nation under the government of temper, instead of a fixed and steady principle; and having once committed itself, however rashly, it feels itself urged along to justify by continuance its first proceeding. Measures which at other times it would censure it now approves, and acts persuasion upon itself to suffocate its judgment. On the return of a new Parliament, the new Minister, Mr. Pitt, found himself in a secure majority; and the Nation gave him credit, not out of regard to himself, but because it had resolved to do it out of resentment to another. He introduced himself to public notice by a proposed Reform of Parliament, which in its operation would have amounted to a public justification of corruption. The Nation was to be at the expense of buying up the rotten boroughs, whereas it ought to punish the persons who deal in the traffic. Passing over the two bubbles of the Dutch business and the million a–year to sink the national debt, the matter which most presents itself, is the affair of the Regency. Never, in the course of my observation, was delusion more successfully acted, nor a nation more completely deceived. But, to make this appear, it will be necessary to go over the circumstances. Mr. Fox had stated in the House of Commons, that the Prince of Wales, as heir in succession, had a right in himself to assume the Government. This was opposed by Mr. Pitt; and, so far as the opposition was confined to the doctrine, it was just. But the principles which Mr. Pitt maintained on the contrary side were as bad, or worse in their extent, than those of Mr. Fox; because they went to establish an aristocracy over the nation, and over the small representation it has in the House of Commons. Whether the English form of Government be good or bad, is not in this case the question; but, taking it as it stands, without regard to its merits or demerits, Mr. Pitt was farther from the point than Mr. Fox. It is supposed to consist of three parts:—while therefore the Nation is disposed to continue this form, the parts have a national standing, independent of each other, and are not the creatures of each other. Had Mr. Fox passed through Parliament, and said that the person alluded to claimed on the ground of the Nation, Mr. Pitt must then have contended what he called the right of the Parliament against the right of the Nation. By the appearance which the contest made, Mr. Fox took the hereditary ground, and Mr. Pitt the Parliamentary ground; but the fact is, they both took hereditary ground, and Mr. Pitt took the worst of the two. What is called the Parliament is made up of two Houses, one of which is more hereditary, and more beyond the control of the Nation than what the Crown (as it is called) is supposed to be. It is an hereditary aristocracy, assuming and asserting indefeasible, irrevocable rights and authority, wholly independent of the Nation. Where, then, was the merited popularity of exalting this hereditary power over another hereditary power less independent of the Nation than what itself assumed to be, and of absorbing the rights of the Nation into a House over which it has neither election nor control? The general impulse of the Nation was right; but it acted without reflection. It approved the opposition made to the right set up by Mr. Fox, without perceiving that Mr. Pitt was supporting another indefeasible right more remote from the Nation, in opposition to it. With respect to the House of Commons, it is elected but by a small part of the Nation; but were the election as universal as taxation, which it ought to be, it would still be only the organ of the Nation, and cannot possess inherent rights.—When the National Assembly of France resolves a matter, the resolve is made in right of the Nation; but Mr. Pitt, on all national questions, so far as they refer to the House of Commons, absorbs the rights of the Nation into the organ, and makes the organ into a Nation, and the Nation itself into a cypher. In a few words, the question on the Regency was a question of a million a–year, which is appropriated to the executive department: and Mr. Pitt could not possess himself of any management of this sum, without setting up the supremacy of Parliament; and when this was accomplished, it was indifferent who should be Regent, as he must be Regent at his own cost. Among the curiosities which this contentious debate afforded, was that of making the Great Seal into a King, the affixing of which to an act was to be royal authority. If, therefore, Royal Authority is a Great Seal, it consequently is in itself nothing; and a good Constitution would be of infinitely more value to the Nation than what the three Nominal Powers, as they now stand, are worth. The continual use of the word Constitution in the English Parliament shows there is none; and that the whole is merely a form of government without a Constitution, and constituting itself with what powers it pleases. If there were a Constitution, it certainly could be referred to; and the debate on any constitutional point would terminate by producing the Constitution. One member says this is Constitution, and another says that is Constitution—To–day it is one thing; and to–morrow something else—while the maintaining of the debate proves there is none. Constitution is now the cant word of Parliament, tuning itself to the ear of the Nation. Formerly it was the universal supremacy of Parliament—the omnipotence of Parliament: But since the progress of Liberty in France, those phrases have a despotic harshness in their note; and the English Parliament have catched the fashion from the National Assembly, but without the substance, of speaking of Constitution. As the present generation of the people in England did not make the Government, they are not accountable for any of its defects; but, that sooner or later, it must come into their hands to undergo a constitutional reformation, is as certain as that the same thing has happened in France. If France, with a revenue of nearly twenty–four millions sterling, with an extent of rich and fertile country above four times larger than England, with a population of twenty–four millions of inhabitants to support taxation, with upwards of ninety millions sterling of gold and silver circulating in the nation, and with a debt less than the present debt of England—still found it necessary, from whatever cause, to come to a settlement of its affairs, it solves the problem of funding for both countries. It is out of the question to say how long what is called the English constitution has lasted, and to argue from thence how long it is to last; the question is, how long can the funding system last? It is a thing but of modern invention, and has not yet continued beyond the life of a man; yet in that short space it has so far accumulated, that, together with the current expenses, it requires an amount of taxes at least equal to the whole landed rental of the nation in acres to defray the annual expenditure. That a government could not have always gone on by the same system which has been followed for the last seventy years, must be evident to every man; and for the same reason it cannot always go on. The funding system is not money; neither is it, properly speaking, credit. It, in effect, creates upon paper the sum which it appears to borrow, and lays on a tax to keep the imaginary capital alive by the payment of interest and sends the annuity to market, to be sold for paper already in circulation. If any credit is given, it is to the disposition of the people to pay the tax, and not to the government, which lays it on. When this disposition expires, what is supposed to be the credit of Government expires with it. The instance of France under the former Government shows that it is impossible to compel the payment of taxes by force, when a whole nation is determined to take its stand upon that ground. Mr. Burke, in his review of the finances of France, states the quantity of gold and silver in France, at about eighty–eight millions sterling. In doing this, he has, I presume, divided by the difference of exchange, instead of the standard of twenty–four livres to a pound sterling; for M. Neckar’s statement, from which Mr. Burke’s is taken, is two thousand two hundred millions of livres, which is upwards of ninety–one millions and a half sterling. M. Neckar in France, and Mr. George Chalmers at the Office of Trade and Plantation in England, of which Lord Hawkesbury is president, published nearly about the same time (1786) an account of the quantity of money in each nation, from the returns of the Mint of each nation. Mr. Chalmers, from the returns of the English Mint at the Tower of London, states the quantity of money in England, including Scotland and Ireland, to be twenty millions sterling. [12] M. Neckar [13] says that the amount of money in France, recoined from the old coin which was called in, was two thousand five hundred millions of livres (upwards of one hundred and four millions sterling); and, after deducting for waste, and what may be in the West Indies and other possible circumstances, states the circulation quantity at home to be ninety–one millions and a half sterling; but, taking it as Mr. Burke has put it, it is sixty–eight millions more than the national quantity in England. That the quantity of money in France cannot be under this sum, may at once be seen from the state of the French Revenue, without referring to the records of the French Mint for proofs. The revenue of France, prior to the Revolution, was nearly twenty–four millions sterling; and as paper had then no existence in France the whole revenue was collected upon gold and silver; and it would have been impossible to have collected such a quantity of revenue upon a less national quantity than M. Neckar has stated. Before the establishment of paper in England, the revenue was about a fourth part of the national amount of gold and silver, as may be known by referring to the revenue prior to King William, and the quantity of money stated to be in the nation at that time, which was nearly as much as it is now. It can be of no real service to a nation, to impose upon itself, or to permit itself to be imposed upon; but the prejudices of some, and the imposition of others, have always represented France as a nation possessing but little money—whereas the quantity is not only more than four times what the quantity is in England, but is considerably greater on a proportion of numbers. To account for this deficiency on the part of England, some reference should be had to the English system of funding. It operates to multiply paper, and to substitute it in the room of money, in various shapes; and the more paper is multiplied, the more opportunities are offered to export the specie; and it admits of a possibility (by extending it to small notes) of increasing paper till there is no money left. I know this is not a pleasant subject to English readers; but the matters I am going to mention, are so important in themselves, as to require the attention of men interested in money transactions of a public nature. There is a circumstance stated by M. Neckar, in his treatise on the administration of the finances, which has never been attended to in England, but which forms the only basis whereon to estimate the quantity of money (gold and silver) which ought to be in every nation in Europe, to preserve a relative proportion with other nations. Lisbon and Cadiz are the two ports into which (money) gold and silver from South America are imported, and which afterwards divide and spread themselves over Europe by means of commerce, and increase the quantity of money in all parts of Europe. If, therefore, the amount of the annual importation into Europe can be known, and the relative proportion of the foreign commerce of the several nations by which it can be distributed can be ascertained, they give a rule sufficiently true, to ascertain the quantity of money which ought to be found in any nation, at any given time. M. Neckar shows from the registers of Lisbon and Cadiz, that the importation of gold and silver into Europe, is five millions sterling annually. He has not taken it on a single year, but on an average of fifteen succeeding years, from 1763 to 1777, both inclusive; in which time, the amount was one thousand eight hundred million livres, which is seventy–five millions sterling. [14] From the commencement of the Hanover succession in 1714 to the time Mr. Chalmers published, is seventy–two years; and the quantity imported into Europe, in that time, would be three hundred and sixty millions sterling. If the foreign commerce of Great Britain be stated at a sixth part of what the whole foreign commerce of Europe amounts to (which is probably an inferior estimation to what the gentlemen at the Exchange would allow) the proportion which Britain should draw by commerce of this sum, to keep herself on a proportion with the rest of Europe, would be also a sixth part which is sixty millions sterling; and if the same allowance for waste and accident be made for England which M. Neckar makes for France, the quantity remaining after these deductions would be fifty–two millions; and this sum ought to have been in the nation (at the time Mr. Chalmers published), in addition to the sum which was in the nation at the commencement of the Hanover succession, and to have made in the whole at least sixty–six millions sterling; instead of which there were but twenty millions, which is forty–six millions below its proportionate quantity. As the quantity of gold and silver imported into Lisbon and Cadiz is more exactly ascertained than that of any commodity imported into England, and as the quantity of money coined at the Tower of London is still more positively known, the leading facts do not admit of controversy. Either, therefore, the commerce of England is unproductive of profit, or the gold and silver which it brings in leak continually away by unseen means at the average rate of about three–quarters of a million a year, which, in the course of seventy–two years, accounts for the deficiency; and its absence is supplied by paper. [15] The Revolution of France is attended with many novel circumstances, not only in the political sphere, but in the circle of money transactions. Among others, it shows that a government may be in a state of insolvency and a nation rich. So far as the fact is confined to the late Government of France, it was insolvent; because the nation would no longer support its extravagance, and therefore it could no longer support itself—but with respect to the nation all the means existed. A government may be said to be insolvent every time it applies to the nation to discharge its arrears. The insolvency of the late Government of France and the present of England differed in no other respect than as the dispositions of the people differ. The people of France refused their aid to the old Government; and the people of England submit to taxation without inquiry. What is called the Crown in England has been insolvent several times; the last of which, publicly known, was in May, 1777, when it applied to the nation to discharge upwards of £600,000 private debts, which otherwise it could not pay. It was the error of Mr. Pitt, Mr. Burke, and all those who were unacquainted with the affairs of France to confound the French nation with the French Government. The French nation, in effect, endeavoured to render the late Government insolvent for the purpose of taking government into its own hands: and it reserved its means for the support of the new Government. In a country of such vast extent and population as France the natural means cannot be wanting, and the political means appear the instant the nation is disposed to permit them. When Mr. Burke, in a speech last winter in the British Parliament, \"cast his eyes over the map of Europe, and saw a chasm that once was France,\" he talked like a dreamer of dreams. The same natural France existed as before, and all the natural means existed with it. The only chasm was that the extinction of despotism had left, and which was to be filled up with the Constitution more formidable in resources than the power which had expired. Although the French Nation rendered the late Government insolvent, it did not permit the insolvency to act towards the creditors; and the creditors, considering the Nation as the real pay–master, and the Government only as the agent, rested themselves on the nation, in preference to the Government. This appears greatly to disturb Mr. Burke, as the precedent is fatal to the policy by which governments have supposed themselves secure. They have contracted debts, with a view of attaching what is called the monied interest of a Nation to their support; but the example in France shows that the permanent security of the creditor is in the Nation, and not in the Government; and that in all possible revolutions that may happen in Governments, the means are always with the Nation, and the Nation always in existence. Mr. Burke argues that the creditors ought to have abided the fate of the Government which they trusted; but the National Assembly considered them as the creditors of the Nation, and not of the Government—of the master, and not of the steward. Notwithstanding the late government could not discharge the current expenses, the present government has paid off a great part of the capital. This has been accomplished by two means; the one by lessening the expenses of government, and the other by the sale of the monastic and ecclesiastical landed estates. The devotees and penitent debauchees, extortioners and misers of former days, to ensure themselves a better world than that they were about to leave, had bequeathed immense property in trust to the priesthood for pious uses; and the priesthood kept it for themselves. The National Assembly has ordered it to be sold for the good of the whole nation, and the priesthood to be decently provided for. In consequence of the revolution, the annual interest of the debt of France will be reduced at least six millions sterling, by paying off upwards of one hundred millions of the capital; which, with lessening the former expenses of government at least three millions, will place France in a situation worthy the imitation of Europe. Upon a whole review of the subject, how vast is the contrast! While Mr. Burke has been talking of a general bankruptcy in France, the National Assembly has been paying off the capital of its debt; and while taxes have increased near a million a year in England, they have lowered several millions a year in France. Not a word has either Mr. Burke or Mr. Pitt said about the French affairs, or the state of the French finances, in the present Session of Parliament. The subject begins to be too well understood, and imposition serves no longer. There is a general enigma running through the whole of Mr. Burke’s book. He writes in a rage against the National Assembly; but what is he enraged about? If his assertions were as true as they are groundless, and that France by her Revolution, had annihilated her power, and become what he calls a chasm, it might excite the grief of a Frenchman (considering himself as a national man), and provoke his rage against the National Assembly; but why should it excite the rage of Mr. Burke? Alas! it is not the nation of France that Mr. Burke means, but the Court; and every Court in Europe, dreading the same fate, is in mourning. He writes neither in the character of a Frenchman nor an Englishman, but in the fawning character of that creature known in all countries, and a friend to none—a courtier. Whether it be the Court of Versailles, or the Court of St. James, or Carlton–House, or the Court in expectation, signifies not; for the caterpillar principle of all Courts and Courtiers are alike. They form a common policy throughout Europe, detached and separate from the interest of Nations: and while they appear to quarrel, they agree to plunder. Nothing can be more terrible to a Court or Courtier than the Revolution of France. That which is a blessing to Nations is bitterness to them: and as their existence depends on the duplicity of a country, they tremble at the approach of principles, and dread the precedent that threatens their overthrow.",
        "char_count": 49610
      },
      {
        "heading": "Chapter 12",
        "text": "CONCLUSION Reason and Ignorance, the opposites of each other, influence the great bulk of mankind. If either of these can be rendered sufficiently extensive in a country, the machinery of Government goes easily on. Reason obeys itself; and Ignorance submits to whatever is dictated to it. The two modes of the Government which prevail in the world, are: First, Government by election and representation. Secondly, Government by hereditary succession. The former is generally known by the name of republic; the latter by that of monarchy and aristocracy. Those two distinct and opposite forms erect themselves on the two distinct and opposite bases of Reason and Ignorance.—As the exercise of Government requires talents and abilities, and as talents and abilities cannot have hereditary descent, it is evident that hereditary succession requires a belief from man to which his reason cannot subscribe, and which can only be established upon his ignorance; and the more ignorant any country is, the better it is fitted for this species of Government. On the contrary, Government, in a well–constituted republic, requires no belief from man beyond what his reason can give. He sees the rationale of the whole system, its origin and its operation; and as it is best supported when best understood, the human faculties act with boldness, and acquire, under this form of government, a gigantic manliness. As, therefore, each of those forms acts on a different base, the one moving freely by the aid of reason, the other by ignorance; we have next to consider, what it is that gives motion to that species of Government which is called mixed Government, or, as it is sometimes ludicrously styled, a Government of this, that and t' other. The moving power in this species of Government is, of necessity, Corruption. However imperfect election and representation may be in mixed Governments, they still give exercise to a greater portion of reason than is convenient to the hereditary Part; and therefore it becomes necessary to buy the reason up. A mixed Government is an imperfect everything, cementing and soldering the discordant parts together by corruption, to act as a whole. Mr. Burke appears highly disgusted that France, since she had resolved on a revolution, did not adopt what he calls \"A British Constitution\"; and the regretful manner in which he expresses himself on this occasion implies a suspicion that the British Constitution needed something to keep its defects in countenance. In mixed Governments there is no responsibility: the parts cover each other till responsibility is lost; and the corruption which moves the machine, contrives at the same time its own escape. When it is laid down as a maxim, that a King can do no wrong, it places him in a state of similar security with that of idiots and persons insane, and responsibility is out of the question with respect to himself. It then descends upon the Minister, who shelters himself under a majority in Parliament, which, by places, pensions, and corruption, he can always command; and that majority justifies itself by the same authority with which it protects the Minister. In this rotatory motion, responsibility is thrown off from the parts, and from the whole. When there is a Part in a Government which can do no wrong, it implies that it does nothing; and is only the machine of another power, by whose advice and direction it acts. What is supposed to be the King in the mixed Governments, is the Cabinet; and as the Cabinet is always a part of the Parliament, and the members justifying in one character what they advise and act in another, a mixed Government becomes a continual enigma; entailing upon a country by the quantity of corruption necessary to solder the parts, the expense of supporting all the forms of government at once, and finally resolving itself into a Government by Committee; in which the advisers, the actors, the approvers, the justifiers, the persons responsible, and the persons not responsible, are the same persons. By this pantomimical contrivance, and change of scene and character, the parts help each other out in matters which neither of them singly would assume to act. When money is to be obtained, the mass of variety apparently dissolves, and a profusion of parliamentary praises passes between the parts. Each admires with astonishment, the wisdom, the liberality, the disinterestedness of the other: and all of them breathe a pitying sigh at the burthens of the Nation. But in a well–constituted republic, nothing of this soldering, praising, and pitying, can take place; the representation being equal throughout the country, and complete in itself, however it may be arranged into legislative and executive, they have all one and the same natural source. The parts are not foreigners to each other, like democracy, aristocracy, and monarchy. As there are no discordant distinctions, there is nothing to corrupt by compromise, nor confound by contrivance. Public measures appeal of themselves to the understanding of the Nation, and, resting on their own merits, disown any flattering applications to vanity. The continual whine of lamenting the burden of taxes, however successfully it may be practised in mixed Governments, is inconsistent with the sense and spirit of a republic. If taxes are necessary, they are of course advantageous; but if they require an apology, the apology itself implies an impeachment. Why, then, is man thus imposed upon, or why does he impose upon himself? When men are spoken of as kings and subjects, or when Government is mentioned under the distinct and combined heads of monarchy, aristocracy, and democracy, what is it that reasoning man is to understand by the terms? If there really existed in the world two or more distinct and separate elements of human power, we should then see the several origins to which those terms would descriptively apply; but as there is but one species of man, there can be but one element of human power; and that element is man himself. Monarchy, aristocracy, and democracy, are but creatures of imagination; and a thousand such may be contrived as well as three. From the Revolutions of America and France, and the symptoms that have appeared in other countries, it is evident that the opinion of the world is changing with respect to systems of Government, and that revolutions are not within the compass of political calculations. The progress of time and circumstances, which men assign to the accomplishment of great changes, is too mechanical to measure the force of the mind, and the rapidity of reflection, by which revolutions are generated: All the old governments have received a shock from those that already appear, and which were once more improbable, and are a greater subject of wonder, than a general revolution in Europe would be now. When we survey the wretched condition of man, under the monarchical and hereditary systems of Government, dragged from his home by one power, or driven by another, and impoverished by taxes more than by enemies, it becomes evident that those systems are bad, and that a general revolution in the principle and construction of Governments is necessary. What is government more than the management of the affairs of a Nation? It is not, and from its nature cannot be, the property of any particular man or family, but of the whole community, at whose expense it is supported; and though by force and contrivance it has been usurped into an inheritance, the usurpation cannot alter the right of things. Sovereignty, as a matter of right, appertains to the Nation only, and not to any individual; and a Nation has at all times an inherent indefeasible right to abolish any form of Government it finds inconvenient, and to establish such as accords with its interest, disposition and happiness. The romantic and barbarous distinction of men into Kings and subjects, though it may suit the condition of courtiers, cannot that of citizens; and is exploded by the principle upon which Governments are now founded. Every citizen is a member of the Sovereignty, and, as such, can acknowledge no personal subjection; and his obedience can be only to the laws. When men think of what Government is, they must necessarily suppose it to possess a knowledge of all the objects and matters upon which its authority is to be exercised. In this view of Government, the republican system, as established by America and France, operates to embrace the whole of a Nation; and the knowledge necessary to the interest of all the parts, is to be found in the center, which the parts by representation form: But the old Governments are on a construction that excludes knowledge as well as happiness; government by Monks, who knew nothing of the world beyond the walls of a Convent, is as consistent as government by Kings. What were formerly called Revolutions, were little more than a change of persons, or an alteration of local circumstances. They rose and fell like things of course, and had nothing in their existence or their fate that could influence beyond the spot that produced them. But what we now see in the world, from the Revolutions of America and France, are a renovation of the natural order of things, a system of principles as universal as truth and the existence of man, and combining moral with political happiness and national prosperity. \"I. Men are born, and always continue, free and equal in respect of their rights. Civil distinctions, therefore, can be founded only on public utility.\" \"II. The end of all political associations is the preservation of the natural and imprescriptible rights of man; and these rights are liberty, property, security, and resistance of oppression.\" \"III. The nation is essentially the source of all sovereignty; nor can any Individual, or Any Body Of Men, be entitled to any authority which is not expressly derived from it.\" In these principles, there is nothing to throw a Nation into confusion by inflaming ambition. They are calculated to call forth wisdom and abilities, and to exercise them for the public good, and not for the emolument or aggrandisement of particular descriptions of men or families. Monarchical sovereignty, the enemy of mankind, and the source of misery, is abolished; and the sovereignty itself is restored to its natural and original place, the Nation. Were this the case throughout Europe, the cause of wars would be taken away. It is attributed to Henry the Fourth of France, a man of enlarged and benevolent heart, that he proposed, about the year 1610, a plan for abolishing war in Europe. The plan consisted in constituting an European Congress, or as the French authors style it, a Pacific Republic; by appointing delegates from the several Nations who were to act as a Court of arbitration in any disputes that might arise between nation and nation. Had such a plan been adopted at the time it was proposed, the taxes of England and France, as two of the parties, would have been at least ten millions sterling annually to each Nation less than they were at the commencement of the French Revolution. To conceive a cause why such a plan has not been adopted (and that instead of a Congress for the purpose of preventing war, it has been called only to terminate a war, after a fruitless expense of several years) it will be necessary to consider the interest of Governments as a distinct interest to that of Nations. Whatever is the cause of taxes to a Nation, becomes also the means of revenue to Government. Every war terminates with an addition of taxes, and consequently with an addition of revenue; and in any event of war, in the manner they are now commenced and concluded, the power and interest of Governments are increased. War, therefore, from its productiveness, as it easily furnishes the pretence of necessity for taxes and appointments to places and offices, becomes a principal part of the system of old Governments; and to establish any mode to abolish war, however advantageous it might be to Nations, would be to take from such Government the most lucrative of its branches. The frivolous matters upon which war is made, show the disposition and avidity of Governments to uphold the system of war, and betray the motives upon which they act. Why are not Republics plunged into war, but because the nature of their Government does not admit of an interest distinct from that of the Nation? Even Holland, though an ill–constructed Republic, and with a commerce extending over the world, existed nearly a century without war: and the instant the form of Government was changed in France, the republican principles of peace and domestic prosperity and economy arose with the new Government; and the same consequences would follow the cause in other Nations. As war is the system of Government on the old construction, the animosity which Nations reciprocally entertain, is nothing more than what the policy of their Governments excites to keep up the spirit of the system. Each Government accuses the other of perfidy, intrigue, and ambition, as a means of heating the imagination of their respective Nations, and incensing them to hostilities. Man is not the enemy of man, but through the medium of a false system of Government. Instead, therefore, of exclaiming against the ambition of Kings, the exclamation should be directed against the principle of such Governments; and instead of seeking to reform the individual, the wisdom of a Nation should apply itself to reform the system. Whether the forms and maxims of Governments which are still in practice, were adapted to the condition of the world at the period they were established, is not in this case the question. The older they are, the less correspondence can they have with the present state of things. Time, and change of circumstances and opinions, have the same progressive effect in rendering modes of Government obsolete as they have upon customs and manners.—Agriculture, commerce, manufactures, and the tranquil arts, by which the prosperity of Nations is best promoted, require a different system of Government, and a different species of knowledge to direct its operations, than what might have been required in the former condition of the world. As it is not difficult to perceive, from the enlightened state of mankind, that hereditary Governments are verging to their decline, and that Revolutions on the broad basis of national sovereignty and Government by representation, are making their way in Europe, it would be an act of wisdom to anticipate their approach, and produce Revolutions by reason and accommodation, rather than commit them to the issue of convulsions. From what we now see, nothing of reform in the political world ought to be held improbable. It is an age of Revolutions, in which everything may be looked for. The intrigue of Courts, by which the system of war is kept up, may provoke a confederation of Nations to abolish it: and an European Congress to patronise the progress of free Government, and promote the civilisation of Nations with each other, is an event nearer in probability, than once were the revolutions and alliance of France and America. END OF PART I.",
        "char_count": 15198
      }
    ]
  },
  "federalist": {
    "meta": {
      "key": "federalist",
      "title": "The Federalist Papers",
      "creator": "Alexander Hamilton; James Madison; John Jay",
      "filepath": "G:/My Drive/15_E-BOOKS/file004299.epub",
      "subject": "History"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Table of Contents FROM THE PAGES OF THE FEDERALIST Title Page Copyright Page ALEXANDER HAMILTON, JAMES MADISON, AND JOHN JAY THE WORLD OF THE FEDERALIST Introduction PREFACE TO THE GIDEON EDITION (1818) No. 1 - BY ALEXANDER HAMILTON No. 2 - BY JOHN JAY No. 3 - BY JOHN JAY No. 4 - BY JOHN JAY No. 5 - BY JOHN JAY No. 6 - BY ALEXANDER HAMILTON No. 7 - BY ALEXANDER HAMILTON No. 8 - BY ALEXANDER HAMILTON No. 9 - BY ALEXANDER HAMILTON No. 10 - BY JAMES MADISON No. 11 - BY ALEXANDER HAMILTON No. 12 - BY ALEXANDER HAMILTON No. 13 - BY ALEXANDER HAMILTON No. 14 - BY JAMES MADISON No. 15 - BY ALEXANDER HAMILTON No. 16 - BY ALEXANDER HAMILTON No. 17 - BY ALEXANDER HAMILTON No. 18 - BY JAMES MADISON No. 19 - BY JAMES MADISON No. 20 - BY JAMES MADISON No. 21 - BY ALEXANDER HAMILTON No. 22 - BY ALEXANDER HAMILTON No. 23 - BY ALEXANDER HAMILTON No. 24 - BY ALEXANDER HAMILTON No. 25 - BY ALEXANDER HAMILTON No. 26 - BY ALEXANDER HAMILTON No. 27 - BY ALEXANDER HAMILTON No. 28 - BY ALEXANDER HAMILTON No. 29 - BY ALEXANDER HAMILTON No. 30 - BY ALEXANDER HAMILTON No. 31 - BY ALEXANDER HAMILTON No. 32 - BY ALEXANDER HAMILTON No. 33 - BY ALEXANDER HAMILTON No. 34 - BY ALEXANDER HAMILTON No. 35 - BY ALEXANDER HAMILTON No. 36 - BY ALEXANDER HAMILTON No. 37 - BY JAMES MADISON No. 38 - BY JAMES MADISON No. 39 - BY JAMES MADISON No. 40 - BY JAMES MADISON No. 41 - BY JAMES MADISON No. 42. - BY JAMES MADISON No. 43 - BY JAMES MADISON No. 44 - BY JAMES MADISON No. 45 - BY JAMES MADISON No. 46 - BY JAMES MADISON No. 47 - BY JAMES MADISON No. 48 - BY JAMES MADISON No. 49 - BY JAMES MADISON No. 50 - BY JAMES MADISON No. 51 - BY JAMES MADISON No. 52 - BY JAMES MADISON No. 53 - BY JAMES MADISON No. 54 - BY JAMES MADISON No. 55 - BY JAMES MADISON No. 56 - BY JAMES MADISON No. 57 - BY JAMES MADISON No. 58 - BY JAMES MADISON No. 59 - BY ALEXANDER HAMILTON No. 60 - BY ALEXANDER HAMILTON No. 61 - BY ALEXANDER HAMILTON No. 62 - BY JAMES MADISON No. 63 - BY JAMES MADISON No. 64 - BY JOHN JAY No. 65 - BY ALEXANDER HAMILTON No. 66 - BY ALEXANDER HAMILTON No. 67 - BY ALEXANDER HAMILTON No. 68 - BY ALEXANDER HAMILTON No. 69 - BY ALEXANDER HAMILTON No. 70 - BY ALEXANDER HAMILTON No. 71 - BY ALEXANDER HAMILTON No. 72 - BY ALEXANDER HAMILTON No. 73 - BY ALEXANDER HAMILTON No. 74 - BY ALEXANDER HAMILTON No. 75 - BY ALEXANDER HAMILTON No. 76 - BY ALEXANDER HAMILTON No. 77 - BY ALEXANDER HAMILTON No. 78 - BY ALEXANDER HAMILTON No. 79 - BY ALEXANDER HAMILTON No. 80 - BY ALEXANDER HAMILTON No. 81 - BY ALEXANDER HAMILTON No. 82 - BY ALEXANDER HAMILTON No. 83 - BY ALEXANDER HAMILTON No. 84 - BY ALEXANDER HAMILTON No. 85 - BY ALEXANDER HAMILTON APPENDIX: THE CONSTITUTION OF THE UNITED STATES ENDNOTES FOR FURTHER READING",
        "char_count": 2711
      },
      {
        "heading": "Chapter 2",
        "text": "FROM THE PAGES OF THE FEDERALIST After full experience of the insufficiency of the existing federal government, you are invited to deliberate upon a New Constitution for the United States of America. (No. 1, page 9) Let Americans disdain to be the instruments of European greatness ! Let the Thirteen States, bound together in a strict and indissoluble union, concur in erecting one great American system, superior to the control of all transatlantic force or influence, and able to dictate the terms of the connexion between the old and the new world! (No. 11, page 65) What are the chief sources of expense in every government? What has occasioned that enormous accumulation of debts with which several of the European nations are oppressed? The answer plainly is, wars and rebellions; the support of those institutions which are necessary to guard the body politic against these two mortal diseases of society. (No. 34, pages 178-179) It is a misfortune, inseparable from human affairs, that public measures are rarely investigated with that spirit of moderation, which is essential to a just estimate of their real tendency to advance, or obstruct, the public good. (No. 37, page 194) Not less true is it, that the liberties of Rome proved the final victim to her military triumphs, and that the liberties of Europe, as far as they ever existed, have, with few exceptions, been the price of her military establishments. A standing force, therefore, is a dangerous, at the same time that it may be a necessary, provision. On the smallest scale, it has its inconveniencies. On an extensive scale, its consequences may be fatal. (No. 41, page 226) But what is government itself, but the greatest of all reflections on human nature? If men were angels, no government would be necessary. If angels were to govern men, neither external nor internal controls on government would be necessary. In framing a government which is to be administered by men over men, the great difficulty lies in this: you must first enable the government to control the governed; and in the next place oblige it to control itself. (No. 51, page 288) Who are to be the electors of the federal representatives? Not the rich, more than the poor; not the learned, more than the ignorant; not the haughty heirs of distinguished names, more than the humble sons of obscure and unpropitious fortune. (No. 57, page 317) A good government implies two things: first, fidelity to the object of government, which is the happiness of the people; secondly, a knowledge of the means by which that object can be best attained. Some governments are deficient in both these qualities: most governments are deficient in the first. I scruple not to assert, that, in the American governments, too little attention has been paid to the last. (No. 62, page 345) Though individual oppression may now and then proceed from the courts of justice, the general liberty of the people can never be endangered from that quarter: I mean, so long as the judiciary remains truly distinct from both the legislature and the executive. For I agree that “there is no liberty, if the power of judging be not separated from the legislative and executive powers.” (No. 78, page 429) Nothing need be said to illustrate the importance of the prohibition of titles of nobility. This may truly be denominated the corner stone of republican government for so long as they are excluded, there can never be serious danger that the government will be any other than that of the people. (No. 84, page 473) A NATION without a NATIONAL GOVERNMENT, is an awful spectacle. The establishment of a constitution, in time of profound peace, by the voluntary consent of a whole people, is a PRODIGY, to the completion of which I look forward with trembling anxiety. (No. 85, page 487)",
        "char_count": 3801
      },
      {
        "heading": "Chapter 3",
        "text": "Published by Barnes & Noble Books 122 Fifth Avenue New York, NY 10011 www.barnesandnoble.com/classics The Federalist, Hamilton, Madison, and Jay’s series of eighty-five essays, was written in 1787-1788 and printed in various New York newspapers, with the exception of the final eight essays. These last were included in the two-volume book edition of 1788. The current text is that of the authoritative Gideon Edition of 1818. Published in 2006 by Barnes & Noble Classics with new Introduction, Notes, Biography, Chronology, and For Further Reading. Introduction, Endnotes, and For Further Reading Copyright © 2006 by Robert A. Ferguson. Note on Hamilton, Madison, and Jay and The World of The Federalist Copyright © 2006 by Barnes & Noble, Inc. All rights reserved. No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopy, recording, or any information storage and retrieval system, without the prior written permission of the publisher. Barnes & Noble Classics and the Barnes & Noble Classics colophon are trademarks of Barnes & Noble, Inc. The Federalist ISBN-13: 978-1-59308-282-6 ISBN-10: 1-59308-282-7 eISBN : 978-1-411-43219-2 LC Control Number 2005932485 Produced and published in conjunction with: Fine Creative Media, Inc. 322 Eighth Avenue New York, NY 10001 Michael J. Fine, President and Publisher Printed in the United States of America QM 1 3 5 7 9 10 8 6 4 2 FIRST PRINTING",
        "char_count": 1469
      },
      {
        "heading": "Chapter 4",
        "text": "ALEXANDER HAMILTON, JAMES MADISON, AND JOHN JAY The document now known as the Constitution of the United States was composed in 1787 by the fifty-five delegates of the Constitutional Convention in Philadelphia. A declared compromise of divergent interests, its authority in the new nation at the time was by no means assured. A national debate on its legitimacy ensued. To the federal Constitution’s defense came James Madison, Alexander Hamilton, and John Jay; sharing the pen name Publius, the three men argued the new Constitution’s merits in a series of essays that became known as The Federalist. In the eyes of many Americans, the proposed Constitution was an invitation to tyranny that neglected individual liberties even as it closed gaping holes in the nation’s existing system of governance. The new document seemed most threatened in Hamilton’s state of New York. In response, Hamilton conceived a public relations effort to promote the Constitution, by publishing pro-ratification treatises in the major newspapers. In all, eighty-five essays by the three authors appeared: John Jay authored five, Madison twenty-nine, and Hamilton fifty-one. Alexander Hamilton (c.1755-1804) was born on the Caribbean island of Nevis, the illegitimate son of a married woman and a struggling Scottish businessman. After the death of his mother, Hamilton left the West Indies for New York, where he settled in 1772. Bright and ambitious, he enrolled in King’s College (now Columbia University), intending to become a doctor. Serving as General George Washington’s aide-de-camp during the Revolutionary War, he became a member of the Constitutional Convention in 1787. Hamilton, who believed economic prosperity required a strong government, was an outspoken proponent of centralized government and the architect of the country’s financial institutions. He later served as the first secretary of the Treasury (1789-1795), exerted significant influence over foreign policy, and played a crucial role in shaping the government. His caustic wit earned him many enemies, including Aaron Burr, whose political career suffered under Hamilton’s criticism. Burr challenged Hamilton to a duel and on July 11, 1804, delivered a mortal wound. Hamilton died the next day. James Madison ( 1751-1836) was the son of a Virginia planter and a member of the southern aristocracy. Though his health kept him from military service, he was active in revolutionary politics in his home state and was chosen for the Continental Congress (1780) and then the Constitutional Convention. Because of his efforts and influence at the convention, he is sometimes called the “father of the Constitution.” Madison served in the U.S. House of Representatives from 1789 to 1797 and was secretary of state for eight years under Thomas Jefferson, whom he helped in engineering the Louisiana Purchase. In 1809 Madison succeeded Jefferson and was elected the nation’s fourth president; he won a second term in 1812 and, although a proponent of peace, led the United States to victory in that year’s war with Britain. Madison was the last of the leading founders to die when he passed away on June 28, 1836. John Jay (1745-1829) was born in New York City. He became an attorney in 1768 and gained early fame with The Address to the People of Great Britain (1774), a tract outlining colonial demands on the mother country, which Jay wrote while representing New York in the First Continental Congress. He drafted New York’s earliest constitution and in 1777 was made the state’s first chief justice. Minister to Spain from 1779 to 1782, he spent much of the Revolutionary War on diplomatic service in Europe, where, along with Benjamin Franklin, he negotiated the Treaty of Paris, which was signed in 1783. Jay did not attend the Constitutional Convention, but his work in foreign affairs in the late 1780s under the encumbering Articles of Confederation shaped his support for a new U.S. Constitution; his five Federalist essays primarily concern foreign affairs. In 1789 President Washington appointed Jay the country’s first chief justice of the Supreme Court, and his measured stewardship helped cement the court’s reputation for impartiality. The unpopular Jay Treaty of 1794 with Great Britain spoiled Jay’s hopes to succeed Washington as president, although he was elected governor of New York the following year. John Jay died on May 17, 1829.",
        "char_count": 4406
      },
      {
        "heading": "Chapter 5",
        "text": "THE WORLD OF THE FEDERALIST 1775 On April 19, the American Revolution begins with battles at Lexington and Concord, Massachusetts. 1776 On January 10, Thomas Paine publishes Common Sense as an anonymous fifty-page pamphlet denouncing the British monarch and monarchy in general. Adam Smith publishes The Wealth of Nations. In May, George Mason drafts Virginia’s Declaration of Rights. Members of the Second Continental Congress sign the Declaration of Independence, which draws heavily from its Virginian counterpart. In July, George Washington takes command of the Continental Army. 1777 On November 15, the Articles of Confederation are formally endorsed by the Continental Congress; they are sent to the thirteen colonies for ratification. The Articles provide a system of governance during the upheaval of the Revolution. 1781 On March 1, the Articles of Confederation are ratified. In October, British General Charles Cornwallis surrenders to General Washington, ending military conflict. 1783 Jay is appointed secretary for foreign affairs. 1784 The Treaty of Paris, negotiated by John Jay, Benjamin Franklin, and John Adams, formally ends the Revolutionary War. 1786 In September, at the Annapolis Convention, which brings together delegates from five states, Alexander Hamilton promotes new laws governing interstate commerce; the meeting increases momentum in favor of a national convention to strengthen the Articles of Confederation. 1787 Congress agrees to amend the flawed Articles of Confederation. In May, the Constitutional Convention convenes in Philadelphia; the delegation drafts the U.S. Constitution, which is signed on September 17 and sent to the states for ratification. Amid widespread anxiety that the proposed government insufficiently protects individual liberty, the first Federalist paper is published in New York on October 27. Written by Hamilton, it appears under the pseudonym “Publius,” a pen name shared by Hamilton, James Madison,and Jay. By the end of the year, thirty Publius essays are in print. In December, Delaware, Pennsylvania, and New Jersey ratify the Constitution. 1788 The promotional campaign continues until the final Federalist essay is published on August 16. In January, Georgia and Connecticut ratify the Constitution.Massachusetts, Maryland, South Carolina, and New Hampshire follow. In May, a collection of the Publius essays is published and becomes known as The Federalist. Virginia ratifies the Constitution, and New York follows suit but recommends that a bill of rights be added. By August, all eighty-five Federalist essays are in print. In France, the Marquis de Lafayette drafts “The Declaration of the Rights of Man and of the Citizen.” 1789 In March, the U.S. Constitution takes effect and the first Congress of the United States is convened. On April 30, President George Washington delivers his first inaugural address. On June 8, Madison introduces the Bill of Rights amendments to the Constitution. North Carolina ratifies the Constitution. Washington appoints Jay the first chief justice of the Supreme Court. Hamilton is appointed secretary of the Treasury. Madison serves as congressman from Virginia in the House of Representatives. On July 14, the French Revolution begins with the storming of the Bastille in Paris. 1790 On April 17, Benjamin Franklin dies at the age of eighty-four. 1791 In England, Thomas Paine publishes the first part of Rights of Man, in part a response to Edmund Burke’s Reflections on the Revolution in France (1790). On December 15, the Bill of Rights, the name given the first ten amendments to the U.S. Constitution, is adopted into law. These individual rights, established in George Washington’s first term, address many of the concerns articulated by the Anti-Federalists 1792 George Mason, an Anti-Federalist, dies. 1793 On March 4, George Washington, elected to a second term, delivers his second inaugural address. A Proclamation of Neutrality, issued in April, codifies American foreign policy. 1794 Washington sends Jay on a diplomatic mission to quell tensions with Britain; the resulting understanding becomes known as Jay’s Treaty. 1795 During his absence Jay is elected governor of his home state of New York; he must retire from his seat on the Supreme Court in order to fill his new appointment. 1796 On September 17, George Washington delivers his farewell address. John Adams is elected the second president of the United States. 1797 Madison retires from Congress, returning to his estate, Montpelier, in Virginia. 1798 Congress passes the Alien and Sedition Acts, which restrict immigration and curtail press freedoms. The four laws are widely condemned as unconstitutional; Madison writes the Virginia Resolution, denouncing the laws. 1799 On December 14, George Washington dies. 1801 Thomas Jefferson is sworn in as the third U.S. president; he appoints Madison secretary of state. 1804 On July 11, Aaron Burr mortally wounds Alexander Hamilton in a duel on the cliffs at Weehawken, New Jersey; Hamilton dies the next day. 1809 Madison becomes the fourth president of the United States. 1812 The War of 1812 against Britain tests the resolve and abilities of the new U.S. government. 1814 The United States and Great Britain sign the Treaty of Ghent in Belgium, ending the War of 1812. 1815 Ignorant of the Treaty of Ghent, Andrew Jackson wins a decisive victory at the Battle of New Orleans 1826 On July 4, Presidents John Adams and Thomas Jefferson die. 1829 On May 17, John Jay dies at his home in New York. 1836 On June 28, the last of the founding fathers, James Madison, dies.",
        "char_count": 5606
      },
      {
        "heading": "Chapter 6",
        "text": "INTRODUCTION The greatest American contribution to world literature has come through the country’s originating: claims. Between 1776 and 1820, the most intense philosophical period of civic discourse ever known, a literature of public documents dominates intellectual creativity in the United States. It consists of pamphlets, orations, declarations, ordinances of expansion, bills of rights, petitions of toleration, constitutions of all kinds. and a handful of judicial opinions. The best of these works reach for national identity through claims of universal rights and faith in the dignity of humankind. The words they contain are the aspirations that have attracted so many to American shores. More concretely, the same writings create representative government as we know it and a continental republicanism previously unimaginable. The obvious capstones of this literature are the Declaration of Independence in 1776 and the Constitution of the United States in 1787. official texts honored throughout the world. Not far behind them. however, and a commentary on both, comes a collaboration of essays known as The Federalist. Printed first as ephemeral newspaper articles amid factional clamor but then as a two-volume book, it stands alone today as a practical guide to political theory and a sourcebook of civic understanding. Alexander Hamilton, James Madison, and John Jay were the three very different and mostly separate authors of the eighty-five papers that make up The Federalist. They proceeded under a general plan set by Hamilton. but they worked independently on individual assignments. The loose partnership would last ten months, from October 27, 1787, until August 16, 1788, and when it was done, the result, better than any other writing of the time, would come closest to articulating what the new and struggling United States might become. The Federalist took its direction and tone from the most vital dispute in American history. At issue was acceptance or rejection of the newly proposed Federal Constitution of 1787, and the debate over it was an acrimonious one. Citizens were being forced to make a choice between radically different conceptions of their country at a time when few observers could predict with confidence that the states would survive for long as one nation. We forget how controversial the Constitution was in the moment of its birth. The document that now governs the United States was drafted in secrecy by men who knew that they had acted beyond the mandate given to them. Sent as state delegates to Philadelphia in the summer of 1787 to discuss problems in the new union, they had been told to make any adjustments within the Articles of Confederation as the official compact of union. The Articles had been drafted in the anti-authoritarian moment and spirit of 1776. It was a companion document to the Declaration of Independence, and it left autonomy in the hands of the individual states. Nonetheless, five years would pass before the apprehensive states approved even this loose coalition, and they did so in 1781 only after many revisions by Revolutionary leaders who feared centralized authority. The framers of the Constitution in Philadelphia basically ignored these fears. Instead of tinkering with the arrangement, they junked the Articles of Confederation altogether and wrote out their own document of fundamental principles. When they were done, they had substituted a much stronger ideal of union than the suspicious compromisers of the original Confederation had contemplated or would have allowed. Nor was that all. When the framers in Philadelphia made their document public on September 17, 1787, after four long months of closed deliberation, they tacked on a string of non-negotiable demands. They insisted that their document, the new Constitution, be submitted unchanged by Confederation authorities to the states for ratification, that it be approved through state conventions for that purpose rather than through the existing state legislatures, that ratification require only a strong majority of the states rather than the unanimity stipulated under the original compact, and that their own deliberations remain secret and inviolable during debate over the document that they had written. Finally, the framers resisted any reconsideration by a comparable deliberative body of the kind that they had just conducted among themselves. When asked toward the end of the Convention about possible amendments through another general conclave because “it was improper to say to the people, take this or nothing,” Charles Pinckney answered for all of the framers when he replied, “Conventions are serious things, and ought not to be repeated.” 1 The early responses to the framers’ proposals ranged from uncertainty to outrage. If the Constitution was to be accepted, clearly much would have to be explained and quickly. The essays that make up The Federalist sought to be that explanation. They began to appear almost immediately. The first two anonymous newspaper essays were in print the month after the Constitution became public. The Federalist, in this sense, must be read as a partisan response to the anxiety that most early republicans felt as they tried to absorb the altered plan of union offered to them. The initial articles were treated, in fact, as political bluster for the popular press. When they continued to appear and accumulate, they won another dubious distinction: The eighty-five assembled papers would be the most protracted and prolix pamphlet series Americans had seen in an age of obsessive pamphleteering. Beleaguered opponents dubbed them the most tiresome production they had ever encountered. Supporters, of course, found higher qualities; a few even saw what the essays would become. When Thomas Jefferson, ambassador to France, read his own copy of The Federalist in Paris in late 1788, he called it “the best commentary on the principles of government, which ever was written,” a claim that holds up well today. 2 There is no other book in constitutional thought in any language quite like The Federalist for its careful and thorough blend of range, penetration, principle, structure, and practical implication. These minimal facts are important because they contain the puzzles that a reader today must solve to understand The Federalist . The first puzzle involves the original anonymity of the essays. Throughout their collaboration, Hamilton, Jay, and Madison hid behind the shared pen name Publius, after Publius Valerius, a founder of the Roman Republic. Resort to a pseudonym was a convention of the period among gentlemen of letters appearing in print, and classical reference was common in this regard. Even so, there was more to the choice of a name in this case than meets the eye. Why was this figure selected from the host of admired and better-known figures of antiquity? The original Publius was also known as Publicola—literally, “pleaser of the people”—and the Publius of 1787 ardently sought this identification for himself. The three authors belonged to the elite among early republican leaders, but they were not popular men, and they were defending a proposal that would curb the people’s power through a stronger central government. Why should the people bother to listen, much less accept, their arguments? The writers of The Federalist made themselves “Publius” in search of a common touch and bond with a general audience of citizens. Their efforts, while philosophically complex, would be couched in simple tones and a polemical style. How this adroit combination of sophistication and commonality worked is one measure of creativity in the Publius essays. Pleasing the people through the symbolic signature had another virtue. It covered differences between the collaborators. Better far to write as Publius than as Hamilton, the belligerent and often divisive upstart from the British West Indies, or as the genteel Jay, from the highest stratum of New York society, or as the painfully shy and scholarly Madison, from the squirearchy of Virginia, which he personally deplored. The writers knew they would have to fashion themselves beyond their own mundane reality, and their success raises a second major puzzle. Men of obvious talent but recent colonials, Hamilton, Madison, and Jay were relatively dispersed and parochial figures living on the outer limits of the English-speaking world. What enabled these very different men to come together effectively—so effectively that critics still argue over who wrote given sections of The Federalist and turn to statistical theory and computer analysis to bolster their competing claims of authorship? Once joined, how did these busy men of affairs transcend their situation as writers? How did they produce a timeless work of literature out of the political rancor of their moment? The remaining puzzles turn on the nature of influence. Publius spoke for the people but meant to curb their excesses in the body politic through federal authority. Does The Federalist confirm and save the Revolution or more deviously cap its broader intentions? Are the rhetorical strategies of inclusiveness to be taken seriously, or is Publius more realistically the spokesperson of a conservative elite? The Federalist is authoritative today as a legal citation in leading court cases, and it appears as a resource in every constitutional crisis. Where, in its pages, does the verbiage of wily politicians end and the statesmanship of proclaimed lawgivers take over? And who gets to make that determination? The Federalist had a limited impact on the ratification of the Federal Constitution except perhaps in New York, where the Constitution would be ratified by the narrow margin of thirty to twenty-seven votes in the state assembly called for that purpose. How does The Federalist become a universal source of national explanation? How can the modern reader take on such a dense text with pleasure and profit? Even eighteenth-century citizens complained of tedium when faced with this endless flow of newspaper articles, and it is the rare individual in any era who can pick up Publius and follow him straight through. How, then, should The Federalist be approached today? These puzzles are ones that every reader must solve in approaching a national text that grows slowly out of pamphlets dashed off in episodic bursts more than two centuries ago. They must be solved because no citizen of the world can afford to ignore The Federalist, despite its mysteries and arcane limitations. Its wisdom on common political problems cannot be gainsaid. Like every major work of political science and social theory, this one must also be understood with its integrities in mind. Value lies not in the ability to quote selectively from The Federalist, a favorite ploy in both politics and law, but in coming to grips with writings that envisage and then explain how a new kind of nation, an uncertain experiment at best, could thrive on the American strand. In the success of the United States, now the oldest republic in the world, Publius continues to speak to the twenty-first century, but his words offer more than confirmation. The reader will find a poignant series of cautionary tales in these pages. The many warnings about correct governance in The Federalist protect the rule of law and should be required reading for both ruler and ruled. The Creative Circumstance It is easier to describe the creativity that produced the literature of public documents than to explain it. The men who crafted national understandings wrote with strong beliefs in place. Their convictions can be summarized briefly: Principles could alter history. Good ideas would convince reasonable people everywhere of their merit. The right answers to problems would spread throughout the world. As writers, they assumed that the structure of thought was of a piece with knowledge, that the correct placement of language could encompass the most complicated and intractable of difficulties, and that eighteenth-century political theory could produce a better world for all of humanity. Most important of all, they thought they possessed the means to fulfill these goals in America. “Federalist No. 1” opened with a colossal claim: It seems to have been reserved to the people of this country to decide, by their conduct and example, the important question, whether societies of men are really capable or not, of establishing good government from reflection and choice, or whether they are forever destined to depend, for their political constitutions, on accident and force (p. 9). Forever? Everything was at stake for all peoples in such language. Knowledge would be the legacy of the New World with the United States of America as its leading exponent. These ideas are still afloat today, but early republican writers embraced them with an assurance that we can no longer match. John Adams, hardly an optimist but an expert in what he called “the divine science of politics,” believed so strongly in these assumptions that he wrote of being “sent into life at a time when the greatest lawgivers of antiquity would have wished to live.” Edmund Randolph, a man of uncertainties, could nonetheless open the Constitutional Convention by talking about how rapidly new knowledge would bring change. He argued that the framers in Philadelphia were in a much better position as lawgivers than the first patriots who wrote the Articles of Confederation a mere decade before. Those first drafters in 1776 had written their defective document “in the then infancy of the science, of constitutions, & of confederacies.” 3 The men of 1787 knew so much more! Where does this confidence in creating a dramatically better form of government come from? Why were these recent colonials so sure of their expertise as they contemplated saving the world? Four fundamentals contribute to their creativity, and each is a dominant element in The Federalist. First and counter-intuitively, Americans were more adept at writing out instruments of government than the English counterparts to whom they often looked. They had to be. There were no customs to call up in the New World, no established legal institutions to fall back upon. The first colonists had to draft formal compacts that would define acceptable behavior as they carved new communities out of the wilderness. Much was borrowed from English traditions, but everything had to be readjusted to fresh circumstances. Americans of succeeding generations, many starting over, also formalized their arrangements and with a growing appreciation for procedure and form. In literary terms, no writer composes a masterpiece on the first attempt; one learns from the sequent toil of each new composition. By 1787 early republicans had thoroughly mastered the craft of composing compacts. Every state except Rhode Island and Connecticut wrote, debated, and adopted a new constitution between 1776 and 1784. Seventeen constitutions in all were written during the course of the Revolution. The Federal Constitution would contain many innovations, but procedurally and generically it belonged to a familiar past and came out of a set of intellectual skills that few cultures in history could match. The Federalist, with its thorough grasp of constitutionalism, was part of a general sophistication in making officialdom available to the people. The ideals of the secular Enlightenment were a second factor in the writers’ creativity and reception. Belief in the progress of ideas and in the capacity of any rational person to benefit from them had a lot to do with an early American faith in the dissemination of knowledge. Thomas Jefferson would scorn all backward thinking when he wrote, “Thank heaven the American mind is already too much opened, to listen to these impostures; and while the art of printing is left to us, science can never be retrograde; what is once acquired of real knowledge can never be lost.” 4 Progress was a matter of better understanding; the proper writing would encourage order from below instead of having it imposed from above. Excitement over the spread of ideas also had its technological side, as Jefferson’s words indicated. The invention of the portable printing press made publication available everywhere; it created a republic of letters that knew no boundaries. Anyone who had access to print could become a member. The international scope of this republic of letters guaranteed that ideas could come from any stratum of society or any location. Needless to say, Revolutionary American writers benefited. Intellectuals in Europe looked to the new United States as a plausible solution to larger problems. It was no accident that the first edition to carry the names of the authors of The Federalist would appear in France in 1792, where another set of political leaders were struggling to bring order to their own revolution. The third source of literary self-confidence may seem the simplest. The success of the Revolution gave early republicans a worldwide subject and the assurance to write it. Defeat of the British and the heroes who accomplished it made for a fascinating story and not just in America. The triumph of revolutionary principles gave hope to the oppressed everywhere. Interested observers could see that the Revolution had been fought with the pen as much as the sword. They could see that principles had mattered. But, that said, admitting the relevance of principle raised a new question to be answered: Where would those principles lead next? Only three generations of American writers have ever held the immediate attention of Europe. The first settlers in the New World held on to that honor as emigrants who were still Europeans. Much later, in the 1920s, the novelists and poets of “the lost generation” would attain a similar cachet; they were voluntary exiles in Europe after performing as welcome allies in World War I. Between these two epochs, only the writers of the Revolutionary generation could easily see themselves as equal to European literati in their own time. Their radical experiment in government was thought to have lessons for the world, and they could count on an international audience for whatever they decided to say or write about it. A problem rather than a resource supplied the fourth basis of creativity in the literature of public documents. The problem was uncontrolled space. To what extent could one create social form out of “empty” land? Land as property was the measure of meaning and power in the Anglo-American world of the eighteenth century. What did one do when there was too much land not owned by anyone or, alternatively, huge chunks of it claimed abstractly by political claimants? The greatest anxieties in the early republic involved the open territory to the west of every state and the sometimes terrifying tribes of peoples already there. Who would seize these territories? The imperialism of neighboring states as well as foreign powers raised ugly suspicions on all sides. Some citizens were in favor of the incorporation of new territories; others were not. The plausibility of a large republic remained a question. The task of the writer in this situation was to make a virtue out of necessity. Publius offers a perfect example. “It has often given me pleasure to observe,” he would write in “Federalist No. 2,” “that independent America was not composed of detached and distant territories, but that one connected, fertile, wide spreading country, was the portion of our western sons of liberty” (p. 14). Nothing could have been further from the case in 1787, but the style and strategy of the writer were sound. Imagination was the main prerequisite in circumscribing a United States that no map could yet define. Early republican writers would use language to impose form and structure in the absence of concrete reality. Documents like the Northwest Ordinance of 1787 projected ideal societies long before early republicans could build them. The Federalist depended on the same skill. It imposed abstractions over a host of evils and made claims that would become self-fulfilling prophecies. The Collaboration The four impulses of creative confidence just noted fueled the collaboration. Hamilton, Jay, and Madison shared these impulses to an extraordinary degree. All three men possessed detailed knowledge and practical experience in the writing of official documents. All three shared the optimism that made self-evidence in ideas the mode of address to enlightened citizens of the world. All three held positions of high honor and success in the Revolution, and all three believed that only a new and proper structure could save a failing union on the verge of chaos and collapse; correct form was missing, and only the new “frame” of the proposed Constitution could supply it. Even Hamilton, easily the most cynical of the three authors, would write in “Federalist No. 11” that ”wisdom” was the key in making America ”the admiration and envy of the world” (p. 62). He spoke of grand opportunities: ”It belongs to us to vindicate the honor of the human race” (p. 65). Stylistic cohesion came from yet another source. Each of the three authors of The Federalist became gentlemen of letters through a college education, a rarity of the times. Hamilton and Jay attended King’s College, which later became Columbia University, and Madison graduated from the College of New Jersey, soon to become Princeton. The elevated tone, careful civility, abstract claims of felicity, and stresses on decorum and candor of The Federalist were typical features in the eighteenth-century epistolary tradition of college clubs and literary circles. These virtues in writing were also signposts of station and, therefore, of authority in communal affairs. As important in its own way as the ideas presented in The Federalist, the etiquette of eighteenth-century writing secured the uniformity of style that everyone notes about the collaboration and its claim to authority. Anonymity was also a complicated virtue in such writing. A true gentleman of letters wrote under a veil of secrecy in public and only then if the writing could be shown to assist the common good. An inner circle of peers generally knew the identity of an author and contributed ideas and corrections during private circulation of a manuscript before encouraging actual publication. It followed that publication was often understood in collective terms. An assertive claim of personal authorship could be dismissed as a vulgar trait obscuring the civic goal that justified publication in the first place. In perhaps the most extraordinary example of the phenomenon, no one beyond intimates knew that Gouverneur Morris composed the finished draft of the Constitution until forty years after the event. These mannerisms of “polite letters” are forgotten or satirized today as empty courtesies, but they were the stabilizing sources of sequestered negotiation and compromise in early republican politics. Neither the United States Constitution nor The Federalist could have been written without these accepted standards. Who can imagine a comparable degree of respected confidentiality in a major political gathering today? Among the collaborators, Alexander Hamilton was the moving force, the organizer, the dominant contributor, the figure who arranged for publication in four of five New York City newspapers, and the editor who gathered the individual papers into book form. By conservative estimate and discounting minor addenda from the other authors, he composed fifty-one of the eighty-five papers himself, with Madison writing twenty-nine, and Jay adding just five more. Hamilton had argued for a new constitution and the means to achieve it as early as 1780. “If a Convention is called,” he wrote then, “the minds of all the states and the people ought to be prepared to receive its determinations by sensible and popular writings.” 5 Typical of the man, he knew exactly what had to be done long before it could happen. Seven years later, The Federalist essays would be those “popular writings” and more. It would be Hamilton, in an added touch of creativity, who would conceive of the ephemeral newspaper series as a permanent book. Never just a thinker, the restless Hamilton seized initiative at every opportunity. He had been one of the prime architects of the Constitutional Convention, personally drafting the resolution in 1786 that called for it to meet in Philadelphia and enlarge the powers of the Confederation. No one was better suited to write a commentary on the new Constitution. Here, in effect, is another answer to the power and achievement of The Federalist. Among the founding generation there were three persons of unambiguous genius. The rest were figures who fortuitously prepared for the unexpected roles that they had to play and then played them well. Genius, in these terms, refers to individuals who, given half a chance, would rise to prominence in any context through foresight, ability, and unusual qualities. The first two intellects of note were, of course, Benjamin Franklin and Thomas Jefferson. The third was Alexander Hamilton, and he had the farthest to climb, beginning as he did in the lowest level of society and coming from a disdained minor province beyond the thirteen colonies. Of illegitimate birth, Hamilton began in an unsupportive, dysfunctional, and contentious family in Nevis, in the British West Indies. He was on his own at the age of twelve, largely self-taught, and rose entirely through his own prowess and energy. No one at any point needed a second glance to see the brilliance in this outgoing, often argumentative youth; those with whom he worked learned that he could make the most of any opportunity. Hamilton’s talents describe only part of him, but they are worth summarizing in thinking about The Federalist. He wrote with amazing rapidity and with one of the neatest and most stylish hands of the age. Even today an observer can read one of Hamilton’s now withered letters while standing some distance away from them. These were distinct advantages in the haphazard and often desperate needs of eighteenth-century newspaper publication. Hamilton was always available with something written that was more than sensible and easily set into print. Only such a man could have sustained the pace that occasionally required two and three long newspaper essays a week from Publius. Hamilton saw the nature of problems just as clearly and quickly as he wrote about them and seems to never have been without an answer to them. Ambitious to a fault, he knew how to make others around him better than they were—not least, George Washington, whom he served as aide-de-camp in the Revolutionary Army from 1777 to 1781. Just twenty-two, with the rank of lieutenant-colonel at the time and already a recognized pamphleteer in the propaganda wars of the Revolution, Hamilton would prove of inestimable value throughout Washington’s career as an organizer, strategist, and writer. No one found or articulated the root of a matter more rapidly than Hamilton. Typically, he would demand and receive an examination and then gain admission to the New York Bar in 1782 after just three months of legal study and immediately take his place as one of its most brilliant members. There is, however, something more difficult to grasp in the brilliance of Hamilton, and it explains the first virtue of The Federalist . As his foresight over the need for a constitutional convention implies, Hamilton possessed a singular knack for rearranging the different pieces of a dilemma into a farsighted solution. One can see it in his Revolutionary War letters over key issues of military strategy. It appears again when, as the country’s first secretary of the Treasury, he organized the economy and national bank. His Report on Manufactures in 1791 would be uniquely prescient in mapping the relations of government to economic growth and private capital. In virtually every debate of note, Hamilton possessed a better grasp of the economic and social variables at work in America than others. Call it a scrutiny that led to comprehensiveness of view. Hamilton would use it to his advantage in the collaboration of The Federalist by making sure that every imaginable aspect of constitutional controversy, whether near or far in the distant future, was raised and answered. It is hard to find a serious governmental problem in the history of the United States that is not first mentioned here. John Jay wrote just five of The Federalist essays, but his role in the collaboration was more significant than mere numbers suggest. Forty-one years old in 1787, Jay was a better-known and more polished politician and diplomat than either Hamilton at thirty-two or Madison at thirty-six. No doubt Hamilton asked him to join the enterprise because of Jay’s greater reputation and ideological compatibility as another conservative New York lawyer who favored the new Constitution. Jay had been active in the defense of New York during the Revolution and in writing the first New York state constitution. He had been instrumental in getting George Washington to attend the Constitutional Convention in Philadelphia, and he already had served effectively as chief justice of New York, president of the Continental Congress, ambassador to Spain, and one of the three peace commissioners to negotiate and sign the Treaty of Paris ending the war with England in 1783. Jay also had worked hard and long as the permanent foreign secretary of the United States while other positions rotated under the Articles of Confederation. This experience gave him greater knowledge than others in diagnosing the weaknesses of the Confederation as well as unique credibility in public debates on the subject. The major contribution of Jay came early in the collaboration. He wrote Essays Nos. 2, 3, 4, and 5 of The Federalist before bowing out because of illness, and then, much later, Essay No. 64. His first four offerings dealt mostly with the dangers of foreign influence and the need for a stronger union to cope with them; his last essay explained the Senate’s role in the treaty-making power. But if workmanlike on the facts, Jay’s essays accomplished something far more important for the overall tone and direction of the collaboration. Alexander Hamilton had been mired in petty squabbles over the new Constitution even as a delegate at the Convention. Immediately after, he became the instigator in vitriolic newspaper exchanges with the opposition, and it showed in his own first essay introducing the collaboration. Deeply embroiled, Hamilton couldn’t help himself even though he realized that a higher register was called for in The Federalist. “Federalist No. 1” would devote whole paragraphs to the ”obvious interest,“ perverted ambition,” and “preconceived jealousies and fears” of the ”classes” of men who opposed the Constitution. It called for objectivity but compulsively returned again and again to enemies guided by ”ambition, avarice, personal animosity, party opposition, and many other motives, not more laudable than these” (p. 10). It was not a tactic that could hope to win friends and influence people to accept the new Constitution. Jay would quell these tendencies of party spirit with a more inclusive reading of the problem in ratification. In “Federalist No. 2” he welcomed all parties into the new union through “sedate and candid conversation.” Instead of acrimony, a new aesthetics of ratification and goodwill through “isible union” dominated Jay’s contributions. Citizens, in Jay’s view, would stop arguing to the extent that they saw their interest clearly. In ”Federalist No. 64,” he would write: ”In proportion as the United States assume a national form, and a national character, so will the good of the whole be more and more an object of attention” (p. 360). The opposition was not perverted by ambition so much as it was sadly mistaken. In Enlightenment terms, the problem of those who opposed the Constitution was ignorance and a simple lack of education. Jay urged everyone to learn to belong together instead of standing apart. Here, as well, was the adroit creation by Publius of a new and more favorable meaning of the word “federal.” Originally, the term provided an antidote to proponents of further nationalism and consolidation under the Confederation. One of the boldest rhetorical achievements of The Federalist would be to attach a new meaning of “federal” to the proposed Constitution through its self-proclaimed “federalist” supporters and writings. In the wake of Publius, all opponents to the Constitution would be “antifederalists,” a designation that quickly carried the implications of gloomy partiality for something less than joyous union with other Americans. Always a fast learner, Hamilton would see Jay’s strategy and adopt it as his own in subsequent papers. His abrasive tones would resurface, but Jay’s composure and equanimity in the positive claim of union, also more in keeping with Madison’s temperament, would guide and control the tone of The Federalist henceforth. James Madison, as the last to join, is harder to figure as a logical collaborator until one looks at the facts. Madison and Hamilton were temperamentally unsuited for each other and would become political enemies in 1789, during George Washington’s first administration, but there was a great deal to hold them together in 1787. It made sense for Hamilton to reach out to a leader from another state, especially Virginia, in his nationalist project of union. Madison was available in New York after the Convention as a representative in Congress. Previously, the two men had joined as instigators of the Annapolis Convention of 1786, which brought together delegates from five states to discuss the economic problems of the union and ended by calling for a more general constitutional convention, and they then became firm allies as delegates in Philadelphia the following year. Both were strong unionists, and Madison, by common consensus even then, had been the guide for others in framing the Constitution in Philadelphia. William Pierce, a delegate from Georgia, wrote thumbnail sketches of the other framers in Philadelphia and found Madison to be “the best informed Man of any point in debate. The affairs of the United States, he perhaps, has the most correct knowledge of, of any Man in the Union.” 6 This evaluation would be borne out again in The Federalist. For while Hamilton had the tougher and more comprehensive view of politics, Madison would prove the deeper reader of theoretical possibilities and would provide philosophical heft. A scholar first and man of affairs only after, the reclusive Madison had schooled himself with great care in the history of congresses and confederacies. He had identified all of the problems and knew how to create imaginative solutions to them. Today Madison’s first contribution to the collaboration, “Federalist No. 10,” is accepted as a separate tour de force within the collection. It gave, among other things, a new philosophical answer to the problem of an extended republic. Madison claimed that an enlarged sphere with proper representation could best balance competing interests and protect minorities from majoritarian pressures. He also fused federalism and republicanism as joint operations under the Constitution and soothed fears about the bugaboo of the age, namely factionalism. “Liberty is to faction, what air is to fire,” Madison wrote in one of his boldest strokes, “an aliment, without which it instantly expires” (p. 53). Liberty, like fire, was dangerous when uncontrolled but a virtue when properly exercised. In words that would gain a life of their own in the American polity, “Federalist No. 10” argued that “diversity” had to be celebrated instead of squelched. Factional differences were inevitable as a practical matter, and recognition of their constant presence brought a moral component, toleration, to bear on how a citizenry should deal with the nature of conflict. There was room and opportunity in America for all to get along. Admonitions for every age followed. Madison warned that “those who hold and those who are without property have ever formed distinct interests in society.” Class warfare was always possible because of “the unequal distribution of property” and “interfering interests.” Likewise, enlightened statesmen would “not always be at the helm” to manage affairs. Madison’s answer to factionalism and conflict, like Hamilton’s but with deeper philosophical perception, turned on the proper structure and accepted routine of governmental operations. Neither Madison nor Hamilton had been completely happy with the Federal Constitution that emerged from the Convention, and both saw problems in its makeup. But they had been delegates together in Philadelphia, and the refining processes of debate and disagreement there had turned them into realists concerning what was possible. The experience had taught them how to reinforce each other’s arguments through separate and not always compatible lines of inquiry. They knew enough not to get in each other’s way. Here was the heart of the collaboration. Both men accepted the same larger predicament to be solved. How, in Madison’s words in “Federalist No. 37,” could one combine “the requisite stability and energy in government with the inviolable attention due to liberty and to the republican form” (p. 196)? Wouldn’t citizens always disagree about where that line should be drawn? The two major collaborators had different approaches, but Madison would answer these questions for both of them in the very next paper. He observed in “Federalist No. 38” that the legendary Greek lawgiver Solon “had not given to his countrymen the government best suited to their happiness, but most tolerable to their prejudices” (p. 202). Citizens could recognize their interests only through the customary forms available to them. The real question was whether those forms could be rearranged to serve the nation better. Expertise and artifice were needed. In “Federalist No. 51,” Madison would build the conflict of interests that he saw into the very structure of government by providing the separate branches of government “the necessary constitutional means, and personal motives, to resist encroachments of the others.” Hamilton and Madison were always ahead of their opponents in the ideological battle over ratification, and they had schooled themselves in the moderating theory of human nature that all good government requires. “But what is government itself, but the greatest of all reflections on human nature?” Madison opined in “Federalist No. 51.” That nature was fallen, but not without possibilities. “If men were angels, no government would be necessary,” Madison reasoned. “If angels were to govern men, neither external nor internal controls on government would be necessary.” Alas, there were no angels, and human participants could not be expected to act like them anyway. A tougher, more realistic arrangement of “opposite and rival interests,” had to supply “the defect of better motives.” The “great difficulty” in this balancing process was also clear to both writers: “You must first enable the government to control the governed; and in the next place oblige it to control itself” (p. 288). How was this program of control to be managed? Technique would replace temperament. The guarded blend of pessimism and optimism in “Federalist No. 51” is one of the most endearing traits of Publius throughout the collaboration. Consider the qualifiers in his reply to the problem just stated: “Happily for the republican cause, the practicable sphere may be carried to a very great extent, by a judicious modification and mixture of the federal principle ” (p. 292). What was necessarily and crucially “practicable” in the design of government had to be ”judicious” and carried to a limited but “great extent” through “modification” and “mixture.” The passage is awash in misgivings paired to a contrasting confidence that will thwart danger through “the federal principle.” Anxiety answered by expertise struggle with each other throughout the collection, and part of the fun for a reader is watching Publius win out over difficulties that are psychological as well as political. The Federalist could succeed because it was itself “a judicious modification and mixture” of collaborators who understood and used each other effectively. Hamilton’s bulldog intensity and inclusive drive, Jay’s international flavor and aplomb, and Madison’s learned approach to political theory came together in common language that all three could accept under the one name of Publius. Belief in the moment cemented their alliance. All of them wrote as Jay did in “Federalist No. 2,” that rejection of the Constitution “would put the continuance of the union in the utmost jeopardy” (p. 17). There was work to be done, and Publius held the keys to communal greatness in his hands! This urgency held the three writers together; it made them greater than the sum of their parts. Hamilton, often impatient in relations, deserves special credit in his choice of colleagues. An overlooked attribute of genius consists in knowing when to call upon others to raise the level of achievement. The Success of The Federalist How did The Federalist transcend time and place to become a touchstone in republican theory as well as a guide for the United States? Three aspects of the pamphlet series turn this thoroughly American book into a universal text. First, the collected essays succeed as a comprehensive interpretation of the Federal Constitution. Second, they define republicanism effectively, culling examples from history to refine the concept. Third, they wrestle courageously with the riddle at the base of all government: namely, where must authority control and where should authority give way to the independent impulses of the controlled? Modern readers should study these three facets for themselves. At its best, The Federalist is a treatise on what political science can do and mean for any society. If calling it a treatise makes the book sound dry, the designation changes dramatically depending on where readers stand within their own situation. For some, the book has obvious panegyric or congratulatory significance; for others, it is a monody, a lament over lost or unattainable opportunities. Either way, Publius writes out important aspirations in human understanding. The comprehensiveness for which Hamilton is largely responsible serves a number of ends that have been useful to later generations. The thorough, even dogged, reach of The Federalist to all parts of the Constitution provides a check on misinterpretation of specific provisions in it. To the extent that The Federalist posits a seamless fabric to be mastered, it reminds everyone of the strategic scale required for constitutional interpretation. Inclusiveness simultaneously illustrates the structural relation of interdependent parts, a reminder of the complexity of assigned tasks in the federal government. Then, too, The Federalist provides a language of celebration as it explains the Constitution. Publius naturally wallows in confirmative prose as part of his quest for ratification, and later supporters have not hesitated to crib from him. Each of these holistic traits aids judicial interpretation as well as general legal scrutiny of national problems. The American judiciary looks to Publius’s lofty tones to bolster its own rhetoric, and it relies on his specific words in “Federalist No. 78” for the doctrine of judicial review. There we are told that the courts have the duty and obligation “to declare all acts contrary to the manifest tenor of the constitution void” (p. 429). The Constitution itself is silent on the question of judicial review; not so Publius, who thinks of this power as the ultimate guarantee of limited government. The Constitution leaves many aspects of governance to implication; Publius offers fulsome explanation. Others interpret the Constitution, but extensive commentary in The Federalist by two writers who attended the Constitutional Convention as framers provides unique authority. Hamilton made absolutely sure that everyone would see the scope of his project immediately. In ”Federalist No. 1” he pledges “to give a satisfactory answer to all the objections which shall have made their appearance.” He promises to include everything “that may seem to have any claim to your attention” (p. 12). Constitutional theory prides itself on seeing the whole picture. Often enough, its proponents find their controlling image of that picture in the pages of The Federalist. The second aspect of enduring success in The Federalist, its definition of republicanism, serves a wide range of political theory and debate. In “Federalist No. 9” Hamilton expresses his “horror and disgust” over republicanism in its ancient forms, “the petty republics of Greece and Italy.” Fortunately, modern knowledge in “the science of politics” has made possible a “more perfect structure” in current republics. The institutional innovations of eighteenth-century republicanism—innovations ”not known at all, or imperfectly known to the ancients“—include distribution of power into distinct departments, legislative checks and balances, an independent judiciary holding office during good behavior, and representation of the people in legislatures by deputies of their own election. More succinctly in “Federalist No. 39,” after dismissing all previous theories on the subject, Madison defines a republic as “a government which derives all its powers directly or indirectly from the great body of the people; and is administered by persons holding their offices during pleasure, for a limited period, or during good behaviour” (p. 210). But if the ideals of Greek and Roman republics were corrupt in practice, what did the definitions of Hamilton and Madison mean for actual practice by a republic in the modern world? Publius was not always sure, but his need for the definition flowed from a further assumption. Only a “strictly republican” form of government would tally with “the genius of the people of America.” Madison would take up in earnest the deeper problem in “Federalist No. 39.” His task here was to convince Americans that a government with both federal and national components could still be termed “strictly republican” because the new Constitution left supreme authority in the people. Other so-called republics—including Holland, Poland, and England—had fallen short in this regard. Madison was quite insistent on the point and its extent. “It is essential to such a government,” he wrote, “that it be derived from the great body of the society, not from an inconsiderable proportion, or a favoured class of it” (p. 210). But this definition raised an unresolved worry in The Federalist. What, after all, was to be the proper role of the people in the performance of government, and would they accept necessary limitations on their authority? Publius hesitates over the questions, and his squeamishness leads into the third universal claim of The Federalist on modern sensibilities. What was the connection between the authority of government and the liberty of the people? How should deference and democracy come together? Not very long after ratification, Madison would reveal just how troubled the framers’ invocations of the people had been in 1787. How could their proposal for a much stronger government also produce a freer people? Why wasn’t this a contradiction in terms, as many anti-federalists would claim? “Every word of [the Constitution],” Madison revealed in 1792, “decides a question between power and liberty.” 7 Every word? The claim could be true only in the knowledge of a complete structure that kept everything in place and only if power and liberty were to be held in eternal tension with each other. Publius would wrestle with the role of the people more than any other problem of government. Hamilton, always in favor of stronger authority, openly feared emphasis on the people’s rights as early as “Federalist No. 1.” The people’s “zeal for liberty” was “more ardent than enlightened,” he would write again in “Federalist No. 26” (p. 140). What was wanted from the people—and Hamilton would put it in capital letters in ”Federalist No. 22”—was their “CONSENT” (p. 124). Their role was to receive. They agreed to be governed in the right way. Hamilton would hope against hope in “Federalist No. 35” that the lower orders in society would simply defer to the upper class in government as their “natural patron and friend.” More thoughtful, Madison pinned his own hopes of control on the structured dispersal of representation and the check that a detached Senate of worthies would exercise over the more popular House of Representatives, but he was just as worried. He acknowledged in “Federalist No. 49” that the people were given to passions more quickly than reason and that those passions “ought to be controlled and regulated by the government” (p. 283). Yet he was just as convinced in ”Federalist No. 37” that there could be no justice in society without liberty. The greatest problem in the Convention and, hence for Publius, involved “combining the requisite stability and energy in government, with the inviolable attention due to liberty, and to the republican form” (p. 196). If there was acrimony over these combinations, it was because people would diverge over “the difficulty of mingling them together in their due proportions.” Popular government could be consensual only if power was placed in “a number of hands” and if the powerful were “kept in dependence on the people.” The interesting questions for modern readers revolve around these variables in defining and maintaining a truly republican government. Have the due proportions between power and liberty been maintained in the modern nation state? Are the far more powerful and isolated leaders of today kept in dependence on the people? Has the evolution of the American empire, a phrase used often by both Hamilton and Madison, changed the meaning and definition of republicanism itself? The delineations of republicanism, power, and liberty in The Federalist are tools for testing the health of any government. A reason for reading with care lies here. If Publius can insist that “mingling” power and liberty is a balance difficult to achieve, the modern reader should join him in searching the fragile dynamics in that difficulty. Balances are susceptible to the unfolding of circumstance. One of many admonitions from Publius would come over this issue of maintenance. In “Federalist No. 48,” he warns all future citizens that “a mere demarkation on parchment of the constitutional limits of the several departments, is not a sufficient guard against those encroachments which lead to a tyrannical concentration of all the powers of government in the same hands” (p. 279). How Should The Federalist Be Read Today? The first task of any reader must be to appreciate the organization of The Federalist for what it is. Hamilton presents his overall plan for the collaboration in “Federalist No. 1,” and he holds the partnership of writers to that understanding across the ten months of haphazard newspaper production and political adjustment. The breakdown of subjects covered by the full pamphlet series falls into six basic units: Nos. 1—14 discuss the importance of a strong union to safety and prosperity. Nos. 15—22 describe weaknesses and problems in the current Confederation. Nos. 23—36 explain and justify the powers required for a more energetic union. Nos. 37—51 cover the Constitutional Convention and define the new federalism. Nos. 52—83 analyze the branches of government: the House of Representatives and federal election system (52—61), the Senate (62—66), the Executive (67—77), and the judiciary (78—83). Nos. 84—85 answer miscellaneous objections and appeal again for ratification. Historians, political scientists, biographers, constitutionalists, politicians, and the student of civic affairs will naturally approach each unit in different ways. The Federalist is inevitably a digest to be mined by specific interests. But every reader, whether specialized or general, should remember that Hamilton designed the series as an urgent plea against a sea of troubles. If his strategies were controversial in their time, they belong to conventional wisdom today, and there is a problem in this. The very success of the plan can blind one to the intricate strategies that made it successful. It follows that the second task of the interested reader must be to entertain a certain suspension of disbelief. Publius emerges in all of his creativity only if he is regarded as a persona crafted for crisis and made to think hard about the difficulties that he must encounter as a model citizen. It helps to think of Publius as the nation’s first significant fictional character—predating Washington Irvings Rip Van Winkle by more than three decades. The narrator of The Federalist develops in episodic ways and through moments of stress across the collaboration, and these patterns can help to hold a reader’s interest. Essays No. 1-22 of The Federalist contend with the anxieties that pervade Revolutionary America as colonials turn themselves into the first uneasy citizens of a republic. They are marked by a curious manic-depressive tone in argument. Gloom and gladness chase each other across the page in “the dark catalogue of our public misfortunes” under the Confederation. In “Federalist No. 15,” Publius comes close to despair: “The frail and tottering edifice seems ready to fall upon our heads, and to crush us beneath its ruins” (p. 86). These same essays describe the depressing history of failed republics and confederacies from antiquity to the present. Yet Publius is confident that he can change history with “a different prospect.” He says he has “the cure for which we are seeking.” Mostly, this unit is the place to study Publius’s discovery of himself and the collaboration’s achievement of a tonal equanimity that will disarm frustrated opponents. Essays No. 23—36 present the case for greater energy in the union, and they are understandably defensive as they joust with the status quo and try to answer objections from the states over centralized authority. Publius feels his way slowly, though right away in “Federalist No. 23” he introduces the theme of this unit: “the quantity of power necessary” for such unpopular measures as military defense and taxation. He worries openly in ”Federalist No. 26” that “we shall never be likely to make any material change for the better.” “Federalist No. 31” then points to the intractable nature of people set in their ways and to the need to proceed with caution as “a necessary armor against error and imposition.” Hamilton is the author of this entire section, and he believed more strongly than his partners in the legitimacy of power, but he seems strangely handicapped in arguing for it as a general need. ”Federalist No. 31” reveals his frustration: “The moment we launch into conjectures about the usurpations of the federal government,” he complains, “we get into an unfathomable abyss, and fairly put ourselves out of the reach of all reasoning” (p. 166). This unit of The Federalist strives to rise above its negative terms, and it illustrates an interesting feature of the emerging rhetoric in American nationalism. Few political figures have wanted to identify themselves with powerful government after Thomas Paine convinced the country in 1776 that government “is but a necessary evil” and “the badge of lost innocence.” 8 Madison takes over in “Federalist No. 37,” and although he too complains about difficulties, he lifts Publius out of an incipient despond. Essays No. 37—51 are Madison’s, and this more reflective-minded version of Publius brings three great positives to bear on the problems of the union. He finds a remarkable and saving altruism in the framers of the Convention (many of whom were war heroes), he tempers Hamilton’s earlier calls for power with more attention to the goal of liberty, and he adjusts an independent federalism to a national federalism under the proposed Constitution. Notable rhetorical range supports all three assertions. Madison, who obviously knew better from his own experience, expresses “wonder” and “astonishment” over “a unanimity almost as unprecedented as it must have been unexpected” in the Constitutional Convention. 9 This claim of unanimity appeals somewhat cynically to a bible culture steeped in Revolutionary ardor. “It is impossible, for the man of pious reflection,” Publius exclaims, “not to perceive in it a finger of that Almighty Hand, which has been so frequently and signally extended to our relief in the critical stages of the revolution” (p. 200). More important in the run-up to the present is the changing meaning of federalism offered by Madison in these fourteen essays. “Federalist No. 39” conflates federalism and nationalism to such an imaginative extent that the Constitution becomes “in strictness, neither a national nor a federal Constitution, but a composition of both.” Publius is perhaps most boldly creative here. Anyone interested in current political battles over whether state or federal authority should control the country will want to study these essays with particular care. Although Madison contributes early on, Hamilton is again the dominating force of the next and longest unit of The Federalist, Essays No. 52-83. These papers cover the specific powers and checks on the three branches of government, and they do it in impressive detail. Publius is in full cry in these sections as an analyst of politics, and the subject matter suits Hamilton well. His legalistic precision in these papers makes him a commentator any time the branches of the federal government come into conflict or a specific branch is accused of overreaching its authority. To be sure, Hamilton writes more with ratification in mind than his own theory of power politics, but he does it with consummate skill—so much so that the theory of checks and balances that it contains are much more than a theory in these pages. Hamilton is a serious student of institutions. He sees how they must work and the dangers in each. Effort, insight, and calculation over the particulars combine here to give us the Publius that most readers remember. Hamilton’s conclusion to The Federalist, Essays No. 84 and 85, brings another change in tone and direction. These papers are the work of an author who has been writing alone over the last twenty contributions to the collection, and he is away from the influence of his more conciliatory colleagues. In any case, Publius reverts here to the belligerence of “Federalist No. 1,” once again taking full aim at opponents, real and imaginary. He sees just two kinds of Americans in the end: “sincere lovers of the Union” and “enemies to a national government in every possible shape.” These last words magnify an overwhelming foe, and they are the last ones that Publius will speak. Hamilton’s anxieties have returned in full force. Back where he was in the first essay, he reiterates “the awful spectacle” of failure and gives yet another catalogue of horrors, including civil war, anarchy, perpetual alienation, demagoguery, and military despotism. The objections of others have come to annoy instead of interest Publius in the end. He has exhausted himself and lost all patience with his opponents. These last essays sweep away reasonable inquiries about the need for a bill of rights in the proposed Constitution and sneer at worries from the strapped states about the added expense of a stronger central government. Nothing pleases this final figure, and the nature of his efforts expose him for what he always has been, a writer uneasy in his own skin. Closing down the series in “Federalist No. 85,” Hamilton pauses rather awkwardly, aware of his predicament. He openly apologizes for “intemperances of expression which I did not intend” but continues to write on intemperately nonetheless. “I have frequently felt a struggle between sensibility and moderation,” he confesses (p. 483). These admissions are illuminating. Hamilton could be such a force in an era of volatile change precisely because of his personal sense of dislocation. He is, in consequence, the ultimate puzzle of his production, a figure for every reader to conjure with. Just a little earlier in The Federalist, we receive a glimpse of what drives this impossibly energetic and difficult man. His ambition was a goad, and the basis of it surfaces in an unguarded moment. As Publius in “Federalist No. 72” Hamilton writes of converting the desire for reward into service by making interest coincide with duty. First on his list of interests is “love of fame, the ruling passion of the noblest minds” (p. 401). Fame comes first because it will “prompt a man to plan and undertake extensive and arduous enterprises for the public benefit.” Hamilton made no secret of his desire for this brand of glory, and it is only fair to give him his due. Publius is a crowning achievement. For whatever else The Federalist appears to be, it fits its creator’s own exacting standards. It is an extensive and arduous enterprise for the public benefit, and it deserves the fame that it receives. Robert A. Ferguson is George Edward Woodberry Professor in Law, Literature, and Criticism at Columbia University; he teaches in both the Law School and the English Department. His books include Law and Letters in American Culture, The American Enlightenment, 1750—1820, and Reading the Early Republic. He is currently at work on a book about courtroom trials as rituals in a republic of laws. Notes 1 Max Farrand, ed., The Records of the Federal Convention of 1787, 4 vols., 1911; revised edition, (New Haven, CT: Yale University Press, 1966); for this quote, see vol. 2, p. 632. 2 Thomas Jefferson to James Madison, November 18, 1788, in Thomas Jefferson, The Republic of Letters: The Correspondence Between Thomas Jefferson and James Madison, 1776—1826, 3 vols., edited by James Morton Smith (New York: W.W. Norton, 1995), vol. 1, p. 567. 3 John Adams, “Thoughts on Government,” in Adrienne Koch, ed., The American Enlightenment: The Shaping of the American Experiment and a Free Society (New York: G. Braziller, 1965), pp. 246, 250, and Farrand, ed., The Records of the Federal Convention, vol. 1, p. 18. 4 Thomas Jefferson to William Green Mumford, June 18, 1799, in Koch, ed., The American Enlightenment, pp. 340-341. 5 Alexander Hamilton to James Duane, September 3, 1780, in Koch, ed., The American Enlightenment, p. 571. 6 Farrand, ed., The Records of the Federal Convention, vol. 3, p. 94. 7 National Gazette, January 19, 1792; quoted in James Madison, The Complete Madison: His Basic Writings, edited and with an introduction by Saul K. Padover (New York: Harper and Brothers, 1953), p. 335. 8 Thomas Paine, Common Sense, in Philip S. Foner, ed., The Complete Writings of Thomas Paine, 2 vols. (New York: Citadel Press, 1945), vol. 1, p. 4. 9 Publius exaggerates here in “Federalist No. 37.” Three leaders of the Convention—Edmund Randolph, George Mason, and Elbridge Gerry—refused to sign the Constitution at the end, and half a dozen other dissenters left the Convention before its end. The claim of unanimity is not even true by state. Alexander Hamilton’s signature could not stand for New York in the absence of the two other delegates, Robert Yates and John Lansing, Jr., both of whom had left earlier in protest.",
        "char_count": 63859
      },
      {
        "heading": "Chapter 7",
        "text": "PREFACE TO THE GIDEON EDITION (1818) The present edition of the Federalist contains all the numbers of that work, as revised by their authors; and it is the only one to which the remark will apply. Former editions, indeed, it is understood, had the advantage of a revisal from Mr. Hamilton and Mr. Jay, but the numbers written by Mr. Madison still remained in the state in which they originally issued from the press, and contained many inaccuracies. The publisher of this volume has been so fortunate as to procure from Mr. Madison the copy of the work which that gentleman had preserved for himself, with corrections of the papers, of which he is the author, in his own hand. The publication of the Federalist, therefore, may be considered, in this instance, as perfect; and it is confidently presented to the public as a standard edition. Some altercation has occasionally taken place concerning the authorship of certain numbers of the Federalist, a few of those now ascertained to have been written by Mr. Madison having been claimed for Mr. Hamilton. It is difficult to perceive the propriety or utility of such an altercation; for whether we assign the disputed papers to the one or to the other, they are all admitted to be genuine, and there will still remain to either of these gentlemen an unquestioned number sufficient to establish for him a solid reputation for sagacity, wisdom, and patriotism. It is not the extent of a man’s writings, but the excellence of them, that constitutes his claim upon his contemporaries and upon posterity for the character of intellectual superiority: and, to the reader, the difference in this case is nothing, since he will receive instruction from the perusal, let them have been written by whom they may. The present moment may be regarded as peculiarly favourable for the republication of this work. Mr. Hamilton is dead; and both Mr. Jay and Mr. Madison have retired from the busy scenes of life. The atmosphere of political passions through which their principles and actions were lately viewed has disappeared, and has been replaced by one more pure and tranquil. Their political virtues are now manifest and almost universally admitted. Time, which tests the truth of every thing, has been just to their merits, and converted the reproaches of party spirit into expressions of gratitude for the usefulness of their labours. It is to be hoped that neither a mistaken zeal of friendship for departed worth, nor an inclination to flatter living virtue, will induce any one to disturb this growing sentiment of veneration. To the Federalist the publisher has added the Letters of Pacificus, written by Mr. Hamilton, and an answer to those Letters by Helvidius, from the pen of Mr. Madison. As these two eminent men had laboured in unison to inculcate the general advantages to be derived from the Constitution, it cannot be deemed irrelevant to shew in what particular point, as it respects the practical construction of that instrument, they afterwards differed. The community is, perhaps, always more enlightened by the candid criticisms of intelligent conflicting minds than it is by their concurring opinions. In this collection, the Act of Confederation and the Constitution of the United States also find an appropriate place. They are the text upon which the Federalist is a commentary. By comparing these two national constitutions, and reflecting upon the results of each, the defects of the former and the perfections of the latter will be easily perceived; and the American people may be thence instructed, that however prudence may dictate the necessity of caution in admitting innovations upon established institutions, yet that it is at all times adviseable to listen with attention to the suggestions and propositions, of temperate and experienced statesmen, for the cure of political evils and the promotion of the general welfare. The Constitution of the United States has had, in the sunshine of peace and in the storm of war, a severe but impartial trial, and it has amply fulfilled the expectations of its friends and completely dissipated the fears of its early opponents. It may, in truth, be asserted, that the ten first declaratory and restrictive amendatory clauses, proposed at the session of congress which commenced on the 4th of March, 1789, and which were ratified by the legislatures of the states, fully satisfied the scruples of those who were inimical to that instrument as it was first adopted, and by whom the amendments were considered necessary as a safeguard for religious and civil liberty. Thus, and still further, amended, the Constitution, as a great rule of political conduct, has guided the public authorities of the United States through the unprecedented political vicissitudes and the perilous revolutionary commotions which have agitated the human race for the last quarter of a century, to a condition at once so prosperous, so commanding, and so happy, that it has wholly outstripped all previous foresight and calculation. When we look back upon the state of inertness in which we reposed under the Act of Confederation, to the languishment of our commerce, and the indifference with which, in that situation, we were regarded by foreign governments, and compare that disposition of things with the energy to which we were subsequently roused by the operation of the Constitution, with the vast theatre on which, under the influence of its provisions, our maritime trade has been actively employed, with the freedom and plenty which we enjoy at home, the respect entertained for the American name abroad, and the alacrity with which our favour and friendship are sought by the nations of the earth, our thankfulness to Providence ought to know no bounds, and to the able men who framed and have supported the Constitution should only be limited by those paramount considerations which are indispensable to the perpetuation and increase of the blessings which have been already realized. The perspicuous brevity of the Constitution has left but little room for misinterpretation. But if at any time ardent or timid minds have exceeded or fallen short of its intentions; if the precision of human language has, in the formation of this instrument, been inadequate to the expression of the exact ideas meant to be conveyed by its framers; if, from the vehemence of party spirit, it has been warped by individuals, so as to incline it either too much towards monarchy or towards an unmodified democracy; let us console ourselves with the reflection, that however these aberrations may have transiently prevailed, the essential principles of the Representative System of government have been well preserved by the clear-sighted common sense of the people; and that our affections all concentre in one great object, which is the improvement and the glory of our country. After deriving so many and such uncommon benefits from the Constitution, the notion of an eventual dissolution of this Union must be held, by every person of unimpaired intellect, as entirely visionary. The state governments, divested of scarcely any thing but national authority, have answered, or are competent to answer, every purpose of amelioration within the boundaries of the territory to which they are respectively restricted; whilst, in times of difficulty and danger, acting directly upon an intimate knowledge of local resources and feeling, they are enabled to afford efficient aid to the exertions of the national government in the defence and protection of the republic. These truths are obvious: they have been demonstrated in times of domestic tranquillity, of internal commotion, and of foreign hostility. In return, the advantages which the national government dispenses to the several states are keenly felt and highly relished. When the Constitution was ratified, Rhode Island and North Carolina, from honest but mistaken convictions, for a moment withheld their assent. But when Congress proceeded solemnly to enact that the manufactures of those states should be considered as foreign, and that the acts laying a duty on goods imported and on tonnage should extend to them, they hastened, with a discernment quickened by a sense of interest, and at the same time honourable to their patriotic views, to unite themselves to the Confederation. The only alteration of importance which the Constitution has undergone since its adoption, is that which changes the mode of electing the President and Vice-President. It is believed that, all things being duly weighed, the alteration has been beneficial. If it enables a man to aim, with more directness, at the first office in the gift of the people, it equally tends to prevent the recurrence of an unpleasant contest for precedency, between the partizans of any two individuals, in Congress, to which body, in the last resort, the choice is referred. Besides, whether the Constitution should prescribe it or not, the people themselves would invariably designate the man they intended for chief magistrate; a reflection which may serve to convince us that the change in question is more in form than in fact . To conclude, the appearance of so perfect an edition of the Federalist as the present must be allowed to be, may be regarded as the more fortunate, as the Journal of the Convention that framed the Constitution is about to be published, and a new light to be thus shed upon the composition of that instrument. The Act of Confederation, and the Constitution itself, have been, by permission of Mr. Adams, the Secretary of State, carefully compared with the originals deposited in the Office of that Department; and their accuracy may therefore be relied on, even to the punctuation. [JACOB GIDEON] City of Washington, May, 1818",
        "char_count": 9770
      },
      {
        "heading": "Chapter 8",
        "text": "No. 1 BY ALEXANDER HAMILTON Introduction AFTER FULL EXPERIENCE OF the insufficiency of the existing federal government, you are invited to deliberate upon a New Constitution for the United States of America. The subject speaks its own importance; comprehending in its consequences, nothing less than the existence of the UNION, the safety and welfare of the parts of which it is composed, the fate of an empire, in many respects, the most interesting in the world. It has been frequently remarked, that it seems to have been reserved to the people of this country to decide, by their conduct and example, the important question, whether societies of men are really capable or not, of establishing good government from reflection and choice, or whether they are forever destined to depend, for their political constitutions, on accident and force. If there be any truth in the remark, the crisis at which we are arrived may, with propriety, be regarded as the period when that decision is to be made; and a wrong election of the part we shall act, may, in this view, deserve to be considered as the general misfortune of mankind. This idea, by adding the inducements of philanthropy to those of patriotism, will heighten the solicitude which all considerate and good men must feel for the event. Happy will it be if our choice should be directed by a judicious estimate of our true interests, uninfluenced by considerations foreign to the public good. But this is more ardently to be wished for, than seriously to be expected. The plan offered to our deliberations, affects too many particular interests, innovates upon too many local institutions, not to involve in its discussion a variety of objects extraneous to its merits, and of views, passions and prejudices little favourable to the discovery of truth. Among the most formidable of the obstacles which the new constitution will have to encounter, may readily be distinguished the obvious interest of a certain class of men in every state to resist all changes which may hazard a diminution of the power, emolument and consequence of the offices they hold under the state establishments ... and the perverted ambition of another class of men, who will either hope to aggrandize themselves by the confusions of their country, or will flatter themselves with fairer prospects of elevation from the subdivision of the empire into several partial confederacies, than from its union under one government. It is not, however, my design to dwell upon observations of this nature. I am aware that it would be disingenuous to resolve indiscriminately the opposition of any set of men into interested or ambitious views, merely because their situations might subject them to suspicion. Candour will oblige us to admit, that even such men may be actuated by upright intentions; and it cannot be doubted, that much of the opposition, which has already shown itself, or that may hereafter make its appearance, will spring from sources blameless at least, if not respectable ... the honest errors of minds led astray by preconceived jealousies and fears. So numerous indeed and so powerful are the causes which serve to give a false bias to the judgment, that we, upon many occasions, see wise and good men on the wrong as well as on the right side of questions, of the first magnitude to society. This circumstance, if duly attended to, would always furnish a lesson of moderation to those, who are engaged in any controversy, however well persuaded of being in the right. And a further reason for caution, in this respect, might be drawn from the reflection, that we are not always sure, that those who advocate the truth are actuated by purer principles than their antagonists. Ambition, avarice, personal animosity, party opposition, and many other motives, not more laudable than these, are apt to operate as well upon those who support, as upon those who oppose, the right side of a question. Were there not even these inducements to moderation, nothing could be more ill judged than that intolerant spirit, which has, at all times, characterized political parties. For, in politics as in religion, it is equally absurd to aim at making proselytes by fire and sword. Heresies in either can rarely be cured by persecution. And yet, just as these sentiments must appear to candid men, we have already sufficient indications, that it will happen in this, as in all former cases of great national discussion. A torrent of angry and malignant passions will be let loose. To judge from the conduct of the opposite parties, we shall be led to conclude, that they will mutually hope to evince the justness of their opinions, and to increase the number of their converts, by the loudness of their declamations, and by the bitterness of their invectives. An enlightened zeal for the energy and efficiency of government, will be stigmatized as the offspring of a temper fond of power, and hostile to the principles of liberty. An over scrupulous jealousy of danger to the rights of the people, which is more commonly the fault of the head than of the heart, will be represented as mere pretence and artifice ... the stale bait for popularity at the expense of public good. It will be forgotten, on the one hand, that jealousy is the usual concomitant of violent love, and that the noble enthusiasm of liberty is too apt to be infected with a spirit of narrow and illiberal distrust. On the other hand, it will be equally forgotten, that the vigour of government is essential to the security of liberty; that, in the contemplation of a sound and well informed judgment, their interests can never be separated; and that a dangerous ambition more often lurks behind the specious mask of zeal for the rights of the people, than under the forbidding appearances of zeal for the firmness and efficiency of government. History will teach us, that the former has been found a much more certain road to the introduction of despotism, than the latter, and that of those men who have overturned the liberties of republics, the greatest number have begun their career, by paying an obsequious court to the people ... commencing demagogues, and ending tyrants. In the course of the preceding observations it has been my aim, fellow citizens, to put you upon your guard against all attempts, from whatever quarter, to influence your decision in a matter of the utmost moment to your welfare, by any impressions, other than those which may result from the evidence of truth. You will, no doubt, at the same time, have collected from the general scope of them, that they proceed from a source not unfriendly to the new constitution. Yes, my countrymen, I own to you, that, after having given it an attentive consideration, I am clearly of opinion, it is your interest to adopt it. I am convinced, that this is the safest course for your liberty, your dignity, and your happiness. I affect not reserves, which I do not feel. I will not amuse you with an appearance of deliberation, when I have decided. I frankly acknowledge to you my convictions, and I will freely lay before you the reasons on which they are founded. The consciousness of good intentions disdains ambiguity. I shall not however multiply professions on this head. My motives must remain in the depository of my own breast: my arguments will be open to all, and may be judged of by all. They shall at least be offered in a spirit, which will not disgrace the cause of truth. I propose, in a series of papers, to discuss the following interesting particulars ... The utility of the UNION to your political prosperity ... The insufficiency of the present confederation to preserve that Union... The necessity of a government at least equally energetic with the one proposed, to the attainment of this object ... The conformity of the proposed constitution to the true principles of republican government... Its analogy to your own state constitution ... and lastly, The additional security, which its adoption will afford to the preservation of that species of government, to liberty and to property. In the progress of this discussion, I shall endeavour to give a satisfactory answer to all the objections which shall have made their appearance, that may seem to have any claim to attention. It may perhaps be thought superfluous to offer arguments to prove the utility of the UNION, a point, no doubt, deeply engraved on the hearts of the great body of the people in every state, and one which, it may be imagined, has no adversaries. But the fact is, that we already hear it whispered in the private circles of those who oppose the new constitution, that the Thirteen States are of too great extent for any general system, and that we must of necessity resort to separate confederacies of distinct portions of the whole. a This doctrine will, in all probability, be gradually propagated, till it has votaries enough to countenance its open avowal. For nothing can be more evident, to those who are able to take an enlarged view of the subject, than the alternative of an adoption of the constitution, or a dismemberment of the Union. It may, therefore, be essential to examine particularly the advantages of that Union, the certain evils, and the probable dangers, to which every state will be exposed from its dissolution. This shall accordingly be done. PUBLIUS",
        "char_count": 9352
      },
      {
        "heading": "Chapter 9",
        "text": "No. 2 BY JOHN JAY Concerning Dangers from Foreign Force & Influence WHEN THE PEOPLE OF America reflect, that the question now submitted to their determination, is one of the most important that has engaged, or can well engage, their attention, the propriety of their taking a very comprehensive, as well as a very serious, view of it, must be evident. Nothing is more certain than the indispensable necessity of government; and it is equally undeniable, that whenever and however it is instituted, the people must cede to it some of their natural rights, in order to vest it with requisite powers. It is well worthy of consideration, therefore, whether it would conduce more to the interest of the people of America, that they should, to all general purposes, be one nation, under one federal government, than that they should divide themselves into separate confederacies, and give to the head of each, the same kind of powers which they are advised to place in one national government. It has until lately been a received and uncontradicted opinion, that the prosperity of the people of America depended on their continuing firmly united, and the wishes, prayers and efforts of our best and wisest citizens have been constantly directed to that object. But politicians now appear, who insist that this opinion is erroneous, and that instead of looking for safety and happiness in union, we ought to seek it in a division of the states into distinct confederacies or sovereignties. However extraordinary this new doctrine may appear, it nevertheless has its advocates; and certain characters who were formerly much opposed to it, are at present of the number. Whatever may be the arguments or inducements which have wrought this change in the sentiments and declarations of these gentlemen, it certainly would not be wise in the people at large to adopt these new political tenets, without being fully convinced that they are founded in truth and sound policy. It has often given me pleasure to observe, that independent America was not composed of detached and distant territories, but that one connected, fertile, wide spreading country, was the portion of our western sons of liberty. Providence has in a particular manner blessed it with a variety of soils and productions, and watered it with innumerable streams, for the delight and accommodation of its inhabitants. A succession of navigable waters forms a kind of chain round its borders, as if to bind it together; while the most noble rivers in the world, running at convenient distances, present them with highways for the easy communication of friendly aids, and the mutual transportation and exchange of their various commodities. With equal pleasure I have as often taken notice, that Providence has been pleased to give this one connected country, to one united people; a people descended from the same ancestors, speaking the same language, professing the same religion, attached to the same principles of government, very similar in their manners and customs, and who, by their joint counsels, arms and efforts, fighting side by side throughout a long and bloody war, have nobly established their general liberty and independence. This country and this people seem to have been made for each other, and it appears as if it was the design of Providence, that an inheritance so proper and convenient for a band of brethren, united to each other by the strongest ties, should never be split into a number of unsocial, jealous and alien sovereignties. Similar sentiments have hitherto prevailed among all orders and denominations of men among us. To all general purposes we have uniformly been one people ... each individual citizen every where enjoying the same national rights, privileges, and protection. As a nation we have made peace and war: as a nation we have vanquished our common enemies: as a nation we have formed alliances and made treaties, and entered into various compacts and conventions with foreign states. A strong sense of the value and blessings of Union induced the people, at a very early period, to institute a federal government to preserve and perpetuate it. They formed it almost as soon as they had a political existence; nay, at a time, when their habitations were in flames, when many of them were bleeding in the field, and when the progress of hostility and desolation left little room for those calm and mature inquiries and reflections, which must ever precede the formation of a wise and well balanced government for a free people. It is not to be wondered at that a government instituted in times so inauspicious, should on experiment be found greatly deficient and inadequate to the purpose it was intended to answer. This intelligent people perceived and regretted these defects. Still continuing no less attached to union, than enamoured of liberty, they observed the danger which immediately threatened the former, and more remotely the latter; and being persuaded that ample security for both, could only be found in a national government more wisely framed, they, as with one voice, convened the late convention at Philadelphia, to take that important subject under consideration. This convention, composed of men who possessed the confidence of the people, and many of whom had become highly distinguished by their patriotism, virtue, and wisdom, in times which tried the souls of men, undertook the arduous task. In the mild season of peace, with minds unoccupied by other subjects, they passed many months in cool uninterrupted and daily consultations ; and finally, without having been awed by power, or influenced by any passion, except love for their country, they presented and recommended to the people the plan produced by their joint and very unanimous councils. Admit, for so is the fact, that this plan is only recommended, not imposed, yet let it be remembered, that it is neither recommended to blind approbation, nor to blind reprobation; but to that sedate and candid consideration, which the magnitude and importance of the subject demand, and which it certainly ought to receive. But, as has been already remarked, it is more to be wished than expected that it may be so considered and examined. Experience on a former occasion teaches us not to be too sanguine in such hopes. It is not yet forgotten, that well grounded apprehensions of imminent danger induced the people of America to form the memorable Congress of 1774. That body recommended certain measures to their constituents, and the event proved their wisdom; yet it is fresh in our memories how soon the press began to teem with pamphlets and weekly papers against those very measures. Not only many of the officers of government who obeyed the dictates of personal interest, but others from a mistaken estimate of consequences, from the undue influence of ancient attachments, or whose ambition aimed at objects which did not correspond with the public good, were indefatigable in their endeavours to persuade the people to reject the advice of that patriotic congress. Many indeed were deceived and deluded, but the great majority reasoned and decided judiciously; and happy they are in reflecting that they did so. They considered that the congress was composed of many wise and experienced men. That being convened from different parts of the country, they brought with them and communicated to each other a variety of useful information. That in the course of the time they passed together in inquiring into and discussing the true interests of their country, they must have acquired very accurate knowledge on that head. That they were individually interested in the public liberty and prosperity, and therefore that it was not less their inclination, than their duty, to recommend such measures only, as after the most mature deliberation they really thought prudent and advisable. These and similar considerations then induced the people to rely greatly on the judgment and integrity of the congress; and they took their advice, notwithstanding the various arts and endeavours used to deter and dissuade them from it. But if the people at large had reason to confide in the men of that congress, few of whom had then been fully tried or generally known, still greater reason have they now to respect the judgment and advice of the convention; for it is well known that some of the most distinguished members of that congress, who have been since tried and justly approved for patriotism and abilities, and who have grown old in acquiring political information, were also members of this convention, and carried into it their accumulated knowledge and experience. It is worthy of remark, that not only the first, but every succeeding congress, as well as the late convention, have invariably joined with the people in thinking that the prosperity of America depended on its Union. To preserve and perpetuate it, was the great object of the people in forming that convention, and it is also the great object of the plan which the convention has advised them to adopt. With what propriety, therefore, or for what good purposes, are attempts at this particular period made, by some men, to depreciate the importance of the union? or why is it suggested that three or four confederacies would be better than one? I am persuaded in my own mind, that the people have always thought right on this subject, and that their universal and uniform attachment to the cause of the union, rests on great and weighty reasons. They who promote the idea of substituting a number of distinct confederacies in the room of the plan of the convention, seem clearly to foresee that the rejection of it would put the continuance of the union in the utmost jeopardy: that certainly would be the case; and I sincerely wish that it may be as clearly forseen by every good citizen, that whenever the dissolution of the union arrives, America will have reason to exclaim in the words of the Poet, “FAREWELL! A LONG FAREWELL, TO ALL MY GREATNESS.” 1 PUBLIUS",
        "char_count": 10021
      },
      {
        "heading": "Chapter 10",
        "text": "No. 3 BY JOHN JAY The same Subject continued IT IS NOT A new observation that the people of any country (if like the Americans intelligent and well informed) seldom adopt, and steadily persevere for many years, in any erroneous opinion respecting their interests. That consideration naturally tends to create great respect for the high opinion which the people of America have so long and uniformly entertained of the importance of their continuing firmly united under one federal government, vested with sufficient powers for all general and national purposes. The more attentively I consider and investigate the reasons which appear to have given birth to this opinion, the more I become convinced that they are cogent and conclusive. Among the many objects to which a wise and free people find it necessary to direct their attention, that of providing for their safety seems to be the first. The safety of the people doubtless has relation to a great variety of circumstances and considerations, and consequently affords great latitude to those who wish to define it precisely and comprehensively. At present I mean only to consider it as it respects security for the preservation of peace and tranquillity, as well against dangers, from foreign arms and influence, as against dangers arising from domestic causes. As the former of these comes first in order, it is proper it should be the first discussed. Let us therefore proceed to examine whether the people are not right in their opinion, that a cordial union under an efficient national government, affords them the best security that can be devised against hostilities from abroad. The number of wars which have happened or may happen in the world, will always be found to be in proportion to the number and weight of the causes, whether real or pretended, which provoke or invite them. If this remark be just, it becomes useful to inquire, whether so many just causes of war are likely to be given by united America, as by disunited America; for if it should turn out that united America will probably give the fewest, then it will follow, that, in this respect, the union tends most to preserve the people in a state of peace with other nations. The just causes of war for the most part arise either from violations of treaties, or from direct violence. America has already formed treaties with no less than six foreign nations, and all of them, except Prussia, are maritime, and therefore able to annoy and injure us: She has also extensive commerce with Portugal, Spain, and Britain, and with respect to the two latter, has the additional circumstance of neighbourhood to attend to. It is of high importance to the peace of America, that she observe the law of nations towards all these powers; and to me it appears evident that this will be more perfectly and punctually done by one national government, than it could be either by thirteen separate states, or by three or four distinct confederacies. For this opinion various reasons may be assigned. When once an efficient national government is established, the best men in the country will not only consent to serve, but will also generally be appointed to manage it; for although town, or county, or other contracted influence, may place men in state assemblies, or senates, or courts of justice, or executive departments; yet more general and extensive reputation for talents and other qualifications, will be necessary to recommend men to offices under the national government, especially as it will have the widest field for choice, and never experience that want of proper persons, which is not uncommon in some of the states. Hence it will result, that the administration, the political counsels, and the judicial decisions of the national government, will be more wise, systematical and judicious, than those of individual states, and consequently more satisfactory with respect to the other nations, as well as more safe with respect to ourselves. Under the national government, treaties and articles of treaties, as well as the laws of nations, will always be expounded in one sense, and executed in the same manner: whereas adjudications on the same points and questions, in thirteen states, or in three or four confederacies, will not always accord or be consistent; and that as well from the variety of independent courts and judges appointed by different and independent governments, as from the different local laws and interests which may affect and influence them. The wisdom of the convention, in committing such questions to the jurisdiction and judgment of courts appointed by, and responsible only to one national government, cannot be too much commended. The prospect of present loss or advantage, may often tempt the governing party in one or two states to swerve from good faith and justice; and those temptations not reaching the other states, and consequently having little or no influence on the national government, the temptations will be fruitless, and good faith and justice be preserved. The case of the treaty of peace with Britain, adds great weight to this reasoning. If even the governing party in a state should be disposed to resist such temptations, yet as such temptations may, and commonly do, result from circumstances peculiar to the state, and may affect a great number of the inhabitants, the governing party may not always be able, if willing, to prevent the injustice meditated, or to punish the aggressors. But the national government, not being affected by those local circumstances, will neither be induced to commit the wrong themselves, nor want power or inclination to prevent, or punish its commission by others. So far therefore as either designed or accidental violations of treaties and of the laws of nations afford just causes of war, they are less to be apprehended under one general government, than under several lesser ones, and in that respect, the former most favors the safety of the people. As to those just causes of war which proceed from direct and unlawful violence, it appears equally clear to me, that one good national government affords vastly more security against dangers of that sort, than can be derived from any other quarter. Such violences are more frequently occasioned by the passions and interests of a part than of the whole of one or two states than of the union. Not a single Indian war has yet been produced by aggressions of the present federal government, feeble as it is; but there are several instances of Indian hostilities having been provoked by the improper conduct of individual states, who, either unable or unwilling to restrain or punish offences, have given occasion to the slaughter of many innocent inhabitants. The neighbourhood of Spanish and British territories, bordering on some states, and not on others, naturally confines the causes of quarrel more immediately to the borderers. The bordering states, if any, will be those who, under the impulse of sudden irritations, and a quick sense of apparent interest or injury, will be most likely, by direct violence, to excite war with those nations; and nothing can so effectually obviate that danger, as a national government, whose wisdom and prudence will not be diminished by the passions which actuate the parties immediately interested. But not only fewer just causes of war will be given by the national government, but it will also be more in their power to accommodate and settle them amicably. They will be more temperate and cool, and in that respect, as well as in others, will be more in capacity to act with circumspection than the offending state. The pride of states as well as of men, naturally disposes them to justify all their actions, and opposes their acknowledging, correcting or repairing their errors and offences. The national government in such cases will not be affected by this pride, but will proceed with moderation and candour, to consider and decide on the means most proper to extricate them from the difficulties which threaten them. Besides it is well known that acknowledgments, explanations and compensations are often accepted as satisfactory from a strong united nation, which would be rejected as unsatisfactory if offered by a state or confederacy of little consideration or power. In the year 1685 the state of Genoa having offended Louis XIVth, endeavoured to appease him. He demanded that they should send their doge or chief magistrate, accompanied by four of their senators, to France, to ask his pardon and receive his terms. They were obliged to submit to it for the sake of peace. Would he on any occasion either have demanded or have received the like humiliation from Spain, or Britain, or any other powerful nation? PUBLIUS",
        "char_count": 8749
      },
      {
        "heading": "Chapter 11",
        "text": "No. 4 BY JOHN JAY The same Subject continued MY LAST PAPER ASSIGNED several reasons why the safety of the people would be best secured by union against the danger it may be exposed to by just causes of war given to other nations; and those reasons show that such causes would not only be more rarely given, but would also be more easily accommodated by a national government, than either by the state governments, or the proposed confederacies. But the safety of the people of America against dangers from foreign force, depends not only on their forbearing to give just causes of war to other nations, but also on their placing and continuing themselves in such a situation as not to invite hostility or insult; for it need not be observed, that there are pretended as well as just causes of war. It is too true, however disgraceful it may be to human nature, that nations in general will make war whenever they have a prospect of getting any thing by it; nay, that absolute monarchs will often make war when their nations are to get nothing by it, but for purposes and objects merely personal, such as, a thirst for military glory, revenge for personal affronts, ambition, or private compacts to aggrandize or support their particular families, or partisans. These, and a variety of motives, which affect only the mind of the sovereign, often lead him to engage in wars not sanctioned by justice, or the voice and interests of his people. But independent of these inducements to war, which are most prevalent in absolute monarchies, but which well deserve our attention, there are others which affect nations as often as kings; and some of them will on examination be found to grow out of our relative situation and circumstances. With France and with Britain we are rivals in the fisheries, and can supply their markets cheaper than they can themselves, notwithstanding any efforts to prevent it by bounties on their own, or duties on foreign fish. With them and with most other European nations, we are rivals in navigation and the carrying trade; and we shall deceive ourselves if we suppose that any of them will rejoice to see these flourish in our hands: for as our carrying trade cannot increase, without in some degree diminishing their’s, it is more their interest and will be more their policy, to restrain, than to promote it. In the trade to China and India, we interfere with more than one nation, inasmuch as it enables us to partake in advantages which they had in a manner monopolized, and as we thereby supply ourselves with commodities which we used to purchase from them. The extension of our own commerce in our own vessels, cannot give pleasure to any nations who possess territories on or near this continent, because the cheapness and excellence of our productions, added to the circumstance of vicinity, and the enterprise and address of our merchants and navigators, will give us a greater share in the advantages which those territories afford, than consists with the wishes or policy of their respective sovereigns. Spain thinks it convenient to shut the Mississippi against us on the one side, and Britain excludes us from the St. Lawrence on the other; nor will either of them permit the other waters, which are between them and us, to become the means of mutual intercourse and traffic. From these and like considerations, which might, if consistent with prudence, be more amplified and detailed, it is easy to see that jealousies and uneasinesses may gradually slide into the minds and cabinets of other nations; and that we are not to expect they should regard our advancement in union, in power and consequence by land and by sea, with an eye of indifference and composure. The people of America are aware that inducements to war may arise out of these circumstances, as well as from others not so obvious at present; and that whenever such inducements may find fit time and opportunity for operation, pretences to colour and justify them will not be wanting. Wisely therefore do they consider union and a good national government as necessary to put and keep them in such a situation as instead of inviting war, will tend to repress and discourage it. That situation consists in the best possible state of defence, and necessarily depends on the government, the arms and the resources of the country. As the safety of the whole is the interest of the whole, and cannot be provided for without government, either one or more or many, let us inquire whether one good government is not, relative to the object in question, more competent than any other given number whatever. One government can collect and avail itself of the talents and experience of the ablest men, in whatever part of the union they may be found. It can move on uniform principles of policy. It can harmonize, assimilate, and protect the several parts and members, and extend the benefit of its foresight and precautions to each. In the formation of treaties it will regard the interest of the whole, and the particular interests of the parts as connected with that of the whole. It can apply the resources and power of the whole to the defence of any particular part, and that more easily and expeditiously than state governments, or separate confederacies can possibly do, for want of concert and unity of system. It can place the militia under one plan of discipline, and by putting their officers in a proper line of subordination to the chief magistrate, will in a manner consolidate them into one corps, and thereby render them more efficient than if divided into thirteen or into three or four distinct independent bodies. What would the militia of Britain be, if the English militia obeyed the government of England, if the Scotch militia obeyed the government of Scotland, and if the Welch militia obeyed the government of Wales? Suppose an invasion: would those three governments (if they agreed at all) be able with all their respective forces, to operate against the enemy so effectually as the single government of Great-Britain would? We have heard much of the fleets of Britain; and if we are wise, the time may come, when the fleets of America may engage attention. But if one national government had not so regulated the navigation of Britain as to make it a nursery for seamen... if one national government had not called forth all the national means and materials for forming fleets, their prowess and their thunder would never have been celebrated. Let England have its navigation and fleet... let Scotland have its navigation and fleet... let Wales have its navigation and fleet... let Ireland have its navigation and fleet... let those four of the constituent parts of the British empire be under four independent governments, and it is easy to perceive how soon they would each dwindle into comparative insignificance. Apply these facts to our own case. Leave America divided into thirteen, or if you please into three or four independent governments, what armies could they raise and pay, what fleets could they ever hope to have? If one was attacked would the others fly to its succour, and spend their blood and money in its defence? Would there be no danger of their being flattered into neutrality by specious promises, or seduced by a too great fondness for peace to decline hazarding their tranquillity and present safety for the sake of neighbours, of whom perhaps they have been jealous, and whose importance they are content to see diminished; although such conduct would not be wise it would nevertheless be natural. The history of the states of Greece, and of other countries, abound with such instances, and it is not improbable that what has so often happened, would, under similar circumstances happen again. But admit that they might be willing to help the invaded state or confederacy. How, and when, and in what proportion shall aids of men and money be afforded? Who shall command the allied armies, and from which of the associates shall he receive his orders? Who shall settle the terms of peace, and in case of disputes what umpire shall decide between them, and compel acquiescence? Various difficulties and inconveniences would be inseparable from such a situation; whereas one government watching over the general and common interests, and combining and directing the powers and resources of the whole, would be free from all these embarrassments, and conduce far more to the safety of the people. But whatever may be our situation, whether firmly united under one national government, or split into a number of confederacies, certain it is, that foreign nations will know and view it exactly as it is, and they will act towards us accordingly. If they see that our national government is efficient and well administered ... our trade prudently regulated... our militia properly organized and disciplined... our resources and finances discreetly managed... our credit re-established ... our people free, contented and united, they will be much more disposed to cultivate our friendship, than to provoke our resentment. If, on the other hand, they find us either destitute of an effectual government, (each state doing right or wrong as to its rulers may seem convenient) or split into three or four independent and probably discordant republics or confederacies, one inclining to Britain, another to France, and a third to Spain, and perhaps played off against each other by the three, what a poor pitiful figure will America make in their eyes! How liable would she become not only to their contempt, but to their outrage; and how soon would dear bought experience proclaim, that when a people or family so divide, it never fails to be against themselves. PUBLIUS",
        "char_count": 9716
      },
      {
        "heading": "Chapter 12",
        "text": "No. 5 BY JOHN JAY The same Subject continued QUEEN ANN, IN HER letter of the 1st July, 1706, to the Scotch Parliament, makes some observations on the importance of the union then forming between England and Scotland, which merit our attention. I shall present the public with one or two extracts from it. “An entire and perfect union will be the solid foundation of lasting peace: it will secure your religion, liberty and property, remove the animosities amongst yourselves, and the jealousies and differences betwixt our two kingdoms. It must increase your strength, riches and trade; and by this union the whole island, being joined in affection and free from all apprehensions of different interests, will be enabled to resist all its enemies.” “We most earnestly recommend to you calmness and unanimity in this great and weighty affair, that the union may be brought to a happy conclusion; being the only effectual way to secure our present and future happiness, and disappoint the designs of our and your enemies, who will doubtless, on this occasion, use their utmost endeavours to prevent or delay this union.” It was remarked in the preceding paper, that weakness and divisions at home, would invite dangers from abroad, and that nothing would tend more to secure us from them than union, strength and good government within ourselves. This subject is copious and cannot easily be exhausted. The history of Great-Britain is the one with which we are in general the best acquainted, and it gives us many useful lessons. We may profit by their experience, without paying the price which it cost them. Although it seems obvious to common sense, that the people of such an island should be but one nation, yet we find that they were for ages divided into three, and that those three were almost constantly embroiled in quarrels and wars with one another. Notwithstanding their true interest, with respect to the continental nations, was really the same, yet by the arts and policy and practices of those nations, their mutual jealousies were perpetually kept enflamed, and for a long series of years they were far more inconvenient and troublesome, than they were useful and assisting to each other. Should the people of America divide themselves into three or four nations, would not the same thing happen? Would not similar jealousies arise, and be in like manner cherished? Instead of their being “joined in affection and free from all apprehension of different interests,” envy and jealousy would soon extinguish confidence and affection, and the partial interests of each confederacy instead of the general interests of all America, would be the only objects of their policy and pursuits. Hence, like most other bordering nations, they would always be either involved in disputes and war, or live in the constant apprehension of them. The most sanguine advocates for three or four confederacies, cannot reasonably suppose that they would long remain exactly on an equal footing in point of strength, even if it was possible to form them so at first: but admitting that to be practicable, yet what human contrivance can secure the continuance of such equality? Independent of those local circumstances which tend to beget and increase power in one part, and to impede its progress in another, we must advert to the effects of that superior policy and good management which would probably distinguish the government of one above the rest, and by which their relative equality in strength and consideration, would be destroyed. For it cannot be presumed that the same degree of sound policy, prudence and foresight would uniformly be observed by each of these confederacies, for a long succession of years. Whenever, and from whatever causes, it might happen, and happen it would, that any one of these nations or confederacies, should rise on the scale of political importance much above the degree of her neighbours, that moment would those neighbours behold her with envy and with fear. Both those passions would lead them to countenance, if not to promote whatever might promise to diminish her importance; and would also restrain them from measures calculated to advance, or even to secure her prosperity. Much time would not be necessary to enable her to discern these unfriendly dispositions. She would soon begin, not only to loose confidence in her neighbours, but also to feel a disposition equally unfavourable to them. Distrust naturally creates distrust, and by nothing is good will and kind conduct more speedily changed, than by invidious jealousies and uncandid imputations, whether expressed or implied. The North is generally the region of strength, and many local circumstances render it probable, that the most northern of the proposed confederacies would, at a period not very far distant, be unquestionably more formidable then any of the others. No sooner would this become evident, than the Northern Hive would excite the same ideas and sensations in the more Southern parts of America, which it formerly did in the Southern parts of Europe : Nor does it appear to be a rash conjecture, that its young swarms might often be tempted to gather honey in the more blooming fields and milder air of their luxurious and more delicate neighbours. They who well consider the history of similar divisions and confederacies, will find abundant reasons to apprehend, that those in contemplation would in no other sense be neighbours, than as they would be borderers; that they would neither love nor trust one another, but on the contrary would be a prey to discord, jealousy and mutual injuries; in short, that they would place us exactly in the situation in which some nations doubtless wish to see us, in which we should be formidable only to each other. From these considerations it appears that those persons are greatly mistaken, who suppose that alliances offensive and defensive might be formed between these confederacies, which would produce that combination and union of wills, of arms, and of resources, which would be necessary to put and keep them in a formidable state of defence against foreign enemies. When did the independent states into which Britain and Spain were formerly divided, combine in such alliances, or unite their forces against a foreign enemy? The proposed confederacies will be distinct nations. Each of them would have to regulate its commerce with foreigners by distinct treaties; and as their productions and commodities are different, and proper for different markets, so would those treaties be essentially different. Different commercial concerns must create different interests, and of course different degrees of political attachment to, and connection with, different foreign nations. Hence it might and probably would happen, that the foreign nation with whom the Southern confederacy might be at war, would be the one, with whom the Northern confederacy would be the most desirous of preserving peace and friendship. An alliance so contrary to their immediate interest would not therefore be easy to form, nor if formed, would it be observed and fulfilled with perfect good faith. Nay, it is far more probable that in America, as in Europe, neighbouring nations, acting under the impulse of opposite interests, and unfriendly passions, would frequently be found taking different sides. Considering our distance from Europe, it would be more natural for these confederacies to apprehend danger from one another, than from distant nations, and therefore that each of them should be more desirous to guard against the others, by the aid of foreign alliances, than to guard against foreign dangers by alliances between themselves. And here let us not forget how much more easy it is to receive foreign fleets into our ports, and foreign armies into our country, than it is to persuade or compel them to depart. How many conquests did the Romans and others make in the character of allies, and what innovations did they under the same character introduce into the governments of those whom they pretended to protect? Let candid men judge then whether the division of America into any given number of independent sovereignties, would tend to secure us against the hostilities and improper interference of foreign nations. PUBLIUS",
        "char_count": 8289
      }
    ]
  },
  "prince": {
    "meta": {
      "key": "prince",
      "title": "The Prince",
      "creator": "Niccolò Machiavelli",
      "filepath": "G:/My Drive/15_E-BOOKS/file001674.epub",
      "subject": "Philosophy"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "About Machiavelli: Niccolò di Bernardo dei Machiavelli (May 3, 1469 – June 21, 1527) was an Italian political philosopher, musician, poet, and romantic comedic playwright. He is a figure of the Italian Renaissance and a central figure of its political component, most widely known for his treatises on realist political theory (The Prince) on the one hand and republicanism (Discourses on Livy) on the other. Source: Wikipedia Also available on Feedbooks for Machiavelli: The Art of War (1521) Note: This book is brought to you by Feedbooks. http://www.feedbooks.com Strictly for personal use, do not use this file for commercial purposes.",
        "char_count": 639
      },
      {
        "heading": "Chapter 2",
        "text": "Dedication: To the Magnificent Lorenzo Di Piero De’ Medici It is customary for such as seek a Prince’s favour, to present themselves before him with those things of theirs which they themselves most value, or in which they perceive him chiefly to delight. Accordingly, we often see horses, armour, cloth of gold, precious stones, and the like costly gifts, offered to Princes as worthy of their greatness. Desiring in like manner to approach your Magnificence with some token of my devotion, I have found among my possessions none that I so much prize and esteem as a knowledge of the actions of great men, acquired in the course of a long experience of modern affairs and a continual study of antiquity. Which knowledge most carefully and patiently pondered over and sifted by me, and now reduced into this little book, I send to your Magnificence. And though I deem the work unworthy of your greatness, yet am I bold enough to hope that your courtesy will dispose you to accept it, considering that I can offer you no better gift than the means of mastering in a very brief time, all that in the course of so many years, and at the cost of so many hardships and dangers, I have learned, and know. This work I have not adorned or amplified with rounded periods, swelling and high-flown language, or any other of those extrinsic attractions and allurements wherewith many authors are wont to set off and grace their writings; since it is my desire that it should either pass wholly unhonoured, or that the truth of its matter and the importance of its subject should alone recommend it. Nor would I have it thought presumption that a person of very mean and humble station should venture to discourse and lay down rules concerning the government of Princes. For as those who make maps of countries place themselves low down in the plains to study the character of mountains and elevated lands, and place themselves high up on the mountains to get a better view of the plains, so in like manner to understand the People a man should be a Prince, and to have a clear notion of Princes he should belong to the People. Let your Magnificence, then, accept this little gift in the spirit in which I offer it; wherein, if you diligently read and study it, you will recognize my extreme desire that you should attain to that eminence which Fortune and your own merits promise you. Should you from the height of your greatness some time turn your eyes to these humble regions, you will become aware how undeservedly I have to endure the keen and unremitting malignity of Fortune. Niccolo Machiavelli",
        "char_count": 2590
      },
      {
        "heading": "Chapter 3",
        "text": "Chapter 1 Of the Various Kinds of Princedom, and of the Ways in Which They Are Acquired All the States and Governments by which men are or ever have been ruled, have been and are either Republics or Princedoms. Princedoms are either hereditary, in which the sovereignty is derived through an ancient line of ancestors, or they are new. New Princedoms are either wholly new, as that of Milan to Francesco Sforza; or they are like limbs joined on to the hereditary possessions of the Prince who acquires them, as the Kingdom of Naples to the dominions of the King of Spain. The States thus acquired have either been used to live under a Prince or have been free; and he who acquires them does so either by his own arms or by the arms of others, and either by good fortune or by merit.",
        "char_count": 782
      },
      {
        "heading": "Chapter 4",
        "text": "Chapter 2 Of Hereditary Princedoms Of Republics I shall not now speak, having elsewhere spoken of them at length. Here I shall treat exclusively of Princedoms, and, filling in the outline above traced out, shall proceed to examine how such States are to be governed and maintained. I say, then, that hereditary States, accustomed to the family of their Prince, are maintained with far less difficulty than new States, since all that is required is that the Prince shall not depart from the usages of his ancestors, trusting for the rest to deal with events as they arise. So that if an hereditary Prince be of average address, he will always maintain himself in his Princedom, unless deprived of it by some extraordinary and irresistible force; and even if so deprived will recover it, should any, even the least, mishap overtake the usurper. We have in Italy an example of this in the Duke of Ferrara, who never could have withstood the attacks of the Venetians in 1484, nor those of Pope Julius in 1510, had not his authority in that State been consolidated by time. For since a Prince by birth has fewer occasions and less need to give offence, he ought to be better loved, and will naturally be popular with his subjects unless outrageous vices make him odious. Moreover, the very antiquity and continuance of his rule will efface the memories and causes which lead to innovation. For one change always leaves a dovetail into which another will fit.",
        "char_count": 1453
      },
      {
        "heading": "Chapter 5",
        "text": "Chapter 3 Of Mixed Princedoms But in new Princedoms difficulties abound. And, first, if the Princedom be not wholly new, but joined on to the ancient dominions of the Prince, so as to form with them what may be termed a mixed Princedom, changes will come from a cause common to all new States, namely, that men, thinking to better their condition, are always ready to change masters, and in this expectation will take up arms against any ruler; wherein they deceive themselves, and find afterwards by experience that they are worse off than before. This again results naturally and necessarily from the circumstance that the Prince cannot avoid giving offence to his new subjects, either in respect of the troops he quarters on them, or of some other of the numberless vexations attendant on a new acquisition. And in this way you may find that you have enemies in all those whom you have injured in seizing the Princedom, yet cannot keep the friendship of those who helped you to gain it; since you can neither reward them as they expect, nor yet, being under obligations to them, use violent remedies against them. For however strong you may be in respect of your army, it is essential that in entering a new Province you should have the good will of its inhabitants. Hence it happened that Louis XII of France, speedily gaining possession of Milan, as speedily lost it; and that on the occasion of its first capture, Lodovico Sforza was able with his own forces only to take it from him. For the very people who had opened the gates to the French King, when they found themselves deceived in their expectations and hopes of future benefits, could not put up with the insolence of their new ruler. True it is that when a State rebels and is again got under, it will not afterwards be lost so easily. For the Prince, using the rebellion as a pretext, will not scruple to secure himself by punishing the guilty, bringing the suspected to trial, and otherwise strengthening his position in the points where it was weak. So that if to recover Milan from the French it was enough on the first occasion that a Duke Lodovico should raise alarms on the frontiers to wrest it from them a second time the whole world had to be ranged against them, and their armies destroyed and driven out of Italy. And this for the reasons above assigned. And yet, for a second time, Milan was lost to the King. The general causes of its first loss have been shown. It remains to note the causes of the second, and to point out the remedies which the French King had, or which might have been used by another in like circumstances to maintain his conquest more successfully than he did. I say, then, that those States which upon their acquisition are joined on to the ancient dominions of the Prince who acquires them, are either of the same Province and tongue as the people of these dominions, or they are not. When they are, there is a great ease in retaining them, especially when they have not been accustomed to live in freedom. To hold them securely it is enough to have rooted out the line of the reigning Prince; because if in other respects the old condition of things be continued, and there be no discordance in their customs, men live peaceably with one another, as we see to have been the case in Brittany, Burgundy, Gascony, and Normandy, which have so long been united to France. For although there be some slight difference in their languages, their customs are similar, and they can easily get on together. He, therefore, who acquires such a State, if he mean to keep it, must see to two things; first, that the blood of the ancient line of Princes be destroyed; second, that no change be made in respect of laws or taxes; for in this way the newly acquired State speedily becomes incorporated with the hereditary. But when States are acquired in a country differing in language, usages, and laws, difficulties multiply, and great good fortune, as well as address, is needed to overcome them. One of the best and most efficacious methods for dealing with such a State, is for the Prince who acquires it to go and dwell there in person, since this will tend to make his tenure more secure and lasting. This course has been followed by the Turk with regard to Greece, who, had he not, in addition to all his other precautions for securing that Province, himself come to live in it, could never have kept his hold of it. For when you are on the spot, disorders are detected in their beginnings and remedies can be readily applied; but when you are at a distance, they are not heard of until they have gathered strength and the case is past cure. Moreover, the Province in which you take up your abode is not pillaged by your officers; the people are pleased to have a ready recourse to their Prince; and have all the more reason if they are well disposed, to love, if disaffected, to fear him. A foreign enemy desiring to attack that State would be cautious how he did so. In short, where the Prince resides in person, it will be extremely difficult to oust him. Another excellent expedient is to send colonies into one or two places, so that these may become, as it were, the keys of the Province; for you must either do this, or else keep up a numerous force of men-at-arms and foot soldiers. A Prince need not spend much on colonies. He can send them out and support them at little or no charge to himself, and the only persons to whom he gives offence are those whom he deprives of their fields and houses to bestow them on the new inhabitants. Those who are thus injured form but a small part of the community, and remaining scattered and poor can never become dangerous. All others being left unmolested, are in consequence easily quieted, and at the same time are afraid to make a false move, lest they share the fate of those who have been deprived of their possessions. In few words, these colonies cost less than soldiers, are more faithful, and give less offence, while those who are offended, being, as I have said, poor and dispersed, cannot hurt. And let it here be noted that men are either to be kindly treated, or utterly crushed, since they can revenge lighter injuries, but not graver. Wherefore the injury we do to a man should be of a sort to leave no fear of reprisals. But if instead of colonies you send troops, the cost is vastly greater, and the whole revenues of the country are spent in guarding it; so that the gain becomes a loss, and much deeper offence is given; since in shifting the quarters of your soldiers from place to place the whole country suffers hardship, which as all feel, all are made enemies; and enemies who remaining, although vanquished, in their own homes, have power to hurt. In every way, therefore, this mode of defence is as disadvantageous as that by colonizing is useful. The Prince who establishes himself in a Province whose laws and language differ from those of his own people, ought also to make himself the head and protector of his feebler neighbours, and endeavour to weaken the stronger, and must see that by no accident shall any other stranger as powerful as himself find an entrance there. For it will always happen that some such person will be called in by those of the Province who are discontented either through ambition or fear; as we see of old the Romans brought into Greece by the Aetolians, and in every other country that they entered, invited there by its inhabitants. And the usual course of things is that so soon as a formidable stranger enters a Province, all the weaker powers side with him, moved thereto by the ill-will they bear towards him who has hitherto kept them in subjection. So that in respect of these lesser powers, no trouble is needed to gain them over, for at once, together, and of their own accord, they throw in their lot with the government of the stranger. The new Prince, therefore, has only to see that they do not increase too much in strength, and with his own forces, aided by their good will, can easily subdue any who are powerful, so as to remain supreme in the Province. He who does not manage this matter well, will soon lose whatever he has gained, and while he retains it will find in it endless troubles and annoyances. In dealing with the countries of which they took possession the Romans diligently followed the methods I have described. They planted colonies, conciliated weaker powers without adding to their strength, humbled the great, and never suffered a formidable stranger to acquire influence. A single example will suffice to show this. In Greece the Romans took the Achaians and Aetolians into their pay; the Macedonian monarchy was humbled; Antiochus was driven out. But the services of the Achaians and Aetolians never obtained for them any addition to their power; no persuasions on the part of Philip could induce the Romans to be his friends on the condition of sparing him humiliation; nor could all the power of Antiochus bring them to consent to his exercising any authority within that Province. And in thus acting the Romans did as all wise rulers should, who have to consider not only present difficulties but also future, against which they must use all diligence to provide; for these, if they be foreseen while yet remote, admit of easy remedy, but if their approach be awaited, are already past cure, the disorder having become hopeless; realizing what the physicians tell us of hectic fever, that in its beginning it is easy to cure, but hard to recognize; whereas, after a time, not having been detected and treated at the first, it becomes easy to recognize but impossible to cure. And so it is with State affairs. For the distempers of a State being discovered while yet inchoate, which can only be done by a sagacious ruler, may easily be dealt with; but when, from not being observed, they are suffered to grow until they are obvious to every one, there is no longer any remedy. The Romans, therefore, foreseeing evils while they were yet far off, always provided against them, and never suffered them to take their course for the sake of avoiding war; since they knew that war is not so to be avoided, but is only postponed to the advantage of the other side. They chose, therefore, to make war with Philip and Antiochus in Greece, that they might not have to make it with them in Italy, although for a while they might have escaped both. This they did not desire, nor did the maxim leave it to Time, which the wise men of our own day have always on their lips, ever recommend itself to them. What they looked to enjoy were the fruits of their own valour and foresight. For Time, driving all things before it, may bring with it evil as well as good. But let us now go back to France and examine whether she has followed any of those methods of which I have made mention. I shall speak of Louis and not of Charles, because from the former having held longer possession of Italy, his manner of acting is more plainly seen. You will find, then, that he has done the direct opposite of what he should have done in order to retain a foreign State. King Louis was brought into Italy by the ambition of the Venetians, who hoped by his coming to gain for themselves a half of the State of Lombardy. I will not blame this coming, nor the part taken by the King, because, desiring to gain a footing in Italy, where he had no friends, but on the contrary, owing to the conduct of Charles, every door was shut against him, he was driven to accept such friendships as he could get. And his designs might easily have succeeded had he not made mistakes in other particulars of conduct. By the recovery of Lombardy, Louis at once regained the credit which Charles had lost. Genoa made submission; the Florentines came to terms; the Marquis of Mantua, the Duke of Ferrara, the Bentivogli, the Countess of Forli, the Lords of Faenza, Pesaro, Rimini, Camerino, and Piombino, the citizens of Lucca, Pisa, and Siena, all came forward offering their friendship. The Venetians, who to obtain possession of a couple of towns in Lombardy had made the French King master of two-thirds of Italy, had now cause to repent the rash game they had played. Let any one, therefore, consider how easily King Louis might have maintained his authority in Italy had he observed the rules which I have noted above, and secured and protected all those friends of his, who being weak, and fearful, some of the Church, some of the Venetians, were of necessity obliged to attach themselves to him, and with whose assistance, for they were many, he might readily have made himself safe against any other powerful State. But no sooner was he in Milan than he took a contrary course, in helping Pope Alexander to occupy Romagna; not perceiving that in seconding this enterprise he weakened himself by alienating friends and those who had thrown themselves into his arms, while he strengthened the Church by adding great temporal power to the spiritual power which of itself confers so mighty an authority. Making this first mistake, he was forced to follow it up, until at last, in order to curb the ambition of Pope Alexander, and prevent him becoming master of Tuscany, he was obliged to come himself into Italy. And as though it were not enough for him to have aggrandized the Church and stripped himself of friends, he must needs in his desire to possess the Kingdom of Naples, divide it with the King of Spain; thus bringing into Italy, where before he had been supreme, a rival to whom the ambitious and discontented in that Province might have recourse. And whereas he might have left in Naples a King willing to hold as his tributary, he displaced him to make way for another strong enough to effect his expulsion. The wish to acquire is no doubt a natural and common sentiment, and when men attempt things within their power, they will always be praised rather than blamed. But when they persist in attempts that are beyond their power, mishaps and blame ensue. If France, therefore, with her own forces could have attacked Naples, she should have done so. If she could not, she ought not to have divided it. And if her partition of Lombardy with the Venetians may be excused as the means whereby a footing was gained in Italy, this other partition is to be condemned as not justified by the like necessity. Louis, then, had made these five blunders. He had destroyed weaker States, he had strengthened a Prince already strong, he had brought into the country a very powerful stranger, he had not come to reside, and he had not sent colonies. And yet all these blunders might not have proved disastrous to him while he lived, had he not added to them a sixth in depriving the Venetians of their dominions. For had he neither aggrandized the Church, nor brought Spain into Italy, it might have been at once reasonable and necessary to humble the Venetians; but after committing himself to these other courses, he should never have consented to the ruin of Venice. For while the Venetians were powerful they would always have kept others back from an attempt on Lombardy, as well because they never would have agreed to that enterprise on any terms save of themselves being made its masters, as because others would never have desired to take it from France in order to hand it over to them, nor would ever have ventured to defy both. And if it be said that King Louis ceded Romagna to Alexander, and Naples to Spain in order to avoid war, I answer that for the reasons already given, you ought never to suffer your designs to be crossed in order to avoid war, since war is not so to be avoided, but is only deferred to your disadvantage. And if others should allege the King’s promise to the Pope to undertake that enterprise on his behalf, in return for the dissolution of his marriage, and for the Cardinal’s hat conferred on d’Amboise, I answer by referring to what I say further on concerning the faith of Princes and how it is to be kept. King Louis, therefore, lost Lombardy from not following any one of the methods pursued by others who have taken Provinces with the resolve to keep them. Nor is this anything strange, but only what might reasonably and naturally be looked for. And on this very subject I spoke to d’Amboise at Nantes, at the time when Duke Valentino, as Cesare Borgia, son to Pope Alexander, was vulgarly called, was occupying Romagna. For, on the Cardinal saying to me that the Italians did not understand war, I answered that the French did not understand statecraft, for had they done so, they never would have allowed the Church to grow so powerful. And the event shows that the aggrandizement of the Church and of Spain in Italy has been brought about by France, and that the ruin of France has been wrought by them. Whence we may draw the general axiom, which never or rarely errs, that he who is the cause of another’s greatness is himself undone, since he must work either by address or force, each of which excites distrust in the person raised to power.",
        "char_count": 16999
      },
      {
        "heading": "Chapter 6",
        "text": "Chapter 4 Why the Kingdom of Darius, Conquered by Alexander, Did Not, on Alexander’s Death, Rebel Against His Successors Alexander the Great having achieved the conquest of Asia in a few years, and dying before he had well entered on possession, it might have been expected, having regard to the difficulty of preserving newly acquired States, that on his death the whole country would rise in revolt. Nevertheless, his successors were able to keep their hold, and found in doing so no other difficulty than arose from their own ambition and mutual jealousies. If any one think this strange and ask the cause, I answer, that all the Princedoms of which we have record have been governed in one or other of two ways, either by a sole Prince, all others being his servants permitted by his grace and favour to assist in governing the kingdom as his ministers; or else, by a Prince with his Barons who hold their rank, not by the favour of a superior Lord, but by antiquity of blood, and who have States and subjects of their own who recognize them as their rulers and entertain for them a natural affection. States governed by a sole Prince and by his servants vest in him a more complete authority; because throughout the land none but he is recognized as sovereign, and if obedience be yielded to any others, it is yielded as to his ministers and officers for whom personally no special love is felt. Of these two forms of government we have examples in our own days in the Turk and the King of France. The whole Turkish empire is governed by a sole Prince, all others being his slaves. Dividing his kingdom into sandjaks, he sends thither different governors whom he shifts and changes at his pleasure. The King of France, on the other hand, is surrounded by a multitude of nobles of ancient descent, each acknowledged and loved by subjects of his own, and each asserting a precedence in rank of which the King can deprive him only at his peril. He, therefore, who considers the different character of these two States, will perceive that it would be difficult to gain possession of that of the Turk, but that once won it might be easily held. The obstacles to its conquest are that the invader cannot be called in by a native nobility, nor expect his enterprise to be aided by the defection of those whom the sovereign has around him. And this for the various reasons already given, namely, that all being slaves and under obligations they are not easily corrupted, or if corrupted can render little assistance, being unable, as I have already explained, to carry the people with them. Whoever, therefore, attacks the Turk must reckon on finding a united people, and must trust rather to his own strength than to divisions on the other side. But were his adversary once overcome and defeated in the field, so that he could not repair his armies, no cause for anxiety would remain, except in the family of the Prince; which being extirpated, there would be none else to fear; for since all beside are without credit with the people, the invader, as before his victory he had nothing to hope from them, so after it has nothing to dread. But the contrary is the case in kingdoms governed like that of France, into which, because men who are discontented and desirous of change are always to be found, you may readily procure an entrance by gaining over some Baron of the Realm. Such persons, for the reasons already given, are able to open the way to you for the invasion of their country and to render its conquest easy. But afterwards the effort to hold your ground involves you in endless difficulties, as well in respect of those who have helped you, as of those whom you have overthrown. Nor will it be enough to have destroyed the family of the Prince, since all those other Lords remain to put themselves at the head of new movements; whom being unable either to content or to destroy, you lose the State whenever occasion serves them. Now, if you examine the nature of the government of Darius, you will find that it resembled that of the Turk, and, consequently, that it was necessary for Alexander, first of all, to defeat him utterly and strip him of his dominions; after which defeat, Darius having died, the country, for the causes above explained, was permanently secured to Alexander. And had his successors continued united they might have enjoyed it undisturbed, since there arose no disorders in that kingdom save those of their own creating. But kingdoms ordered like that of France cannot be retained with the same ease. Hence the repeated risings of Spain, Gaul, and Greece against the Romans, resulting from the number of small Princedoms of which these Provinces were made up. For while the memory of these lasted, the Romans could never think their tenure safe. But when that memory was worn out by the authority and long continuance of their rule, they gained a secure hold, and were able afterwards in their contests among themselves, each to carry with him some portion of these Provinces, according as each had acquired influence there; for these, on the extinction of the line of their old Princes, came to recognize no other Lords than the Romans. Bearing all this in mind, no one need wonder at the ease wherewith Alexander was able to lay a firm hold on Asia, nor that Pyrrhus and many others found difficulty in preserving other acquisitions; since this arose, not from the less or greater merit of the conquerors, but from the different character of the States with which they had to deal.",
        "char_count": 5522
      },
      {
        "heading": "Chapter 7",
        "text": "Chapter 5 How Cities or Provinces Which Before Their Acquisition Have Lived Under Their Own Laws Are To Be Governed When a newly acquired State has been accustomed, as I have said, to live under its own laws and in freedom, there are three methods whereby it may be held. The first is to destroy it; the second, to go and reside there in person; the third, to suffer it to live on under its own laws, subjecting it to a tribute, and entrusting its government to a few of the inhabitants who will keep the rest your friends. Such a Government, since it is the creature of the new Prince, will see that it cannot stand without his protection and support, and must therefore do all it can to maintain him; and a city accustomed to live in freedom, if it is to be preserved at all, is more easily controlled through its own citizens than in any other way. We have examples of all these methods in the histories of the Spartans and the Romans. The Spartans held Athens and Thebes by creating oligarchies in these cities, yet lost them in the end. The Romans, to retain Capua, Carthage, and Numantia, destroyed them and never lost them. On the other hand, when they thought to hold Greece as the Spartans had held it, leaving it its freedom and allowing it to be governed by its own laws, they failed, and had to destroy many cities of that Province before they could secure it. For, in truth, there is no sure way of holding other than by destroying, and whoever becomes master of a City accustomed to live in freedom and does not destroy it, may reckon on being destroyed by it. For if it should rebel, it can always screen itself under the name of liberty and its ancient laws, which no length of time, nor any benefits conferred will ever cause it to forget; and do what you will, and take what care you may, unless the inhabitants be scattered and dispersed, this name, and the old order of things, will never cease to be remembered, but will at once be turned against you whenever misfortune overtakes you, as when Pisa rose against the Florentines after a hundred years of servitude. If, however, the newly acquired City or Province has been accustomed to live under a Prince, and his line is extinguished, it will be impossible for the citizens, used, on the one hand, to obey, and deprived, on the other, of their old ruler, to agree to choose a leader from among themselves; and as they know not how to live as freemen, and are therefore slow to take up arms, a stranger may readily gain them over and attach them to his cause. But in Republics there is a stronger vitality, a fiercer hatred, a keener thirst for revenge. The memory of their former freedom will not let them rest; so that the safest course is either to destroy them, or to go and live in them.",
        "char_count": 2764
      },
      {
        "heading": "Chapter 8",
        "text": "Chapter 6 Of New Princedoms Which a Prince Acquires With His Own Arms and by Merit Let no man marvel if in what I am about to say concerning Princedoms wholly new, both as regards the Prince and the form of Government, I cite the highest examples. For since men for the most part follow in the footsteps and imitate the actions of others, and yet are unable to adhere exactly to those paths which others have taken, or attain to the virtues of those whom they would resemble, the wise man should always follow the roads that have been trodden by the great, and imitate those who have most excelled, so that if he cannot reach their perfection, he may at least acquire something of its savour. Acting in this like the skilful archer, who seeing that the object he would hit is distant, and knowing the range of his bow, takes aim much above the destined mark; not designing that his arrow should strike so high, but that flying high it may alight at the point intended. I say, then, that in entirely new Princedoms where the Prince himself is new, the difficulty of maintaining possession varies with the greater or less ability of him who acquires possession. And, because the mere fact of a private person rising to be a Prince presupposes either merit or good fortune, it will be seen that the presence of one or other of these two conditions lessens, to some extent, many difficulties. And yet, he who is less beholden to Fortune has often in the end the better success; and it may be for the advantage of a Prince that, from his having no other territories, he is obliged to reside in person in the State which he has acquired. Looking first to those who have become Princes by their merit and not by their good fortune, I say that the most excellent among them are Moses, Cyrus, Romulus, Theseus, and the like. And though perhaps I ought not to name Moses, he being merely an instrument for carrying out the Divine commands, he is still to be admired for those qualities which made him worthy to converse with God. But if we consider Cyrus and the others who have acquired or founded kingdoms, they will all be seen to be admirable. And if their actions and the particular institutions of which they were the authors be studied, they will be found not to differ from those of Moses, instructed though he was by so great a teacher. Moreover, on examining their lives and actions, we shall see that they were debtors to Fortune for nothing beyond the opportunity which enabled them to shape things as they pleased, without which the force of their spirit would have been spent in vain; as on the other hand, opportunity would have offered itself in vain, had the capacity for turning it to account been wanting. It was necessary, therefore, that Moses should find the children of Israel in bondage in Egypt, and oppressed by the Egyptians, in order that they might be disposed to follow him, and so escape from their servitude. It was fortunate for Romulus that he found no home in Alba, but was exposed at the time of his birth, to the end that he might become king and founder of the City of Rome. It was necessary that Cyrus should find the Persians discontented with the rule of the Medes, and the Medes enervated and effeminate from a prolonged peace. Nor could Theseus have displayed his great qualities had he not found the Athenians disunited and dispersed. But while it was their opportunities that made these men fortunate, it was their own merit that enabled them to recognize these opportunities and turn them to account, to the glory and prosperity of their country. They who come to the Princedom, as these did, by virtuous paths, acquire with difficulty, but keep with ease. The difficulties which they have in acquiring arise mainly from the new laws and institutions which they are forced to introduce in founding and securing their government. And let it be noted that there is no more delicate matter to take in hand, nor more dangerous to conduct, nor more doubtful in its success, than to set up as a leader in the introduction of changes. For he who innovates will have for his enemies all those who are well off under the existing order of things, and only lukewarm supporters in those who might be better off under the new. This lukewarm temper arises partly from the fear of adversaries who have the laws on their side, and partly from the incredulity of mankind, who will never admit the merit of anything new, until they have seen it proved by the event. The result, however, is that whenever the enemies of change make an attack, they do so with all the zeal of partisans, while the others defend themselves so feebly as to endanger both themselves and their cause. But to get a clearer understanding of this part of our subject, we must look whether these innovators can stand alone, or whether they depend for aid upon others; in other words, whether to carry out their ends they must resort to entreaty, or can prevail by force. In the former case they always fare badly and bring nothing to a successful issue; but when they depend upon their own resources and can employ force, they seldom fail. Hence it comes that all armed Prophets have been victorious, and all unarmed Prophets have been destroyed. For, besides what has been said, it should be borne in mind that the temper of the multitude is fickle, and that while it is easy to persuade them of a thing, it is hard to fix them in that persuasion. Wherefore, matters should be so ordered that when men no longer believe of their own accord, they may be compelled to believe by force. Moses, Cyrus, Theseus, and Romulus could never have made their ordinances be observed for any length of time had they been unarmed, as was the case, in our own days, with the Friar Girolamo Savonarola, whose new institutions came to nothing so soon as the multitude began to waver in their faith; since he had not the means to keep those who had been believers steadfast in their belief, or to make unbelievers believe. Such persons, therefore, have great difficulty in carrying out their designs; but all their difficulties are on the road, and may be overcome by courage. Having conquered these, and coming to be held in reverence, and having destroyed all who were jealous of their influence, they remain powerful, safe, honoured, and prosperous. To the great examples cited above, I would add one other, of less note indeed, but assuredly bearing some proportion to them, and which may stand for all others of a like character. I mean the example of Hiero the Syracusan. He from a private station rose to be Prince of Syracuse, and he too was indebted to Fortune only for his opportunity. For the Syracusans being oppressed, chose him to be their Captain, which office he so discharged as deservedly to be made their King. For even while a private citizen his merit was so remarkable, that one who writes of him says, he lacked nothing that a King should have save the Kingdom. Doing away with the old army, he organized a new, abandoned existing alliances and assumed new allies, and with an army and allies of his own, was able on that foundation to build what superstructure he pleased; having trouble enough in acquiring, but none in preserving what he had acquired.",
        "char_count": 7251
      },
      {
        "heading": "Chapter 9",
        "text": "Chapter 7 Of New Princedoms Acquired By the Aid of Others and By Good Fortune They who from a private station become Princes by mere good fortune, do so with little trouble, but have much trouble to maintain themselves. They meet with no hindrance on their way, being carried as it were on wings to their destination, but all their difficulties overtake them when they alight. Of this class are those on whom States are conferred either in return for money, or through the favour of him who confers them; as it happened to many in the Greek cities of Ionia and the Hellespont to be made Princes by Darius, that they might hold these cities for his security and glory; and as happened in the case of those Emperors who, from privacy, attained the Imperial dignity by corrupting the army. Such Princes are wholly dependent on the favour and fortunes of those who have made them great, than which supports none could be less stable or secure; and they lack both the knowledge and the power that would enable them to maintain their position. They lack the knowledge, because unless they have great parts and force of character, it is not to be expected that having always lived in a private station they should have learned how to command. They lack the power, since they cannot look for support from attached and faithful troops. Moreover, States suddenly acquired, like all else that is produced and that grows up rapidly, can never have such root or hold as that the first storm which strikes them shall not overthrow them; unless, indeed, as I have said already, they who thus suddenly become Princes have a capacity for learning quickly how to defend what Fortune has placed in their lap, and can lay those foundations after they rise which by others are laid before. Of each of these methods of becoming a Prince, namely, by merit and by good fortune, I shall select an instance from times within my own recollection, and shall take the cases of Francesco Sforza and Cesare Borgia. By suitable measures and singular ability, Francesco Sforza rose from privacy to be Duke of Milan, preserving with little trouble what it cost him infinite efforts to gain. On the other hand, Cesare Borgia, vulgarly spoken of as Duke Valentino, obtained his Princedom through the favourable fortunes of his father, and with these lost it, although, so far as in him lay, he used every effort and practised every expedient that a prudent and able man should, who desires to strike root in a State given him by the arms and fortune of another. For, as I have already said, he who does not lay his foundations at first, may, if he be of great parts, succeed in laying them afterwards, though with inconvenience to the builder and risk to the building. And if we consider the various measures taken by Duke Valentino, we shall perceive how broad were the foundations he had laid whereon to rest his future power. These I think it not superfluous to examine, since I know not what lessons I could teach a new Prince, more useful than the example of his actions. And if the measures taken by him did not profit him in the end, it was through no fault of his, but from the extraordinary and extreme malignity of Fortune. In his efforts to aggrandize the Duke his son, Alexander VI had to face many difficulties, both immediate and remote. In the first place, he saw no way to make him Lord of any State which was not a State of the Church, while, if he sought to take for him a State belonging to the Church, he knew that the Duke of Milan and the Venetians would withhold their consent; Faenza and Rimini being already under the protection of the latter. Further, he saw that the arms of Italy, and those more especially of which he might have availed himself, were in the hands of men who had reason to fear his aggrandizement, that is, of the Orsini, the Colonnesi, and their followers. These therefore he could not trust. It was consequently necessary that the existing order of things should be changed, and the States of Italy thrown into confusion, in order that he might safely make himself master of some part of them; and this became easy for him when he found that the Venetians, moved by other causes, were plotting to bring the French once more into Italy. This design he accordingly did not oppose, but furthered by annulling the first marriage of the French King. King Louis therefore came into Italy at the instance of the Venetians, and with the consent of Pope Alexander, and no sooner was he in Milan than the Pope got troops from him to aid him in his enterprise against Romagna, which Province, moved by the reputation of the French arms, at once submitted. After thus obtaining possession of Romagna, and after quelling the Colonnesi, Duke Valentino was desirous to follow up and extend his conquests. Two causes, however, held him back, namely, the doubtful fidelity of his own forces, and the waywardness of France. For he feared that the Orsini, of whose arms he had made use, might fail him, and not merely prove a hindrance to further acquisitions, but take from him what he had gained, and that the King might serve him the same turn. How little he could count on the Orsini was made plain when, after the capture of Faenza, he turned his arms against Bologna, and saw how reluctantly they took part in that enterprise. The King’s mind he understood, when, after seizing on the Dukedom of Urbino, he was about to attack Tuscany; from which design Louis compelled him to desist. Whereupon the Duke resolved to depend no longer on the arms or fortune of others. His first step, therefore, was to weaken the factions of the Orsini and Colonnesi in Rome. Those of their following who were of good birth, he gained over by making them his own gentlemen, assigning them a liberal provision, and conferring upon them commands and appointments suited to their rank; so that in a few months their old partisan attachments died out, and the hopes of all rested on the Duke alone. He then awaited an occasion to crush the chiefs of the Orsini, for those of the house of Colonna he had already scattered, and a good opportunity presenting itself, he turned it to the best account. For when the Orsini came at last to see that the greatness of the Duke and the Church involved their ruin, they assembled a council at Magione in the Perugian territory, whence resulted the revolt of Urbino, commotions in Romagna, and an infinity of dangers to the Duke, all of which he overcame with the help of France. His credit thus restored, the Duke trusting no longer either to the French or to any other foreign aid, that he might not have to confront them openly, resorted to stratagem, and was so well able to dissemble his designs, that the Orsini, through the mediation of Signor Paolo (whom he failed not to secure by every friendly attention, furnishing him with clothes, money, and horses), were so won over as to be drawn in their simplicity into his hands at Sinigaglia. When the leaders were thus disposed of, and their followers made his friends, the Duke had laid sufficiently good foundations for his future power, since he held all Romagna together with the Dukedom of Urbino, and had ingratiated himself with the entire population of these States, who now began to see that they were well off. And since this part of his conduct merits both attention and imitation, I shall not pass it over in silence. After the Duke had taken Romagna, finding that it had been ruled by feeble Lords, who thought more of plundering than correcting their subjects, and gave them more cause for division than for union, so that the country was overrun with robbery, tumult, and every kind of outrage, he judged it necessary, with a view to render it peaceful and obedient to his authority, to provide it with a good government. Accordingly he set over it Messer Remiro d’Orco, a stern and prompt ruler, who being entrusted with the fullest powers, in a very short time, and with much credit to himself, restored it to tranquillity and order. But afterwards apprehending that such unlimited authority might become odious, the Duke decided that it was no longer needed, and established in the centre of the Province a civil Tribunal, with an excellent President, in which every town was represented by its advocate. And knowing that past severities had generated ill-feeling against himself, in order to purge the minds of the people and gain their good-will, he sought to show them that any cruelty which had been done had not originated, with him, but in the harsh disposition of his minister. Availing himself of the pretext which this afforded, he one morning caused Remiro to be beheaded, and exposed in the market place of Cesena with a block and bloody axe by his side. The barbarity of which spectacle at once astounded and satisfied the populace. But, returning to the point whence we diverged, I say that the Duke, finding himself fairly strong and in a measure secured against present dangers, being furnished with arms of his own choosing and having to a great extent got rid of those which, if left near him, might have caused him trouble, had to consider, if he desired to follow up his conquests, how he was to deal with France, since he saw he could expect no further support from King Louis, whose eyes were at last opened to his mistake. He therefore began to look about for new alliances, and to waver in his adherence to the French, then occupied with their expedition into the kingdom of Naples against the Spaniards, at that time laying siege to Gaeta; his object being to secure himself against France; and in this he would soon have succeeded had Alexander lived. Such was the line he took to meet present exigencies. As regards the future, he had to apprehend that a new Head of the Church might not be his friend, and might even seek to deprive him of what Alexander had given. This he thought to provide against in four ways. First, by exterminating all who were of kin to those Lords whom he had despoiled of their possessions, that they might not become instruments in the hands of a new Pope. Second, by gaining over all the Roman nobles, so as to be able with their help to put a bridle, as the saying is, in the Pope’s mouth. Third, by bringing the college of Cardinals, so far as he could, under his control. And fourth, by establishing his authority so firmly before his father’s death, as to be able by himself to withstand the shock of a first onset. Of these measures, at the time when Alexander died, he had already effected three, and had almost carried out the forth. For of the Lords whose possessions he had usurped, he had put to death all whom he could reach, and very few had escaped. He had gained over the Roman nobility, and had the majority in the College of Cardinals on his side. As to further acquisitions, his design was to make himself master of Tuscany. He was already in possession of Perugia and Piombino, and had assumed the protectorship of Pisa, on which city he was about to spring; taking no heed of France, as indeed he no longer had occasion, since the French had been deprived of the kingdom of Naples by the Spaniards under circumstances which made it necessary for both nations to buy his friendship. Pisa taken, Lucca and Siena would soon have yielded, partly through jealousy of Florence, partly through fear, and the position of the Florentines must then have been desperate. Had he therefore succeeded in these designs, as he was succeeding in that very year in which Alexander died, he would have won such power and reputation that he might afterwards have stood alone, relying on his own strength and resources, without being beholden to the power and fortune of others. But Alexander died five years from the time he first unsheathed the sword, leaving his son with the State of Romagna alone consolidated, with all the rest unsettled, between two powerful hostile armies, and sick almost to death. And yet such were the fire and courage of the Duke, he knew so well how men must either be conciliated or crushed, and so solid were the foundations he had laid in that brief period, that had these armies not been upon his back, or had he been in sound health, he must have surmounted every difficulty. How strong his foundations were may be seen from this, that Romagna waited for him for more than a month; and that although half dead, he remained in safety in Rome, where though the Baglioni, the Vitelli, and the Orsini came to attack him, they met with no success. Moreover, since he was able if not to make whom he liked Pope, at least to prevent the election of any whom he disliked, had he been in health at the time when Alexander died, all would have been easy for him. But he told me himself on the day on which Julius II was created, that he had foreseen and provided for everything else that could happen on his father’s death, but had never anticipated that when his father died he too should be at death’s-door. Taking all these actions of the Duke together, I can find no fault with him; nay, it seems to me reasonable to put him forward, as I have done, as a pattern for all such as rise to power by good fortune and the help of others. For with his great spirit and high aims he could not act otherwise than he did, and nothing but the shortness of his father’s life and his own illness prevented the success of his designs. Whoever, therefore, on entering a new Princedom, judges it necessary to rid himself of enemies, to conciliate friends, to prevail by force or fraud, to make himself feared yet not hated by his subjects, respected and obeyed by his soldiers, to crush those who can or ought to injure him, to introduce changes in the old order of things, to be at once severe and affable, magnanimous and liberal, to do away with a mutinous army and create a new one, to maintain relations with Kings and Princes on such a footing that they must see it for their interest to aid him, and dangerous to offend, can find no brighter example than in the actions of this Prince. The one thing for which he may be blamed was the creation of Pope Julius II, in respect of whom he chose badly. Because, as I have said already, though he could not secure the election he desired, he could have prevented any other; and he ought never to have consented to the creation of any one of those Cardinals whom he had injured, or who on becoming Pope would have reason to fear him; for fear is as dangerous an enemy as resentment. Those whom he had offended were, among others, San Pietro ad Vincula, Colonna, San Giorgio, and Ascanio; all the rest, excepting d’Amboise and the Spanish Cardinals (the latter from their connexion and obligations, the former from the power he derived through his relations with the French Court), would on assuming the Pontificate have had reason to fear him. The duke, therefore, ought, in the first place, to have laboured for the creation of a Spanish Pope; failing in which, he should have agreed to the election of d’Amboise, but never to that of San Pietro ad Vincula. And he deceives himself who believes that with the great, recent benefits cause old wrongs to be forgotten. The Duke, therefore, erred in the part he took in this election; and his error was the cause of his ultimate downfall.",
        "char_count": 15291
      },
      {
        "heading": "Chapter 10",
        "text": "Chapter 8 Of Those Who By Their Crimes Come to Be Princes But since from privacy a man may also rise to be a Prince in one or other of two ways, neither of which can be referred wholly either to merit or to fortune, it is fit that I notice them here, though one of them may fall to be discussed more fully in treating of Republics. The ways I speak of are, first, when the ascent to power is made by paths of wickedness and crime; and second, when a private person becomes ruler of his country by the favour of his fellow-citizens. The former method I shall make clear by two examples, one ancient, the other modern, without entering further into the merits of the matter, for these, I think, should be enough for any one who is driven to follow them. Agathocles the Sicilian came, not merely from a private station, but from the very dregs of the people, to be King of Syracuse. Son of a potter, through all the stages of his fortunes he led a foul life. His vices, however, were conjoined with so great vigour both of mind and body, that becoming a soldier, he rose through the various grades of the service to be Praetor of Syracuse. Once established in that post, he resolved to make himself Prince, and to hold by violence and without obligation to others the authority which had been spontaneously entrusted to him. Accordingly, after imparting his design to Hamilcar, who with the Carthaginian armies was at that time waging war in Sicily, he one morning assembled the people and senate of Syracuse as though to consult with them on matters of public moment, and on a preconcerted signal caused his soldiers to put to death all the senators, and the wealthiest of the commons. These being thus got rid of, he assumed and retained possession of the sovereignty without opposition on the part of the people; and although twice defeated by the Carthaginians, and afterwards besieged, he was able not only to defend his city, but leaving a part of his forces for its protection, to invade Africa with the remainder, and so in a short time to raise the siege of Syracuse, reducing the Carthaginians to the utmost extremities, and compelling them to make terms whereby they abandoned Sicily to him and confined themselves to Africa. Whoever examines this man’s actions and achievements will discover little or nothing in them which can be ascribed to Fortune, seeing, as has already been said, that it was not through the favour of any, but by the regular steps of the military service, gained at the cost of a thousand hardships and hazards, he reached the princedom which he afterwards maintained by so many daring and dangerous enterprises. Still, to slaughter fellow-citizens, to betray friends, to be devoid of honour, pity, and religion, cannot be counted as merits, for these are means which may lead to power, but which confer no glory. Wherefore, if in respect of the valour with which he encountered and extricated himself from difficulties, and the constancy of his spirit in supporting and conquering adverse fortune, there seems no reason to judge him inferior to the greatest captains that have ever lived, his unbridled cruelty and inhumanity, together with his countless crimes, forbid us to number him with the greatest men; but, at any rate, we cannot attribute to Fortune or to merit what he accomplished without either. In our own times, during the papacy of Alexander VI, Oliverotto of Fermo,. who some years before had been left an orphan, and had been brought up by his maternal uncle Giovanni Fogliani, was sent while still a lad to serve under Paolo Vitelli, in the expectation that a thorough training under that commander might qualify him for high rank as a soldier. After the death of Paolo, he served under his brother Vitellozzo, and in a very short time, being of a quick wit, hardy and resolute, he became one of the first soldiers of his company. But thinking it beneath him to serve under others, with the countenance of the Vitelleschi and the connivance of certain citizens of Fermo who preferred the slavery to the freedom of their country, he formed the design to seize on that town. He accordingly wrote to Giovanni Fogliani that after many years of absence from home, he desired to see him and his native city once more, and to look a little into the condition of his patrimony; and as his one endeavour had been to make himself a name, in order that his fellow-citizens might see his time had not been mis-spent, he proposed to return honourably attended by a hundred horsemen from among his own friends and followers; and he begged Giovanni graciously to arrange for his reception by the citizens of Fermo with corresponding marks of distinction, as this would be creditable not only to himself, but also to the uncle who had brought him up. Giovanni accordingly, did not fail in any proper attention to his nephew, but caused him to be splendidly received by his fellow-citizens, and lodged him in his house; where Oliverotto having passed some days, and made the necessary arrangements for carrying out his wickedness, gave a formal banquet, to which he invited his uncle and all the first men of Fermo. When the repast and the other entertainments proper to such an occasion had come to an end, Oliverotto artfully turned the conversation to matters of grave interest, by speaking of the greatness of Pope Alexander and Cesare his son, and of their enterprises; and when Giovanni and the others were replying to what he said, he suddenly rose up, observing that these were matters to be discussed in a more private place, and so withdrew to another chamber; whither his uncle and all the other citizens followed him, and where they had no sooner seated themselves, than soldiers rushing out from places of concealment put Giovanni and all the rest to death. After this butchery, Oliverotto mounted his horse, rode through the streets, and besieged the chief magistrate in the palace, so that all were constrained by fear to yield obedience and accept a government of which he made himself the head. And all who from being disaffected were likely to stand in his way, he put to death, while he strengthened himself with new ordinances, civil and military, to such purpose, that for the space of a year during which he retained the Princedom, he not merely kept a firm hold of the city, but grew formidable to all his neighbours. And it would have been as impossible to unseat him as it was to unseat Agathocles, had he not let himself be overreached by Cesare Borgia on the occasion when, as has already been told, the Orsini and Vitelli were entrapped at Sinigaglia; where he too being taken, one year after the commission of his parricidal crime, was strangled along with Vitellozzo, whom he had assumed for his master in villany as in valour. It may be asked how Agathocles and some like him, after numberless acts of treachery and cruelty, have been able to live long in their own country in safety, and to defend themselves from foreign enemies, without being plotted against by their fellow-citizens, whereas, many others, by reason of their cruelty, have failed to maintain their position even in peaceful times, not to speak of the perilous times of war. I believe that this results from cruelty being well or ill-employed. Those cruelties we may say are well employed, if it be permitted to speak well of things evil, which are done once for all under the necessity of self-preservation, and are not afterwards persisted in, but so far as possible modified to the advantage of the governed. Ill-employed cruelties, on the other hand, are those which from small beginnings increase rather than diminish with time. They who follow the first of these methods, may, by the grace of God and man, find, as did Agathocles, that their condition is not desperate; but by no possibility can the others maintain themselves. Hence we may learn the lesson that on seizing a state, the usurper should make haste to inflict what injuries he must, at a stroke, that he may not have to renew them daily, but be enabled by their discontinuance to reassure men’s minds, and afterwards win them over by benefits. Whosoever, either through timidity or from following bad counsels, adopts a contrary course, must keep the sword always drawn, and can put no trust in his subjects, who suffering from continued and constantly renewed severities, will never yield him their confidence. Injuries, therefore, should be inflicted all at once, that their ill savour being less lasting may the less offend; whereas, benefits should be conferred little by little, that so they may be more fully relished. But, before all things, a Prince should so live with his subjects that no vicissitude of good or evil fortune shall oblige him to alter his behaviour; because, if a need to change come through adversity, it is then too late to resort to severity; while any leniency you may use will be thrown away, for it will be seen to be compulsory and gain you no thanks.",
        "char_count": 8988
      },
      {
        "heading": "Chapter 11",
        "text": "Chapter 9 Of the Civil Princedom I come now to the second case, namely, of the leading citizen who, not by crimes or violence, but by the favour of his fellow-citizens is made Prince of his country. This may be called a Civil Princedom, and its attainment depends not wholly on merit, nor wholly on good fortune, but rather on what may be termed a fortunate astuteness. I say then that the road to this Princedom lies either through the favour of the people or of the nobles. For in every city are to be found these two opposed humours having their origin in this, that the people desire not to be domineered over or oppressed by the nobles, while the nobles desire to oppress and domineer over the people. And from these two contrary appetites there arises in cities one of three results, a Princedom, or Liberty, or Licence. A Princedom is created either by the people or by the nobles, according as one or other of these factions has occasion for it. For when the nobles perceive that they cannot withstand the people, they set to work to magnify the reputation of one of their number, and make him their Prince, to the end that under his shadow they may be enabled to indulge their desires. The people, on the other hand, when they see that they cannot make head against the nobles, invest a single citizen with all their influence and make him Prince, that they may have the shelter of his authority. He who is made Prince by the favour of the nobles, has greater difficulty to maintain himself than he who comes to the Princedom by aid of the people, since he finds many about him who think themselves as good as he, and whom, on that account, he cannot guide or govern as he would. But he who reaches the Princedom by the popular support, finds himself alone, with none, or but a very few about him who are not ready to obey. Moreover, the demands of the nobles cannot be satisfied with credit to the Prince, nor without injury to others, while those of the people well may, the aim of the people being more honourable than that of the nobles, the latter seeking to oppress, the former not to be oppressed. Add to this, that a Prince can never secure himself against a disaffected people, their number being too great, while he may against a disaffected nobility, since their number is small. The worst that a Prince need fear from a disaffected people is, that they may desert him, whereas when the nobles are his enemies he has to fear not only that they may desert him, but also that they may turn against him; because, as they have greater craft and foresight, they always choose their time to suit their safety, and seek favour with the side they think will win. Again, a Prince must always live with the same people, but need not always live with the same nobles, being able to make and unmake these from day to day, and give and take away their authority at his pleasure. But to make this part of the matter clearer, I say that as regards the nobles there is this first distinction to be made. They either so govern their conduct as to bind themselves wholly to your fortunes, or they do not. Those who so bind themselves, and who are not grasping, should be loved and honoured. As to those who do not so bind themselves, there is this further distinction. For the most part they are held back by pusillanimity and a natural defect of courage, in which case you should make use of them, and of those among them more especially who are prudent, for they will do you honour in prosperity, and in adversity give you no cause for fear. But where they abstain from attaching themselves to you of set purpose and for ambitious ends, it is a sign that they are thinking more of themselves than of you, and against such men a Prince should be on his guard, and treat them as though they were declared enemies, for in his adversity they will always help to ruin him. He who becomes a Prince through the favour of the people should always keep on good terms with them; which it is easy for him to do, since all they ask is not to be oppressed. But he who against the will of the people is made a Prince by the favour of the nobles, must, above all things, seek to conciliate the people, which he readily may by taking them under his protection. For since men who are well treated by one whom they expected to treat them ill, feel the more beholden to their benefactor, the people will at once become better disposed to such a Prince when he protects them, than if he owed his Princedom to them. There are many ways in which a Prince may gain the good-will of the people, but, because these vary with circumstances, no certain rule can be laid down respecting them, and I shall, therefore, say no more about them. But this is the sum of the matter, that it is essential for a Prince to be on a friendly footing with his people, since otherwise, he will have no resource in adversity. Nabis, Prince of Sparta, was attacked by the whole hosts of Greece, and by a Roman army flushed with victory, and defended his country and crown against them; and when danger approached, there were but few of his subjects against whom he needed to guard himself, whereas had the people been hostile, this would not have been enough. And what I affirm let no one controvert by citing the old saw that ’he who builds on the people builds on mire,’ for that may be true of a private citizen who presumes on his favour with the people, and counts on being rescued by them when overpowered by his enemies or by the magistrates. In such cases a man may often find himself deceived, as happened to the Gracchi in Rome, and in Florence to Messer Giorgio Scali. But when he who builds on the people is a Prince capable of command, of a spirit not to be cast down by ill-fortune, who, while he animates the whole community by his courage and bearing, neglects no prudent precaution, he will not find himself betrayed by the people, but will be seen to have laid his foundations well. The most critical juncture for Princedoms of this kind, is at the moment when they are about to pass from the popular to the absolute form of government: and as these Princes exercise their authority either directly or through the agency of the magistrates, in the latter case their position is weaker and more hazardous, since they are wholly in the power of those citizens to whom the magistracies are entrusted, who can, and especially in difficult times, with the greatest ease deprive them of their authority, either by opposing, or by not obeying them. And in times of peril it is too late for a Prince to assume to himself an absolute authority, for the citizens and subjects who are accustomed to take their orders from the magistrates, will not when dangers threaten take them from the Prince, so that at such seasons there will always be very few in whom he can trust. Such Princes, therefore, must not build on what they see in tranquil times when the citizens feel the need of the State. For then every one is ready to run, to promise, and, danger of death being remote, even to die for the State. But in troubled times, when the State has need of its citizens, few of them are to be found. And the risk of the experiment is the greater in that it can only be made once. Wherefore, a wise Prince should devise means whereby his subjects may at all times, whether favourable or adverse, feel the need of the State and of him, and then they will always be faithful to him.",
        "char_count": 7443
      },
      {
        "heading": "Chapter 12",
        "text": "Chapter 10 How the Strength of All Princedoms Should Be Measured In examining the character of these Princedoms, another circumstance has to be considered, namely, whether the Prince is strong enough, if occasion demands, to stand alone, or whether he needs continual help from others. To make the matter clearer, I pronounce those to be able to stand alone who, with the men and money at their disposal, can get together an army fit to take the field against any assailant; and, conversely, I judge those to be in constant need of help who cannot take the field against their enemies, but are obliged to retire behind their walls, and to defend themselves there. Of the former I have already spoken, and shall speak again as occasion may require. As to the latter there is nothing to be said, except to exhort such Princes to strengthen and fortify the towns in which they dwell, and take no heed of the country outside. For whoever has thoroughly fortified his town, and put himself on such a footing with his subjects as I have already indicated and shall hereafter speak of, will always be attacked with much circumspection; for men are always averse to enterprises that are attended with difficulty, and it is impossible not to foresee difficulties in attacking a Prince whose town is strongly fortified and who is not hated by his subjects. The towns of Germany enjoy great freedom. Having little territory, they render obedience to the Emperor only when so disposed, fearing neither him nor any other neighbouring power. For they are so fortified that it is plain to every one that it would be a tedious and difficult task to reduce them, since all of them are protected by moats and suitable ramparts, are well supplied with artillery, and keep their public magazines constantly stored with victual, drink and fuel, enough to last them for a year. Besides which, in order to support the poorer class of citizens without public loss, they lay in a common stock of materials for these to work on for a year, in the handicrafts which are the life and sinews of such cities, and by which the common people live. Moreover, they esteem military exercises and have many regulations for their maintenance. A Prince, therefore, who has a strong city, and who does not make himself hated, can not be attacked, or should he be so, his assailant will come badly off; since human affairs are so variable that it is almost impossible for any one to keep an army posted in leaguer for a whole year without interruption of some sort. Should it be objected that if the citizens have possessions outside the town, and see them burned, they will lose patience, and that self-interest, together with the hardships of a protracted siege, will cause them to forget their loyalty; I answer that a capable and courageous Prince will always overcome these difficulties, now, by holding out hopes to his subjects that the evil will not be of long continuance; now, by exciting their fears of the enemy’s cruelty; and, again, by dexterously silencing those who seem to him too forward in their complaints. Moreover, it is to be expected that the enemy will burn and lay waste the country immediately on their arrival, at a time when men’s minds are still heated and resolute for defence. And for this very reason the Prince ought the less to fear, because after a few days, when the first ardour has abated, the injury is already done and suffered, and cannot be undone; and the people will now, all the more readily, make common cause with their Prince from his seeming to be under obligations to them, their houses having been burned and their lands wasted in his defence. For it is the nature of men to incur obligation as much by the benefits they render as by those they receive. Wherefore, if the whole matter be well considered, it ought not to be difficult for a prudent Prince, both at the outset and afterwards, to maintain the spirits of his subjects during a siege; provided always that victuals and other means of defence do not run short.",
        "char_count": 4033
      }
    ]
  },
  "social_eng": {
    "meta": {
      "key": "social_eng",
      "title": "Social Engineering: The Art of Human Hacking",
      "creator": "Christopher Hadnagy",
      "filepath": "G:/My Drive/15_E-BOOKS/file005374.epub",
      "subject": "Computer Science"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Table of Contents Cover Title Page Copyright Dedication About the Author About the Technical Editor Credits Foreword Preface and Acknowledgments Chapter 1: A Look into the World of Social Engineering Why This Book Is So Valuable Overview of Social Engineering Summary Chapter 2: Information Gathering Gathering Information Sources for Information Gathering Communication Modeling The Power of Communication Models Chapter 3: Elicitation What Is Elicitation? The Goals of Elicitation Mastering Elicitation Summary Chapter 4: Pretexting: How to Become Anyone What Is Pretexting? The Principles and Planning Stages of Pretexting Successful Pretexting Summary Chapter 5: Mind Tricks: Psychological Principles Used in Social Engineering Modes of Thinking Microexpressions Neurolinguistic Programming (NLP) Interview and Interrogation Building Instant Rapport The Human Buffer Overflow Summary Chapter 6: Influence: The Power of Persuasion The Five Fundamentals of Influence and Persuasion Influence Tactics Altering Reality: Framing Manipulation: Controlling Your Target Manipulation in Social Engineering Summary Chapter 7: The Tools of the Social Engineer Physical Tools Online Information-Gathering Tools Summary Chapter 8: Case Studies: Dissecting the Social Engineer Mitnick Case Study 1: Hacking the DMV Mitnick Case Study 2: Hacking the Social Security Administration Hadnagy Case Study 1: The Overconfident CEO Hadnagy Case Study 2: The Theme Park Scandal Top-Secret Case Study 1: Mission Not Impossible Top-Secret Case Study 2: Social Engineering a Hacker Why Case Studies Are Important Summary Chapter 9: Prevention and Mitigation Learning to Identify Social Engineering Attacks Creating a Personal Security Awareness Culture Being Aware of the Value of the Information You Are Being Asked For Keeping Software Updated Developing Scripts Learning from Social Engineering Audits Concluding Remarks Summary Index",
        "char_count": 1915
      },
      {
        "heading": "Chapter 2",
        "text": "Social Engineering: The Art of Human Hacking Published by Wiley Publishing, Inc. 10475 Crosspoint Boulevard Indianapolis, IN 46256 www.wiley.com Copyright © 2011 by Christopher Hadnagy Published by Wiley Publishing, Inc., Indianapolis, Indiana Published simultaneously in Canada ISBN: 978-0-470-63953-5 ISBN: 978-1-118-02801-8 (ebk) ISBN: 978-1-118-02971-8 (ebk) ISBN: 978-1-118-02974-9 (ebk) Manufactured in the United States of America 10 9 8 7 6 5 4 3 2 1 No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600. Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions . Limit of Liability/Disclaimer of Warranty: The publisher and the author make no representations or warranties with respect to the accuracy or completeness of the contents of this work and specifically disclaim all warranties, including without limitation warranties of fitness for a particular purpose. No warranty may be created or extended by sales or promotional materials. The advice and strategies contained herein may not be suitable for every situation. This work is sold with the understanding that the publisher is not engaged in rendering legal, accounting, or other professional services. If professional assistance is required, the services of a competent professional person should be sought. Neither the publisher nor the author shall be liable for damages arising herefrom. The fact that an organization or Web site is referred to in this work as a citation and/or a potential source of further information does not mean that the author or the publisher endorses the information the organization or website may provide or recommendations it may make. Further, readers should be aware that Internet websites listed in this work may have changed or disappeared between when this work was written and when it is read. For general information on our other products and services please contact our Customer Care Department within the United States at (877) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic books. Library of Congress Control Number: 2010937817 Trademarks: Wiley and the Wiley logo are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without written permission. All other trademarks are the property of their respective owners. Wiley Publishing, Inc. is not associated with any product or vendor mentioned in this book.",
        "char_count": 3225
      },
      {
        "heading": "Chapter 3",
        "text": "About the Technical Editor Jim O’Gorman is a professional penetration tester and social engineering auditor with more 14 years of experience working for companies ranging from small ISPs to Fortune 100 corporations. Jim is co-trainer of the Offensive Security Advanced Windows Exploitation class, one of the most difficult exploit development classes available. A founding member of www.social-engineer.org , Jim is an authority on educating the public about social engineering threats.",
        "char_count": 486
      },
      {
        "heading": "Chapter 4",
        "text": "Credits Executive Editor Carol Long Project Editor Brian Herrmann Technical Editor Jim O’Gorman Production Editor Kathleen Wisor Copy Editor Paula Lowell Editorial Director Robyn B. Siesky Editorial Manager Mary Beth Wakefield Freelancer Editorial Manager Rosemarie Graham Marketing Manager Ashley Zurcher Production Manager Tim Tate Vice President and Executive Group Publisher Richard Swadley Vice President and Executive Publisher Barry Pruett Associate Publisher Jim Minatel Project Coordinator, Cover Lynsey Stanford Compositor Maureen Forys, Happenstance Type-O-Rama Proofreader Jen Larsen, Word One New York Indexer Johnna VanHoose Dinse Cover Image © Digital Vision/Getty Images Cover Designer Ryan Sneed",
        "char_count": 712
      },
      {
        "heading": "Chapter 5",
        "text": "Foreword Security is a puzzle with two sides. From the inside, we look for a sense of comfort and assurance. From the outside, thieves, hackers, and vandals are looking for gaps. Most of us believe our homes are safe until one day, we find ourselves locked out. Suddenly, our perspective shifts and weaknesses are easily found. To completely understand any kind of security it is essential to step outside of the fence, in essence locking ourselves out, and start looking for other ways in. The problem is that most of us are blinded to potential problems by our own confidence or our belief that strong locks, thick doors, a high-end security system, and a guard dog are more than enough to keep most people at bay. I’m not most people. In the last ten years I have pulled more cons and scams than anyone in history. I’ve beaten casinos, faked sports events, fixed auctions, talked people out of their dearest possessions, and walked right past seemingly unbeatable levels of security. I have made a living exposing the methods of thieves, liars, crooks, and con men on a hit TV show called The Real Hustle . If I’d been a real criminal I would probably be rich, famous, or dead—probably all three. I have used a lifetime of research into all forms of deception to teach the public just how vulnerable they really are. Each week, along with Alexis Conran, I pull real scams on real people who have no idea they are being ripped off. Using hidden cameras, we show the audience at home what is possible so they can recognize the same scam. This unusual career has resulted in a unique understanding of how criminals think. I’ve become a sheep in wolves’ clothing. I’ve learned that, no matter how impossible something might seem, there’s almost always a clever, unexpected way to solve the problem. An example of this is when I offered to show how easy it would be to not only steal a woman’s purse, but also to get her to tell me the PIN to her ATM or credit cards. The BBC didn’t think it was possible to accomplish this. When we presented this as an item for The Real Hustle , the BBC commissioner wrote “will never happen” beside it and sent it back. We knew it was entirely possible because different versions of the same scam had been reported, where victims of theft were talked into revealing their PINs in several clever scams around the UK. We took elements from different scams to illustrate exactly how someone might be duped into giving someone else complete access to their bank account. To prove our point we set up the scam at a local cafe. The cafe was on the top floor of a mall on Oxford Street in London. It was relatively quiet as I sat at an empty table wearing a business suit. I placed my briefcase on the table and waited for a suitable victim. In a few moments, just such a victim arrived with a friend and sat at the table next to mine, placing her bag on the seat beside her. As was probably her habit, she pulled the seat close and kept her hand on the bag at all times. I needed to steal the entire bag, but, with her hand resting on it and her friend sitting opposite, she was beginning to look like bad news. But, after a few minutes, her friend left to find a restroom. The mark was alone so I gave Alex and Jess the signal. Playing the part of a couple, Alex and Jess asked the mark if she would take a picture of them both. She was happy to do so. She removed her hand from her bag to take the camera and snap a picture of the “happy couple” and, while distracted, I casually reached over, took her bag, and calmly locked it inside my briefcase. My victim was yet to notice the empty chair as Alex and Jess left the cafe. Once out of sight, Alex headed quickly for the parking garage. It didn’t take long for her to realize her bag was gone. Instantly, she began to panic. She stood up and looked around, frantically. This was exactly what we were hoping for so, I asked her if she needed help. She started to ask me if I had seen anything. I told her I hadn’t but convinced her to sit down and think about what was in the bag. A phone. Make-up. A little cash. And her credit cards. Bingo! I asked who she banked with and then told her that I worked for that bank. What a stroke of luck! I reassured her that everything would be fine but she would need to cancel her credit card right away. I called the “help-desk” number, which was actually Alex, and handed my phone to her. She was hooked and it was now up to Alex to reel her in. Alex was downstairs in the van. On the dashboard, a CD player was playing office noises we had downloaded from the Internet. He kept the mark calm, strung her along, and then assured her that her card could easily be canceled but, to verify her identity, she needed to enter her PIN on the keypad of the phone she was using. My phone and my keypad. You can guess the rest. Once we had her PIN, I left her with her friend and headed for the door. If we were real thieves, we would have had access to her account via ATM withdrawals and chip and PIN purchases. Fortunately for her, it was just a TV show and she was so happy when I came back to return her bag and tell her it was all a fake scam. She even thanked me for giving her bag back to which I replied, “Don’t thank me. I’m the one who stole it.” No matter how secure a system is, there’s always a way to break through. Often, the human elements of the system are the easiest to manipulate and deceive. Creating a state of panic, using influence, manipulation tactics, or causing feelings of trust are all methods used to put a victim at ease. The scenario outlined here is an extreme example, but it shows that, with a little creativity, seemingly impossible scams can be pulled off. The first step in becoming more secure is simply conceding that a system is vulnerable and can be compromised. On the contrary, by believing a breach is impossible, a blindfold is placed over your eyes as you run full speed ahead. Social Engineering is designed to provide you with invaluable insight into the methods used to break seemingly secure systems and expose the threats that exist in the largest vulnerability, the people. This book is not a guide for hackers—they already know how to break in and are finding new ways every day. Instead, Chris Hadnagy offers those inside the fence an opportunity to take a look from the other side, the dark side, as he exposes the thinking and methods of the world’s most malicious hackers, con men, and social engineers. Remember: those who build walls think differently than those who seek to go over, under, around, or through them. As I often tell my audiences, if you think you can’t be conned, you’re just the person I’d like to meet. Paul Wilson October 2010",
        "char_count": 6720
      },
      {
        "heading": "Chapter 6",
        "text": "Preface and Acknowledgments It was just a few years ago that I was sitting with my friend and mentor, Mati Aharoni, deciding to launch www.social-engineer.org . The idea grew and grew until it became an amazing website supported by some truly brilliant people. It didn’t take long to come up with the idea to put those years of research and experience down into the pages of a book. When I had the idea, I was met with overwhelming support. That said, some specific acknowledgements are very important to how this book became what it is today. From a very young age I was always interested in manipulating people. Not in a bad way, but I found it interesting how many times I was able to obtain things or be in situations that would be unreal. One time I was with a good friend and business associate at a tech conference at the Javits Center in New York City. A large corporation had rented FAO Schwarz for a private party. Of course, the party was by invitation only, and my friend and I were two small fish in a large pond: the party was for the CEOs and upper management of companies like HP, Microsoft, and the like. My friend said to me, “It would be really cool to get into that party.” I simply responded, “Why can’t we?” At that point I thought to myself, “I know we can get in there if we just ask the right way . ” So I approached the women in charge of the ticket booth and the guest list and I spoke to them for a few minutes. As I was speaking to them, Linus Torvalds, the creator of the Linux kernel, walked by. I had picked up a Microsoft plush toy at one of the booths and as I joke I turned to Linus and said, “Hey, you want to autograph my Microsoft toy?” He got a good laugh out of it and as he grabbed his tickets he said, “Nice job, young man. I will see you at the party.” I turned back to the women in charge of the ticket booth and was handed two tickets to an exclusive party inside FAO Schwartz. It wasn’t until later in life that I began to analyze stories like this, after some started calling it “the Hadnagy Effect.” As funny as that sounds, I began to see that much of what occurred to me wasn’t luck or fate, but rather knowing how to be where I needed to be at the right time. That doesn’t mean it didn’t take hard work and a lot of help along the way. My muse in life is my wonderful wife. For almost two decades you have supported me in all my ideas and efforts and you are my best friend, my confidant, and my support pillar. Without you I would not be where I am today. In addition, you have produced two of the most beautiful children on this planet. My son and my daughter are the motivation to keep doing all of this. If anything I do can make this place just a little more secure for them, or teach them how to keep themselves safe, it is all worthwhile. To my son and daughter, I cannot express enough gratitude for your support, love, and motivation. My hope is that my son and my little princess will not have to deal with the malicious, bad people out in this world, but I know just how unlikely that is. May this information keep you both just a little more secure. Paul, aka rAWjAW, thanks for all your support on the website. The thousands of hours you spent as the “wiki-master” paid off and now we have a beautiful resource for the world to use. I know I don’t say it enough, but “you’re fired!” Combined with the beautiful creation of Tom, aka DigIp, the website is a work of art. Carol, my editor at Wiley, worked her butt off to get this organized and following some semblance of a timeline. She did an amazing job putting together a great team of people and making this idea a reality. Thank you. Brian, I meant what I said. I am going to miss you when this is over. As I worked with you over the last few months I began to look forward to my editing sessions and the knowledge you would lay on me. Your honest and frank counsel and advice made this book better than it was. My gratitude goes out to Jim, aka Elwood, as well. Without you a lot of what has happened on social-engineer.org as well as inside this book, heck in my life in the last couple years, would not be a reality. Thank you for keeping me humble and in check. Your constant reality checks helped me stay focused and balance the many different roles I had to play. Thank you. Liz, about twelve years ago you told me I should write a book. I am sure you had something different in mind, but here it is. You have helped me through some pretty dark times. Thank you and I love you. Mati, my mentor, and my achoti , where would I be without you? Mati, you truly are my mentor and my brother. Thank you from the bottom of my heart for having the faith in me that I could write this book and launch www.social-engineer.org and that both would be good. More than that, your constant counsel and direction have been translated on the pages of this book to make me more than I thought I could be. Your support with the BackTrack team along with the support of the team at www.offensive-security.com have transcended all I could have expected. Thank you for helping me balance and prioritize. My achoti , a special thanks to you for being the voice of reason and the light at the end of some frustrating days. With all my love I thank you. Each person I mentioned here contributed to this book in some fashion. With their help, support and love this book has become a work that I am proud to have my name on. For the rest of you who have supported the site, the channel, and our research, thank you. As you read this book, I hope it affects you the way writing it has affected me. Albert Einstein once said, “Information is not knowledge.” That is a powerful thought. Just reading this book will not somehow implant this knowledge into your being. Apply the principles, practice what is taught in these pages, and make the information a part of your daily life. When you do that is when you will see this knowledge take effect. Christopher Hadnagy October 2010",
        "char_count": 5973
      },
      {
        "heading": "Chapter 7",
        "text": "Chapter 1 A Look into the World of Social Engineering If you know the enemy and know yourself you need not fear the results of a hundred battles. —Sun Tzu Social engineering (SE) has been largely misunderstood, leading to many differing opinions on what social engineering is and how it works. This has led to a situation where some may view SE as simply lying to scam trivial free items such as pizza or obtaining sexual gratification; others think SE just refers to the tools used by criminals or con men, or perhaps that it is a science whose theories can be broken down into parts or equations and studied. Or perhaps it’s a long-lost mystical art giving practitioners the ability to use powerful mind tricks like a magician or illusionist. In whatever camp your flag flies, this book is for you. Social engineering is used every day by everyday people in everyday situations. A child trying to get her way in the candy aisle or an employee looking for a raise is using social engineering. Social engineering happens in government or small business marketing. Unfortunately, it is also present when criminals, con men, and the like trick people into giving away information that makes them vulnerable to crimes. Like any tool, social engineering is not good or evil, but simply a tool that has many different uses. Consider some of these questions to drive that point home: Have you been tasked to make sure your company is as secure as possible? Are you a security enthusiast who reads every bit of the latest information out there? Are you a professional penetration tester who is hired to test the security of your clients? Are you a college student taking some form of IT specialization as your major? Are you presently a social engineer looking for new and improved ideas to utilize in your practice? Are you a consumer who fears the dangers of fraud and identity theft? Regardless of which one of those situations fits you, the information contained within this book will open your eyes to how you can use social engineering skills. You will also peer into the dark world of social engineering and learn how the “bad guys” use these skills to gain an upper hand. From there, you learn how to become less vulnerable to social engineering attacks. One warning up front: This book is not for the weak. It takes you into those dark corners of society where the “black hats,” the malicious hackers, live. It uncovers and delves into areas of social engineering that are employed by spies and con men. It reviews tactics and tools that seem like they are stolen from a James Bond movie. In addition, it covers common, everyday situations and then shows how they are complex social engineering scenarios. In the end, the book uncovers the “insider” tips and tricks of professional social engineers and yes, even professional criminals. Some have asked why I would be willing to reveal this information. The answer is simple: The “bad guys” don’t stop because of a contractual limitation or their own morals. They don’t cease after one failed attempt. Malicious hackers don’t go away because companies don’t like their servers to be infiltrated. Instead, social engineering, employee deception, and Internet fraud are used more and more each day. While software companies are learning how to strengthen their programs, hackers and malicious social engineers are turning to the weakest part of the infrastructure—the people. Their motivation is all about return on investment (ROI); no self-respecting hacker is going to spend 100 hours to get the same results from a simple attack that takes one hour, or less. The sad result in the end is that no way exists to be 100% secure—unless you unplug all electronic devices and move to the mountains. Because that isn’t too practical, nor is it a lot of fun, this book discusses ways to become more aware and educated about the attacks out there and then outlines methods that you can use to protect against them. My motto is “security through education.” Being educated is one of the only surefire ways to remain secure against the increasing threats of social engineering and identity theft. Kaspersky Labs, a leading provider of antivirus and protection software, estimated that more than 100,000 malware samples were spread through social networks in 2009. In a recent report, Kaspersky estimated that “attacks against social networks are 10 times more successful” than other types of attacks. The old hacker adage, “knowledge is power” does apply here. The more knowledge and understanding one has of the dangers and threats of social engineering each consumer and business can have and the more each attack scenario is dissected, the easier it will be to protect from, mitigate, and stop these attacks. That is where the power of all this knowledge will come in. Why This Book Is So Valuable Many books are available on the market on security, hacking, penetration testing, and even social engineering. Many of these books have very valuable information and tips to help their readers. Even with all that the information available, a book was needed that takes social engineering information to the next level and describes these attacks in detail, explaining them from the malicious side of the fence. This book is not merely a collection of cool stories, neat hacks, or wild ideas. This book covers the world’s first framework for social engineering. It analyzes and dissects the very foundation of what makes a good social engineer and gives practical advice on how to use these skills to enhance the readers’ abilities to test the biggest weakness—the human infrastructure . The Layout This book offers a unique approach to social engineering. It is structured closely to the in-depth social engineering framework found at www.social-engineer.org/framework . This framework outlines the skills and the tools (physical, mental, and personality) a person should strive to possess to be an excellent social engineer. This book takes a “tell and show approach” by first presenting a principle behind a topic then defining, explaining, and dissecting, then showing its application using collections of real stories or case studies. This is not merely a book about stories or neat tricks, but a handbook, a guide through the dark world of social engineering. Throughout the book you can find many Internet links to stories or accounts as well as links to tools and other aspects of the topics discussed. Practical exercises appear throughout the book that are designed to help you master not only the social engineering framework but also the skills to enhance your daily communications. These statements are especially true if you are a security specialist. As you read this book, I hope to impress upon you that security is not a “part-time” job and is not something to take lightly. As criminals and malicious social engineers seem to go from bad to worse in this world, attacks on businesses and personal lives seem to get more intense. Naturally, everyone wants to be protected, as evidenced by the increase in sales for personal protection software and devices. Although these items are important, the best protection is knowledge: security through education. The only true way to reduce the effect of these attacks is to know that they exist, to know how they are done, and to understand the thinking process and mentality of the people who would do such things. When you possess this knowledge and you understand how malicious hackers think, a light bulb goes off. That proverbial light will shine upon the once-darkened corners and enable you to clearly see the “bad guys” lurking there. When you can see the way these attacks are used ahead of time, you can prepare your company's and your personal affairs to ward them off. Of course, I am not contradicting what I said earlier; I believe there is no way to truly be 100% secure. Even top-secret, highly guarded secrets can be and have been hacked in the simplest of manners. Look at the archived story at www.social-engineer.org/resources/book/TopSecretStolen.htm , from a newspaper in Ottawa, Canada. This story is very interesting, because some documents ended up in the wrong hands. These weren’t just any documents, but top-secret defense documents that outlined things such as locations of security fences at the Canadian Forces Base (CFB) in Trenton, the floor plan of the Canadian Joint Incident Response Unit, and more. How did the breach occur? The plans were thrown away, in the trashcan, and someone found them in the dumpster. A simple dumpster dive could have led to one of that country’s largest security breaches. Simple-yet-deadly attacks are launched every day and point to the fact that people need education; need to change the way they adhere to password policies and the way they handle remote access to servers; and need to change the way they handle interviews, deliveries, and employees who are hired or fired. Yet without education the motivation for change just isn’t there. In 2003 the Computer Security Institute did a survey along with the FBI and found that 77% of the companies interviewed stated a disgruntled employee as the source of a major security breach. Vontu, the data loss prevention section of Symantec ( http://go.symantec.com/vontu/ ), says that 1 out of every 500 emails contains confidential data. Some of the highlights of that report, quoted from http://financialservices.house.gov/media/pdf/062403ja.pdf , are as follows: 62% reported incidents at work that could put customer data at risk for identity theft. 66% say their co-workers, not hackers, pose the greatest risk to consumer privacy. Only 10% said hackers were the greatest threat. 46% say it would be “easy” to “extremely easy” for workers to remove sensitive data from the corporate database. 32%, about one in three, are unaware of internal company policies to protect customer data. These are staggering and stomach-wrenching statistics. Later chapters discuss these numbers in more detail. The numbers show a serious flaw in the way security itself is handled. When there is education, hopefully before a breach, then people can make changes that can prevent unwanted loss, pain, and monetary damage. Sun Tzu said, “If you know the enemy and know yourself you need not fear the results of a hundred battles.” How true those words are, but knowing is just half the battle. Action on knowledge is what defines wisdom, not just knowledge alone. This book is most effective used as a handbook or guide through the world of social attacks, social manipulation, and social engineering. What’s Coming Up This is book is designed to cover all aspects, tools, and skills used by professional and malicious social engineers. Each chapter delves deep into the science and art of a specific social engineering skill to show you how it can be used, enhanced, and perfected. The next section of this chapter, “Overview of Social Engineering,” defines social engineering and what roles it plays in society today, as well as the different types of social engineering attacks, including other areas of life where social engineering is used in a non-malicious way. I will also discuss how a social engineer can use the social engineering framework in planning an audit or enhancing his own skills. Chapter 2 is where the real meat of the lessons begins. Information gathering is the foundation of every social engineering audit. The social engineer’s mantra is, “I am only as good as the information I gather.” A social engineer can possess all the skills in the world, but if he or she doesn’t know about the target, if the social engineer hasn’t outlined every intimate detail, then the chance of failure is more likely to occur. Information gathering is the crux of every social engineering engagement, although people skills and the ability to think on your feet can help you get out of a sticky situation. More often than not, the more information you gather, the better your chances of success. The questions that I will answer in that chapter include the following: What sources can a social engineer use? What information is useful? How can a social engineer collect, gather, and organize this information? How technical should a social engineer get? How much information is enough? After the analyzation of information gathering, the next topic addressed in Chapter 2 is communication modeling. This topic closely ties in with information gathering. First I will discuss what communication modeling is and how it began as a practice. Then the chapter walks through the steps needed to develop and then use a proper communication model. It outlines how a social engineer uses this model against a target and the benefits in outlining it for every engagement. Chapter 3 covers elicitation, the next logical step in the framework. It offers a very in-depth look into how questions are used to gain information, passwords, in-depth knowledge of the target, and his or her company. You will learn what is good and proper elicitation and learn how important it is to have your elicitations planned out. Chapter 3 also covers the important topic of preloading the target’s mind with information to make your questions more readily accepted. As you unravel this section you will clearly see how important it is to become an excellent elicitor. You will also clearly see how you can use that skill not just in your security practices but in daily life. Chapter 4, which covers pretexting, is powerful. This heavy topic is one of the critical points for many social engineers. Pretexting involves developing the role the social engineer will play for the attack on the company. Will the social engineer be a customer, vendor, tech support, new hire, or something equally realistic and believable? Pretexting involves not just coming up with the storyline but also developing the way your persona would look, act, talk, walk; deciding what tools and knowledge they would have; and then mastering the entire package so when you approach the target, you are that person, and not simply playing a character. The questions covered include the following: What is pretexting? How do you develop a pretext? What are the principles of a successful pretext? How can a social engineer plan and then execute a perfect pretext? The next step in the framework is one that can fill volumes. Yet it must be discussed from the viewpoint of a social engineer. Chapter 5 is a no-holds-barred discussion on some very confrontational topics, including that of eye cues . For example, what are the varying opinions of some professionals about eye cues, and how can a social engineer use them? The chapter also delves into the fascinating science of microexpressions and its implications on social engineering. Chapter 5 goes on analyzing the research, yielding answers to these questions: Is it possible to use microexpressions in the field of security? How would you do so? What benefit are microexpressions? Can people train themselves to learn how to pick up on microexpressions automatically? After we do the training, what information is obtained through microexpressions? Probably one of the most debated-on topics in Chapter 5 is neurolinguistic programming (NLP). The debate has many people undecided on what it is and how it can be used. Chapter 5 presents a brief history of NLP as well as what makes NLP such a controversy. You can decide for yourself whether NLP is usable in social engineering. Chapter 5 also discusses one of the most important aspects of social engineering in person or on the phone: knowing how to ask good questions, listen to responses, and then ask more questions. Interrogation and interviewing are two methods that law enforcement has used for years to manipulate criminals to confess as well as to solve the hardest cases. This part of Chapter 5 puts to practical use the knowledge you gained in Chapter 3. In addition, Chapter 5 discusses how to build instant rapport—a skill you can use in everyday life. The chapter ends by covering my own personal research into “the human buffer overflow”: the notion that the human mind is much like the software that hackers exploit every day. By applying certain principles, a skilled social engineer can overflow the human mind and inject any command they want. Just like hackers write overflows to manipulate software to execute code, the human mind can be given certain instructions to, in essence, “overflow” the target and insert custom instructions. Chapter 5 is a mind-blowing lesson in how to use some simple techniques to master how people think. Many people have spent their lives researching and proving what can and does influence people. Influence is a powerful tool with many facets to it. To this end, Chapter 6 discusses the fundamentals of persuasion. The principles engaged in Chapter 6 will start you on the road toward becoming a master of persuasion. The chapter presents a brief discussion of the different types of persuasion that exist and provides examples to help solidify how you can use these facets in social engineering. The discussion doesn’t stop there—framing is also a hot topic nowadays. Many different opinions exist on how one can use framing, and this book shows some real-life examples of it. Then dissecting each, I take you through the lessons learned and things you can do to practice reframing yourself as well as use framing in everyday life as a social engineer. Another overwhelming theme in social engineering is manipulation : What is its purpose? What kinds of incentives drive manipulators? How can a person use it in social engineering? Chapter 6 presents all a social engineer needs to know on the topic of manipulation, and how to successfully apply such skills. Chapter 7 covers the tools that can make a social engineering audit more successful. From physical tools such as hidden cameras to software-driven information gathering tools, each section covers tested-and-tried tools for social engineers. Once you understand the social engineering framework, Chapter 8 discusses some real-life case studies. I have chosen two excellent accounts from world-renowned social engineer Kevin Mitnick. I analyze, dissect, and then propose what you can learn from these examples and identify the methods he used from the social engineering framework. Moreover, I discuss what can be learned from his attack vectors as well as how they can be used today. I discuss some personal accounts and dissect them, as well. What social engineering guide would be complete without discussing some of the ways you can mitigate these attacks? The appendix provides this information. I answer some common questions on mitigation and give some excellent tips to help secure you and your organization against these malicious attacks. The preceding overview is just a taste of what is to come. I truly hope you enjoy reading this book as much as I have enjoyed writing it. Social engineering is a passion for me. I do believe there are certain traits, whether learned or inherent, that can make someone a great social engineer. I also subscribe to the belief that with enough time and energy anyone can learn the different aspects of social engineering and then practice these skills to become a proficient social engineer. The principles in this book are not new; there is no mind-blowing technology that you will see that will change the face of security forever. There are no magic pills. As a matter of fact, the principles have been around for as long as people have. What this book does do is combine all of these skills in one location. It does give you clear direction on how to practice these skills as well as examples of real-life situations where they are used. All of this information can help you gain a true sense of understanding the topics discussed. The best place to start is with the basics, by answering one fundamental question: “What is social engineering?” Overview of Social Engineering What is social engineering? I once asked this question to a group of security enthusiasts and I was shocked at the answers I received: “Social engineering is lying to people to get information.” “Social engineering is being a good actor.” “Social engineering is knowing how to get stuff for free.” Wikipedia defines it as “the act of manipulating people into performing actions or divulging confidential information. While similar to a confidence trick or simple fraud, the term typically applies to trickery or deception for the purpose of information gathering, fraud, or computer system access; in most cases the attacker never comes face-to-face with the victim.” Although it has been given a bad name by the plethora of “free pizza,” “free coffee,” and “how to pick up chicks” sites, aspects of social engineering actually touch many parts of daily life. Webster’s Dictionary defines social as “of or pertaining to the life, welfare, and relations of human beings in a community.” It also defines engineering as “the art or science of making practical application of the knowledge of pure sciences, as physics or chemistry, as in the construction of engines, bridges, buildings, mines, ships, and chemical plants or skillful or artful contrivance; maneuvering.” Combining those two definitions you can easily see that social engineering is the art or better yet, science, of skillfully maneuvering human beings to take action in some aspect of their lives. This definition broadens the horizons of social engineers everywhere. Social engineering is used in everyday life in the way children get their parents to give in to their demands. It is used in the way teachers interact with their students, in the way doctors, lawyers, or psychologists obtain information from their patients or clients. It is definitely used in law enforcement, and in dating—it is truly used in every human interaction from babies to politicians and everyone in between. I like to take that definition a step further and say that a true definition of social engineering is the act of manipulating a person to take an action that may or may not be in the “target’s” best interest. This may include obtaining information, gaining access, or getting the target to take certain action. For example, doctors, psychologists, and therapists often use elements I consider social engineering to “manipulate” their patients to take actions that are good for them, whereas a con man uses elements of social engineering to convince his target to take actions that lead to loss for them. Even though the end game is much different, the approach may be very much the same. A psychologist may use a series of well-conceived questions to help a patient come to a conclusion that change is needed. Similarly, a con man will use well-crafted questions to move his target into a vulnerable position. Both of these examples are social engineering at its truest form, but have very different goals and results. Social engineering is not just about deceiving people or lying or acting a part. In a conversation I had with Chris Nickerson, a well-known social engineer from the TV series Tiger Team, he said, “True social engineering is not just believing you are playing a part, but for that moment you are that person, you are that role, it is what your life is.” Social engineering is not just any one action but a collection of the skills mentioned in the framework that when put together make up the action, the skill, and the science I call social engineering. In the same way, a wonderful meal is not just one ingredient, but is made up by the careful combining, mixing, and adding of many ingredients. This is how I imagine social engineering to be, and a good social engineer is like a master chef. Put in a little dab of elicitation, add a shake of manipulation, and a few heaping handfuls of pretexting, and bam! —out comes a great meal of the perfect social engineer. Of course, this book discusses some of these facets, but the main focus is what you can learn from law enforcement, the politicians, the psychologists, and even children to better your abilities to audit and then secure yourself. Analyzing how a child can manipulate a parent so easily gives the social engineer insight into how the human mind works. Noticing how a psychologist phrases questions can help to see what puts people at ease. Noticing how a law enforcement agent performs a successful interrogation gives a clear path on how to obtain information from a target. Seeing how governments and politicians frame their messages for the greatest impact can show what works and what doesn’t. Analyzing how an actor gets into a role can open your eyes to the amazing world of pretexting. By dissecting the research and work of some of the leading minds in microexpressions and persuasion you can see how to use these techniques in social engineering. By reviewing some of the motivators of some of the world’s greatest salespeople and persuasion experts you can learn how to build rapport, put people at ease, and close deals. Then by researching and analyzing the flip side of this coin—the con men, scam artists, and thieves—you can learn how all of these skills come together to influence people and move people in directions they thought they would never go. Mix this knowledge with the skills of lock picks, spies who use hidden cameras, and professional information gatherers and you have a talented social engineer. You do not use every one of these skills in each engagement, nor can you master every one of these skills. Instead, by understanding how these skills work and when to use them, anyone can master the science of social engineering. It is true that some people have a natural talent, like Kevin Mitnick, who could talk anyone into anything, it seemed. Frank Abagnale, Jr., seemed to have the natural talents to con people into believing he was who he wanted them to believe he was. Victor Lustig did the unbelievable, actually convincing some people that he had the rights to sell the Eiffel Tower, topped only by his scam on Al Capone. These social engineers and many more like them seem to have natural talent or a lack of fear that enables them to try things that most of us would never consider attempting. Unfortunately in the world today, malicious hackers are continually improving their skills at manipulating people and malicious social engineering attacks are increasing. DarkReading posted an article ( www.darkreading.com/database_security/security/attacks/showArticle.jhtml?articleID=226200272 ) that cites that data breaches have reached between $1 and $53 million per breach. Citing research by the Ponemon Institute DarkReading states, “Ponemon found that Web-borne attacks, malicious code, and malicious insiders are the most costly types of attacks, making up more than 90 percent of all cybercrime costs per organization per year: A Web-based attack costs $143,209; malicious code, $124,083; and malicious insiders, $100,300.” Malicious insiders being listed on the top three suggests that businesses need to be more aware of the threats posed by malicious social engineering, even from employees. Many of these attacks could have been avoided if people were educated, because they could act on that education. Sometimes just finding out how malicious people think and act can be an eye opener. As example on a much smaller and more personal scale, I was recently discussing with a close friend her financial accounts and how she was worried about being hacked or scammed. In the course of the conversation we started to discuss how easy it is to “guess” people’s passwords. I told her that many people use the same passwords for every account; I saw her face go white as she realized this is her. I told her that most people use simplistic passwords that combine things like their spouse’s name, his or her birthday, or anniversary date. I saw her go an ever-brighter shade of pale. I continued by saying that most of the time people chose the simplest “security question” such as “your (or your mother’s) maiden name” and how easy finding that information is via the Internet or a few fake phone calls. Many people will list this information in Blippy, Twitter, or Facebook accounts. This particular friend didn’t use social media sites too much, so I asked her that if she thought with a few phone calls she could picture herself giving over this information. Of course she said no. To illustrate how easily people hand over personal information, I told her that I once saw a placemat in a restaurant that had a $50-off coupon for a local golf course—a very attractive offer. To take advantage of this offer, you only had to provide your name, date of birth, and street address, and provide a password for an account that would be set up and sent to your e-mail address. (I only noticed this in the first place because someone had started filling out the coupon and left it on the table.) Every day websites are created to collect such sensitive information. A phone call with a survey or some quick research on the Internet can yield a birth date or anniversary date, and armed with this information I have enough to build a password attack list. Plus, a dozen sites offer detailed records of all sorts of personal information on an individual for a mere $9–$30 USD. Realizing how malicious social engineers think, how scammers react to information, and how con men will try anything, can help people to be more aware of what is going on around them. A team of security enthusiasts and I have scoured the Internet collecting stories that show many different aspects of social engineering. These stories can help answer a vital question—“how is social engineering used in society over time?”—and see where social engineering’s place is and how it is used maliciously. Social Engineering and Its Place in Society As already discussed social engineering can be used in many areas of life, but not all of these uses are malicious or bad. Many times social engineering can be used to motivate a person to take an action that is good for them. How? Think about this: John needs to lose weight. He knows he is unhealthy and needs to do something about it. All of John’s friends are overweight, too. They even make jokes about the joys of being overweight and say things like, “I love not worrying about my figure.” On one hand, this is an aspect of social engineering. It is social proof or consensus, where what you find or deem acceptable is determined by those around you. Because John’s close associations view being overweight as acceptable, it is easier for John to accept it. However, if one of those friends lost weight and did not become judgmental but was motivated to help, the possibility exists that John’s mental frame about his weight might change and he might start to feel that losing weight is possible and good. This is, in essence, social engineering. So you can clearly see how social engineering fits into society and everyday life, the following sections present a few examples of social engineering, scams, and manipulation and a review of how they worked. The 419 Scam The 419 scam, better known as the Nigerian Scam, has grown into an epidemic. You can find an archived story and article about this scam at www.social-engineer.org/wiki/archives/ConMen/ConMen-Scam-NigerianFee.html . Basically an email (or as of late, a letter) comes to the target telling him he has been singled out for a very lucrative deal and all he needs to do is offer a little bit of help. If the victim will help the letter sender extract a large sum of money from foreign banks he can have a percentage. After the target is confident and “signs on,” a problem arises that causes the target to pay a fee. After the fee is paid another problem comes up, along with another fee. Each problem is “the last” with “one final fee” and this can be stretched out over many months. The victim never sees any money and loses from $10,000–$50,000 USD in the process. What makes this scam so amazing is that in the past, official documents, papers, letterhead, and even face-to-face meetings have been reported. Recently a variation of this scam has popped up where victims are literally sent a real check. The scammers promise a huge sum of money and want in return only a small portion for their efforts. If the target will wire transfer a small sum (in comparison) of $10,000, when they receive the promised check they can deposit the check and keep the difference. The problem is that the check that comes is a fraud and when the victim goes to cash it she is slapped with check fraud charges and fines, in some cases after the victim has already wired money to the scammer. This scam is successful because it plays on the victim’s greed. Who wouldn’t give $10,000 to make $1,000,000 or even $100,000? Most smart people would. When these people are presented with official documents, passports, receipts, and even official offices with “government personnel” then their belief is set and they will go to great lengths to complete the deal. Commitment and consistency play a part in this scam as well as obligation. I discuss these attributes in greater detail in later chapters, and when I do, you will see why this scam is so powerful. The Power of Scarcity The article archived at www.social-engineer.org/wiki/archives/Governments/Governments-FoodElectionWeapon.html talks about a principle called scarcity . Scarcity is when people are told something they need or want has limited availability and to get it they must comply with a certain attitude or action. Many times the desired behavior is not even spoken, but the way it is conveyed is by showing people who are acting “properly” getting rewards. The article talks about the use of food to win elections in South Africa. When a group or person does not support the “right” leader, foodstuffs become scarce and jobs people once had are given to others who are more supportive. When people see this in action, it doesn’t take long to get them in line. This is a very malicious and hurtful form of social engineering, but nonetheless, one to learn from. It is often the case that people want what is scarce and they will do anything if they are lead to believe that certain actions will cause them to lose out on those items. What makes certain cases even worse, as in the earlier example, is that a government took something necessary to life and made it “scarce” and available only to supporters—a malicious, but very effective, manipulation tactic. The Dalai Lama and Social Engineering The interesting article archived at www.social-engineer.org/wiki/archives/Spies/Spies-DalaiLama.html details an attack made on the Dalai Lama in 2009. A Chinese hacker group wanted to access the servers and files on the network owned by the Dalai Lama. What methods were used in this successful attack? The attackers convinced the office staff at the Dalai Lama’s office to download and open malicious software on their servers. This attack is interesting because it blends both technology hacking and social engineering. The article states, “The software was attached to e-mails that purported to come from colleagues or contacts in the Tibetan movement, according to researcher Ross Anderson, professor of security engineering at the University of Cambridge Computer Laboratory, cited by the Washington Times Monday. The software stole passwords and other information, which in turn gave the hackers access to the office’s e-mail system and documents stored on computers there.” Manipulation was used as well as common attack vectors such as phishing (the practice of sending out emails with enticing messages and links or files that must be opened to receive more information; often those links or files lead to malicious payloads) and exploitation. This attack can work and has worked against major corporations as well as governments. This example is just one in a large pool of examples where these vectors cause massive damage. Employee Theft The topic of employee theft could fill volumes, especially in light of the staggering statistic found at www.social-engineer.org/wiki/archives/DisgruntledEmployees/DisgruntledEmployees-EmployeeTheft.html that more than 60 percent of employees interviewed admitted to taking data of one sort or another from their employers. Many times this data is sold to competitors (as happened in this story from a Morgan Stanley employee: www.social-engineer.org/wiki/archives/DisgruntledEmployees/DisgruntledEmployees-MorganStanley.html ). Other times employee theft is in time or other resources; in some cases a disgruntled employee can cause major damage. I once talked to a client about employee discharge policies, things like disabling key cards, disconnecting network accounts, and escorting discharged employees out of the building. The company felt that everyone was part of the “family” and that those policies wouldn’t apply. Unfortunately, the time came to let go of “Jim,” one of the higher-ranking people in the company. The “firing” went well; it was amicable and Jim said he understood. The one thing the company did right was to handle the firing around closing time to avoid embarrassment and distraction. Hands were shook and then Jim asked the fateful question, “Can I take an hour to clean out my desk and take some personal pictures off my computer? I will turn my key card into the security guard before I leave.” Feeling good about the meeting, they all quickly agreed and left with smiles and a few laughs. Then Jim went to his office, packed a box of all his personal items, took the pictures and other data off his computer, connected to the network, and wiped clean 11 servers’ worth of data—accounting records, payroll, invoices, orders, history, graphics, and much more just deleted in a matter of minutes. Jim turned in his key card as he promised and calmly left the building with no proof that he was the one to initiate these attacks. The next morning a call came in to me from the owner describing the carnage in the ex-employee’s wake. Hoping for a silver bullet, the client had no choice but try to recover what could be recovered forensically and start over from the backups, which were more than two months old. A disgruntled employee who is left unchecked can be more devastating than a team of determined and skilled hackers. To the tune of $15 billion USD, that is what the loss is estimated at being to businesses in the U.S. alone due to employee theft. These stories may leave a question about what different categories of social engineers are out there and whether they can be classified. DarkMarket and Master Splynter In 2009 a story broke about an underground group called DarkMarket—the so-called eBay for criminals, a very tight group that traded stolen credit card numbers and identity theft tools, as well as the items needed to make fake credentials and more. An FBI agent by the name of J. Keith Mularski went under deep cover and infiltrated the DarkMarket site. After a while, Agent Mularski was made an administrator of the site. Despite many trying to discredit him he hung in for more than three years as the admin of the site. During this time, Mularski had to live as a malicious hacker, speak and act as one, and think as one. His pretext was one of a malicious spammer and he was knowledgeable enough to pull it off. His pretext and his social engineering skills paid off because Agent Mularski infiltrated DarkMarket as the infamous Master Splynter, and after three years was essential in shutting down a massive identity theft ring. The three-year social engineering sting operation netted 59 arrests and prevented over $70 million in bank fraud. This is just one example of how social engineering skills can be used for good. The Different Types of Social Engineers As previously discussed, social engineering can take on many forms. It can be malicious and it can be friendly, it can build up and it can tear down. Before moving on to the core of this book, take a brief look at the different forms of social engineers and a very short description of each: Hackers: Software vendors are becoming more skilled at creating software that is hardened , or more difficult to break into. As hackers are hitting more hardened software and as software and network attack vectors, such as remote hacking, are becoming more difficult, hackers are turning to social engineering skills. Often using a blend of hardware and personal skills, hackers are using social engineering in major attacks as well as in minor breaches throughout the world. Penetration testers: Since a real-world penetration tester (also known as a pentester) is very offensive in nature, this category must follow after hackers. True penetration testers learn and use the skills that the malicious hackers use to truly help ensure a client’s security. Penetration testers are people who might have the skills of a malicious black hat but who never use the information for personal gain or harm to the target. Spies: Spies use social engineering as a way of life. Often employing every aspect of the social engineering framework (discussed later in this chapter), spies are experts in this science. Spies from all around the world are taught different methods of “fooling” victims into believing they are someone or something they are not. In addition to being taught the art of social engineering, many times spies also build on credibility by knowing a little or even a lot about the business or government they are trying to social engineer. Identity thieves: Identity theft is the use of information such as a person’s name, bank account numbers, address, birth date, and social security number without the owner’s knowledge. This crime can range from putting on a uniform to impersonating someone to much more elaborate scams. Identity thieves employ many aspects of social engineering and as time passes they seem more emboldened and indifferent to the suffering they cause. Disgruntled employees: After an employee has become disgruntled, they often enter into an adversarial relationship with their employer. This can often be a one-sided situation, because the employee will typically try to hide their level of displeasure to not put their employment at risk. Yet the more disgruntled they become, the easier it becomes to justify acts of theft, vandalism, or other crimes. Scam artist: Scams or cons appeal to greed or other principles that attract people’s beliefs and desires to “make a buck.” Scam artists or con men master the ability to read people and pick out little cues that make a person a good “mark.” They also are skillful at creating situations that present as unbeatable opportunities to a mark. Executive recruiters: Recruiters also must master many aspects of social engineering. Having to master elicitation as well as many of the psychological principles of social engineering, they become very adept at not only reading people but also understanding what motivates people. Many times a recruiter must take into consideration and please not only the job seeker but also the job poster. Salespeople: Similar to recruiters, salespeople must master many people skills. Many sales gurus say that a good salesperson does not manipulate people but uses their skills to find out what people’s needs are and then sees whether they can fill it. The art of sales takes many skills such as information gathering, elicitation, influence, psychological principles, as well as many other people skills. Governments: Not often looked at as social engineers, governments utilize social engineering to control the messages they release as well as the people they govern. Many governments utilize social proof, authority, and scarcity to make sure their subjects are in control. This type of social engineering is not always negative, because some of the messages governments relay are for the good of the people and using certain elements of social engineering can make the message more appealing and more widely accepted. Doctors, psychologists, and lawyers: Although the people in these careers might not seem like they fit into the same category as many of these other social engineers, this group employs the same methods used by the other groups in this list. They must use elicitation and proper interview and interrogation tactics as well as many if not all of the psychological principles of social engineering to manipulate their “targets” (clients) into the direction they want them to take. Regardless of the field, it seems that you can find social engineering or an aspect of it. This is why I hold firmly to the belief that social engineering is a science. Set equations exist that enable a person to “add up” elements of social engineering to lead to the goal. In the example of a con man, think of the equation like this: pretext + manipulation + attachment to greed = target being social engineered. In every situation, knowing what elements will work is the hard part, but then learning how to utilize those elements is where the skill comes in. This was the basis for thought behind developing the social engineering framework. This framework has revolutionized the way social engineering is dissected, as discussed in the next section. The Social Engineering Framework and How to Use It Through experience and research I have tried to outline the elements that make up a social engineer. Each of these elements defines a part of the equation that equals a whole social engineer. These aspects are not set in stone; as a matter of fact, from its original state until now the framework has grown. The purpose of the framework is to give enough information for anyone to build on these skills. The framework is not designed to be an all-inclusive resource for all information in each chapter. For example, the portion of Chapter 5 that covers microexpressions is based on the research of some of the greatest minds in this field and my experience in using that information. By no means is it meant to replace the 50 years of research by such great minds as Dr. Paul Ekman. As you read through the framework you will see that by utilizing the many skills within it, you can not only enhance your security practice, but also your mindset about how to remain secure, how to communicate more fully, and how to understand how people think. Refer to the table of contents for a clear picture of the framework or view it online at www.social-engineer.org/framework . At first glance the framework may appear daunting, but inside this book you will find an analysis of each topic that will enable you to apply, enhance, and build these skills. Knowledge is power—it is true. In this sense, education is the best defense against most social engineering attacks. Even the ones that knowledge can’t protect 100 percent against, having details of these attacks keeps you alert. Education can help you enhance your own skills, as well as be alert. Along with education, though, you need practice. This book was not designed to be a once-read manual; instead it was designed to be a study guide. You can practice and customize each section for your needs. The framework is progressive in the sense that it is the way a social engineering attack is laid out. Each section of the framework discusses the next topic in the order that a social engineer might utilize that skill in their engagement or planning phases. The framework shows how an attack might be outlined. After the attack is planned out, the skills that are needed can be studied, enhanced, and practiced before delivery. Suppose, for example, that you are planning a social engineering audit against a company that wanted to see whether you could gain access to its server room and steal data. Maybe your plan of attack would be to pretend to be a tech support person who needs access to the server room. You would want to gather information, maybe even perform a dumpster dive. Then under the pretext of being the tech guy, you could utilize some covert camera tools as well as practice the proper language and facial/vocal cues for how to act, sound, and look like a tech guy. If you locate what company your client uses for tech support you may need to do info gathering on it. Who does your client normally get to service them? What are the names of the employees with whom they interact? The attack needs to be planned out properly. This book is not just for those who perform audits, though. Many readers are curious about what the attacks are, not because they are protecting a company, but because they need to protect themselves. Not being aware of the way a malicious social engineer thinks can lead someone down the path toward being hacked. College students in the field of security have also used the framework. The information in the framework outlines a realistic path for these vectors, or methods of attack, and enables the reader to study them in depth. Generally, this information can also help enhance your ability to communicate in everyday life. Knowing how to read facial expressions or how to use questions to put people at ease and elicit positive responses can enhance your ability to communicate with your family and friends. It can assist you in becoming a good listener and more aware of people’s feelings. Being able to read people’s body language, facial expressions, and vocal tones can also enhance your ability to be an effective communicator. Understanding how to protect yourself and your loved ones will only make you more valuable and more aware of the world around you. Summary Like any book, the knowledge contained herein is only useful if it you put it into practice. The more you practice the more you will succeed at mastering these skills. Previously, I discussed how social engineering is like mastering the art of cooking. By mixing the right ingredients in the right quantity you can have a meal that is full of flavor and excitement. The first time you try to cook a meal it might have too much salt or it might lack flavor altogether, but you don’t immediately throw in the towel—you keep trying until you get it right. The same goes for social engineering. Some of the necessary skills may come more naturally to you and others may be more difficult. If a particular topic is hard to understand or difficult for you to grasp, do not give up, and do not assume you cannot learn it. Anyone can learn and use these skills with the right amount of effort and work. Also keep in mind that, just like a real recipe, many “ingredients” go into a good social engineering gig. The first ingredient might make more sense after you get down the line a little more. Certain skills—such as “the human buffer overflow” covered in Chapter 5—will only make sense after you master some of the other skills discussed in this book. Regardless, keep practicing and make sure to do extra research on topics for which you need clarity. Now let’s start cooking. Your “recipe” starts in the next chapter with the first ingredient, information gathering.",
        "char_count": 51148
      },
      {
        "heading": "Chapter 8",
        "text": "Chapter 2 Information Gathering War is ninety percent information. —Napoleon Bonaparte It has been said that no information is irrelevant. Those words ring true when it comes to this chapter on information gathering. Even the slightest detail can lead to a successful social engineering breach. My good friend and mentor, Mati Aharoni, who has been a professional pentester for more than a decade, tells a story that really drives this point home. He was tasked with gaining access to a company that had an almost nonexistent footprint on the Web. Because the company offered very few avenues to hack into, gaining this access would prove to be very challenging. Mati began scouring the Internet for any details that could lead to a path in. In one of his searches he found a high-ranking company official who used his corporate email on a forum about stamp collecting and who expressed an interest in stamps from the 1950s. Mati quickly registered a URL, something like www.stampcollection.com , and then found a bunch of old-looking 1950 stamp pictures on Google. Creating a quick website to show his “stamp collection,” he then crafted an email to the company official: Dear Sir, I saw on www.forum.com you are interested in stamps from the 1950s. Recently my grandfather passed away and left me with a stamp collection that I would like to sell. I have a website set up; if you would like to see it please visit www.stampcollection.com . Thanks, Mati Before he sent the email to the target, he wanted to ensure there would be maximum impact. He took the office number from the forum post and placed a phone call to the man. “Good morning, sir, this is Bob. I saw your posting on www.forum.com . My grandfather recently passed and he left me a bunch of stamps from the 1950s and 60s. I took pictures and made a website. If you are interested I can send you the link and you can take a look.” The target was very eager to see this collection and readily accepted the email. Mati sent the man the email and waited for him to click the link. What Mati did was embed a malicious frame on the website. This frame had code in it that would exploit a vulnerability then known in the popular Internet Explorer browser and give control over the target’s computer to Mati. The wait was not long: as soon as the man received the email he clicked the link and the company’s perimeter was compromised. A tiny piece of information—the corporate email this man used to look for stamps—is what led to this compromise. No piece of information is irrelevant. With that knowledge in mind, here are questions that come up with regard to information gathering: How can you gather information? What sources exist for social engineers to gather information? What can you glean from this information to profile your targets? How can you locate, store, and catalog all this information for the easiest level of use? These are just a few of the questions that you will need to find answers for in order to accomplish proper and effective information gathering. With the plethora of social networking sites out there, people can easily share every aspect of their lives with anyone they choose, making potentially damaging information more readily available than ever before. This chapter focuses on the principles of information gathering by presenting examples of how it can be used in social engineering and the devastating effects some of the information people release on the Web can have on their personal and business security. Many of the skills or methods that a social engineer may use come from other fields. One field that is superb at gathering information is sales. Salespeople tend to be very talkative, easygoing, and very good at collecting data about those with whom they interact. I once read a book on sales in which the author encouraged salespeople to gather referrals from the buyer—something along these lines: “Can you tell me one person who you think could benefit from this product as much as you will?” Using simple wording can get a person to open up and refer family, friends, and maybe even coworkers. Harvesting , or gathering this information and then storing it, allows the sales people to have what they call “warm leads” to call on. A warm lead is where they have a person with an “in,” a way to get in the door without having to cold call. The salesperson can now call on those referrals and say something like, “I was just at Jane’s house two doors down, and she bought our premium policy. After reviewing the benefits and paying for the year upfront she said you might benefit from the same coverage. Do you have a minute for me to show you what Jane purchased?” These skills used by salespeople are often mirrored by social engineers. Of course a social engineer is not asking for referrals, but think about the flow of information in and out of this conversation. The salesperson gathers information from his present client, then he relays that information in a way that will make the new “target” more susceptible to listen and let him in. In addition, by dropping hints on what the first customer bought and using words like “premium” and “in advance” the salesperson is preloading the new target with the keywords he wants to use on him in just a little while. This technique is effective in that it builds trust, uses familiarity, and allows the target to feel comfortable with the salesperson, or the social engineer, giving their mind a bridge over the gap that normally would exist there. This chapter, as well as the following chapter, will delve deep into these topics. As a social engineer, both angles are of vital importance to understand and then to use effectively. To return to the illustration used in Chapter 1 of being a chef, a good chef knows all about how to spot good quality products, fresh vegetables, and quality meats. They are knowledgeable about what goes into the recipe, but unless the right quantities are used the food may be too bland or too strong or not good enough to eat at all. Simply knowing that a recipe calls for salt doesn’t make you a chef, but knowing how to mix the right amount and types of ingredients can help you master the art of cooking. A social engineer needs to master the type and quantity of skills to be used (the “recipe”). When that is done they can become a master social engineer. This chapter helps identify this balance. The first ingredient in any recipe for a social engineer is information (detailed in the next section). The higher the quality of the information the more likely you are to achieve success. This chapter begins by discussing how to gather information. Then it moves on to discuss what sources can be used to harvest information. This chapter would not be complete without discussing how to tie it all together and utilize these resources as a social engineer. Gathering Information Gathering information is like building a house. If you try to start with the roof your house will surely be a failure. A good house will be built using a solid foundation and from there it will be built literally from the ground up. As you gather information you may be overwhelmed with how to organize and then use this data, so starting a file or an information gathering service to gather this data in is a good idea. Many tools exist to assist in collecting and then using this data. For penetration tests and social engineering audits I use a Linux distribution called BackTrack that is specifically designed for this purpose. BackTrack is like most Linux distributions in that it is free and open source. Perhaps its greatest asset is that it contains more than 300 tools designed to assist in security auditing. All of the tools within BackTrack are also open source and free. Especially attractive is the high quality of BackTrack’s tools, many of which rival and even surpass tools you would pay an arm and a leg for. Two BackTrack tools that are particularly useful for information gathering and storing are called Dradis and BasKet. The following sections take a quick look at each. Using BasKet BasKet is similar in functionality to Notepad, but more like Notepad on steroids. It is presently maintained by Kelvie Wong and can be found for free either in BackTrack or at http://basket.kde.org/ . The website has full instructions for how to install BasKet. Once installed BasKet is easy to use and the interface is not difficult to understand. As seen in Figure 2-1 , the interface is easy to figure out. Adding a new “Basket” to hold data is as simple as right clicking on the left side of the screen and selecting New Basket. Once new Baskets are added the sky is the limit. You can copy and paste data, place screen shots in the Basket, or even tie in OpenOffice or other types of charts, graphs, and other utilities. Figure 2-1: BasKet allows for easy organization of the data found during information gathering. Adding a screenshot can be done in a few ways. The easiest is to copy the image then right mouse click on the new Basket and click Paste. As shown in Figure 2-1 , adding images is simple but also shows the image right away. Notes can be typed or pasted around the images by simply clicking in the Basket and starting to type. In a normal security audit, what makes BasKet attractive is the way it catalogs data and shows it on the screen. I usually add a different Basket for each type of data such as Whois, social media, and so on. After that, I will do some recon using Google Maps or Google Earth to capture some images of the client’s building or facility, which I can store in BasKet as well. When the audit is complete, being able to pull up and utilize this information quickly is very easy. Figure 2-2 illustrates a nearly complete BasKet that contains a lot of useful information and tabs. As shown in Figure 2-2 , BasKet is easy to store the information in an easy-to-read format. I try to include as much information as possible because no information is too small to store. The information I include is items from the client’s website, WhoIs information, social media sites, images, employee contact info, resumes found, forums, hobbies, and anything else I find linked to the company. Figure 2-2: A nearly completed BasKet with lots of useful information. When I am done, I simply click on the menu called Basket then Export and export the whole BasKet as an HTML page. This is great for reporting or sharing this data. For a social engineer, collecting data, as will be discussed in detail later, is the crux of every gig, but if you cannot recall and utilize the data quickly, it becomes useless. A tool like BasKet makes retaining and utilizing data easy. If you give BasKet a try and use it once, you will be hooked. Using Dradis Although BasKet is a great tool, if you do a lot of information gathering, or if you work on team that needs to collect, store, and utilize data, then a tool that allows for multi-user sharing of this data is important. Enter Dradis. According to the creators of the open-source Dradis, the program is a “self-contained web application that provides a centralized repository of information” you have gathered, and a means by which to plan for what’s to come. Like BasKet, Dradis is a free, open-source tool that can be found at http://dradisframework.org/ . Whether you are using Linux, Windows, or a Mac, Dradis has easy-to-use set up and installation instructions found at http://dradisframework.org/install.html . Once Dradis is installed and set up, you simply browse to the localhost and port you assigned, or use the standard 3004. You can do this by opening a browser and typing https://localhost:3004/ . Once logged in, you’re greeted with the screen shown in Figure 2-3 . Notice the Add Branch button at the top left. Adding a branch allows you to add similar details as you can in BasKet: notes, images, and more, and you can even import notes. Figure 2-3: Dradis has a nice, easy-to-use interface. Dradis and BasKet are just two tools that I have used to collect and store data. The websites for both Dradis and BasKet have very nice tutorials on setting up and using these powerful tools. Whatever operating system you use—Mac, Windows, or Linux—there are choices out there for you. What is important is to use a tool that you are comfortable with and that can handle large amounts of data. For that reason I suggest staying away from things like Notepad in Windows or Smultron or TextEdit in Mac. You want to be able to format and highlight certain areas to make them stand out. In my Dradis server, pictured in Figure 2-3 , I have a section for phone scripts. This functionality is handy for transcribing ideas that might work based on the information I gathered. These tools suggest how a social engineer begins to utilize the information he collects. The first stage in utilizing the information you gather is thinking like a social engineer. Thinking Like a Social Engineer Having a few hundred megabytes of data and pictures is great, but when you start reviewing it, how do you train yourself to review and then think of the data in a way that has maximum impact? Of course you could just open a browser and type in long-winded random searches that may lead to some form of information, some of which may even be useful. If you are hungry you probably don’t just run to the kitchen and start to throw whatever ingredients you see into a bowl and start digging in. Planning, preparation, and thought all cause the meal to be good. Similar to a real meal, a social engineer needs to plan, prepare, and think about what information he will try to obtain and how he will obtain it. When it comes to this vital step of information gathering many people will have to change the way they think. You have to approach the world of information in front of you with a different opinion and mindset than what you normally may have. You have to learn to question everything, and, when you see a piece of information, learn to think of it as a social engineer would. The way you ask questions of the web or other sources must change. The way you view the answers that come back must also change. Overhearing a conversation, reading what seems like a meaningless forum post, seeing a bag of trash—you should assimilate this information in a different way than you did before. My mentor Mati gets excited when he sees a program crash. Why? Because he is a penetration tester and exploit writer. A crash is the first step to finding a vulnerability in software, so instead of being irritated at losing data he gets excited at the crash. A social engineer must approach information in much the same way. When finding a target that utilizes many different social media sites, look for the links between them and the information that can create a whole profile. As an example, one time I rented a car to drive a few states away for business. My companion and I loaded all of our luggage in the trunk; as we were entering the car we noticed a small bag of trash in the back seat. The other person said something like, “Service today just stinks. You figure for what you pay they would at least clean out the car.” True, you would expect that, but I stopped that bag from just being chucked into the nearest can, and I said, “Let me just look at that really quick.” As I opened the bag and pushed aside the Taco Bell wrappers, what was lying in plain sight was a shock to me—half of a ripped-up check. I quickly dumped out the bag and found a bank receipt and the other half of the check. The check was written out for a couple thousand dollars, then just ripped up—not into tiny little pieces, but just into four large chunks, then thrown into a small bag with a Taco Bell wrapper. Taping it back together revealed this person’s name, company name, address, phone number, bank account number, and bank routing number. Together with the bank receipt I now had the balance of his account. Thankfully for him I am not a malicious person because only a couple more steps are needed to commit identity theft. This story personifies how people view their valuable information. This guy rented the car before me and then because he threw the check away he felt it was gone, disposed of safely. Or so he thought; but this is not an isolated case. At this URL you can find a recent story about very valuable things people just threw away or sold for next to nothing at a garage sale: www.social-engineer.org/wiki/archives/BlogPosts/LookWhatIFound.html . Things like: A painting that a museum bought for $1.2 million 1937 Bugatti Type 57S Atalante with a mere 24,000 miles sold for $3 million A copy of the Declaration of Independence If people throw away a painting with a hidden copy of the Declaration of Independence in it, then throwing away bills, medical records, old invoices, or credit card statements probably isn’t such a huge deal. How you interact with people in public can have devastating effects. In the following scenario I was asked to audit a company and before I could proceed I needed to gather some data. Take a look at how simple, seemingly meaningless information can lead to a breach. Simply following one of the higher ups of the target company for a day or two showed me that he stopped for coffee every morning at the same time. Since I was aware of his 7:30 a.m. coffee stop at the local coffee shop I could plan a “meeting.” He would sit for 30–35 minutes, read the paper, and drink a medium cafe latte. I enter the shop about 3–5 minutes after he sits down. I order the same drink as him and sit down next to him in the shop. I look over as he places one section of the paper down and ask whether I can read the paper he is done with. Having already picked up a paper on the way I knew that page three contained an article about a recent murder in the area. After acting as if I just read it, I say out loud, “Even in these small towns things are scary nowadays. You live around here?” Now at this point the target can blow me off, or if I played my cards right, my body language, vocal tone, and appearance will put him at ease. He says, “Yeah, I moved in a few years back for a job. I like small towns, but you hear this more and more.” I continue, “I am just traveling through the area. I sell high-end business consulting services to large companies and always enjoy traveling through the smaller towns but I seem to hear more and more of these stories even in the rural areas.” Then in a very joking tone I say, “You don’t happen to be a bigwig in a large company that needs some consulting do you?” He laughs it off and then as if I just challenged him to prove his worth says, “Well I am a VP of finance at XYZ Corp. here locally, but I don’t handle that department.” “Hey, look, I am not trying to sell you something, just enjoy coffee, but if you think I can stop by and leave you some information tomorrow or Wednesday?” This is where the story gets interesting, as he says, “Well I would but I am heading out for a much-needed vacation on Wednesday. But why don’t you mail it to me and I will call you.” He then hands me a card. “Going somewhere warm and sunny, I hope?” I ask this knowing that I am probably getting close to my point where I need to cut it off. “Taking the wife on a cruise south.” I can tell he doesn’t want to tell me where, which is fine, so we shake hands and part ways. Now could he have been blowing me off? Probably, but I have some valuable information: His direct number When he is leaving for vacation What type of vacation That he is local The name of his company His title in his company That he recently relocated Of course, some of this information I already had from previous information gathering, but I was able to add a substantial amount to it after this meeting. Now to launch the next part of the attack, I call his direct line the day after he is supposed to be gone and ask for him, only to be told by his receptionist, “Sorry, Mr. Smith is on vacation—can I take a message?” Excellent. The information is verified and now all I need to do is launch the final phase, which means dressing up in a suit and taking my $9 business cards to his office. I enter, sign in, and tell the receptionist I have an appointment with Mr. Smith at 10:00 a.m. To which she replies, “He is on vacation, are you sure it is today?” Using my practice sessions on microexpressions, a topic addressed in Chapter 5, I show true surprise: “Wait, his cruise was this week? I thought he left next week.” Now this statement is vital—why? I want the appointment to be believable and I want the receptionist to trust me by proxy. By stating I know about his cruise this must mean Mr. Smith and I have had intimate conversation—enough so that I know his itinerary. But my helplessness elicits pity and right away the secretary comes to my aid. “Oh, honey, I am sorry, do want me to call his assistant?” “Ah, no.” I reply. “I really wanted to leave some information with him. How about this—I will just leave it with you and you can give it to him when he gets back? I am terribly embarrassed; maybe you can avoid even telling him I did this?” “My lips are sealed.” “Thank you. Look I am going to crawl out of here, but before I do can I just use your bathroom?” I know that I normally would not be buzzed in, but I hope the combination of my rapport, my helplessness, and their pity will lead to success—and it does. While in the bathroom, I place an envelope in one stall. On the cover of the envelope I put a sticker that says PRIVATE. Inside the “private” envelope is a USB key with a malicious payload on it. I do this in one stall and also in the hallway by a break room to increase my chances and hope that the person that finds one of them is curious enough to insert it into their computer. Sure enough, this method seems to always work. The scary thing is that this attack probably wouldn’t work if it weren’t for a useless little conversation in a coffee shop. The point is not only about how small data can still lead to a breach, but also how you collect this data. The sources that you can use to collect data are important to understand and test until you are proficient with each method and each source of collection. There are many different types of sources for collecting data. A good social engineer must be prepared to spend some time learning the strengths and weaknesses of each as well as the best way to utilize each source. Thus the topic of the next section. Sources for Information Gathering Many different sources exist for information gathering. The following list cannot possibly cover every source out there, but it does outline the major choices you have. Gathering Information from Websites Corporate and/or personal websites can provide a bounty of information. The first thing a good social engineer will often do is gather as much data as he can from the company’s or person’s website. Spending some quality time with the site can lead to clearly understanding: What they do The products and services they provide Physical locations Job openings Contact numbers Biographies on the executives or board of directors Support forum Email naming conventions Special words or phrases that can help in password profiling Seeing people’s personal websites is also amazing because they will link to almost every intimate detail about their lives—kids, houses, jobs, and more. This information should be cataloged into sections because it will often be something from this list that is used in the attack. Many times company employees will be part of the same forums, hobby lists, or social media sites. If you find one employee on LinkedIn or Facebook, chances are that many more are there as well. Trying to gather all that data can really help a social engineer profile the company as well as the employees. Many employees will talk about their job title in their social media outlets. This can help a social engineer to profile how many people may be in a department and how the departments are structured. Search Engines Johnny Long wrote a famous book called Google Hacking for Penetration Testers and really opened up many people’s eyes to the amazing amount of information that Google holds. Google forgives but it never forgets, and it has been compared to the Oracle. As long as you know how to ask, it can tell you most anything you want to know. Johnny developed a list of what he calls “Google Dorks,” or a string that can be used to search in Google to find out information about a company. For example if you were to type in: site:microsoft.com filetype:pdf you be given a list of every file with the extension of PDF that is on the microsoft.com domain. Being familiar with search terms that can help you locate files on your target is a very important part of information gathering. I make a habit of searching for filetype:pdf , filetype:doc , filetype:xls , and filetype:txt . It is also a good idea to see if employees actually leave files like DAT, CFG, or other database or configuration files open on their servers to be harvested. Entire books are dedicated to the topic of using Google to find data, but the main thing to remember is learning about Google’s operands will help you develop your own. A website like www.googleguide.com/advanced_operators.html has a very nice list of both the operands and how to use them. Google is not the only search engine that reveals amazing information. A researcher named John Matherly created a search engine he called Shodan ( www.shodanhq.com ). Shodan is unique in that it searches the net for servers, routers, specific software, and so much more. For example, a search of microsoft-iis os:“windows 2003” reveals the following number of servers running Windows 2003 with Microsoft IIS: United States 59,140 China 5,361 Canada 4,424 United Kingdom 3,406 Taiwan 3,027 This search is not target-specific, but it does demonstrate one vital lesson: the web contains an amazing wealth of information that needs to be tapped by a social engineer seeking to become proficient at information gathering. Whois Reconnaissance Whois is a name for a service and a database. Whois databases contain a wealth of information that in some cases can even contain full contact information of the website administrators. Using a Linux command prompt or using a website like www.whois.net can lead you to surprisingly specific results like such as a person’s email address, telephone number, or even DNS server IP address. Whois information can be very helpful in profiling a company and finding out details about their servers. All of this information can be used for further information gathering or to launch social engineering attacks. Public Servers A company’s publicly reachable servers are also great sources for what its websites don’t say. Fingerprinting a server for its OS, installed applications, and IP information can say a great deal about a company’s infrastructure. After you determine the platform and applications in use, you could combine this data with a search on the corporate domain name to find entries on public support forums. IP addresses may tell you whether the servers are hosted locally or with a provider; with DNS records you can determine server names and functions, as well as IPs. In one audit after searching the web using the tool called Matelgo (discussed in Chapter 7), I was able to uncover a publicly facing server that housed literally hundreds of documents with key pieces of information about projects, clients, and the creators of those documents. This information was devastating to the company. An important note to keep in mind is that performing a port scan —using a tool like NMAP or another scanner to locate open ports, software, and operating systems used on a public server—can lead to problems with the law in some areas. For example, in June 2003, an Israeli, Avi Mizrahi, was accused by the Israeli police of the offense of attempting the unauthorized access of computer material. He had port scanned the Mossad website. About eight months later, he was acquitted of all charges. The judge even ruled that these kinds of actions should not be discouraged when they are performed in a positive way ( www.law.co.il/media/computer-law/mizrachi_en.pdf ). In December 1999, Scott Moulton was arrested by the FBI and accused of attempted computer trespassing under Georgia’s Computer Systems Protection Act and Computer Fraud and Abuse Act of America. At the time, his IT service company had an ongoing contract with the Cherokee County of Georgia to maintain and upgrade the 911 center security ( www.securityfocus.com/news/126 ). As part of his work, Moulton performed several port scans on Cherokee County servers to check their security and eventually port scanned a web server monitored by another IT company. This provoked a lawsuit, although he was acquitted in 2000. The judge ruled that no damage occurred that would impair the integrity and availability of the network. In 2007 and 2008, England, France, and Germany passed laws that make unlawful the creation, distribution, and possession of materials that allow someone to break any computer law. Port scanners fall under this description. Of course, if you are involved in a paid audit of a company most of this will be in the contract, but it is important to state that it is up to the social engineer auditor to be aware of the local laws and make sure you are not breaking them. Social Media Many companies have recently embraced social media. It’s cheap marketing that touches a large number of potential customers. It’s also another stream of information from a company that can provide breadcrumbs of viable information. Companies publish news on events, new products, press releases, and stories that may relate them to current events. Lately, social networks have taken on a mind of their own. When one becomes successful it seems that a few more pop up that utilize similar technology. With sites like Twitter, Blippy, PleaseRobMe, ICanStalkU, Facebook, LinkedIn, MySpace, and others, you can find information about people’s lives and whereabouts in the wide open. Later, this book will discuss this topic in much more depth and you will see that social networks are amazing sources of information. User Sites, Blogs, and So On User sites such as blogs, wikis, and online videos may provide not only information about the target company, but also offer a more personal connection through the user(s) posting the content. A disgruntled employee who’s blogging about his company’s problems may be susceptible to a sympathetic ear from someone with similar opinions or problems. Either way, users are always posting amazing amounts of data on the web for anyone to see and read. Case in point: Take a look at a new site that has popped up— www.icanstalku.com (see Figure 2-4 ). Contrary to its name, it does not encourage people to actually stalk others. This site points to the complete thoughtlessness of many Twitter users. It scrapes the Twitter site and looks for users who are silly enough to post pictures using their smart phones. Many people do not realize that most smart phones embed GPS location data in their photos. When a user posts a picture to the web with this data embedded it can lead a person right to their location. Displaying location-based information is a scary aspect of social media websites. Not only do they allow you to post pictures of yourself, they also implicitly reveal your location—possibly without your knowledge. Sites like ICanStalkU underscore the danger of this information. Check out a story (one of many) that shows how this data is used for home break-ins, robberies, and sometimes more at www.social-engineer.org/wiki/archives/BlogPosts/TwitterHomeRobbery.html . This type of information can give you a very detailed profile of your target. People love to tweet about where they are, what they are doing, and who they are with. Blippy allows a person to connect their bank accounts and in essence it will “tweet” with each purchase, where it was from, and how much it costs. With pictures including embedded location data and then sites like Facebook, which many use to put personal pictures, stories, and other related info, it is a social engineer’s dream. In a short while a whole profile can be developed with a person’s address, job, pictures, hobbies, and more. Another aspect of social media sites that makes them excellent sources of information gathering is the ability to be anonymous. If the target is a recently divorced middle-aged man who loves his Facebook page, you can be a young woman who is looking for a new friend. Many times, while flirting, people divulge valuable pieces of information. Combine the ability to be anyone or anything you want on the web with the fact that most people believe everything they read as gospel fact and what you have is one of the greatest risks to security. Figure 2-4: A typical scene on the homepage of ICanStalkU.com. Public Reports Public data may be generated by entities inside and outside the target company. This data can consist of quarterly reports, government reports, analyst reports, earnings posted for publicly traded companies, and so on. An example of these are Dunn and Bradstreet reports or other sales reports that are sold for very little money and contain a lot of details on the target company. Another avenue discussed in more detail later is using background checkers such as those found at www.USSearch.com and www.intelius.com . These sites, along with many others, can offer background check services for as little as $1 for one limited report to a $49 per month fee that lets you run as many checks as you want. You can get much of this information for free using search engines, but some of the detailed financial data and personal information can only be obtained easily and legally through a paid-for service. Perhaps most shocking is that many of these companies may even provide data like a person’s Social Security Number to some customers. Using the Power of Observation Though not used enough as a social engineering tool, , simple observation can tell you much about your target. Does the target’s employees use keys, RFID cards, or other methods to enter the building? Is there a designated area for smoking? Are dumpsters locked, and does the building have external cameras? External devices such as power supplies or air conditioning units usually reveal who the service company is, and that can allow the social engineer another vector to gain access. These are just a few of the questions that you can get answers for through observation. Taking some time to watch the target, film using a covert camera, and then studying and analyzing the information later can teach you a lot and give your information file a major boost. Going through the Garbage Yes, as hard as it is to imagine enjoying jumping through the trash, it can yield one of the most lucrative payoffs for information gathering. People often throw away invoices, notices, letters, CDs, computers, USB keys, and a plethora of other devices and reports that can truly give amazing amounts of information. As mentioned previously, if people are willing to throw away art that is worth millions, then things they view as trash will often go without a second thought, right into the garbage. Sometimes companies shred documents they deem as too important to just throw out, but they use an inefficient shredder that leaves paper too easy to put back together, as shown in Figure 2-5 . Figure 2-5: Large one-way shreds leave some words still readable. This image shows a few documents after shredding, but some whole words are still discernable. This type of shredding can be thwarted with a little time and patience and some tape, as seen in Figure 2-6 . Documents that can be even partially taped back together can reveal some very devastating information. Figure 2-6: Putting documents back together only takes time and patience. However, using a shredder that shreds both directions into a fine minced mess makes taping documents back together nearly impossible, as shown in Figure 2-7 . Figure 2-7: You can hardly tell this was once money. Many companies use commercial services that take their shredded documents away for incineration. Some companies even leave the shredding to a third party, which, as you probably guessed, leaves them open to another attack vector. A social engineer who finds out the name of their vendor for this can easily mimic the pickup person and be handed all their documents. Nevertheless, dumpster diving can offer a quick way to find all the information you want. Remember some key pointers when performing a dumpster dive: Wear good shoes or boots: Nothing will ruin your day faster than jumping in a dumpster and having a nail go through your foot. Make sure your shoes tie on nice and tight as well as offer protection from sharp objects. Wear dark clothing: This doesn’t need much explanation. You probably want to wear clothes you don’t mind having to get rid of, and dark clothes to avoid being detected. Bring a flashlight Grab and run: Unless you are in such a secluded area that you have no chance of being caught, grabbing some bags and going elsewhere to rummage through them might be best. Dumpster diving almost always leads to some very useful information. Sometimes a social engineer doesn’t even have to dive into a dumpster to find the goods. Already mentioned in Chapter 1 is the article found at www.social-engineer.org/resources/book/TopSecretStolen.htm , but it solidifies this thought. The Canadian CTU (Counter-Terrorism Unit) had plans for a new building that outlined its security cameras, fences, and other top-secret items. These blueprints were just thrown away—yes, just tossed in the trash, not even shredded, and fortunately found by a friendly person. This story is just one of many that show “the height of stupidity,” as the article stated, but from a social engineer’s point of view, trash diving is one of the best information gathering tools out there. Using Profiling Software Chapter 7 discusses the tools that make up some of the professional toolsets of social engineers, but this section offers a quick overview. Password profilers such as Common User Passwords Profiler (CUPP) and Who’s Your Daddy (WYD) can help a social engineer profile the potential passwords a company or person may use. How to use these tools is discussed in Chapter 7, but a tool like WYD will scrape a person or company’s website and create a password list from the words mentioned on that site. It is not uncommon for people to use words, names, or dates as passwords. These types of software make it easy to create lists to try. Amazing tools such as Maltego (see Chapter 7 for more details), made by Paterva, are an information gatherer’s dream. Maltego allows a social engineer to perform many web-based and passive information gathering searches without having to use any utilities but Maltego itself. Then it will store and graph this data on the screen to be used in reporting, exporting or other purposes. This can really help in developing a profile on a company. Remember, your goal as you collect data is to learn about the target company and the people within the company. Once a social engineer collects enough data, a clear picture will form in their minds as to the best way to manipulate the data from the targets. You want to profile the company as a whole and find out roughly how many employees are part of some club, a hobby, or group. Do they donate to a certain charity or do their kids go to the same school? All of this information is very helpful in developing a profile. A clear profile can help the social engineer not only in developing a good pretext, but can also outline what questions to use, what are good or bad days to call or come onsite as well as many other clues that can make the job so much easier. All of the methods discussed so far are mostly physical, very personal methods of information gathering. I didn’t touch on the very technical side of information gathering like services such as SMTP, DNS, Netbios, and the almighty SNMP. I do cover some of the more technical aspects that Maltego can help with in Chapter 7 in more detail. These methods are worth looking into but are very much technical in nature as opposed to more “human” in nature. Whatever the method you utilize to gather information logically, the question that may come up is now that you know where to gather, how to gather, and even how to catalog, store, and display this info, what do you do with it? As a social engineer, after you have information you must start planning your attacks. To do that you need to start modeling an outline that will use this information. One of the best ways to start utilizing this data is to develop what is called a communication model. Communication Modeling The more elaborate our means of communication, the less we communicate. —Joseph Priestley Communication is a process of transferring information from one entity to another. Communication entails interactions between at least two agents, and can be perceived as a two-way process in which there is an exchange of information and a progression of thoughts, feelings, or ideas toward a mutually accepted goal or direction. This concept is very similar to the definition of social engineering, except the assumption is that those involved in the communication already have a common goal, whereas the goal of the social engineer is to use communication to create a common goal. Communication is a process whereby information is enclosed in a package and is channeled and imparted by a sender to a receiver via some medium. The receiver then decodes the message and gives the sender feedback. All forms of communication require a sender, a message, and a receiver. Understanding how communication works is essential to developing a proper communication model as a social engineer. Modeling your communication as a social engineer will help us to decide the best method of delivery, the best method for feedback, and the best message to include. Communication can take many different forms. There are auditory means, such as speech, song, and tone of voice, and there are nonverbal means, such as body language, sign language, paralanguage, touch, and eye contact. Regardless of the type of communication used, the message and how it is delivered will have a definite effect on the receiver. Understanding the basic ground rules is essential to building a model for a target. Some rules cannot be broken, such as communication always has a sender and a receiver. Also everyone has different personal realities that are built and affected by their past experiences and their perceptions. Everyone perceives, experiences, and interprets things differently based on these personal realities. Any given event will always be perceived differently by different people because of this fact. If you have siblings, a neat exercise to prove this is to ask them their interpretation or memory of an event, especially if it is an emotional event. You will see that their interpretation of this event is very different from what you remember. Each person has both a physical and a mental personal space. You allow or disallow people to enter that space or get close to you depending on many factors. When communicating with a person in any fashion, you are trying to enter their personal space. As a social engineer communicates they are trying to bring someone else into their space and share that personal reality. Effective communication attempts to bring all participants into each other’s mental location. This happens with all interactions, but because it is so common people do it without thinking about it. In interpersonal communications two layers of messages are being sent: verbal and nonverbal. Communication usually contains a verbal or language portion, whether it is in spoken, written, or expressed word. It also usually has a nonverbal portion—facial expressions, body language, or some non-language message like emoticons or fonts. Regardless of the amount of each type of cue (verbal or nonverbal), this communication packet is sent to the receiver and then filtered through her personal reality. She will form a concept based on her reality, then based on that will start to interpret this packet. As the receiver deciphers this message she begins to unscramble its meaning, even if that meaning is not what the sender intended. The sender will know whether his packet is received the way he intended if the receiver gives a communication packet in return to indicate her acceptance or denial of the original packet. Here the packet is the form of communication: the words or letters or emails sent. When the receiver gets the message she has to decipher it. Many factors depend on how it is interpreted. Is she in a good mood, bad mood, happy, sad, angry, compassionate—all of these things as well as the other cues that alter her perception will help her to decipher that message. The social engineer’s goal has to be to give both the verbal and nonverbal cues the advantage to alter the target’s perception so as to have the impact the social engineer desires. Some more basic rules for communication include the following: Never take for granted that the receiver has the same reality as you. Never take for granted that the receiver will interpret the message the way it was intended. Communication is not an absolute, finite thing. Always assume as many different realities exist as there are different people involved in the communication. Knowing these rules can greatly enhance the ability for good and useful communications. This is all good and great but what does communication have to do with developing a model? Even more, what does it have to do with social engineering? The Communication Model and Its Roots As already established, communication basically means sending a packet of information to an intended receiver. The message may come from many sources like sight, sound, touch, smell, and words. This packet is then processed by the target and used to paint an overall picture of “What’s being said.” This method of assessment is called the communication process . This process was originally outlined by social scientists Claude Shannon and Warren Weaver in 1947, when they developed the Shannon-Weaver model, also known as “the mother of all models.” The Shannon-Weaver model, according to Wikipedia, “embodies the concepts of information source, message, transmitter, signal, channel, noise, receiver, information destination, probability of error, coding, decoding, information rate, [and] channel capacity,” among other things. Shannon and Weaver defined this model with a graphic, as shown in Figure 2-8 . In a simple model, also known as the transmission model, information or content is sent in some form from a sender to a destination or receiver. This common concept of communication simply views communication as a means of sending and receiving information. The strengths of this model are its simplicity, generality, and quantifiability. Figure 2-8: The Shannon-Weaver “mother of all models.” Shannon and Weaver structured this model based on: An information source, which produces a message A transmitter, which encodes the message into signals A channel, to which signals are adapted for transmission A receiver, which “decodes” (reconstructs) the message from the signal A destination, where the message arrives They argued that three levels of problems for communication existed within this theory: The technical problem—How accurately can the message be transmitted? The semantic problem—How precisely is the meaning conveyed? The effectiveness problem—How effectively does the received meaning affect behavior? (This last point is important to remember for social engineering. The whole goal of the social engineer is to create a behavior that the social engineer wants.) Almost 15 years later, David Berlo expanded on Shannon and Weaver’s linear model of communication and created the Sender-Message-Channel-Receiver (SMCR) model of communication. SMCR separated the model into clear parts, as shown in Figure 2-9 . Figure 2-9: The Berlo model. You can think of communication as processes of information transmission governed by three levels of rules: Formal properties of signs and symbols The relations between signs/expressions and their users The relationships between signs and symbols and what they represent Therefore, you can further refine the definition of communication as social interaction where at least two interacting agents share a common set of signs and a common set of rules. In 2008 another researcher, D. C. Balmund, combined the research of many of his previous cohorts with his own and developed the transactional model of communication, as shown in Figure 2-10 . In this model you can see that the channel and message can take on many forms, not just spoken, as represented by the picture. The message can be in written, video, or audio form and the receiver can be one person or many people. The feedback also can take on many forms. Combining and analyzing this research can help a social engineer develop a solid communication model. Not only social engineers can benefit from doing this—everyone can. Learning how to develop a plan of communication can enhance the way you deal with your spouse, your kids, your employer or employees—anyone you communicate with. Figure 2-10: The new and improved communication model. Because the focus of this book is social engineers, you need to analyze what a social engineer can take away from all of this. After reading all this theory you may begin to wonder how this can be used. Remember, a social engineer must be a master at communication. They must be able to effectively enter into and remain in a person’s personal and mental space and not offend or turn off the target. Developing, implementing, and practicing effective communication models is the key to accomplishing this goal. The next step then is developing a communication model. Developing a Communication Model Now that you know about the key elements of a communication model, take a look at them from the eyes of a social engineer: The Source: The social engineer is the source of the information or communication that is going to be relayed. The Channel: This is the method of delivery. The Message: Probably the biggest part of the message is knowing what you are going to say to the receiver(s). The Receiver(s): This is the target. The Feedback: What do you want them to do after you effectively give them the communication? How can you use these elements effectively? The first step into the world of communication modeling is starting with your goal. Try working with a couple of the scenarios that might be part of a typical social engineering gig: Develop a phishing email targeted against 25–50 employees and attempt to have them go during work hours to a non-business website that will be embedded with malicious code to hack into their networks. Make an onsite visit to portray a potential interviewee who has just ruined his resume by spilling coffee on it and needs to convince the front-desk person to allow a USB key to be inserted into a computer to print a copy of the resume. When developing a communication strategy you may find working on the model in reverse order to be beneficial. Feedback: What is your desired response? The desired response is to have the majority of the employees you send this email to click on it. That is ideal; of course, you might be happy with just a handful or even one, but the goal, the desired feedback, is to have the majority of targets click on the phishing link. Receivers: This is where your information gathering skills come in handy. You need to know all about the targets. Do they like sports? Are they predominantly male or female? Are they members of local clubs? What do they do in their off time? Do they have families? Are they older or younger? The answers to these questions can help the social engineer decide what type of message to send. Message: If the target is predominantly 25–40-year-old males, with a few being part of a fantasy football or basketball league, your targets may click on a link about sports, women, or a sporting event. Developing the email’s content is essential, but also grammar, spelling, and punctuation are very important to consider. One of the biggest tip-offs to phishing emails in the past has been the bad spelling. Getting an email that reads like this: “Click here and enter ur pasword to verify ur account settings,” is a dead giveaway to its being a non-legitimate email. Your email must be legit with good spelling and an appealing offer that fits the target. Even with the same goal the message will change depending on gender, age, and many other factors. The same email would probably fail if the targets were predominately female. Channel: This answer to this element is easy, because you already know it is going to be an email. Source: Again, this element is a no-brainer, because you, the social engineer, are the source. How believable you are depends on your skill level as a social engineer. Scenario One: Phishing Email The targets are 45 males ranging from the age of 25 to 45. Out of the 45 targets, 24 are in the same fantasy basketball league. They all go daily to a site ( www.myfantasybasketballleague.com) to register their picks. This is verified by posts on the forums. The goal is to drive them to a site that is available and that you now own, www.myfantasybasketballeague.com , which is a slight misspelling. This site is a clone of the site they visit with one change—it has an embedded iframe. There will be a Login button in the center of the page that when clicked, brings them back to the real site. The delay in loading and clicking will give the code the time it needs to hack their systems. How would you write the email? Here is a sample that I wrote: Hello, We have some exciting news at My Fantasy Basket Ball League. We have added some additional features that will allow you more control over your picks as well as some special features. We are working hard on offering this to all of our members but some additional service fees may apply. We are excited to say that the first 100 people to log in will get this new service for free. Click this link to be taken to the special page, click the gray LOGIN button on the page, and log in to have these features added to your account. www.myfantasybasketballeague.com Thanks, The MFBB Team This email would mostly likely get at least the 24 who are already in the league interested enough to click the link and check out the site and try these new features for free. Analyze that email. First, it contains an offer that would attract the present members of that fantasy league. Many of them realize the offer is limited to only the first 100, so they would click on it soon as they get the email, which more than likely is at work. The site that the email drives them to has the malicious code and although the majority will fall victim, all the malicious social engineer needs is one victim. Also notice that the email contains good grammar and spelling, an enticing hook, and enough motivation to click quickly. It is a perfect email based off a solid communication model. Scenario Two: USB Key The onsite scenario is a little more difficult to do because it is in person. You can only do so much to “spoof” your identity in person. In this scenario remember that you must have all these details in memory because you can’t be pulling out and using cue cards. It is also important to remember that oftentimes we have only one chance to make an impression. If we do a bad job at it, it can ruin the rest of the gig. Feedback: The goal with this scenario is to get the front desk receptionist to accept your USB drive that has a malicious program on it. The program will auto load and scrape her system for all information, such as usernames, passwords, email accounts, SAM files that contain all the passwords on the system, and more, copying it all to a directory on the USB drive. It also creates a reverse connection from the receptionist’s machine to your servers, giving you access to her machine and hopefully the network. I am fond of using the Metasploit framework or the Social Engineering Toolkit (see Chapter 7) that ties in with Metasploit. Metasploit executes exploit code on its victims and it has a built-in handler called Meterpreter. The user can script many things like keylogging, screenshots, and recon from the victim’s machines. Receivers: Having one true target can be tricky because if your target is unreceptive to the idea, your plan is shot. You must be warm, friendly, and convincing. This must be done fast, too, because too much time will allow doubt to set in. But if you move too fast you can cause doubt and fear, killing your chances. A perfect balance must be accomplished. Message: Because you’re delivering the message in person, it must be clear and concise. The basic story is that you saw the ad in the paper for a database administrator and you called in and spoke to Debbie, the HR person. She said she was booked today but you should stop in and drop off a resume for her review and then meet her at the end of the week. While you were driving over, a squirrel ran out, causing you to slam on the brakes and causing your coffee to come out of the holder and spill in your bag, ruining your resumes and other stuff. Anyhow, you have another appointment but really need this job and wonder whether she would print you a fresh copy from your USB drive. Channel: You are going in person using verbal, facial, and body language communication. Source: Again, this is you as the social engineer, unless you have a good reason to have a stand in. Holding a coffee-stained folder with some wet papers in it can help sell the story. Looking dejected and not alpha-male-ish can also help sell it. Politely speaking to her and not using foul language will help her feel a liking to you and maybe even some pity. The USB key should contain a file called myresume.doc or myresume.pdf and be printable. PDFs are the most commonly used formats since most companies are running an older version of Adobe Reader that is vulnerable to many different exploits. Make sure the resume is in a format that allows for the most people to be able to open it—not some odd format. Most of the time people want to help. They want to be able to assist a person in distress if the story is believable as well as heart wrenching. For a special twist if you really lack a heart as a social engineer, you can put a spin on the story: On my way over, it was my turn today to drop my daughter off at school. When she climbed over the seat to give me a kiss goodbye she knocked over my coffee into my bag. I was already running late and closer to here than home; could you print me a fresh copy? Either way, this story usually works and will lead to the USB key being inserted into the computer and most likely a complete compromise of the receptionist’s computer, which can lead to a total compromise of the company. The Power of Communication Models Communication modeling is a powerful tool that is a must-have skill for every social engineer. The hardest part about communication modeling is to ensure your information-gathering sessions are solid. In both of the earlier scenarios, not having enough a good enough plan and model will lead to failure. A good way to practice communication modeling is to write out a model for manipulating people you know well—a husband, wife, parent, child, boss, or friend—to do something you want, to take some action you desire. Set a goal, nothing malicious, such as getting someone to agree to a different vacation spot or a to go to a restaurant you love and your partner hates, or to allow you to spend some money on something you normally wouldn’t ask for. Whatever it is you come up with, write out the five communication components and then see how well the communication goes when you have a written plan. You will find that with your goals clearly defined, you can better test your social engineering communication methods, and be able to achieve your goals more easily. List the following five points and fill them out one by one, connecting the dots as you go along. Source Message Channel Receivers Feedback Communication modeling yields very valuable information and without it, most communication will not be successful for a social engineer. As previously mentioned, information gathering is the crux of every social engineering gig, but if you become proficient at information gathering and you are able to gather amazing amounts of data but don’t know how to use it, it is a waste. Learn to become a master at information gathering and then practice putting that into action with communication modeling. This is just the start, but it can literally change the way you deal with people both as a social engineer and in everyday contexts. Yet so much more goes into developing a solid message in the communication model. One key aspect of learning how to communicate, how to manipulate, and how to be a social engineer is learning how to use questions, as discussed in the next chapter.",
        "char_count": 61486
      },
      {
        "heading": "Chapter 9",
        "text": "Chapter 3 Elicitation The supreme art of war is to subdue the enemy without fighting. —Sun Tzu Being able to effectively draw people out is a skill that can make or break a social engineer. When people see you and talk to you they should feel at ease and want to open up. Have you ever met someone and instantly felt, “Wow I like that person”? Why? What was it about him that made you feel that way? Was it his smile? The way he looked? The way he treated you? His body language? Maybe he even seemed to be “in tune” with your thoughts and desires. The way he looked at you was non-judgmental and right away you felt at ease with him. Now imagine you can tap into that and master that ability. Don’t shrug off this chapter as a simple “how to build rapport” lesson. This chapter is about elicitation , a powerful technique used by spies, con men, and social engineers, as well as doctors, therapists, and law enforcement, and if you want to be protected or be a great social engineer auditor then you need to master this skill. Used effectively, elicitation can produce astounding results. What is elicitation? Very few aspects of social engineering are as powerful as elicitation. This is one of the reasons it is near the top of the framework. This skill alone can change the way people view you. From a social engineering standpoint, it can change the way you practice security. This chapter dissects examples of expert elicitation and delves deep into how to utilize this powerful skill in a social engineering context. Before getting in too deep, you must begin with the basics. What Is Elicitation? Elicitation means to bring or draw out, or to arrive at a conclusion (truth, for instance) by logic. Alternatively, it is defined as a stimulation that calls up (or draws forth) a particular class of behaviors, as in “the elicitation of his testimony was not easy.” Read that definition again and if it doesn’t give you goose bumps you may have a problem. Think about what this means. Being able to effectively use elicitation means you can fashion questions that draw people out and stimulate them to take a path of a behavior you want. As a social engineer, what does this mean? Being effective at elicitation means you can fashion your words and your questions in such a way that it will enhance your skill level to a whole new level. In terms of information gathering, expert elicitation can translate into you target wanting to answer your every request. I want to take this discussion one step further because many governments educate and warn their employees against elicitation because it is used by spies all over the earth. In training materials, the National Security Agency of the United States government defines elicitation as “the subtle extraction of information during an apparently normal and innocent conversation.” These conversations can occur anywhere that the target is—a restaurant, the gym, a daycare—anywhere. Elicitation works well because it is low risk and often very hard to detect. Most of the time, the targets don’t ever know where the information leak came from. Even if a suspicion exists that there is some wrong intent, one can easily pass it off as an angry stranger being accused of wrong doing for just asking a question. Elicitation works so well for several reasons: Most people have the desire to be polite, especially to strangers. Professionals want to appear well informed and intelligent. If you are praised, you will often talk more and divulge more. Most people would not lie for the sake of lying. Most people respond kindly to people who appear concerned about them. These key factors about most humans are why elicitation works so well. Getting people to talk about their accomplishments is too easy. In one scenario in which I was tasked to gather intel on a company, I met my target at a local chamber of commerce function. Because it was a mixer I hung back until I saw the target approaching the bar. We got there at the same time and because the purpose of these functions is to meet and greet people and exchange business cards, my first move wasn’t extreme. I said, “Escaping from the vultures?” He replied with a chuckle, “Yeah, this is what makes these things worth the time—open bar.” I listened to him order, and I ordered a similar drink. I lean over with my hand out, and said, “Paul Williams.” “Larry Smith.” I pulled out a business card I had ordered online. “I work with a little import company as the head of purchasing.” He said as he handed me his card, “I am the CFO for XYZ.” With a chuckle I responded, “You’re the guy with the bucks—that’s why everyone is after you out there. What exactly do you guys do?” He bagan to relate a few details of his company’s products, and when he listed one that is well known, I said, “Oh right, you guys make that widget ; I love that thing. I read in XYZ Magazine it hit a new sales record for you guys.” From my previous information gathering I knew he had personal interest in that device so my praise was well received. He began to puff his chest out a bit. “Did you know that device sold more in the first month that our previous and next five products combined?” “Yikes, well I can see why, because I bought five myself.” I chuckled through the mild praise. After another drink and some more time I was able to discover that they recently purchased accounting software, the name of the CSO (and the fact he was on vacation for a few days), and that my friend here was also going on vacation soon to the Bahamas with his wife. This seemingly useless info is not useless at all. I have a list of details about software, people, and vacations that can help me plan an attack. But I didn’t want to stop there; I went in for the kill with a question like this: “I know this is a weird question, but we are a small company and my boss told me I am to research and buy a security system for the doors. We just use keys now, but he was thinking RFID or something like that. Do you know what you guys use?” This question I thought would send up red flares and smoke signals. Instead, he said “I have no clue; I just signed the checks for it. What I do know is I have this fancy little card…” as he pulls out his wallet to show me his card. “I think it is RFID, but all I know is that I wave my wallet in front of the little box and the door opens.” We exchanged laughs and I walked away with knowledge that led to some very successful attack vectors. As you may have noticed, elicitation is similar to and linked to information gathering. This particular information-gathering session was made so much easier by a solid pretext (discussed in Chapter 3) as well good elicitation skills. Elicitation skills are what made the questions flow smoothly and what made the target feel comfortable answering my questions. Knowing that he was on vacation and what kinds of accounting software they used as well door locking security I was able to plan an onsite visit to repair a “faulty” RFID box and time clock. Simply telling the front desk receptionist, “Larry called me before he left for the Bahamas and said there was a time clock by the manufacturing department that is not registering properly. It will take me a few minutes to test and analyze it.” I was given access in a matter of seconds without ever being questioned. Elicitation led me to that success because with the knowledge I was given there was no reason for the receptionist to doubt my pretext. Simple, light, airy conversation is all it takes to get some of the best information out of many people. As discussed so far, clearly defining your goals to achieve maximum results is vital. Elicitation is not used merely for information gathering, but it can also be used to solidify your pretext and gain access to information. All of this depends on a clearly defined and thought-out elicitation model. The Goals of Elicitation Reviewing the definition for elicitation can give you a clear path of what your goals are. Really, though, you can boil it down to one thing. A social engineer wants the target to take an action, whether that action be as simple as answering a question or as big as allowing access to a certain restricted area. To get the target to comply, the social engineer will ask a series of questions or hold a conversation that will motivate the target to that path. Information is the key. The more information that you gather, the more successful the attack will be. Because elicitation is non-threatening it is very successful. Count how many times in a week you have meaningless little conversations with someone at a store, coffee shop, or elsewhere. The whole methodology of holding conversations is steeped in elicitation and it is used in a non-malicious way daily. That is why it is so effective. In one episode of the popular British television show The Real Hustle , the hosts demonstrated the ease of many social engineering attacks. In this episode the goal was to draw a target into a game of luck that was rigged. To do so someone had a partner who acted as a complete stranger play a role in being interested and conversational with the attacker. This conversation draws in the surrounding people, which made eliciting proper responses from the target very easy. This is one method that works well. Whichever method is used, the goal is to obtain information then utilize that information to motivate a target to the path the social engineer wants him to take. Understanding this fact is important. Later chapters cover pretexting and other manipulation tactics, but you don’t want to confuse elicitation with those. Realizing that elicitation is conversation is important. Sure, it may be closely linked to your pretext, body language, and eye cues, but all of those pale in comparison to your ability to engage people in conversation. Some experts agree that mastering the art of conversation has three main steps: 1. Be natural. Nothing can kill a conversation quicker than seeming to be uncomfortable or unnatural in the conversation. To see this for yourself try this exercise. Have a conversation with someone about something you know a lot about. If you can record it somehow or have someone else take notice, see how you stand, your posture, and the way you assert your knowledge. All of these things will scream confidence and naturalness. Then inject yourself in a conversation you know nothing about and have the same recording or friend observing. See how all those nonverbal aspects change for you when you try to inject an intelligent thought into a conversation you know nothing about. This exercise shows you the difference in being natural and not being natural. The person(s) you are conversing with will be able to see it easily, which will kill all chances of successful elicitation. How do you seem natural in conversations? Thus we arrive at step 2. 2. Educate yourself. You must have knowledge of what it is you will be talking to your targets about. This section should come with a big fat red neon light warning, but because every book can’t include one let me emphasize this part: It is imperative that you not pretend you are more than you can reasonably be believed you are. Confused? Here’s an example to break it down. If you wanted to obtain the chemical composition for a top-secret product and your elicitation target is one of the chemists involved in making the product, and you decide to start talking chemistry, do not play yourself off as a world-class chemist (unless you are). He may throw something at you that will show you know nothing and then your cover is blown and so is the elicitation. A more realistic approach may be that you are a research student studying XYZ, and was told he had amazing knowledge in this area. Due to his expertise, you just wanted to ask him a question on a chemical formula you are working on and why it doesn’t seem to be working out. The point is that whatever you chose to converse about and whomever with, do research, practice, and be prepared. Have enough knowledge to speak intelligently about a topic that will interest the target. 3. Don’t be greedy. Of course, the goal is to get information, get answers, and be given the key to the kingdom. Yet, do not let that be the focus. That you are only there for yourself will quickly become evident and the target will lose interest. Often, giving someone something will elicit the feeling of reciprocation (discussed in Chapter 6), where he or she now feels obligated to give you something in return. Being this way in conversation is important. Make the conversation a give and take, unless you are conversing with a person who wants to dominate the conversation. If he wants to dominate, let him. But if you get a few answers, feel the conversation out and don’t get greedy trying to go deeper and deeper, which can raise a red flag. Sometimes the people who are labeled as the “best conversationalists” in the world are those who do more listening than talking. These three steps to successful elicitation can literally change the way you converse with people daily, and not just as a social engineer or a security auditor, but as an everyday person. I personally like to add one or two steps to the “top three.” For example, an important aspect to elicitation is facial expressions during a conversation. Having your gaze be too intense or too relaxed can affect the way people react to your questions. If your words are calm and you have engaged the target in a conversation but your body language or facial expressions show disinterest, it can affect the mood of the person, even if she doesn’t realize it. This may seem odd to bring up here, but I am a fan of Cesar Milan, aka, The Dog Whisperer. I think that guy is a genius. He takes dogs that seem unruly and in a matter of minutes has both the dogs and their owners produce high-quality personality traits that will merit a very successful relationship for both. He basically teaches people how to communicate with a dog—how to ask and tell it to do things in a language it understands. One of the things he preaches that I fully believe in is that the “spirit” or energy of the person affects the “spirit” or energy of the dog. In other words, if the person approaches the dog all tense and anxious, even if the words are calm, the dog will act tense, bark more, and be more on edge. Obviously, people are not the same as dogs but I truly believe that this philosophy applies. As a social engineer approaches a target her “spirit” or energy will affect the person’s perception. The energy is portrayed through body language, facial expressions, dress, and grooming, and then the words spoken to back that up. Without even knowing it, people pick up on these things. Have you ever thought or heard someone say, “That guy gave me the creeps” or “She looked like such a nice person”? How does that work? The person’s spirit or energy is relayed to your “sensors,” that data is correlated with past experiences, and then a judgment is formed. People do it instantaneously, many times without even knowing it. So your energy when you are going to elicit must match the role you are going to play. If your personality or mental makeup doesn’t enable you to easily play a manager then don’t try. Work with what you have. Personally, I have always been a people person and my strong suit is not topics like chemistry or advanced math. If I were in the situation mentioned earlier I would not try to play the role of a person who knows about those things. Instead my elicitation might be as simple as a stranger interested in starting a conversation about the weather. Whatever methods you chose to use, you can take certain steps to have the upper edge. One of these steps is called preloading . Preloading You stand in line to buy your $10 movie ticket and are barraged with sensory overload of posters of upcoming movies. You stand in line to buy your $40 worth of popcorn and drinks, see more posters, and then you push your way through to get a seat. Finally, when the movie starts you are presented with a series of clips about upcoming movies. Sometimes these movies aren’t even in production yet, but the announcer comes on and says, “The funniest movie since…” or the music starts with an ominous tone, a dense fog fills the screen, and the voiceover intones, “You thought it was over in Teenage Killer Part 45 ….” Whatever the movie is, the marketers are telling you how to feel—in other words, preloading what you should be thinking about this movie—before the preview starts. Then the short 1–3 minutes they have to show you what the movie is about is spent showing you clips to entice your desire to see the movie and to appeal to the crowd that wants the comedy, horror, or love story. Not much has been written about preloading, but it is a very serious topic. Preloading denotes that you can do just what it says—preload targets with information or ideas on how you want them to react to certain information. Preloading is often used in marketing messages; for example, in the national restaurant chain ads that show beautiful people laughing and enjoying the meal that looks so beautiful and perfect. As they say “yummm!” and “ohhh!” you can almost taste the food. Of course as a social engineer you can’t run a commercial for your targets so how can you use preloading? As with much in the social engineering world, you have to start from the end results and work backward. What is your goal? You might have the standard goal of elicitation to gain information from a target on a project she is working on or dates she will be in the office or on vacation. Whatever it is, you must set the goal first. Next you decide the type of questions that you want to ask, and then decide what type of information can preload a person to want to answer those questions. For example, if you know that later tonight you want to go to a steak place that your coupon-loving wife doesn’t really enjoy, but you are in the mood for a rib eye, you can preload to get a response that may be in your favor. Maybe earlier in the day you can say something like, “Honey, you know what I am in the mood for? A big, juicy, grilled steak. The other day I was driving to the post office and Fred down the road had his grill out. He had just started cooking the steaks on charcoal and the smell came in the car window and it has been haunting me ever since.” Whether this elicits a response at this exact moment is not important; what you did is plant a seed that touched every sense. You made her imagine the steaks sizzling on the grill, talked about seeing them go on, talked about smelling the smoke, and about how much you wanted one. Suppose then you bring home the paper and as you’re going through it you see an ad with a coupon for the restaurant you want to go to. You simply leave that page folded on the table. Again, maybe your wife sees it or maybe she doesn’t, but chances are that because you left it with the mail, because you mentioned steak, and because she loves coupons she will see the coupon left on the table. Now later on she comes to you and says, “What do you want for dinner tonight?” Here is where all your preloading comes in—you mentioned the smell, sight, and desire for steak. You left an easy-to-find coupon on the table for the steak restaurant of choice and now it is dinner discussion time. You answer her with, “Instead of making you cook and having a mess to clean up tonight, we haven’t been to XYZ Steaks in a while. What if we just hit that place tonight?” Knowing she doesn’t like that place all you can hope is the preloading is working. She responds, “I saw a coupon for that place in the newspaper. It had a buy one meal get a second half off. But you know I don’t like….” As she is speaking you can jump in and offer praise: “Ha! Coupon queen strikes again. Heck, I know you don’t like steak too much but I hear from Sally that they have awesome chicken meals there, too.” A few minutes later you are on the way to steak heaven. Whereas a frontal assault stating your desire to go to XYZ would have most likely met with a resounding “No!” preloading helped set her mind up to accept your input and it worked. One other really simplistic example before moving on: A friend walks up and says, “I have to tell you a really funny story.” What happens to you? You might even start smiling before the story starts and your anticipation is to hear something funny, so you look and wait for opportunities to laugh. He preloaded you and you anticipated the humor. How do these principles work within the social engineering world? Preloading is a skill in itself. Being able to plant ideas or thoughts in a way that is not obvious or overbearing sometimes takes more skill than the elicitation itself. Other times, depending on the goal, preloading can be quite complex. The earlier steak scenario is a complex problem. The preload took some time and energy, where a simplistic preload might be something as simple as finding out what kind of car they drive or some other innocuous piece of information. In a very casual conversation where you “happen” to be in the same deli at the same time as your target you start a casual conversation with something like, “Man, I love my Toyota. This guy in a Chevy just backed into me in the parking lot, not even a scratch.” With any luck as you engage the target in conversation, your exclamation about your car might warm him up to the questions that you can then place about types of cars or other topics you want to gather intel on. The topic of preloading makes more sense as you start to analyze how you can utilize elicitation. Social engineers have been mastering this skill for as long as social engineering has been around. Many times the social engineer realizes he has this skill way before he turns to a life of social engineering. As a youth or a young adult he finds interacting with people easy, and later finds that he gravitates toward employment that uses these skills. Maybe he is the center of his group of friends and people seem to tell him all their problems and have no problem talking to him about everything. He realizes later that these skills are what gets him through doors that might be closed otherwise. When I was young I always had this talent. My parents would tell me stories of how I at five or six years old would strike up conversations with complete strangers, sometimes even walking into the kitchen of busy restaurants to ask questions about our order or inquire how things were being done. Somehow I got away with it—why? Probably because I didn’t know this behavior wasn’t acceptable and because I did it with confidence. As I got older, that skill (or a lack of fear) came into full effect. It also seemed that people, sometimes even complete strangers, loved to tell me their problems and talk to me about things. One story that I think helps to see how I was able to utilize not only preloading but also good elicitation skills was when I was around 17 or 18 years old. I was an avid surfer and would do odd jobs to support my hobby—basically anything from pizza delivery to fiberglass cutter to lifeguard. One time I ran errands for my father who owned an accounting/financial consulting company. I would deliver papers to his clients, get signatures, and bring them back. Often, many of the clients would open up and tell me all about their lives, their divorces, and their business successes and failures. Usually this started with a small session with them telling me how great my Dad was to them. At the time I never understood why people, especially adults, would open up to a 17–18 year old with the reasons their universe is breaking apart. One particular client I would visit often owned an apartment complex. It was nothing huge and fancy; he just had a few properties that he owned and managed. This poor guy had real problems—family problems, health problems, and personal problems—all of which he routinely would tell me about for as long as I would sit and listen. This is when it began to hit me that I could get away with saying or doing amazing things if I just spent time listening to people. It made them feel important and like I was a good person. It didn’t matter if I sat there thinking about my next great wave; what mattered was that I listened. Normally I would listen for as long as I could stand the amazing amount of tobacco smoke he put out (he smoked more than any person I ever have seen in my life). But I would sit and listen and because I was young and had no experience I would offer no advice, no solution, just an ear. The thing was that I was truly concerned; I didn’t fake it. I wished I had a solution. One day he told me about how he wanted to move back out West where his daughter was and be closer to family. I wanted to move on in life and get a job I thought would be cool, fun, and give me some more cash for surfboards and other things I “needed.” During one of my listening sessions, a crazy idea popped in my head, and he viewed me as a responsible, compassionate young man with a “good head” on my shoulders. The preloading took place over the months I spent sitting with him and listening. Now it was time to cash in on that. I said, “Why don’t you go back and let me run your apartment complex for you?” The idea was so absurd, so ridiculous that looking back now I would have laughed in my face. But for weeks, months even, I had listened to his problems. I knew the man and his woes. On top of that, I never laughed at or rejected him. Now he had shared a problem with me, and here was a perfect solution, one that took care of all of his problems as well as mine. My income needs were low, and he wanted to be close to his family. We had built a relationship over the last few months and thus he “knew” me and trusted me. After some discussion we came to an agreement and he up and moved back out West and I was a 17-year-old running a 30-unit apartment complex as the vice-landlord. I could go on and tell you much more on this story but the point is already made. (I will tell you the job went great until he asked me to try to sell his complex for him, which I did in record time, at the same time selling myself out of a job.) The point is that I developed a rapport, a trust, with someone and without trying and without malicious intent, I had a chance to preload him over months with the ideas that I was kind and compassionate and intelligent. Then when the time arose I was able to present an absurd idea, and because of the months of preloading, it was accepted. It wasn’t until later in life that it hit me what was going on here. There were so many factors at play that I didn’t realize at the time. Preloading from a social engineering standpoint involves knowing your goal before you start. In this case, I didn’t know I was going to try and land a crazy job with this guy. But preloading still worked. In most social engineering cases it would much quicker, but I think the principles apply. Being as genuine as you can is essential. Because preloading involves the person’s emotions and senses, give them no reason to doubt. The question you ask should match your pretext. For preloading to work you have to ask for something that matches the belief you built into them. For example, if my offer was to have me go visit my client’s family and take pictures rather than manage his apartment complex, it wouldn’t have matched the belief system he had of me, namely that I was a smart, business-minded, caring young man. Finally, the offer, when made, must be of benefit to the target, or at least perceived as benefit. In my case, there was lots of benefit to my client. But in social engineering the benefit can be as little as “bragging rights”: giving the person a platform to brag a bit. Or the benefit can be much more and involve physical, monetary, or psychological benefits. Practicing elicitation and becoming proficient at it will make you a master social engineer. Logically, the next section is how to become a successful elicitor. Becoming a Successful Elicitor Analyzing just my own experiences I can identify some key components that led to my success from five-years-old to now: A lack of fear to talk to people and be in situations that are not considered “normal.” I truly do care for people, even if I don’t know them. I want to and enjoy listening to people. I offer advice or help only when I have a real solution. I offer a non-judgmental ear for people to talk about their problems. These are key elements to successful elicitation. The United States Department of Homeland Security (DHS) has an internal pamphlet on elicitation it hands out to its agents that I was able to obtain and archive at www.social-engineer.org/wiki/archives/BlogPosts/ocso-elicitation-brochure.pdf . This brochure contains some excellent pointers. Basically, as stated in it and in this chapter, elicitation is used because it works, is very hard to detect, and is non-threatening. The DHS pamphlet approaches elicitation from a “how to avoid” point of view, but the following sections take some of the scenarios and show you what can be learned. Appealing to Someone’s Ego The scenario painted in the DHS brochure goes like this: Attacker: “You must have an important job; so and so seems to think very highly of you.” Target: “Thank you, that is nice of you to say, but my job isn’t that important. All I do here is…” The method of appealing to someone’s ego is simplistic but effective. One caution, though: Stroking someone’s ego is a powerful tool but if you overdo it or do it without sincerity it just turns people off. You don’t want to come off as a crazy stalker: “Wow, you are the most important person in the universe and you are so amazing-looking, too.” Saying something like that might get security called on you. Using ego appeals needs to be done subtly, and if you are talking to a true narcissist avoid eye rolls, sighs, or argumentativeness when she brags of her accomplishments. Subtle ego appeals are things like, “That research you did really changed a lot of people’s viewpoints on…” or “I overheard Mr. Smith telling that group over there that you are one of the most keen data analysts he has.” Don’t make the approach so over the top that it is obvious. Subtle flattery can coax a person into a conversation that might have never taken place, as stated in the DHS brochure, and that is exactly what you want as a social engineer. Expressing a Mutual Interest Consider this mock scenario: Attacker: “Wow, you have a background in ISO 9001 compliance databases? You should see the model we built for a reporting engine to assist with that certification. I can get you a copy.” Target: “I would love to see that. We have been toying with the idea of adding a reporting engine to our system.” Expressing mutual interest is an important aspect of elicitation. This particular scenario is even more powerful than appealing to someone’s ego because it extends the relationship beyond the initial conversation. The target agreed to further contact, to accept software from the attacker, and expressed interest in discussing plans for the company’s software in the future. All of this can lead to a massive breach in security. The danger in this situation is that now the attacker has full control. He controls the next steps, what information is sent, how much, and when it is released. This is a very powerful move for the social engineer. Of course, if the engagement were long-term, then having a literal piece of software that can be shared would prove even more advantageous. Sharing usable and non-malicious software would build trust, build rapport, and make the target have a sense of obligation. Making a Deliberate False Statement Delivering a false statement seems like it would backfire off the top, but it can prove to be a powerful force to be reckoned with. Attacker: “Everybody knows that XYZ Company produced the highest-selling software for this widget on earth.” Target: “Actually, that isn’t true. Our company started selling a similar product in 1998 and our sales records have beaten them routinely by more than 23%.” These statements, if used effectively, can elicit a response from the target with real facts. Most people must correct wrong statements when they hear them. It’s almost as if they are challenged to prove they are correct. The desire to inform others, appear knowledgeable, and be intolerant of misstatements seems to be built into human nature. Understanding this trait can make this scenario a powerful one. You can use this method to pull out full details from the target about real facts and also to discern who in a group might have the most knowledge about a topic. Volunteering Information The DHS brochure makes a good point about a personality trait many of us have. A few mentions of it have appeared in the book already and it’s covered in much more detail later on, but obligation is a strong force. As a social engineer, offering up information in a conversation almost compels the target to reply with equally useful information. Want to try this one out? Next time you are with your friends say something like, “Did you hear about Ruth? I heard she just got laid off from work and is having serious problems finding more work.” Most of the time you will get, “Wow, I didn’t hear that. That is terrible news. I heard that Joe is getting divorced and they are going to lose the house, too.” A sad aspect of humanity is that we tend to live the saying “misery loves company”—how true it is in this case. People tend to want to share similar news. Social engineers can utilize this proclivity to set the tone or mood of a conversation and build a sense of obligation. Assuming Knowledge Another powerful manipulation tool is that of assumed knowledge . It is commonplace to assume that if someone has knowledge of a particular situation, it’s acceptable to discuss it with them. An attacker can deliberately exploit this trait by presenting information as if he is in the know and then using elicitation to build a conversation around it. He then can regurgitate the information as if it were his own and continue to build the illusion that he has intimate knowledge of this topic. This scenario might be better illustrated with an example. One time I was going to China to negotiate a large deal on some materials. I needed to have some intimate knowledge about my target company in the negotiations and had to find a way to get it before I met with them. We had never met face to face but I was heading to a conference in China before my negotiations started. While at the conference I happened to overhear a conversation starting about how to place yourself in a higher position when dealing with the Chinese on negotiations. I knew this was my opportunity, and to make the situation even sweeter one of the people in the small group was from the company I was going to be meeting with. I quickly injected myself into the conversation and knew that if I didn’t say something quick I would lose face. My knowledge was limited but they didn’t need to know that. When a small pause arose I began to talk about the Guanxi theory. Guanxi is basically how two people who may not have the same social status can become connected, and then one is pressed upon to perform a favor for the other. I talked about how this connection can be used, and then concluded by tying it in with how important it is as an American to not simply take a business card and stick it in my back pocket but to review it, comment on it, then place it somewhere respectful. This conversation was enough to set me up as someone who had some knowledge and deserved to stay in the circle of trust there. Now that I had established my knowledge base I sat back and listened to each person express his or her experience and personal knowledge on how to negotiate properly with large Chinese companies. I paid very close and particular attention when the gentlemen who worked for my target company spoke. As he talked I could tell the “tips” he was giving were closely linked to the business philosophies of his company. This knowledge was more valuable than anything I could have paid for and it led to a very successful trip. There are a couple more scenarios I feel are often used in elicitations. Using the Effects of Alcohol Nothing loosens lips more than the juice. This is an unfortunate but true fact. Mix any one of the preceding five scenarios with alcohol and you can magnify its effects by 10. Probably the best way to describe this scenario is with a true story. In 1980 a senior scientist from Los Alamos National Laboratory traveled to a research institute in the People’s Republic of China (PRC) to talk about his specialty, nuclear fusion. He had extensive knowledge of U.S. nuclear weapons information but knew the situation he was entering was dangerous and he needed to be determined to stick to his topic. Yet he was constantly barraged with increasingly detailed inquiries directly related to nuclear weapons. The attackers’ tactics would change and they would ask many benign questions about fusion and astrophysics, his specialty. Once they even threw a cocktail party in his honor. They gathered around and applauded his knowledge and research—each time with a toast and a drink. They began to inquire about classified matters such as the ignition conditions of deuterium and tritium, the two components in the then-new neutron bomb. He did well at fending off the constant questions, but after many toasts and a party in his honor, he decided to give an analogy. He mused to the group that if you rolled those two components into a ball and then rolled them off the table they would most likely ignite because they had such low temperature threshold levels. This seemingly useless story and information most likely caused the researchers in China to discern a clear path of research on nuclear weapons. They would take this information to yet another scientist and now armed with a little more knowledge, use that knowledge to get to the next stage with him or her. After many attempts, it is very likely the Chinese scientist would possess a clear picture of what path to take. This is a serious example of how using elicitation can lead to gaining a clear picture of the whole answer. In social engineering it may be the same for you. All the answers might not come from one source. You may elicit some information from one person about their whereabouts on a particular date, and then use that information to elicit more information from the next stage, and so on and so forth. Putting those nuggets of information together is often the hard part of perfecting elicitation skills. That is discussed next. Using Intelligent Questions As a social engineer you must realize that the goal with elicitation is not to walk up and say, “What is the password to your servers?” The goal is getting small and seemingly useless bits of information that help build a clear picture of the answers you are seeking or the path to gaining those answers. Either way, this type of information gathering can help give the social engineer a very clear path to the target goal. How do you know what type of questions to use? The following sections analyze the types of questions that exist and how a social engineer can use them. Open-Ended Questions Open-ended questions cannot be answered with yes or no. Asking, “Pretty cold out today, huh?” will lead to a “Yes,” “Uh-uh,” “Yep,” or some other similar affirmative guttural utterance, whereas asking, “What do you think of the weather today?” will elicit a real response: the person must answer with more than a yes or no. One way a social engineer can learn about how to use open-ended questions is to analyze and study good reporters. A good reporter must use open-ended questions to continue eliciting responses from his or her interviewee. Suppose I had plans to meet a friend and he canceled, and I wanted to know why. I can ask a question like, “I was curious about what happened to our plans the other night.” “I wasn’t feeling too well.” “Oh, I hope you are better now. What was wrong?” This line of questioning usually gets more results than doing an all-out assault on the person and saying something like, “What the heck, man? You ditched me the other night!” Another aspect of open-ended questions that adds power is the use of why and how . Following up a question with how or why can lead to a much more in-depth explanation of what you were originally asking. This question again is not “yes” or “no” answerable, and the person will reveal other details you may find interesting. Sometimes open-ended questions can meet with some resistance, so using the pyramid approach might be good. The pyramid approach is where you start with narrow questions and then ask broader questions at the end of the line of questioning. If you really want to get great at this technique learn to use it with teenagers. For example, many times open-ended questions such as, “How was school today?” will be met with an “OK” and nothing more, so asking a narrow question might open up the flow of information better. “What are you doing in math this year?” This question is very narrow and can be answered only with a very specific answer: “Algebra II.” “Ah, I always hated that. How do you like it?” From there you can always branch out into broader questions, and after you get the target talking, getting more info generally becomes easier. Closed-Ended Questions Obviously, closed-ended questions are the opposite of open-ended questions but are a very effective way to lead a target where you want. Closed-ended questions often cannot be answered with more than one or two possibilities. In an open-ended question one might ask, “What is your relationship with your manager?” but a closed-ended question might be worded, “Is your relationship with your manager good?” Detailed information is usually not the goal with closed-ended questions; rather, leading the target is the goal. Law enforcement and attorneys use this type of reasoning often. If they want to lead their target down a particular path they ask very closed questions that do not allow for freedom of answers. Something like this: “Do you know the defendant, Mr. Smith?” “Yes I do.” “On the night of June 14th, did you see Mr. Smith at the ABC Tavern?” “I did.” “And at what time was that?” “11:45pm.” All of these questions are very closed ended and only allow for one or two types of responses. Leading Questions Combining aspects from both open- and closed-ended questions, leading questions are open ended with a hint leading toward the answer. Something like, “You were at the ABC Tavern with Mr. Smith on June 14th at around 11:45pm, weren’t you?” This type of question leads the target where you want but also offers him the opportunity to express his views, but very narrowly. It also preloads the target with the idea that you have knowledge of the events being asked about. Leading questions often can be answered with a yes or no but are different from closed-ended questions because more information is planted in the question that when answered gives the social engineer more information to work with. Leading questions state some facts and then ask the target to agree or disagree with them. In 1932 the British psychologist Frederic C. Bartlett concluded a study on reconstructive memory. He told subjects a story and then asked them to recall the facts immediately, two weeks later, and then four weeks later. Bartlett found that subjects modified the story based on their culture and beliefs as well as personality. None were able to recall the story accurately and in its entirety. It was determined that memories are not accurate records of our past. It seems that humans try to make the memory fit into our existing representations of the world. When asked questions, many times we respond from memory based on our perceptions and what is important to us. Because of this, asking people a leading question and manipulating their memory is possible. Elizabeth Loftus, a leading figure in the field of eyewitness testimony research, has demonstrated through the use of leading questions how distorting a person’s memory of an event is easily possible. For example, if you showed a person a picture of a child’s room that contained no teddy bear, and then asked her, “Did you see a teddy bear?” you are not implying that one was in the room, and the person is free to answer yes or no as they wish. However, asking, “Did you see the teddy bear?” implies that one was in the room and the person is more likely to answer “yes,” because the presence of a teddy bear is consistent with that person’s schema of a child’s room. Because of this research the use of leading questions can be a powerful tool in the hands of a skilled social engineer. Learning how to lead the target can also enhance a social engineer’s ability to gather information. Assumptive Questions Assumptive questions are just what they sound like—where you assume that certain knowledge is already in the possession of the target. The way a social engineer can determine whether or not a target possesses the information he is after is by asking an assumptive question. For example, one skill employed by law enforcement is to assume the target already has knowledge—for example, of a person—and ask something like, “Where does Mr. Smith live?” Depending on the answer given, the officer can determine whether the target knows the person and how much she knows about him. A good point to note is that when a social engineer uses assumptive questions the whole picture should never be given to the target. Doing so gives all the power to the target and removes much of the social engineer’s ability to control the environment. The social engineer never wants to use assumptive questions to accuse the target of a wrong. Doing so alienates the target and again costs the social engineer power. A social engineer should use assumptive questions when he has some idea of the real facts he can use in the question. Using an assumptive question with bogus information may turn the target off and will only confirm that the target doesn’t know about something that didn’t happen. Back to an earlier example, if I wanted to gain information from a leading chemist and I did some research and knew enough to formulate one intelligent sentence I could make an assumptive question but it would ruin future follow up if I was not able to back up the assumption the target would make of my knowledge. For example, if I were to ask, “Because deuterium and tritium have such low temperature thresholds, how does one handle these materials to avoid ignition?” The follow-up information might be hard to follow if I am not a nuclear physicist. This is counterproductive and not too useful. Plan your assumptive questions to have the maximum effect. One adjunct that is taught to law enforcement officials that comes in very handy when using assumptive questions is to say, “Now think carefully before you answer the next question…” This kind of a statement preloads the target’s mind with the idea that he must be truthful with his next statement. It can take months or years to master these skills. Don’t get disheartened if the first few attempts are not successful, and keep trying. Don’t fear, though, there are some tips to mastering this skill. I will review these in closing. Mastering Elicitation This chapter has a lot of information for you to absorb, and if you are not a people person, employing the techniques covered might seem like a daunting task. Like most aspects of social engineering, elicitation has a set of principles that when applied will enhance your skill level. To help you master these principles, remember these pointers: Too many questions can shut down the target. Peppering the target with a barrage of questions will do nothing but turn off the target. Remember, conversation is a give and take. You want to ask, but you have to give to make the target feel at ease. Too few questions will make the target feel uncomfortable. Have you ever been in a conversation that is filled with “awkward silences”? It isn’t good is it? Don’t assume that your target is a skilled and willing conversationalist. You must work at making a conversation an enjoyable experience. Ask only one question at a time. Chapter 5 covers buffer overflows on the human mind, but at this time your goal is not to overflow the target. It is to merely gather information and build a profile. To do this you can’t seem too eager or non-interested. As you have probably gathered, making elicitation work right is a delicate balance. Too much, too little, too much at once, not enough—any one of them will kill your chances at success. However, these principles can help you master this amazing talent. Whether you use this method for social engineering or just learning how to interact with people, try this: Think of conversation as a funnel, where on the top is the largest, most “neutral” part and at the bottom is the very narrow, direct ending. Start by asking the target very neutral questions, and gather some intel using these questions. Give and take in your conversation, and then move to a few open-ended questions. If needed, use a few closed-ended questions to direct the target to where you want to go and then if the situation fits, move to highly directed questions as you reach the end of funnel. What will pour out of the “spout” of that funnel is a river of information. Think about it in the situation discussed in this chapter of my target at the chamber of commerce gathering. My goal was to gather intel on anything that might lead to a security breach. I started off the conversation with a very neutral question. “Escaping the vultures?” This question broke the ice on the conversation as well as used a little humor to create a bridge that allowed us to exist on the same plane of thought. I asked a few more neutral questions and handed him my card while inquiring what he does. This segues smoothly into the open-ended questions. A brief information-gathering session that occurred earlier, using carefully placed closed-ended or assumptive questions was key. After hearing about the company’s recent purchase for new accounting software and network upgrades I wanted to go in for the kill. Having scoped out the building I knew it used RFID, but I wasn’t sure if the target would go so far as to describe the card and show it to me. This is where the use of direct questions played a role: coming right out and asking what security the company used. By the time I used that type of question our rapport and trust factor was so high he probably would have answered any questions I asked. Understanding how to communicate with people is an essential skill for an elicitor. The social engineer must be adaptive and able to match the conversation to his or her environment and situation. Quickly building even the smallest amount of trust with the target is crucial. Without that rapport, the conversation will most likely fail. Other key factors include making sure that your communication style, the questions used, and the manner in which you speak all match your pretext. Knowing how to ask questions that force a response is a key to successful elicitation, but if all that skill and all those questions do not match your pretext then the elicitation attempt will most surely fail. Summary This chapter covered some of the most powerful points in this whole book—powerful in the sense that applying them can change not only your social engineering abilities but also your abilities as a communicator. Knowing how to ask the right questions in the right tense and the right manner can open so many opportunities. As a social engineer, this is what separates success from failure. First impressions are based initially on sight, but what comes out of your mouth first can make or break the deal. Mastering elicitation can almost guarantee success as a social engineer and can add serious weight to any pretext you decide to use. Throughout this chapter I mentioned the power of pretexting. This is another topic that every social engineer, both malicious and professional, must master. But how can you ensure you accomplish this goal? To answer this you must learn about pretexting and understand exactly what it is, as discussed in Chapter 4.",
        "char_count": 52573
      },
      {
        "heading": "Chapter 10",
        "text": "Chapter 4 Pretexting: How to Become Anyone Honesty is the key to a relationship. If you can fake that, you’re in. —Richard Jeni At times we probably all wish we could be someone else. Heck, I would love to be a little skinnier and better looking. Even though medical science hasn’t come up with a pill that can make that possible, a solution to this dilemma does exist—it’s called pretexting . What is pretexting? Some people say it is just a story or lie that you will act out during a social engineering engagement, but that definition is very limiting. Pretexting is better defined as the background story, dress, grooming, personality, and attitude that make up the character you will be for the social engineering audit. Pretexting encompasses everything you would imagine that person to be. The more solid the pretext, the more believable you will be as a social engineer. Often, the simpler your pretext, the better off you are. Pretexting, especially since the advent of the Internet, has seen an increase in malicious uses. I once saw a t-shirt that read, “The Internet: Where men are men, women are men, and children are FBI agents waiting to get you.” As slightly humorous as that saying is, it has a lot of truth in it. On the Internet you can be anyone you want to be. Malicious hackers have been using this ability to their advantage for years and not just with the Internet. In social engineering playing a role or being a different person to successfully accomplish the goal is often imperative. Chris Hadnagy might not have as much pull as the tech support guy or the CEO of a major importing organization. When a social engineering situation arises, having the skills needed to become the pretext is important. In a discussion I was having with world-renowned social engineer, Chris Nickerson, on this topic he said something I think really hits home. Nickerson stated that pretexting is not about acting out a role or playing a part. He said it is not about living a lie, but actually becoming that person. You are, in every fiber of your being, the person you are portraying. The way he walks, the way he talks, body language—you become that person. I agree with this philosophy on pretexting. Often when people watch a movie the ones we feel are the “best we have ever seen” are where the actors get us so enthralled with their parts we can’t separate them from their portrayed characters. This was proven true to me when many years ago my wife and I watched a great movie with Brad Pitt, Legends of the Fall . He was a selfish jerk in this movie, a tormented soul who made a lot of bad decisions. He was so good at playing this part my wife literally hated him as an actor for a few years. That is a good pretexter. The problem with using pretexting for many social engineers is that they feel it is just dressing up as a part and that’s it. True, the dress can help, but pretexting is a science. In a way, your whole persona is going to portray you in a light that is different than who you are. To do this, you, as a social engineer, must have a clear picture of what pretexting really is. Then you can plan out and perform the pretext perfectly. Finally, you can apply the finishing touches. This chapter will cover those aspects of pretexting. First is a discussion of what pretexting really is. Following that is discussion of how to use pretexting as a social engineer. Finally, to tie it all together, this chapter explores some stories that show how to use pretexting effectively. What Is Pretexting? Pretexting is defined as the act of creating an invented scenario to persuade a targeted victim to release information or perform some action. It is more than just creating a lie; in some cases it can be creating a whole new identity and then using that identity to manipulate the receipt of information. Social engineers can use pretexting to impersonate people in certain jobs and roles that they never themselves have done. Pretexting is not a one-size-fits-all solution. A social engineer must develop many different pretexts over his or her career. All of them will have one thing in common: research. Good information gathering techniques can make or break a good pretext. For example, mimicking the perfect tech support rep is useless if your target does not use outside support. Pretexting is also used in areas of life other than social engineering. Sales; public speaking; so-called fortune tellers; neurolinguistic programming (NLP) experts; and even doctors, lawyers, therapists, and the like all have to use a form of pretexting. They all have to create a scenario where people are comfortable with releasing information they normally would not. The difference in social engineers using pretexting and others is the goals involved. A social engineer, again, must live that persona for a time, not just act a part. As long as the audit or social engineering gig lasts, you need to be in the persona. I “get in character” myself, as do many of my colleagues, some of whom even stay in character “off the clock.” Anywhere you need to, you should be the pretext you set out to be. In addition, many professional social engineers have many different online, social media, email, and other accounts to back up a slew of pretexts. I once interviewed radio icon Tom Mischke on this topic for a social engineering podcast I am a part of (hosted at www.social-engineer.org/episode-002-pretexting-not-just-for-social-engineers/ ). Radio hosts must be proficient at pretexting because they constantly have to release only the information they want to the public. Tom was so proficient at this that many listeners felt as if they “knew” him as a friend. He would get invitations to weddings, anniversaries, and even births. How was Tom able to accomplish this amazing kind of pretext? The answer is practice. Lots and lots of practice is what he prescribed. He told me that he would actually plan out his “acts” then practice them—use the voice they would have, sit how they would sit, maybe even dress like they would dress. Practice is exactly what makes a good pretext. A very important aspect to remember is that the quality of the pretext is directly linked to the quality of the information gathered. The more, the better, and the more relevant the information the easier it will be for the pretext to be developed and be successful. For example, the classic pretext of a tech support guy would utterly fail if you went to a company that either had internal support or outsourced to a very small company of one or two people. As natural as you are when you converse with someone about who you really are is how easy applying your pretext should be. So that you can see how you can utilize this skill, the following section covers the principles of pretexting then shows how you can apply them to actually planning a solid pretext. The Principles and Planning Stages of Pretexting As with every skill, certain principles dictate the steps to performing that task. Pretexting is no different. The following is a list of principles of pretexting that you can use. By no means are these the only principles out there; maybe others can be added, but these principles embody the essence of pretexting: The more research you do the better the chance of success. Involving your own personal interests will increase success. Practice dialects or expressions. Many times social engineering effort can be reduced if the phone is viewed as less important. But as a social engineer, using the phone should not reduce the effort put into the social engineering gig. The simpler the pretext the better the chance of success. The pretext should appear spontaneous. Provide a logical conclusion or follow through for the target. The following sections discuss each of these principles in detail. The More Research You Do, the Better the Chance of Success This principle is self-explanatory, but it can’t be said enough—the level of success is directly connected to the level and depth of research. As discussed in Chapter 2, it is the crux of successful social engineering. The more information a social engineer holds the more chances he or she has of developing a pretext that works. Remember the story I told in Chapter 2 about my mentor Mati Aharoni and how he convinced a high-level executive to visit his “stamp collection” site online? At first glance, the path inside that company might have seemed to be something to do with financial, banking, fund raising, or something along those lines because it was a banking facility. The more research Mati did, the clearer it became that the pretext could be a person who was selling a stamp collection. Finding out what the executive’s interests were allowed Mati to find an easy way into the company, and it worked. Sometimes those little details that are what make the difference. Remember, no information is irrelevant. While gathering information, looking for stories, items, or aspects of a personal nature is also a good idea. Using a target’s personal or emotional attachments can enable you to get a foot in the door. If the social engineer finds out that every year the CFO donates a sizable sum to a children’s cancer research center, then a pretext that involves fund raising for this cause could very likely work, as heartless as it sounds. The problem is that malicious social engineers use pretexts that feed on emotions without a second thought. After the attacks on the Twin Towers in New York City on September 11, 2001, many malicious hackers and social engineers used the losses of these people to raise funds for themselves via websites and emails that targeted people’s computers and fake fund raisers that obtained funds from those with a giving heart. After the earthquakes in Chile and Haiti in 2010, the same things occurred where many malicious social engineers developed websites that were positioned as giving out information on the seismic activity or the people who were lost. These sites were encoded with malicious code and hacked people’s computers. This is even more evident directly after the death of a movie or music star. Search engine optimization (SEO) and marketing geniuses will have the search engines pulling up their stories in a matter of hours. Along with marketers, malicious social engineers will take advantage of the increased search engine attention by launching malicious sites that feed off that SEO. Drawing people to these sites, they harvest information or infect them with viruses. That people will take advantage of others’ misfortune is a sad fact about this world, and one of those dark corners I said you would visit in this book. As a social engineering auditor, I can use an employee’s emotions to show a company that even people with seemingly good intentions can trick a company’s employees into giving access to valuable and business-ruining data. All these examples solidify the point that the better a social engineer’s information-gathering and research-gathering process, the better chance he has at finding some detail that will increase the chances of a successful pretext. Involve Personal Interests to Increase Success Using your own personal interests to increase the chances of a successful social engineering move seems very simple but it can go a long way in convincing the target that you are credible. Nothing can ruin rapport and trust faster than a person who claims to be knowledgeable about a topic and then falls short. As a social engineer, if you have never seen a server room before and have never taken a computer apart, trying to play the part of a technician can be a quick path to failure. Including topics and activities in your pretext that you are interested in gives you a lot to talk about and gives you the ability to portray intelligence as well as confidence. Confidence can go a long way toward convincing the target you are who you say you are. Certain pretexts require more knowledge than others (for instance, stamp collector versus nuclear researcher) to be convincing, so again research becomes the recurring theme. Sometimes the pretext is simple enough that you can get the knowledge by reading a few websites or a book. However you gain the knowledge, researching topics that personally interest you, as the social engineer, is important. After you pick up on a story, aspect, service, or interest that you have a lot of knowledge in or at least feel comfortable discussing, see whether that angle can work. Dr. Tom G. Stevens, PhD, says, “It is important to remember that self-confidence is always relative to the task and situation. We have different levels of confidence in different situations.” This statement is very important, because confidence directly links to how others view you as a social engineer. Confidence (as long as it is not overconfidence) builds trust and rapport and makes people feel at ease. Finding a path to your target that offers you the chance to talk about topics you are comfortable with, and that you can speak about with confidence, is very important. In 1957 psychologist Leon Festinger came up with the theory of cognitive dissonance. This theory states that people have a tendency to seek consistency among their beliefs, opinions, and basically all their cognitions. When an inconsistency exists between attitudes and behaviors, something must change to eliminate the dissonance. Dr. Festinger states two factors affect the strength of the dissonance: The number of dissonant beliefs The importance of each belief He then stated that three ways exist to eliminate dissonance (which should cause every social engineer’s ears to perk up): Reduce the importance of the dissonant beliefs. Add more consonant beliefs that outweigh the dissonant ones. Change the dissonant beliefs so they are no longer inconsistent. How does a social engineer use this information? Approaching a pretext with lack of confidence when your pretext says that you should be confident automatically creates dissonance. This dissonance raises all sorts of red flags and puts barriers up to rapport, trust, and forward motion. These barriers affect the target’s behavior, who is then expected to balance out her feelings of dissonance, and kills any likelihood of your pretext working. One of the methods to counter that is to add more consonant beliefs so that they outweigh the dissonant ones. What would the target expect of your pretext? Knowing that will allow you to feed their minds and emotions with actions, words, and attitudes that will build the belief system and outweigh any beliefs that might bring in doubt. Of course, a skilled social engineer can also change the dissonant beliefs so they are no longer inconsistent. Although this is trickier, it is a powerful skill to have. It is possible that your appearance does not fit what the target might envision for your pretext. You might think back to the show Doogie Howser, M.D . Doogie’s problem was that his “pretext” of being a top doctor never fit since he was so young. That was a dissonant belief, but his knowledge and actions often brought that into the consonant beliefs of his “targets.” Just like the previous example, a social engineer can align his pretext with the target’s beliefs by their attitudes, actions, and especially their knowledge of the pretext. One example of this I recently saw in real life was at Defcon 18. I was part of the team that brought the Social Engineering CTF to Defcon. We saw many contestants who used the pretext of an internal employee. When presented with an objection like, “What is your employee badge number?” an unskilled social engineer would get nervous and either not have an answer or hang up, whereas a skilled social engineer would bring those dissonant beliefs into alignment for the target. Simply stating a badge number they found online or using another method they were able to convince the target that information was not needed, therefore aligning the target to their beliefs. These points are very technical answers to a very simple problem, but you must understand that one can do only so much faking. Choose your path wisely. Practice Dialects or Expressions Learning to speak in a different dialect cannot be glanced over quickly. Depending on where you live, learning to speak a different dialect or with an accent can take some time. Putting on a southern drawl or an Asian accent can be very difficult, if not impossible. Once I was in a training class with an international sales organization and it had some statistics that said 70% of Americans prefer to listen to people with a British accent. I am not sure if that statistic is true or not, but I can say that I enjoy the accent myself. Now after that class, I heard quite a few people in the class practice their “cheerios” and “Alo Govenors,” which were horrible. I have a good friend from the UK, Jon, who gets very angry when he hears Americans trying to use lines from Mary Poppins in an imitation British accent. If he had heard this group, he might have blown a fuse. What that class taught me was that although the stats might say one accent is better than another for sales or just because you may be social engineering in the south or in Europe doesn’t mean you can easily put on the accent to make you appear local. When in doubt, throw it out. If you can’t make the dialect perfect, if you can’t be natural, and if you can’t be smooth, then just don’t try. Actors use vocal coaches and training sessions to learn to speak clearly in the accent they have to portray. Actor Christian Bale is from Wales, but determining that fact from listening to him is very difficult. He doesn’t sound British in most of his movies. Actor Gwyneth Paltrow took on a very convincing British accent for the movie Shakespeare in Love . Most actors have dialect coaches who will work with them to perfect the target accent. Because most social engineers cannot afford a dialect coach, there are many publications that can help you learn at least the basics of putting on an accent, such as Dialects for the Stage by Evangeline Machlin. Although this is an older book, it contains a lot of great tips: Find native examples of the accent you want to learn, to listen to. Books like Dialects for the Stage often come with audiotapes full of accents to listen to. Try speaking along with the recording you have, to practice sounding like that person. After you feel somewhat confident, record yourself speaking in that accent so you can listen to it later on and correct errors. Create a scenario and practice your new accent with a partner. Apply your accent in public to see if people find it believable. There are innumerable dialects and accents, and I personally find it helpful to write out phonetically some of the sentences I will speak. This enables me to practice reading them and get the ideas sunk into my brain to make my accent more natural. These tips can help a social engineer master or at least become proficient at using another dialect. Even if you cannot master another dialect, learning expressions that are used in the area in which you are working can make a difference. One idea is to spend some time listening to people in public talk to one another. A great place for this is a diner or a shopping mall, or any place you might find groups of people sitting and chatting. Listen closely to phrases or key words. If you hear them used in a few conversations you might want to find a way to incorporate these into your pretext to add believability. Again, this exercise takes research and practice. Using the Phone Should Not Reduce the Effort for the Social Engineer In recent years, the Internet has come to dominate certain more “impersonal” aspects of social engineering, whereas in days past the phone was an integral part of social engineering. Because of this shift, many social engineers do not put the energy or effort into phone usage that can make it truly successful. This topic is here to show that the phone is still one of the most powerful tools of the social engineer and the effort put into using it should not be diminished due to the impersonal nature of the Internet. Sometimes when a social engineer plans a phone attack his thinking may differ because using the Internet might appear easier. Note that you should plan to put the same level of effort, the same level and depth of research and information gathering, and most importantly the same level of practice into your phone-based social engineering attacks. I was once with a small group that was going to practice phone presentations. We outlined the proper methods, the tone, the speed, the pitches, and the words to use. We outlined a script (more on this in a minute) and then launched a session. The first person made the call, got on the phone with someone, and messed up the first few lines. Out of complete embarrassment and fear he just hung up on the person. There is a very good lesson there—the person on the other end of the phone has no clue what you are going to say, so you can’t really “mess up.” Practice sessions can help you learn how to handle the “unknowns” caused by your accidentally altering something in your script that throws you off base. If you are not as fortunate to have a group to practice or hone these skills with, you will have to get creative. Try calling family or friends to see how far you can get manipulating them. Another way to practice is to record yourself as if you were on the phone and then play it back later to hear how you sound. I personally feel that using an outlined script is very important. Here is an illustration: suppose you had to call your phone company or another utility. Maybe they messed up a bill or you had another service problem and you are going to complain. After you explain yourself to the rep, telling her how upset and disappointed you are, and the rep does absolutely nothing for you, she says something like, “XY&Z is committed to excellent service; have I answered all your questions today?” If the drone behind the phone thought for one second about what she was asking she would realize how silly it is, right? This is what happens when you use a written-out script instead of an outline. An outline allows you “creative artistic freedom” to move around in the conversation and not be so worried about what must come next. Using the phone to solidify your pretext is one of the quickest methods inside your target’s door. The phone allows the social engineer to “spoof,” or fake, almost anything. Take into consideration this example: If I wanted to call you and pretend I was in a bustling office to add to the pretext I was trying to use, I could simply grab the audio track from Thriving Office ( www.thrivingoffice.com/ ). This site offers a track called “Busy” and another called “Very Busy.” From the creators: “This valuable CD, which is filled with the sounds people expect to hear from an established company, provides instant credibility. It’s simple, effective, and guaranteed!” That sentence alone is filled with social engineering goodness—filled with what people expect to hear from an established company. Already you can see that the CD is geared to fill expectations and provide credibility (at least, in the target’s mind, after his expectations are met), thereby automatically building trust. In addition, spoofing caller ID information is relatively simple. Services like SpoofCard ( www.spoofcard.com ) or using homegrown solutions, allows a social engineer to tell the target you are calling from a corporate headquarters, the White House, or the local bank. With these services you can spoof the number to be coming from anywhere in the world. The phone is a deadly tool for social engineers; developing the habits to practice using it and to treat it with utter respect will enhance any social engineer’s toolset for pretexting. Because the phone is such a deadly tool and has not lost its effectiveness, you should give it the time and effort it deserves in any social engineering gig. The Simpler the Pretext, the Better the Chance of Success “The simpler, the better” principle just can’t be overstated. If the pretext has so many intricate details that forgetting one will cause a social engineering failure, it is probably going to fail. Keeping the story lines, facts, and details simple can help build credibility. Dr. Paul Ekman, a renowned psychologist and researcher in the field of human deception, cowrote an article in 1993 entitled, “Lies That Fail.” In that article he says [t]here is not always time to prepare the line to be taken, to rehearse and memorize it. Even when there has been ample advance notice, and a false line has been carefully devised, the liar may not be clever enough to anticipate all the questions that may be asked, and to have thought through what his answers must be. Even cleverness may not be enough, for unseen changes in circumstances can betray an otherwise effective line. And, even when a liar is not forced by circumstances to change lines, some liars have trouble recalling the line they have previously committed themselves to, so that new questions cannot be consistently answered quickly. This very salient point explains clearly why simple is better. Trying to remember a pretext can be almost impossible if it is so complex that your cover can be blown by a simple mistake. The pretext should be natural and smooth. It should be easy to remember, and if it feels natural to you, then recalling facts or lines used previously in the pretext will not be a task. To illustrate how important it is to remember the small details I want to share a story with you. Once upon a time I tried my hand at sales. I was placed with a sales manager to learn the ropes. I can recall my first call with him. We drove up to the house, and before we left the car he looked at the info card and told me, “Remember, Becky Smith sent in a request card for supplemental insurance. We will present the XYZ policy. Watch and learn.” In the first three minutes of the sales call he called her Beth and Betty. Each time he used the wrong name I saw her demeanor change and then she would say quietly, “Becky.” I feel we could have been giving away gold bullion and she would have said no. She was so turned off that he couldn’t get her name right that she was not interested in listening to anything. This scenario really drives home the point of keeping the simple facts straight. In addition to remembering the facts, it is equally important to keep the details small. A simple pretext allows for the story to grow and the target to use their imagination to fill the gaps. Do not try to make the pretext elaborate, and above all, remember the tiny details that will make the difference in how people view the pretext. On the other hand, here is an interesting tidbit: A popular tactic used by famous criminals and con men is to purposely make a few mistakes. The thought is that “no one is perfect,” and a few mistakes make people feel at home. Be cautious with what types of mistakes you decide to make if you employ this tactic because it does add complexity to your pretext, but it does make the conversation seem more natural. Use this tip sparingly, however you decide to proceed, keep it simple. Let me tie all this together with a few examples that I have used or seen used in audits. After some excellent elicitation on the phone, a nameless social engineer had been given the name of the waste removal company. A few simple Internet searches and he had a usable and printable logo. There are dozens of local and online shops that will print shirts or hats with a logo on it. A few minutes of aligning things on a template and he ordered a shirt and ball cap with the logo of the waste company on it. A couple days later, wearing the logo-laden clothing and carrying a clipboard, the social engineer approached the security booth of the target company. He said, “Hi, I’m Joe with ABC Waste. We got a call from your purchasing department asking to send someone over to check out a damaged dumpster in the back. The pickup is tomorrow and if the dumpster isn’t repairable I will have them bring out a new one. But I need to run back there and inspect it.” Without blinking, the security officer said, “OK, you will need this badge to get onsite. Just pull through here and drive around the back and you will see the dumpsters there.” The social engineer had a free pass to perform a very long and detailed dumpster dive but wanted to maximize his potential so went in for the kill with this line. While looking at his clipboard he said, “The note says it is not the food dumpsters but one of the ones where paper or tech trash goes. Which block are those in?” “Oh, just drive the same way I told you and they are in the third bay,” replied the security guard. “Thanks,” said Joe. A simple pretext, backed up by clothing and “tools” (like the clipboard), and the storylines were simple to remember and not complex. The simplicity and lack of detail actually made this pretext more believable, and it worked. Another very widely used pretext is that of the tech support guy. This one only requires a polo shirt, pair of khakis, and small computer tool bag. Many social engineers employ this tactic to get in the front door because the “tech guy” is usually given access to everything without supervision. The same rules apply: keeping the storyline simple will help make this particular pretext very real and believable. The Pretext Should Appear Spontaneous Making the pretext appear spontaneous goes back to my point on using an outline versus using script. Outlines will always allow the social engineer more freedom and a script will make the social engineer sound too robotic. It also ties in to using items or stories that interest the social engineer personally. If every time someone asks you a question or makes a statement that requires you to think, and you go, “Ummmm” and start to think deeply, and you cannot come back with an intelligent answer, it will ruin your credibility. Of course many people think before they speak, so this is not about having the answer in one second, but about having an answer or a reason for not having the answer. For example, in one phone call I was asked for a piece of information I didn’t have. I simply said, “Let me get that.” I then leaned over and made it sound like I was yelling for a workmate: “Jill, can you please ask Bill to give me the order form for the XYZ account? Thanks.” Then as “Jill” was getting the paper for me I was able to obtain the data I needed and the paper was never brought up again. I have compiled a small list of ways that you can work on being more spontaneous: Don’t think about how you feel. This point is a good one, because often in a pretext if you overthink you will start to add emotion into the mix, which can cause fear, nervousness, or anxiety, all of which lead to failure. On the other hand, you might not experience nervousness or fear, but over-excitement, which can also cause you to make a lot of mistakes. Don’t take yourself too seriously. Of course, this is great advice in life, but it applies wonderfully to social engineering. As a security professional you have a serious job; this is a serious matter. But if you’re not able to laugh at your mistakes, you may clam up or get too nervous to handle a small bump in the road. I am not suggesting you take security as a joke. In your mind, though, if you view a potential failure as the pinnacle of failure in your life, the pressure you create can cause just what you fear the most. Minor failures can often lead to greater success if you have the ability to roll with it. Learn to identify what is relevant. I like to phrase this concept as, “Get out of your head and into the world,” which is more great advice. A social engineer may be trying to plan three steps ahead and in the meantime miss a vital detail that can cause the pretext to fall apart. Be quick to identify the relevant material and information around you, whether it is the target’s body language, words spoken, or microexpressions (see Chapter 5 for more on this topic), and assimilate the information into the attack vector. Also keep in mind that people can tell when someone isn’t really listening to what they are saying. Getting the feeling that even unimportant sentences are falling on deaf ears can be a massive turnoff for many people. Everyone has experienced being with someone who just didn’t seem to care what he or she is saying. Maybe that person even had a legitimate reason to be thinking on a different path, but doing it is still a turnoff. Be sure to listen to what your target is saying. Pay close attention and you will pick up the details that are very important to them and in the meantime, you might hear something to help you in your success. Seek to gain experience. This concept goes back to what you will probably see repeated four million times in this book—practice. Gaining experience through practice can make or break the pretext. Practice spontaneity with family and friends and total strangers with absolutely no goal in mind but to be spontaneous. Strike up conversations with people, but not in a scary stalker kind of way—simple little conversations can go a long way toward making you feel comfortable being spontaneous. These points can definitely give a social engineer the upper hand when it comes to pretexting. Having the ability to appear spontaneous is a gift. Earlier in this chapter I mentioned my interview with Tom Mischke, who had an interesting take on spontaneity. He said he wants to give the illusion of spontaneity wrapped in practice and preparation. He would practice so much that his pretext would come out as a spontaneous generation of humor and talent. Provide a Logical Conclusion or Follow-through for the Target Believe it or not people want to be told what to do. Imagine if you went to a doctor and he walked in, checked you over, wrote some things on his chart, and said, “Okay; see you in a month.” That would be unacceptable. Even in the event of bad news, people want to be told the next step and what to do. As a social engineer, when you leave the target, you may need him to take or not take an action, or you may have gotten what you came for and just need to leave. Whatever the circumstance, giving the target a conclusion or follow-through fills in the expected gaps for the target. Just as if a doctor checked you over and sent you home with no directions, if you engineer your way into a facility as a tech support guy and just walk out without saying anything to anyone after cloning the database, you leave everyone wondering what happened. Someone may even call the “tech support company” and ask whether he needed to do anything, or at worst you just leave the workers wondering. Either way, leaving everyone hanging is not the way to leave. Even a simple, “I checked over the servers and repaired the file system; you should see a 22% increase in speed over the next couple days,” leaves the targets feeling as if they “got their money’s worth.” The tricky part for a social engineer is getting the target to take an action after he or she is gone. If the action is vital for completion of the social engineer audit, then you may want to take that role upon yourself. For example, in the account in Chapter 3 of my information-gathering session at the chamber of commerce event, if I wanted that target to follow-up with me through email I could have said, “Here is my card; will you email me some details on Monday about XYZ?” He very well may have, or he could have gone to the office, forgotten about me completely, and the whole gig would have failed. What would be better is to say, “I would love to get some more information from you. On Monday could I perhaps call you or shoot you an email to get some more details?” The requests you make should match the pretext, too. If your pretext is being a tech support guy, you won’t “order” people around with what they must and must not do; you work for them. If you are a UPS delivery person, you don’t demand access to the server room. As mentioned earlier, more steps may exist for perfecting a pretext, but the ones listed in this chapter can give a social engineer a solid foundation to build a perfectly believable pretext. You might be asking, “Okay, so you listed all these principles, but now what?” How can a social engineer build a well-researched, believable, spontaneous-sounding, simple pretext that can work either on the phone or in person and get the desired results? Read on. Successful Pretexting To learn how to build a successful pretext, take a look at a couple of stories of social engineers who used pretexts that worked and how they developed them. Eventually they did get caught, which is why these stories are now available. Example 1: Stanley Mark Rifkin Stanley Mark Rifkin is credited with one of the biggest bank heists in American history (see a great article about him at www.social-engineer.org/wiki/archives/Hackers/hackers-Mark-Rifkin-Social-Engineer-furtherInfo.htm ). Rifkin was a computer geek who ran a computer consulting business out of his small apartment. One of his clients was a company that serviced the computers at Security Pacific Bank. The 55-floor Security Pacific National Bank headquarters in Los Angeles looked like a granite-and-glass fortress. Dark-suited guards roamed the lobby and hidden cameras photographed customers as they made deposits and withdrawals. This building seemed impenetrable, so how is it that Rifkin walked away with $10.2 million and never held a gun, never touched a dollar, and never held up anyone? The bank’s wire transfer policies seemed secure. They were authorized by a numerical code that changed daily and was only given out to authorized personnel. It was posted on a wall in a secure room that only “authorized personnel” had access to. From the archived article mentioned previously: In October 1978, he visited Security Pacific, where bank employees easily recognized him as a computer worker. He took an elevator to the D-level, where the bank’s wire transfer room was located. A pleasant and friendly young man, he managed to talk his way into the room where the bank’s secret code-of-the-day was posted on the wall. Rifkin memorized the code and left without arousing suspicion. Soon, bank employees in the transfer room received a phone call from a man who identified himself as Mike Hansen, an employee of the bank’s international division. The man ordered a routine transfer of funds into an account at the Irving Trust Company in New York—and he provided the secret code numbers to authorize the transaction. Nothing about the transfer appeared to be out of the ordinary, and Security Pacific transferred the money to the New York bank. What bank officials did not know was that the man who called himself Mike Hansen was in fact Stanley Rifkin, and he had used the bank’s security code to rob the bank of $10.2 million. This scenario offers much to talk about, but for now, focus on the pretext. Think about the details of what he had to do: He had to be confident and comfortable in order to not raise suspicion for being in that room. He had to have a believable story when he called to do the transfer and have the details to back up his story. He had to be spontaneous enough to go with the flow with questions that might have come up. He had to also be smooth enough to not raise suspicion. This pretext had to be meticulously planned out with the utmost detail being thought through. It wasn’t until he visited a former associate that his pretext failed, and he was caught. When he was caught, people who knew him were amazed and some even said things like, “There is no way he is a thief; everyone loves Mark.” Obviously his pretext was solid. He had a well-thought-out, and one would guess, well-rehearsed plan. He knew what he was there to do and he played the part perfectly. When he was in front of strangers he was able to play the part; his downfall came when he was with a colleague who knew him, and that colleague saw a news story then put two and two together and turned Mark in. Amazingly enough, while out on bail, Rifkin began to target another bank using the same scheme, but a government mole had set him up; he got caught and spent eight years in federal prison. Although Mark is a “bad guy” you can learn much about pretexting from reading his story. He kept it very simple and used the things that were familiar to him to build a good storyline. Mark’s plan was to steal the money and turn it into an untraceable commodity: diamonds. To do so he would first need to be a bank employee to steal the money, then a major diamond buyer to unload the cash, and finally sell the diamonds to have usable, untraceable cash in his pocket. Although his pretext did not involve elaborate costumes or speech patterns he had to play the part of a bank employee, then major diamond buyer, then play the part of a diamond seller. He changed roles maybe three, four, or five times in this gig and was able to do it well enough to fool almost everyone. Mark knew who his targets were and approached the scenario with all the principles outlined earlier. Of course, one can’t condone what he did, but his pretexting talents are admirable. If he put his talents to good use he would probably make a great public figure, salesperson, or actor. Example 2: Hewlett-Packard In 2006 Newsweek published a very interesting article ( www.social-engineer.org/resources/book/HP_pretext.htm ). Basically, HP’s chairwoman, Patricia Dunn, hired a team of security specialists who hired a team of private investigators who used pretexting to obtain phone records. These hired professionals actually got in and played the roles of HP board members and parts of the press. All of this was done to uncover a supposed information leak within the ranks at HP. Ms. Dunn wanted to obtain the phone records of board members and reporters (not the records from the HP facilities, but the personal home and cell phone records of these people) to verify where she supposed the leak was. The Newsweek article states: On May 18, at HP headquarters in Palo Alto, California, Dunn sprung her bombshell on the board: She had found the leaker. According to Tom Perkins, an HP director who was present, Dunn laid out the surveillance scheme and pointed out the offending director, who acknowledged being the CNET leaker. That director, whose identity has not yet been publicly disclosed, apologized. But the director then said to fellow directors, “I would have told you all about this. Why didn’t you just ask?” That director was then asked to leave the boardroom, and did so, according to Perkins. What is notable about this account is what is next mentioned about the topic of pretexting: The HP case specifically also sheds another spotlight on the questionable tactics used by security consultants to obtain personal information. HP acknowledged in an internal e-mail sent from its outside counsel to Perkins that it got the paper trail it needed to link the director-leaker to CNET through a controversial practice called “pretexting”; Newsweek obtained a copy of that e-mail. That practice, according to the Federal Trade Commission, involves using “false pretenses” to get another individual’s personal nonpublic information: telephone records, bank and credit-card account numbers, Social Security numbers and the like. Typically—say in the case of a phone company—pretexters call up and falsely represent themselves as the customer; since companies rarely require passwords, a pretexter may need no more than a home address, account number, and heartfelt plea to get the details of an account. According to the Federal Trade Commission’s Web site, pretexters sell the information to individuals who can range from otherwise legitimate private investigators, financial lenders, potential litigants, and suspicious spouses to those who might attempt to steal assets or fraudulently obtain credit. Pretexting, the FTC site states, “is against the law.” The FTC and several state attorneys general have brought enforcement actions against pretexters for allegedly violating federal and state laws on fraud, misrepresentation, and unfair competition. One of HP’s directors is Larry Babbio, the president of Verizon, which has filed various actions against pretexters. (If you’re interested in exploring it, the Telephone Records and Privacy Protection Act of 2006 can be found at http://frwebgate.access.gpo.gov/cgi-bin/getdoc.cgi?dbname=109_cong_bills&docid=f:h4709enr.txt.pdf .) The end result was that criminal charges were brought not only against Dunn, but against the consultants she hired. You may wonder, “How is that possible considering they were hired and contracted to perform these tests?” Take a look at what avenues they used and what information they obtained to help answer this question. The consultants obtained the names, addresses, Social Security numbers, telephone call logs, telephone billing records, and other information of the HP board members and reporters. They actually used the Social Security number to establish an online account for one reporter and then obtain records of his personal calls. Page 32 of a confidential document from Hewlett-Packard to its lawyer and internal legal staff ( www.social-engineer.org/resources/book/20061004hewlett6.pdf ) lists a communication from Tom Perkins to the HP board members that offers a little more insight about what pretexts were used. A few tactics used were: They represented themselves as the carrier company to obtain the records of calls illegally. The identities of the ones being investigated were used and spoofed to obtain their personal call records. Online accounts with carriers were generated using illegally obtained names, Social Security numbers, and other information to access their call records. On September 11, 2006, the United States House of Representatives Committee on Energy and Commerce sent Ms. Dunn a letter (see a copy of this letter at www.social-engineer.org/resources/book/20061004hewlett6.pdf ) requesting the information she had obtained. They listed in their requests the obtained information as the following: All published and non-published telephone numbers Credit card bills Customer name and address info Utility bills Pager numbers Cell numbers Social Security numbers Credit reports Post office box information Bank account information Asset information Other consumer information All of this information was obtained through a very gray area of professional social engineering: is what they did ethical and moral, even though they were hired to do it? Many professional social engineers would not go to these lengths. The lesson to be learned from this very important case is that as a professional social engineer you might mimic the methodologies and the thinking of malicious social engineers, but never should you stoop completely to their levels. The problem with these consultants came in that they were authorized to pretext, social engineer, and audit Hewlett-Packard. They were not authorized to social engineer AT&T, Verizon, utility companies, and so on. When employing pretexting you must have it outlined and planned so you know what legal lines you might get near and what lines you must not cross. HP’s story lends itself to a discussion about policy, contracts, and outlining what you will be offering if you are a social engineer auditor, but these topics are not within the context of this chapter. Using the principles outlined so far in this chapter can help you make decisions that will keep you out of trouble. The danger with malicious pretexting is the threat of identity theft, which makes it a very valid part of a social engineer pentest. Testing, checking, and verifying that your client’s employees will not fall for the methods used by malicious social engineers can go a long way in safeguarding you from a successful pretexter. Staying Legal In 2005 Private Investigator Magazine was granted an interview with Joel Winston, Associate Director of the Federal Trade Commission (FTC), Division of Financial Practices. His office is in charge of regulating and monitoring the use of pretexting (see a copy of this valuable article at www.social-engineer.org/resources/book/ftc_article.htm ). Here are some of the key points from this interview: Pretexting, according to the FTC, is the obtaining of any information from a bank or consumer, not just financial information, using fraud, deception, or misleading questions to obtain such information. Using already-obtained information to verify that a target is a target, even while using false pretenses, is legal under the FTC’s definition of pretexting, unless the social engineer is using this information to obtain information from a financial institution. Acquiring toll phone or cellular records through deceptive business practices is considered illegal pretexting. The FTC website provides some clarity and additional information to this interview: It is illegal for anyone to use false, fictitious, or fraudulent statements or documents to get customer information from a financial institution or directly from a customer of a financial institution. It is illegal for anyone to use forged, counterfeit, lost, or stolen documents to get customer information from a financial institution or directly from a customer of a financial institution. It is illegal for anyone to ask another person to get someone else’s customer information using false, fictitious, or fraudulent statements or using false, fictitious, or fraudulent documents, or forged, counterfeit, lost, or stolen documents. Although the FTC’s focus is on financial institutions, the guidelines outlined are a reminder of what is considered illegal in the United States. Looking into their local laws and making sure they are not breaking those laws is a good idea for professional social engineers. In 2006, the Federal Trade Commission moved to expand Section 5 of the FTC Act to specifically include a law banning the use of pretexting to retrieve telephone records. HP’s pretexting situation ended in one of the private investigators being charged with conspiracy and federal identity theft—very serious charges. Keeping pretexting legal will entail some research on the part of the professional social engineer as well as a clearly defined and signed-off plan of what pretexts, if any, will be used. Despite the legal matters mentioned earlier, using a solid pretext is one of the quickest ways into a company. Pretexting is a talent all its own and, as you can see from this chapter, is not simply putting on a wig or a pair of fake glasses and pretending you are someone you are not. Additional Pretexting Tools Other tools exist that can enhance a pretext. Props can go a long way in convincing a target of the reality of your pretext; for example, magnetic signs for your vehicle, matching uniforms or outfits, tools or other carry-ons, and the most important—a business card. The power of the business card hit me when I was recently flying to Las Vegas on business. My laptop bag usually gets scanned, rescanned, then swabbed for bomb dust or whatever. I am one of those guys who doesn’t really mind the extra security precautions because they keep me from blowing up in the air, and I am happy with that. Yet I realize that 90 percent of the time I am going to get extra attention by Transportation Security Administration (TSA). On this particular trip I had forgotten to take my lock picks, RFID scanner, four extra hard drives, bump keys (see Chapter 7), and plethora of wireless hacking gear out of my carry-on laptop bag. As it goes through the scanner I hear the lady working the x-ray say, “What the heck?” She then calls over another gentlemen who stares at the screen and says, “I have no clue what the heck that stuff is.” He then looks around, sees my smiling face, and says, “Is this you?” I walk over to the table with him as he is emptying my RFID scanner and my large case of lock picks and he says, “Why do you have all of these items and what are they?” I had nothing planned but decided at the last second to try this move: I pulled out a business card and said, “I am security professional who specializes in testing networks, buildings, and people for security holes. These are the tools of my business.” I said this as I handed him a business card and he looked at it for about five seconds and then said, “Oh, excellent. Thanks for the explanation.” He neatly put all my items back in, zipped the bag up, and let me go. Usually I go through the bomb screening, the little dust machine, and then a patdown, but this time all I got was a thank you and a quick release. I began to analyze what I did differently than normal. The only difference was that I had given him a business card. Granted, my business card is not the $9.99 special from an online card printer, but I was amazed that what seemed to have happened was that a business card added a sense of license to my claims. My next four flights I purposely packed every “hacking” device into my bags I could find and then kept a business card in my pocket. Each time my bag was examined and I was asked about the contents, I flipped out the card. Each time I was apologized to, had my items packed in neatly, and let go. Imagine my experience was a pretext. Little details can add so much weight to what I am saying that I can appear valid, trustworthy, and solid with nothing more than a card that tells people that everything I say is true. Don’t underestimate the power of a business card. One word of caution: getting a weak and pathetic-looking business card can actually cause the opposite effect. A business card that was “free” with an advertisement on the back will not add weight to a professional pretext. Yet there is no reason to spend $300 on a business card to use once. Many online business card printers can print a small amount of very nice cards for less than $100. Another reason to take this chapter very seriously is that often times pretexting is the very first step used by professional identity thieves. Because identity theft is taking a front row seat in the crime industry of late, knowing what it is and how to identify it is important for consumers, businesses, and security professionals. If you are a security auditor you must help your clients become aware of these threats and test them for possible weaknesses. Summary In addition to extensively covering pretexting and providing real-world examples of pretexting in action, this chapter also continually brushed up against the psychological principles that affect different aspects of pretexting. The logical next stop on the framework covers just that—the mental skills that professional social engineers use that make them seem like mind control masters and that give each social engineer a huge leg up in success.",
        "char_count": 55114
      },
      {
        "heading": "Chapter 11",
        "text": "Chapter 5 Mind Tricks: Psychological Principles Used in Social Engineering It all depends on how we look at things, and not on how they are themselves. —Carl Gustav Jung In Hollywood movies and television shows con men and law enforcement are portrayed with almost mystical talents. They have the ability to get away with anything; they seem to be able to just look into the eyes of a person and tell if they are lying or telling the truth. It is not uncommon to see situations like this: the cop looks into the eyes of his suspect and can automatically tell whether he is lying or telling the truth, or with just the power of suggestion the con man’s targets are handing over their life’s savings. Movies might have you believing that manipulation tactics and getting people to do anything you want is plausible or even easy. Are these scenarios really fiction? Is it possible to gain such abilities that are saved for fantasy in the movies? This chapter could be a book unto itself, but I will condense this information down to principles that will truly change the way you interact with people. Some of the topics in this chapter are based on research done by the brightest minds in their respective fields. The techniques discussed in these topics were tested and put through the paces in social engineering environments. For example, the topic of microexpressions is based on the research of the world-renowned psychologist and researcher, Dr. Paul Ekman, who used his genius to develop techniques into reading facial expressions that can literally change the way law enforcement, governments, doctors, and everyday people interact with others. Some of the principles of Richard Brandler and John Grinder, the originators of neurolinguistic programming, changed people’s understanding about thought patterns and the power of words. These topics are subjects for much debate, and this chapter attempts to demystify this subject and explain how you can use them in social engineering. Some of the best interrogators on the planet developed training and frameworks to help law enforcement learn how to effectively interrogate suspects. These principles have such deep psychological roots that learning the methods used can literally unlock the doors to the minds of your targets. Using cues that people give in their speech, gestures, eyes, and faces can make you appear to be a mind reader. This chapter examines these skills and explains them in detail so they can be utilized by a professional social engineer. Rapport is often a word used by sales trainers and salespeople, but it is a very important aspect of gaining trust and displaying confidence. Knowing how to instantly develop rapport with people is a skill that truly enhances the skill set of a social engineer, and this chapter shows you how. This chapter finishes with my own personal research on how you can use these skills to hack the human mind. A buffer overflow is a program usually written by a hacker to execute code, of malicious intent normally, through the normal use of a host program. When executed the program does what the hacker wants. What if it were possible to run “commands” on the human mind that would cause the target to do what you ask, give over information you seek, and, in essence, prove that the human mind is able to be manipulated? This powerful information, of course, can be used for very malicious intentions. My goal in releasing this information to the public in this way is to pull back the curtain from what the “bad guys” are doing by exposing their methods, thinking, and principles, then analyzing each one and showing what you can learn from it. Exposing these techniques makes identifying, defending, and mitigating against these attacks easier for everyone. This chapter is truly a mind-altering collection of data and principles. Following, studying, and researching the methods will not just enhance any security endeavors but these principles can also alter the way you communicate and interact with others. By no means, though, is this chapter a complete collection that covers all aspects of each of these skills. I provide links and tips to where you can find more information and programs to help you enhance these skills. This chapter sets a foundation as well as acts like a guide, pointing you in a direction so you can learn to enhance each skill over time. Learning social engineering skills is not a quick process, so don’t be impatient. The methods of learning some of these skills can take years to perfect and a lot of practice to even become proficient. Of course, you may possess a skill for a certain aspect but if you do not, don’t become impatient with trying to learn it. Keep on trying harder and practicing and you will get it. Before you get into the meat of this chapter, the following section sets the stage for why and how these principles will work. You must understand the modes of thinking that exist. After you understand more clearly how people take in and process information you can begin to understand the emotional, psychological, and physical representations of that process. Modes of Thinking To alter someone’s way of thinking you must understand the way people think and in what modes they think. This seems a logical first step to even attempting this aspect of social engineering. You might think you need to be a psychologist or a neurologist to understand the many aspects of how a person can think. Although that can help, it is not necessary. With a little research and some practical application you can delve into the inner workings of the human mind. In August of 2001 the FBI put out a law enforcement bulletin ( www.social-engineer.org/wiki/archives/ModesOfThinking/MOT_FBI_3of5.htm ) that made a few very profound statements on the modes in which people think: Simply confirming your nonverbal behavior to the client, using language from the client’s preferred representational system and matching speech volume, tone, and area of speech often overcomes client reluctance to communicate. This simple statement has a lot of depth in it. Basically it is saying that if you can first figure out the target’s dominant mode of thinking and then confirm it in subtle ways, you can unlock the doors of the target’s mind and help him actually feel at ease when telling you even intimate details. Logically you may ask then, “How do I figure out a target’s dominant mode of thinking?” Even asking people what their mode of thinking is will not offer a clear answer, because many people do not know what mode of thinking they often reside in. Due to that, as a social engineer you must have some tools to help you determine this mode and then quickly switch gears to match that mode. A clear and easy path exists to this answer but you need to know the basics first. The Senses For centuries philosophers have argued the value of perception. Some go so far as to say that reality is not “real” but just what our senses build into our perceptions. Personally, I do not subscribe to that idea, but I believe that the world is brought to our brain by our senses. People interpret those senses for their perception of reality. In the traditional classification we have five senses: sight, hearing, touch, smell, and taste. People tend to favor one of these senses and that is the one that is dominant. It is also the way people tend to remember things. As one exercise to determine your dominant sense, close your eyes and picture yourself waking up this morning—what is the very first thing you remember? Was the feeling of the warm sun on your face? Or maybe you remember the sound of the voice of your spouse or children calling you? Do you remember clearly the smell of coffee downstairs? Or quite possibly the bad taste in your mouth, reminding you that you need to brush your teeth? Of course, this science is not exact and realizing what your dominant sense is may take a few tries to figure out. I once talked to a couple about this concept and it was interesting to watch their expressions. The wife first remembered waking up and seeing the clock and then worrying that she was running late, whereas the husband first remembered rolling over and not feeling his wife next to him. After some more questions it became evident that the husband was a kinesthetic , or his dominant sense was his feeling, whereas his wife was very visual. Of course, walking up to your target and saying, “Close your eyes and tell me the first thing you remember this morning,” doesn’t seem reasonable. Unless, of course, your pretext is the family shrink, you might meet with some opposition on this route. How can you determine without going through an embarrassing interrogation about their morning rituals what a target’s dominant sense is? The Three Main Modes of Thinking Although we have five senses, the modes of thinking are associated with only three of them: Sight, or a visual thinker Hearing, or an auditory thinker Feeling, or a kinesthetic thinker Each sense has a range within which it works, or a sub-modality . Is something too loud or too soft? Too bright or too dark? Too hot or too cold? Examples of these are as follows: staring at the sun is too bright, jet engines are too loud, and –30 degrees Fahrenheit is too cold. Ivan Pavlov ran an experiment where he rang a bell every time he fed a dog. In the end the dog would hear the sound of the bell, then salivate. What most people don’t know is that he was more interested in the physical and emotional aspects of sub-modalities. The interesting point is that the louder the bell rang the more the dog salivated. The range change of the sub-modality produced a direct physical change. Pavlov’s research and all of his lectures are discussed in much detail at www.ivanpavlov.com . Even though people are very different from dogs, Pavlov’s research is very important in understanding how a person thinks. Many of us can think in all three modes, but we dominate in one—one “rings” the loudest. Even within our dominant mode, we might have varying degrees of depth for that dominant sense. Following I will discuss some of the details of each of these modes in more depth. Visual The majority of people are usually visual thinkers, in that they usually remember what something looked like. They remember the scene clearly—the colors, the textures, the brightness or darkness. They can clearly picture a past event and even build a picture for a future event. When they are presented with material to decide upon they often need something to see because visual input is directly linked to decision making. Many times a visual thinker will make a decision based on what is visually appealing to him regardless of what is really “better” for him. Although men tend to be visual, this does not mean that all men are always visual. That visual marketing or visual aspects normally appeal to men is true, but do not assume all men are visual. A visual person often uses certain words in his speech, such as: “I see what you mean.” “That looks good to me.” “I get the picture now.” And the range that the dominant sense works in for a visual thinker can have certain characteristics, or sub-modalities, such as: Light (bright or dim) Size (large or small) Color (black and white or color) Movement (fast or slow) Focus (clear or hazy) Trying to debate, sell, negotiate, manipulate, or influence a visual thinker with no visual input is very difficult if not impossible. Visual thinkers need visual input to make decisions. Auditory Auditory thinkers remember the sounds of an event. They remember that the alarm was too loud or the woman whispered too low. They recall the sweetness of the child’s voice or the scary bark of the dog. Auditory people learn better from what they hear and can retain far more from being told things than being shown things. Because an auditory thinker remembers the way something sounded, or because the sounds themselves help recall memories, he may use phrases such as: “Loud and clear…” “Something tells me…” “That sounds okay to me.” And the range of this dominant sense can be within these sub-modalities: Volume (loud or soft) Tone (base or treble) Pitch (high or low) Tempo (fast or slow) Distance (near or far) It is imperative to choose your words carefully with auditory thinkers. The words they hear will make or break the deal. I have seen whole encounters go from great to a disaster with one wrong word spoken to an auditory thinker. Kinesthetic Kinesthetic thinkers are concerned with feelings. They remember how an event made them feel—the warmth of the room, the beautiful breeze on their skin, how the movie made them jump out of their seat with fear. Often kinesthetic thinkers feel things with their hands to get the sense of the objects. Merely telling them something is soft isn’t as real as letting them touch it. But helping recall a soft item they touched before can recall emotions and feelings that are very real to a kinesthetic thinker. The term “kinesthetic” relates to tactile, visceral, and sense-of-self sensations of the body—basically, where a person’s body is in space and the self-awareness of how something made him feel. A kinesthetic thinker uses phrases such as: “I can grasp that idea.” “How does that grab you?” “I’ll get in touch with you.” “I just wanted to touch base.” “How does this feel?” And the range for this type can have the following sub-modalities: Intensity (strong or weak) Area (large or small) Texture (rough or smooth) Temperature (hot or cold) Weight (heavy or light) Helping a kinesthetic thinker recall a feeling or emotion tied to something can make those emotions reappear as real as the first time they occurred. Kinesthetic thinkers are probably the most difficult for non-kinesthetic thinkers to deal with because they do not react to sights and sounds and social engineers have to get in touch with their feelings to communicate with this type of thinker. Understanding these basic principles can go a long way toward being able to quickly discern the type of person you are talking to. Again, without asking the target to picture his morning rituals how can you discern the dominant sense? Even more so, why is this so important? Discerning the Dominant Sense The key to determining someone’s dominant sense is to try to introduce yourself, start a small conversation, and pay close attention to what is being said. As you walk up to the target and lean in to say good morning, maybe she barely looks at you. She might be rude, or she just may not be a visual. Visuals need to look at the person speaking to communicate properly, so this behavior would seem to lend to  the fact she is not visual. Now ask a simple question such as, “Don’t you just love the feel of a beautiful day like today?” and notice her response, particularly whether she seems to light up or not. Maybe you wear a large, shiny silver ring. As you talk you gesture; maybe you see that the ring catches her eye. Does she reach out, interested, and need to hold the ring or get close to observe it? Kinesthetics are very touchy-feely when it comes to these things. I know a woman who is a strong kinesthetic and when she sees something she thinks is soft or high quality she must touch it. She will say, “Wow, that sweater looks so soft!” From that statement one might assume she is a visual, but what happens next is what solidifies it. She then walks up to the person and touches the sweater and feels it. This shows her dominant sense is kinesthetic. The same woman must touch everything in the grocery store when she shops, whether she needs it or not. By touching the objects, she makes a connection and that connection makes it real to her. Often she cannot remember things very well that she did not come into physical contact with. Asking questions that contain some of the key dominant words, observing a target’s reactions, and listening can reveal what dominant sense he or she uses. Listening for key words such as see, look, bright, dark can lead you to treat a target like a visual. As mentioned earlier this is not an exact science. There isn’t a general rule that states if a person says, “I can see what you are saying…” then he is always a visual. Each clue should lead you down the path toward verifying your hunch with more questions or statements. One word of caution: talking to someone in a different mode than they think in can be irritating to some. Using questions to determine a person’s mode of thinking can be off-putting. Use questions sparingly and rely more on observation. Why Understanding the Mode Is Important I once worked with a guy, Tony, who could sell a cup of water to a drowning man. Tony was a big believer in seeking out and then using a person’s dominant sense in sales. He had a few methods that he used that you may learn from. When he first engaged the target he had a very shiny silver-and-gold pen he would hold in his hand. He would gesture a lot and notice whether the person followed the pen with her eyes; if she did slightly Tony would continually make the gestures bigger to see whether her eyes followed. If that didn’t seem to work in the first few seconds he would click the pen open and closed. It wasn’t a loud noise, but loud enough to disrupt a thought and draw someone’s attention if she were an auditory. If he thought that was working he would click it with every important thought, causing the target to have a psychological reaction to the sound and what was being said. If that didn’t seem to work he would reach out over the table and tap her wrist or forearm, or if he was close enough touch her shoulder. He didn’t touch excessively, but enough to see whether she would shy away or seemed overly happy or disturbed by the touch. With these subtle methods he could quickly discern what the person’s dominant sense most likely was. This whole act would take under 60 seconds. After he found the information he was looking for, he would then start to move his conversation to that dominant sense, even taking on the traits of that sense in the words he spoke and way he acted and reacted to the conversation. One thing about Tony is that he outsold any person I have ever met. People would often say about him, “It is like he knew exactly what I needed.” Tony would talk to the person and treat the person the way they wanted to be talked to. If the person was a visual thinker, Tony would use phrases like “Can you see what I am saying?” or “How does this look to you?” He would use illustrations that involved “seeing” things or visualizing scenarios. He would put people in their comfort zone. People feel at ease when they are in their comfort zone. The more you can do as a social engineer to put people in their comfort zone, the better chance you have at success. People gravitate towards those with whom they are comfortable; it is human nature. For example, if someone makes you feel “warm and fuzzy,” or seems to understand what you are saying, or seems to see where you are coming from, you easily open up to, trust, and let that person in your circle. I want to reiterate this point: finding and using someone’s dominant sense is not an exact science. A social engineer should use it as a tool in the arsenal and not rely on it as something magical or scientific. Certain psychological aspects of human nature are based on proven science and can be relied upon. As a matter of fact, some of these aspects are so impressive that they can make you seem like a mind reader. Some of them have been a topic of serious debate and some accepted by psychologists, law enforcement, and social engineers for years. The next section of this chapter discusses these, starting with microexpressions. Microexpressions You are probably familiar with the idea of reading facial expressions. When someone is happy, sad, angry, or whatever, when someone feels it you can look at his or her face and see that emotion. What if someone tries to fake that expression, like a fake smile? We have all done it, walking through the market and bumping into someone we just don’t like that much—we put on a “smile” and say, “Hey John, nice to see you. Say hi to Sally.” We may act very pleasant and cordial, but inside we are feeling nothing but irritation. The expressions that we show for longer periods of time on our face are called macroexpressions and are generally easier for people to see the emotion that is being conveyed. Similar to microexpressions, macroexpressions are controlled by our emotions, but are not involuntary and often can be faked. A certain few pioneers into the study of human behavior have spent decades researching something, coined microexpressions , to understand how humans relay emotions. Microexpressions are expressions that are not easily controllable and occur in reaction to emotions. An emotion triggers certain muscular reactions in a face and those reactions cause certain expressions to appear. Many times these expressions last for as short as one-twenty-fifth of a second. Because they are involuntary muscular movements due to an emotional response, they are nearly impossible to control. This definition is not a new understanding either; Charles Darwin wrote a book in 1872 called, The Expression of the Emotions in Man and Animals. In this book Darwin noted the universal nature of facial expressions and how muscles were used in facial expressions. In the early 1960s two researchers, Haggard and Isaacs, first discovered what today is called microexpressions. In 1966, Haggard and Isaacs outlined how they discovered these “micromomentary” expressions in their publication titled, Micromomentary Facial Expressions as Indicators of Ego Mechanisms in Psychotherapy . Also in the 1960s, William Condon, a pioneer who studied hours of tapes frame by frame, discovered that humans had “micro-movements.” He also heavily researched neurolinguistic programming (more on that later) and body language. Probably one of the most influential researchers in the field of microexpressions is Dr. Paul Ekman. Dr. Ekman pioneered microexpressions into the science it is today. Dr. Ekman has been studying microexpressions for more than 40 years, receiving the Research Scientist Award as well as being labeled one of Time Magazine’s most influential people on earth in 2009. Dr. Ekman researched facial expressions with psychologist Silvan Tomkins. His research revealed that, contrary to popular belief, emotions are not culturally determined, but are universal across cultures and biological. Working with Dr. Maureen O’Sullivan he developed a project called the Wizards Project . He began to pioneer the use of microexpressions in lie detection. He used a base of 15,000 people from all walks of life and all cultures and found out of that large number that only 50 had the ability to spot a deception without training. In the 1970s Dr. Ekman developed FACS (Facial Action Coding System) to label and number each conceivable human expression. His work branched out to not only include facial expressions but also how the whole body was involved in deception. By 1972, Dr. Ekman had identified a list of expressions that were linked with basic or biologically universal emotions: Anger Disgust Fear Joy Sadness Surprise Dr. Ekman’s work began to take on a following, and many law enforcement and corporate environments began to use this research in detecting deception. In 1990, in a paper entitled “Basic Emotions,” Dr. Ekman revised his original list to include a range of positive and negative emotions ( www.paulekman.com/wp-content/uploads/2009/02/Basic-Emotions.pdf ). Dr. Ekman has published many books on emotions, facial expressions, and lie detection that can help each person to understand the value in being able to decode facial expressions. This brief history indicates that the subject of microexpressions is not some fantasy; on the contrary, real doctors, researchers, and professionals in the field of human behavior have put countless hours into understanding microexpressions. As a social engineer, understanding microexpressions can go a long way toward protecting your clients and teaching them how to notice subtle hints of deception. If you are a social engineer, or just a person interested in learning about microexpressions, I strongly suggest reading Dr. Ekman’s books, especially Emotions Revealed and Unmasking the Face . He is truly the authority on this topic. The following sections describe the microexpressions in a simplistic format so you can see how you can use this later on as a social engineer. As mentioned earlier, Dr. Ekman labeled six main microexpressions and later on added contempt to the list, making seven. The following sections cover these one by one. Anger Anger is usually easier to spot than some other expressions. In anger the lips become narrow and tense. The eyebrows slant downward and are pushed together—then comes the most noticeable characteristic of anger, the glare. Anger is a strong emotion and can trigger many other emotions along with it. Sometimes when a person feels anger at something, what you see is a microexpression such as that shown in Figure 5-1 . What makes it hard to see is that the facial movements may last only one-twenty-fifth of a second. Dr. Paul Ekman Figure 5-1: Notice the glare, tense lips and tightened brows. Learning to see a specific microexpression can greatly enhance your understanding of people. To learn how to do so, Dr. Ekman recommends practicing that expression on yourself. He says follow these steps: 1. Pull your eyebrows down and together; pretend you are trying to touch your nose with the inner parts of your eyebrows. 2. While your brows are down, try to open your eyes wide, without adjusting your brow position. 3. Press your lips together tight. Do not pucker your lips, just tense them together. 4. Glare. What emotion do you feel? The first time I did this, I was overwhelmed with anger. The following is a vital point to this chapter: If producing the facial expression can cause the emotion, that must mean that our facial movements can affect the emotions we feel, and maybe even the emotions of those around us. Practice this emotion in a mirror until you get it right. Figure 5-2 shows a picture of Simon Cowell wearing a very definite angry expression. Figure 5-2: Notice the definite expression of anger on Simon’s face. It may not be as pronounced as Figure 5-1 , but you can see all the signs on his face of being angry. Mastering the ability to reproduce microexpressions will go a long a way toward understanding the emotion behind them. When you can successfully reproduce and decode a microexpression, you can understand the emotion that is causing it. At that point you can understand the mental state of the person you are dealing with. Not only reproducing them on yourself but also being able to see and read them in others can be helpful in controlling the outcome of your social engineering engagements. Disgust Disgust is a strong emotion usually in reaction to something you really do not like. This “something” does not always have to be a physical object; it can also be something that is based on a belief or feeling. A food that you truly hate can cause the feeling of disgust, which will trigger this expression. What is amazing is even in the absence of the actual smell or sight of the food, the thought of it can cause the same emotion. When I was a teenager, I went to Disney World with a few friends. I am not, and I mean not , a fan of roller coasters. After much prodding I went on Space Mountain, an indoor roller coaster. About halfway through I had determined that I really didn’t mind roller coasters when suddenly I was smeared with something very wet and chunky. I was then hit with an odor that I can only describe as stomach contents. Not only me, but many behind me had the same reaction and none of us could hold back our lunch, so to speak. Before you knew it, a simultaneous puking splattered the glass of the Tomorrowland Transit Authority, a slow-moving observation ride that offers a peek into the actual Space Mountain ride on part of its journey. What is amazing is that people in the Tomorrowland ride who sat there slowly going around the park saw the aftereffects hit the glass as they rode through, and saw all the other riders getting physically ill, which made them also vomit—yet they didn’t smell the odor or have physical contact with the puke from the roller coaster riders. Why? Disgust. Bodily fluids generally bring on feelings of disgust and this is one reason that while reading this paragraph you probably started to exhibit the expressions of disgust. Disgust is often characterized by the upper lip being raised to expose the teeth, and a wrinkling of the nose. It may also result in both cheeks being raised when the nose is wrinkled up, as if to try to block the passage of the bad smell or thought into one’s personal space. I was reading an article on the winter Olympics when I saw this picture of Ekaterina Ilyukhina (see Figure 5-3 ) showing very clear traits of disgust. Notice the raised upper lip and the wrinkled nose. Is she looking at her score? Is a competitor beating her? I am not sure, but whatever she is looking at, it is not sitting well with her. Figure 5-3: Clear signs of disgust with a wrinkled nose and raised lip. Disgust is one of those emotions, according to Dr. Ekman’s research, that is in reaction to the sight, smell, or even thought of something distasteful. From a social engineering standpoint this emotion might not lead you down paths of success, but it can surely help you to see whether you are hitting the mark with your target or causing him or her to mentally shut down to your ideas. The odds are that if you cause disgust for any reason in your target, you have lost. If your appearance, smell, style, breath, or other aspect of your person can make a person feel disgust, then it will most likely close the door to success. You must be aware of what is acceptable and unacceptable to your targets. For example, if your audit is for a prestigious law firm and you have many piercings or tattoos, a very strong negative emotion may rise in your target, which can close the door to your social engineering attempt. If you see a facial expression similar at all to Figure 5-4 then you know it is time to leave the scene. Figure 5-4: If you see this expression, something is wrong. You must seriously consider your appearance when working on your pretext. If you happen to notice the strong negative emotion of disgust in your target, then backing down and politely excusing yourself to rework your pretext or find a different path in may be a good idea. Contempt Contempt is a very strong emotion that is often confused with disgust because it is so closely linked. Dr. Ekman didn’t even include contempt on his first list of the base emotions. In Dr. Ekman’s book Emotions Revealed he says, “Contempt is only experienced about people or the actions of people, but not about tastes, smells, or touches.” He then gave an example of eating calf brains, which might be disgusting to you as a thought, and will trigger disgust. Yet seeing someone eating them may trigger contempt for the person committing the act, not the act itself. In my opinion this is a very important point and makes understanding this microexpression crucial. That contempt is directed at a person rather than an object is crucial to understanding the microexpressions that go along with it. Being able to see whether the person you are dealing with is feeling contempt can help you to pinpoint more closely the reason for his or her emotion. Contempt is distinguished by wrinkling the nose and raising the lip, but only on one side of the face, whereas disgust is the raising of the whole lip and the wrinkling of the whole nose. A very subtle contempt expression can be seen in Figure 5-5 . Dr. Paul Ekman Figure 5-5: Notice the slight nose wrinkle and the raising of only the right side of Dr. Ekman’s face. Try to mimic contempt, and if you are like me, you will quickly feel anger and contempt in your heart. Performing this exercise and seeing how these reactions affect you emotionally is interesting. In Figure 5-6 you can see Serena Williams displaying definite signs of contempt. I found this picture online and didn’t save the news article so I am not sure what the contempt was toward, but whatever it was, she is obviously feeling bad about it. Figure 5-6: Serena Williams showing contempt on the left side of her face. Contempt is often accompanied by anger, because the things that can cause contempt in a person can also trigger strong negative emotions. Contempt is one emotion you want to avoid triggering in anyone with whom you are dealing, especially if you are in a social engineering engagement. Fear Fear is often confused with surprise because the two emotions cause similar muscular reactions in the face. Recently while on a plane, I was about to write the section on happiness, but something amazing happened at that time that served as the impetus for writing this section on fear instead. I am not a short man, being 6’3”, and not a small build, either. While I sat on the plane with a few hours to kill I thought I would take advantage of the time to work. Let me add that coach seats aren’t what they used to be. As I sat with my laptop open staring off into space I pondered how to start the section I had intended to write. I soon realized I was meant to start writing about fear, because the gentlemen next to me pulled out a water bottle and took a swig, but I didn’t see him recap the bottle. Out of the corner of my eye I saw his bottle falling from his hands and toward my keyboard. My instant reaction was easily identified as fear. My eyes opened wide, while my eyebrows crunched together inward. My lips pulled together and out towards my ears. Of course, I didn’t realize all this as it was happening but afterward I was able to analyze what had happened and I knew I had felt fear. I then analyzed the way I felt my face move and determined that if I repeated the expression I felt that same emotion all over again. I am sure I looked similar to what is seen is Figure 5-7 . Try to see whether you can generate this emotion in yourself by following these steps: 1. Raise your eyebrows as high as they will go. 2. Drop your mouth open slightly and pull the corners of your lips back. 3. If you can, pull your eyebrows together while raising them as high as you can. How did you feel? How about in your hands and arms and your stomach? Did you notice any semblance of fear? If not, try the exercise again but think back to a time when you were in a situation (something similar to my plane experience, or a car in front of you screeching to a halt) out of your control. See how you feel then. Dr. Paul Ekman Figure 5-7: Clear signs of fear. Most likely you will feel the emotion. Browsing the Web I found this picture of U.S. Senator Olympia Snowe, who is showing very clear signs of fear (see Figure 5-8 ). Whatever question was asked of her before that picture was snapped caused a very distinct feeling of fear. Her eyebrows are raised high with her lips slightly open and pulled back, and her eyebrows are almost forced together while being raised as high as they can go. From a social engineering standpoint, fear is often used to cause people to react a certain way. Malicious social engineers use fear tactics to get an unsuspecting user to click a banner or give up a valuable piece of information. For example, malicious banners might claim “Your computer is infected with a virus. Click here to get fixed now!!” These banners work against non-technical users who fear the virus and will click, only to be infected at that point. Figure 5-8: Senator Snowe showing clear signs of fear. One company I worked with was hit by a malicious social engineer who used fear to gain access to the building. Knowing that the CFO was out of town on an important business meeting and could not be disturbed, the social engineer went into the company as a tech support guy. He demanded access to the CFO’s office, which was promptly denied. He then played this line, “Mr. Smith, your CFO, called me and told me that while he was away at this meeting I better come down and fix his e-mail problem and that if it is not fixed while he is gone, heads will roll.” The secretary feared that if it didn’t get fixed, she would be to blame. Would her boss really be angry? Could her job be at risk? Because she feared a negative outcome, the secretary let the phony tech support guy in. If he was a skilled social engineer he may have been watching her facial expressions and noticing whether she exhibited signs of worry or anxiety, which are related to fear. He then could have played on these signs more and more, getting her to cave in to her fear. Fear can be a big motivator to do many things that you (or your target) would not normally consider doing. Surprise As mentioned earlier, Dr. Ekman and many other psychologists in the area of microexpressions have concurred that surprise is closely linked to fear because of certain similarities. Even so, some marked differences exist, such as the direction the lips take and the way the eyes react. Try this exercise to show surprise: 1. Raise your eyebrows, not in fear but with the goal of widening your eyes as much as you can. 2. Let your jaw unhinge and open slightly. 3. After you get the expression down pat try doing it quickly. I noticed I almost was forced to gasp in some air when I did it, causing me to feel something similar to surprise. You should see an expression similar to Figure 5-9 . Dr. Paul Ekman Figure 5-9: Notice the way the eyes and lips appear similar to fear. Surprise can be good or bad. Hearing your daughter’s first words, of course, is a good surprise. Or the surprise can be one of an event, statement, or question that you didn’t expect that causes this response. That is what I suspect is happening to Jessica Simpson in Figure 5-10 . Notice how her eyebrows are raised and her jaw is unhinged and open. She is showing all the classic signs of being surprised, maybe by the question that was just asked of her or a response to something she heard. Figure 5-10: Often confused with fear, surprise has some minor differences. If the surprise is positive, it can often cause even a smile or a jovial response. As Jessica’s expression in Figure 5-10 shows, she looks surprised, but also happy about the surprise. A social engineer can sometimes use surprise to open the target’s door, so to speak; following up with quick wit or a joke can quickly put the target at ease, causing her to lower her guard. Sadness Sadness is an overwhelming and strong emotion. Sadness is one of those emotions that we may feel ourselves when we see other people who are expressing this emotion. Some people can feel sadness just by seeing others who are sad, even to the point of crying. To show you how easily you can feel sadness, try this exercise: 1. Drop your mouth open slightly. 2. Pull the corners of your lips down. 3. Hold your lips in place, and while doing that try to raise your cheeks as if you are squinting. 4. While maintaining that tension, look down and let your upper eyelids droop. Most likely you will begin to feel sadness. When I first did this exercise, it was overwhelming for me. I instantly felt sad and found I had to control the length of time I performed it because it caused me to be sad for quite a while. To see how this should look, notice the expression in Figure 5-11 . Dr. Paul Ekman Figure 5-11: Notice the lips and eyes drawn back and down, signifying sadness. Another aspect of sadness that makes it an amazing emotion is that it does not always have to display as agony or extreme grief. Sadness can be very subtle. Sadness can also be displayed in just one part of the face. People may try to hide sadness by using a fake smile or what I call “stoic eyes,” where they stare straight ahead, almost in a daze, but you can tell they are trying to control the emotion they are feeling. Take a look at Figure 5-12 ; in this picture you can see an example of sadness being expressed that way. During an interview about her divorce and family, Kate Gosselin tries to hide her emotion, but if you look at her lips you can see very subtle hints of sadness. Figure 5-12: Notice the lips drawn back and down, signifying sadness. Besides the lips, the eyes are another key indicator of sadness. This expression can be hard to read and can be confused with tiredness and other emotions, but looking at a person’s demeanor and body language can also help with the cues. This is the case with cultures that cover much of their face. As you can see in Figure 5-13 , these women are attending a funeral; although mostly covered, the center woman reveals in her eyes that she is feeling sadness. Figure 5-13: Notice the eyes looking down and the upper eyelid drooping. Sadness is often used in social engineering because it can trigger people to take an action such as donate money or give out information. You have probably seen it used in television commercials showing a very disadvantaged child. These children may be malnourished, poverty stricken, and seemingly unloved, but for just a small donation you can bring a smile to the child’s face. The images of sad, crying, emaciated children will tug at your heartstrings. I am not suggesting that these commercials are malicious social engineering, just that they use social engineering to a degree, by using an emotional trigger to get a reaction out of the target. Unfortunately, malicious social engineers often use this emotional trigger to obtain things from their targets. I once walked into a restaurant and overheard a young man telling a group of older folks who were leaving that he just ran out of gas on the highway and needed to get home because his wife was nine months pregnant. He had been out of work and had just walked a mile off the highway to use the phone to call his wife and wondered if they could give him $20. When I heard some of the story I slowed down and made believe I was on a phone call to observe the rest. He told his tale and then backed it up with, “Look if you give me your address, I will mail you a check for the $20,” concluding with “I swear to God.” The story had some elements in it that could elicit compassion, especially when his face showed concern, anxiety, and sadness. He didn’t get $20—he was given $20 by each of the three people in that group. He said “God bless you” a few times and gave the group a few hugs and said he was going to go in to call his wife and tell her he was on the way home. He hugged them and they left feeling as if they had done their good deed for the week. A few minutes later as I’m eating my meal, I see him at the bar drinking a couple of fully paid-for drinks with his buddies. Mixing a sad story with some sad facial expressions, he had been able to manipulate the emotions of those around him. Happiness Happiness can have many facets to it—so many that I can probably make a chapter just on it, but that is not my focus. Dr. Ekman’s books cover many excellent points about happiness and similar emotions and how they affect the person with the emotion and those around him or her. What I want to focus on are just a couple aspects of happiness—most importantly the difference between a true smile and a fake smile. The true and the fake smile are an important aspect of human expressions to know how to read, and as a social engineer to know how to reproduce. Has there been a time where you met someone who was very pleasant but after you parted ways your spouse or you yourself said, “That guy was a fake…”? You might not have been able to identify the aspects of a true smile in your head but something told you the person wasn’t being “real.” In the late 1800s a French neurologist, Duchenne de Boulogne, did some fascinating research into smiling. He was able to attach electrodes to a man’s face and trigger the same “muscular” response in the face as a smile. Even though the man was using all the right muscles for smiling, de Boulogne determined that the look of the man was still a “fake smile.” Why? When a person smiles for real, de Boulogne indicates, two muscles are triggered, the zygomaticus major muscle and the orbicularis oculi. Duchenne determined that the orbicularis oculi (muscle around the eyes) cannot be triggered voluntarily and that is what separates a real from a fake smile. Dr. Ekman’s research concurs with Duchenne’s and although recent research indicates some can train themselves to think about triggering that muscle, more often than not a fake smile is all about the eyes. A real smile is broad with narrow eyes, raised cheeks, and pulled-up lower eyelids. It has been said that a real smile involves the whole face, from the eyes to the mouth, as seen in Figure 5-14 . Figure 5-14: Dr. Ekman demonstrates a fake smile (left) next to a real smile (right). If you were to cover the top half of Dr. Ekman’s face you would be hard pressed to tell a real from a fake smile. It is not until you examine the eyes that it becomes clear, side by side, which smile is fake and which is real. When a person sees a real smile on another person, it can trigger that same emotion inside of them and cause them to smile. Notice in Figure 5-15 the picture of the two monks. The monk on the left side of the picture is displaying very outward signs of a real smile, real happiness. Just looking at him in this picture probably can trigger happiness in you. From a social engineering standpoint, knowing how to detect and also create a real smile is a valuable piece of information. A social engineer wants a target to be put at ease, so as to have the greatest positive effect on the target. Social engineers in any form, whether they are salespeople, teachers, psychologists, or any other social engineer, often start off a conversation with a smile. Quickly our brains analyze how we feel about that visual input given to us and it can affect the rest of the interaction. A lot of information is packed into the preceding section, yet you may be wondering how social engineers can train themselves not only to see microexpressions but also how to use them. Figure 5-15: His whole face is involved in his smile. Training Yourself to See Microexpressions Hollywood often overstates the abilities of the characters that appear in movies and television. For example, in the new hit television show Lie To Me (based on Dr. Ekman’s research) the main character, Dr. Lightman, can read microexpressions with seemingly no effort, and what is even more amazing is he usually can tell why the emotion is occurring. Yet in real life, much of the research done by those in the field, like Dr. Ekman, meant sitting in front of prerecorded sessions and analyzing these sessions frame by frame. After many years of working on this task he is probably able to notice, pick up, and analyze microexpressions very quickly. In the 1970s he did a research project where he identified some who had a natural ability to notice and correctly analyze microexpressions. Because many of us might not fall into that natural ability category we need a way to practice, train, and become proficient at performing, reading, and using microexpressions. I can tell you what works for me. I read the methods on how a particular microexpression is identified, then practice reproducing it using a mirror, comparing my expression to the notes from the professionals that describe how it is done. I usually have a picture that shows the emotion I am working on because having something to mimic helps me. After I feel relatively good about reproducing the microexpression I focus on how it makes me feel, tweaking small areas until the muscular movements cause me to feel the matching emotions. I then scour the Internet looking for pictures and try to identify the expressions in those pictures. Next, I record news or television shows and play certain parts in slow motion with the sound off to see if can determine the emotion, then listen to the story to see if I was close. All this leads up to working with live “subjects.” I watch people interact with each other and try to identify the emotions they are feeling during their discussions. I try both with being able to hear the conversation and also without being able to. The reason I chose this path before trying to read microexpressions in my own conversations is that I found that trying to do it in a live environment without having to also focus on making good conversation is easier. I just read the facial expressions and do not get confused by other sensory input. The preceding method is the one I used before I had a chance to meet Dr. Ekman and be introduced to his training methods. Of course, he has books that contain step-by-step instructions on recreating and reading these expressions. His books also include pictures showing the emotions as well as examples in the news that show those emotions. His book Emotions Revealed does this in a very professional format that is excellent for learning. In recent years Dr. Ekman has developed and released training specifically for microexpressions. His website, www.paulekman.com , has three different types of training that have changed the way people can learn this powerful science. Ekman’s training gives the user a lesson on each type of microexpression via video and text. The user can replay the expression video to see how each part of the face is involved. After the user spends as much time as needed learning and watching the video sections, she can take a pretest. The pretest enables her to see how good she is at noticing microexpressions. When the user guesses at what microexpression is being displayed, she can get confirmation or correction. If correction is needed then she can take additional education and training. After the user is confident in her abilities she can take the real test. In the final exam no correction is given. The user is shown a microexpression once for a brief one twenty-fifth of a second, and then she must select what the microexpression is and then wait to be graded at the end. This type of training tool can take years off of your learning curve in becoming proficient at reading microexpressions. One caveat: Dr. Ekman, as well as his contemporaries, state that even though you may become proficient in reading microexpressions, a microexpression is limited. What does that mean? One of the tricks actors use to be able to successfully show proper emotion is to remember and focus on a time when they truly felt the emotion they need to portray; for example, a moment of happiness that produced a real smile. As mentioned earlier, making a real smile is very difficult to fake if you aren’t truly feeling happy, but if you can bring up a memory when you felt that emotion your muscles will remember and react. Therefore, although you can become proficient at reading the emotion, you cannot read the why behind it. The why is often lost to science. I had a friend who had some bad experiences as a child with a person who closely resembled a good friend of mine. Whenever my friend would come around she had strong emotional reactions. If you were to read her microexpression you would probably see fear, contempt, and then anger on her face. She did not hate my friend, but she hated the person in her memory who resembled my friend. This is a good point to remember when you are learning how to read microexpressions. The expression is linked to an emotion, but the expression doesn’t tell you why the emotion is being displayed. I know when I first started learning about microexpressions and then became somewhat “proficient” at reading certain expressions, I felt like I was a mind reader. Although this is far from the truth, the caution is to not be assumptive. You may become very good at reading microexpressions; however, later sections discuss how to combine this skill with interrogation tactics, body language skills, and elicitation skills to not only figure out what targets are thinking, but also to lead them down the path you want. The question you still may have is, “How can I use these skills as a social engineer?” How Social Engineers Use Microexpressions This whole section leads up to this: As fascinating as the research is, as amazing as the science is behind this psychology, how do you utilize microexpressions in a social engineer audit and how do malicious social engineers use them? This section discusses two methods of how to use microexpressions in social engineering. The first method is using microexpressions (ME) to elicit or cause an emotion, and the second method is how to detect deceit. Let me start with the first method, using your own ME to cause an emotional response in others. I recently read a research paper that changed my view of ME and opened my eyes to a new area of research. Researchers Wen Li, Richard E. Zinbarg, Stephan G. Boehm, and Ken A. Paller performed a study called “Neural and Behavioral Evidence for Affective Priming from Unconsciously Perceived Emotional Facial Expressions and the Influence of Trait Anxiety” that changes the face of microexpression usage in modern science. The researchers connected dozens of mini-EKGs to muscle points on their subjects’ faces. The devices would register any muscular movements in their face and head. They then played videos for them that had one-twenty-fifth-second flashes of microexpressions in frames. Li et al., found that in almost every case the subject’s muscular movement would begin to mirror that which was embedded in the video. If it was fear or sadness, the subject’s facial muscles would register those emotions. When interviewed about the emotion the subject was feeling it was the emotion embedded in the video. To me, this groundbreaking research proves that a person can manipulate another person to a certain emotional state by displaying subtle hints of that emotion. I have started conducting some research into this from a security angle and I am calling it “neurolinguistic hacking,” mainly because it takes much from microexpressions as well as neurolinguistic programming (discussed in the next section) and combines them to create these emotional states within a target. Imagine this scenario. A social engineer wants to walk into a company with the goal of getting the receptionist to insert a malicious USB key into the computer. His pretext is that he has a meeting with the HR manager, but on the way in, he spilled coffee all over his last resume. He really needs this job and to help, would she print him out another copy of the resume? This is a solid pretext that tugs on the receptionist’s heartstrings and has worked for me in the past. Yet, if the social engineer allows his own emotional state to run rampant he might be showing signs of fear, which is linked to nervousness. That fear can translate to an uneasy feeling in the receptionist and failure or rejection of the request. Whereas if he were to control his emotions and flash subtle hints of sad microexpressions, which is closely linked with empathy, then he might have a very good chance at his request being honored. Recall the previous discussion of the commercials that encourage people to donate “only a dollar a day” to feed a child in need. Before requesting money, before flashing a phone number and URL, before telling you that credit cards are accepted, many long images of very sad children flash across your TV screen. Those images of children in need and children in pain put your brain in the emotional state that is needed to comply with the request. Do those commercials work on everyone? No, of course not. But although not everyone donates, it will affect almost everyone’s emotional state. That is how a social engineer can use ME to the fullest. Learning to exhibit the subtle hints of these ME can cause the neurons in your target’s brain to mirror the emotional state they feel you are displaying, making your target more willing to comply with your request. This usage of ME can be malicious, so I want to take a moment to talk about a mitigation (see also Chapter 9). Being aware of how ME can be used doesn’t mean you need to start training everyone in your company to be an ME expert. What it does mean is that good security awareness training does need to occur. Even when requests are designed to make you desire to help, desire to save, desire to nurture, the security policy must take precedence. A simple, “I’m sorry we cannot insert foreign USB keys into our computers. But two miles down the road is a FedEx Kinko’s shop. You can print another resume there. Should I tell Mrs. Smith you will be a few minutes late?” In this scenario, such a statement would have squashed the social engineer’s plans as well as given the target the feeling of being helpful. To utilize the power of ME, sometimes you have to combine it with other aspects of human behavior as well. The second method, how to detect deceit, describes how you can do this. The second method for using ME as a social engineer is in detecting deception. Wouldn’t it be nice if you could ask a question and know whether the response was truth or not? This subject has been a source of heated debate among many professionals who claim that eye patterns, body language, facial expression, or a combination of all the preceding can indicate truth or deception. While some do not believe this to be the case, others feel these can be used as an exact science. Although some truth may exist in each of those thoughts, how can you use microexpressions to detect deception? To answer this question you must take into account more than just microexpressions because, as identified throughout this section, microexpressions are based on emotions and reactions to emotions. Keep this in mind while reading this section, which analyzes some causes and effects. Four things can help you detect deceit in a target: Contradictions Hesitation Changes in behavior Hand gestures The following sections discuss these items in more detail. Contradictions Contradictions are particularly tricky because they often can and do occur in factual accounts. I know in my case I often forget details, and my wife will fill them in quickly. After I get a little hint here or there I often can remember the full story. This doesn’t mean that I am always lying at the beginning of a story or conversation, but I don’t always remember all the details clearly enough to comment on them at first, or I think I do remember the details but I really don’t. Even after I “remember” the details, the details may be my version of reality and not the way the story actually happened. This inadvertent dishonesty is important to consider when evaluating contradictions as a clue to lying. What a contradiction should do is prompt you to dig more. Watching the person’s microexpressions while you question him about a contradiction is also helpful. For example, suppose you have developed a pretext as a visiting salesperson. You are going to try to gain physical access to the CEO to deliver a CD with a special offer. You know the CEO is very partial to a certain charity so you developed the pretext around that. As you walk into the lobby the front desk person says, “Sorry, he is not in, you can just leave it with me.” You know that if you leave the CD a greater chance exists that your “malicious” CD will never be used. You also feel he is in because you see his car in the parking lot and you know today was a normal work day for him. With those facts in mind and without wanting to embarrass the front desk person you say, “Oh, he’s really not? I called the other day and asked when I could visit and was told today was a good day. Did I mix up my days?” If you’ve played your cards right and your expressions are genuine, this can turn out two ways: She may hold steady and again say, “Sorry, he’s not in.” She may contradict herself (which can be a clue that she is not being truthful): “Let me check whether he is in or not.” What? She went from a stern “He is not in” to “Let me check.” That contradiction is enough to signal that you should dig more. What was her ME when she did that? Did she show shame or maybe some sadness at lying? Was she angry at being caught in a lie? Was she embarrassed that she was wrong and maybe confused? You cannot automatically assume she is lying, because maybe she really didn’t know, and when you rebutted she decided to really find out. After she confirms whether he is in you can choose to dig a little deeper and probe more to determine truthfulness if needed. Again, playing your card of “Maybe I mixed up my days” and watching her facial expressions can be a good indicator of her truthfulness or not. If in your first go-round you saw any hints of anger, continuing to enquire can cause her to be more angry and embarrassed and end your interaction. At this point, you may want to ask something like, “If Mr. Smith isn’t in right now and I really mixed up my days or times, when can I stop in to see him? What time is the best?” This type of question allows her to save face, as well as gives you another opportunity to read some facial expressions. If you didn’t notice anger but maybe saw she looked a little sad or embarrassed then you might want to respond with empathy and understanding to open her up. “I could have sworn that he said today was a good time to drop it off, but you know, my memory is so bad, my wife tells me I am getting Alzheimer’s. I bought one of these smart phones, but I’ll be darned if I can figure it out. I don’t want to be a bother, but when can I just drop this off for him? I want to make sure it gets right into his hands.” Be very observant of minor contradictions as they can be key indicators in deceit and help you get your foot in the door. Hesitation Similarly to contradiction, you can use someone’s hesitation to detect a potential untruth. If you ask a question and the answer should have come quickly from the person, but he hesitates beforehand, it can be an indication that he was using the time to fabricate an answer. For example, when my wife asks me how much my new electronic gadget costs, she knows I know the answer. A hesitation can mean either I am evaluating whether I want to answer truthfully or I might just be remembering the price. When I get a progress report from my son’s school that says he missed X number of days at school and I only know about two or three valid absences, I ask him where the rest of these missed days are from. If his answer was, “Dad, don’t you remember I had that doctor appointment and then you kept me home that day to help you with that project?” Most likely that is full-on truth because it was quick and has facts in the response. However, if he hesitates and comes back with, “Wow, I don’t know—maybe the report is wrong,” then noting his microexpression during his response is a good idea. Does it indicate anger, maybe at being caught, or sadness at the imagined punishment? Either way, it is time for me to investigate more and find out where he was those days. Another thing to look out for is a well-known hesitation tactic of repeating the question back to you as if asking for verification that the question is correct. Doing so allows for time to fabricate a response. The use of hesitation to detect deception is not an exact science, but it can be a good indicator. Some people just think before they speak. I am from New York, so I speak fast. If someone speaks slower than me it is not an indication of deceit. You must be able to use the ME to determine if someone is just slow at speaking or trying to fabricate a response. If the emotion does not match the question asked then it might be worth looking into. Changes in Behavior During a discussion the target may change his behavior every time a certain topic is brought up. Maybe you notice an expression change or a shift in the way he sits, or a marked hesitation. All of these actions can indicate deceit. Whether these actions amount to deceit is not certain, but they should cause you to probe more on the topics being discussed in a way that does not alert suspicion. These behaviors can be signs that the person is using the time delays to generate a story, recall facts, or decide whether he wants to reveal those facts. Hand Gestures People often paint pictures with their hands using gestures. For example, someone may use his hands to show how big something is, how fast something was going, or to show how many times something was said. Many professionals feel that when someone is being untruthful he will touch or rub his face often. Some psychological connection exists between rubbing the face and generating a fabrication. Some of the cues used by psychologists and body language experts to detect deceit are discussed here: www.examiner.com/mental-health-in-new-orleans/detecting-deception-using-body-language-and-verbal-cues-to-detect-lies . Taking note of a change in the size, frequency, or duration of hand gestures during a conversation is important. In addition, you should watch facial expressions during gestures that can raise a flag in your mind. When you detect deceit, having a plan for how to respond is important and a good idea. In the earlier scenario with the front desk person and her “out-of-the-office” boss, calling her out on her lie would most likely have raised all sorts of red flags, embarrassing her, and ruining any chances of success. If your pretext is someone with authority, like a manager or department supervisor, and you catch someone in a lie you can then use that to your advantage. By “forgiving” the person you are now owed a favor in return. But in the same scenario, if the position you are in is lower (someone in a non-management position such as a secretary, receptionist, or sales position) than the target, playing that card can be dangerous. The authority action would not fit the pretext of someone in a non-management position. What it boils down to simply is that as a social engineer auditor you must learn to use a person’s microexpressions to determine whether he is presenting the truth or a lie and to determine whether you are affecting the target the way you want. In some cases you can even use certain expressions to manipulate the target into a certain state of mind. Remember, microexpressions alone are not enough to determine why an emotion is occurring. Determining that someone is angry or sad, for instance, doesn’t tell you why that person is angry or sad. Be cautious when using microexpressions to take into consideration all factors to determine, as closely as possible, the reason for the emotion. Malicious social engineers employ these tactics of using microexpressions discussed in this section but their goals are completely different from those of a social engineer doing an audit. They often don’t care about the residual effect on the target. If damaging a person’s belief system, psychological stability, or even job stability can lead the malicious social engineer to a payday he will take that path. Earlier in this book you read about some scams that came up during the attacks in New York City after 9/11. People who saw an opportunity to cash in on people’s sympathy and the tragedy that occurred didn’t seem to care whether their actions hurt others. Many came out of the shadows claiming to have family who were lost in those attacks. Some of these malicious people received money, gifts, sympathy, and even media attention only for it to be discovered down the road that the stories were all false accounts. The malicious social engineer spends a lot of time learning about people and what makes them tick. This knowledge makes locating an acceptable target to attack easier. This section just scratched the surface of microexpressions; the work of many professionals in the field has filled volumes. Seek out training, become proficient in reading and using microexpressions, and you will see an increase in your communication abilities with others. In addition, this proficiency will enhance your ability to have success in your audits. Neurolinguistic Programming (NLP) Neurolinguistic programming (NLP) studies the structure of how humans think and experience the world. It is very controversial in itself because the structure of NLP does not lend itself to precise, statistical formulas. Many scientists will argue or debate the principles of NLP due to this fact, but the structure does lead to models of how the principles work. From these models, techniques for quickly and effectively changing thoughts, behaviors, and beliefs that limit people have been developed. As stated in Wikipedia (source: Oxford English Dictionary ), neurolinguistic programming is “a model of interpersonal communication chiefly concerned with the relationship between successful patterns of behavior and the subjective experiences (esp. patterns of thought) underlying them,” and “a system of alternative therapy based on this which seeks to educate people in self-awareness and effective communication, and to change their patterns of mental and emotional behavior.” This book is far from a self-help book, so although the principles in it can assist in changing deep-seated thought patterns and habits in yourself, its focus is on how you can use NLP to understand and then manipulate those around you. If you are unfamiliar with NLP your first instinct may be to run to a computer and type the term into Google. I want to ask you not to do that just yet. You will find that similar to social engineering, what you will often find first are many videos and demonstrations that just seem very unrealistic, such as videos of someone touching another person’s shoulder and changing that person’s brain patterns to think brown is white or somesuch. These videos make out NLP to be some form of mysticism, and for those who are leery of these things, these types of videos discredit it. Instead the following sections break NLP down into a few parts. Up next is a very brief history of NLP, which can help you to understand that its roots are not with street magicians; instead, it has deep psychological roots. The History of Neurolinguistic Programming Neurolinguistic programming (NLP) was developed in the 1970s by Richard Bandler and John Grinder with the guidance of Gregory Bateson. Its roots came from Bandler and Grinder’s research into some of the most successful therapists of their time. From this initial research they developed the “code” concepts of NLP. This early research led to the development of a meta-model, which recognizes the use of language patterns to influence change. Both Bandler and Grinder were students at the University of California and used the principles of their research to develop a therapy model called the meta-model. After writing a few books based on this model they began to refine the core principles that would become what we call NLP today. This included things like anchoring, swish pattern, reframing, belief change, nesting loops, chaining states, and submodalities applications. After graduating with degrees in psychology, Bandler and Grinder began hosting seminars and practice groups, which served as places for them to practice and test their newly discovered patterns while allowing them to transfer the skills to the participants. During this period, a creative group of students and psychotherapists who formed around Grinder and Bandler made valuable contributions to NLP, helping refine NLP even more. In the recent years, NLP became the new buzzword again for managers, driving rapid growth of trainers, classes, and experts. Without any regulating body, the field grew as everybody wanted to learn to control others, lie without getting caught, or solve all their psychological problems. Practitioners were not licensed, so each group taught its own form and concept of NLP and issued its own certification as experts. All of this is what led to NLP being viewed somewhat unfavorably. Despite its rocky history, the core foundation of NLP can enhance your abilities as a social engineer. The next section discusses some of the core codes of NLP so you can analyze them more deeply. Codes of Neurolinguistic Programming In the early 1970s NLP had a code comprised of the collective body of learning and investigation that generated the first books and the term neurolinguistic programming . As time went on John Grinder and others have continued to contribute to the field of NLP. The “new code of NLP” is an ethical and aesthetic framework for NLP development. New Code of NLP NLP’s original ideas were born in the 1970s. As time passed, John Grinder began to realize that much of the old code must change to be brought into modern times. He began working with Gregory Bateson and Judith DeLozier and produced the “new code” that focused more on what the person thinks or believes will happen and changing that belief. Learning techniques for expanding your perceptions, overcoming old thought patterns, and changing habits all help in self-change. The new code focuses on the key concepts of states , conscious/unconscious relationships , and perceptual filters , all of these pointing to states of your mind and your perception of those mental states. These new concepts are meant to move NLP forward and help practitioners think about it in new ways. Many of the basic tenets from the new code are being taught now as part of the standard NLP courseware. This new code is best understood by reading Turtles All the Way Down by Grinder and DeLozier. It’s compiled from their seminar “Prerequisites to Personal Genius.” In essence, the new code states that to make a change the client must involve their unconscious mind, the new behavior must satisfy their original positive intention, and the change must occur internally at the state of mind rather than at the behavioral level. This new code suggests how NLP can create serious and drastic changes to a person’s thinking. This is a key concept for social engineers because, as you investigate and analyze the new code, you will begin to see how it can be used to manipulate others. Before doing that, though, you need to understand the scripts that the new code uses. Scripts in the New Code People tend to have common problems, so groups of scripts have been developed to help therapists use NLP in their practice. These scripts lead the participant through a series of thoughts that help guide the person to the desired end. Several good books on NLP scripts exist, with The Big Book of NLP Techniques: 200+ Patterns & Strategies of Neuro Linguistic Programming being highly recommended. An example of one script is an outline of how to increase your sales by getting someone to start talking about their dreams. Once you have them talking about certain goals or aspirations, you can posit your product or service as answering one of the needs to reach those goals. By positively building on your product as fitting a need they have, you give your potential sale’s brain a way to connect your product with positive sales. If you take time to Google much of the information included here you will see that NLP can take on a life of its own. You can take many angles and paths when studying NLP. Despite all the plethora of information out there the question remains, how can a social engineer use NLP? How to Use NLP as a Social Engineer Many of the scripts and principles of NLP tend to lean toward hypnosis and similar avenues. Even though you will not use hypnosis to social engineer a target, you can use many of the principles of NLP as a social engineer. For example, NLP can teach you how to use your voice, language, and choice of words to guide people down the path you want. Voice in NLP You can use your voice to inject commands into people just as you would use code to inject commands into a SQL database. The way you say things is where the injection occurs; this single moment of injection is framed within regular conversation. Sometimes how you say something is more important than what you say. NLP promotes the use of embedded commands to influence a target to think a certain way or take a certain action. Also, using the tones of your voice to emphasize certain words in a sentence can cause a person’s unconscious mind to focus on those words. For example: For instance, ask “Don’t you agree?” Instead of putting an upswing on the word “agree,” like you would normally at the end of a question, put a downswing to make the question more of a command. Another one I have heard used effectively is, “My customers usually do the things I say. Do you want to begin?” The way that sentence is used and surrounded by other statements can make this a very commanding statement. More on this in the next section, but this skill alone can change the way you interact with others; the principles for it are steeped in NLP. Sentence Structure In English, the sound of the person’s voice at the end of sentence indicates whether what is being said is a question, statement, or command. A person’s voice goes up at the end of a sentence for questions. The voice stays the same through the end of the sentence in statements, and the voice lowers at the sentence close for commands. For the next few paragraphs, the bold font denotes to lower (deepen) your voice tone. Try this exercise: When you ask a question such as, “Is that your dog?” your voice will rise at the end of that sentence. Yet you can embed subtle commands into sentences by just changing them to a downward point during the sentence, not at the end. Here are a few simple commands for you to practice. Notice how they have the command injected inside the sentence. “Remember how clean your room looked last Christmas?” The embedded command is “clean your room,” which includes a time shift to a happier time. This is an example of a pleasant, painless injection. “ Buy now , you can see the benefits !” This one starts with the voice low, then up to a normal tone, then back down for benefits . “The higher my company goes in consulting, the more nice people like you we encounter.” Implanting the higher my company with a pleasant comment has just increased your chance of being hired, partly because of the play on words ( Higher sounds like hire —thus what the listener hears is hire my company ). From a social engineering standpoint you can form sentences when performing an audit over the phone to maximize the potential for success, such as: “This is Larry from tech support; we are giving all reps new passwords. Your new password is…” The following are tips for using your voice in successful social engineering: Practice. You have to practice speaking in this manner so you don’t sound like a teenage boy entering puberty. Your rising and falling tones can’t sound canned; they must be subtle. Have careful sentence structure. Develop sentences that maximize your ability to accomplish your tasks. Don’t go for the kill, so to speak. A command like “give me access to your server room now” is probably not going to work, but you can use these voice techniques to help a target be more open to the idea. Be realistic. Don’t expect to speak and have people falling at your feet to do what you ask. These techniques can put your target in a frame of mind that will make getting what you want easier. One technique, Ultimate Voice, if mastered, does have very powerful effects. I once interviewed an NLP practitioner on a podcast who had this gift. When he spoke it was as if you could not argue with him. He spoke with such control and technique that disagreement never even entered my mind. How can one master this technique? Using Ultimate Voice in Social Engineering You can master the Ultimate Voice but it takes lots of practice. The ability to embed commands into normal conversation is a skill that is very useful when mastered. Ultimate voice is the ability to inject commands into people’s minds without their knowledge. It can sound very artificial when new people try it, until enough practice makes them sound natural. Hypnotists often use this technique like so: “You can feel yourself relaxing as you slip into calmness .” This standard therapy phrase can be adapted to nearly any command you like. Put extra emphasis on the vowels in the words you want to accent—for example, “yooouurseeelf reelaaxiing.” Planet NLP ( www.planetnlp.com/ ) offers three exercises that you can use to work on mastering this technique. 1. Move your voice around. Press your hand on your nose and say “nose.” Concentrate on your nose as you repeat the word until you can feel your nose vibrating. Now do the same exercise with your hand on your throat, saying “throat.” Do the same on your chest, saying “chest.” Keep practicing until you can really feel the vibration in each place. Notice how different each one sounds. 2. Use your range. Starting from a high note, say “ar” (as in the letter r ). Keeping your mouth open, allow the note to drop down until your breath runs out. Repeat this exercise ten times. Then, starting from a low note, say “ou” (as in you without the y ), allowing the note to rise until you cannot support the sound. Repeat this exercise ten times. 3. Resonate. To use your voice correctly, it must resonate in the mask , which is the facial area surrounding the nose and mouth. There are two ways to practice resonating: Hum at whatever pitch is most comfortable for you. After you have found your pitch then hum “umm” followed immediately by the word “ready.” Do this a few times, then try the words “now,” “one,” “two,” and “three.” Hum and then allow your lips to vibrate. You are attempting to sound like a dove. Allow the pitch to rise and fall. This is very difficult if you have any tension in the jaw or face. Done correctly for a few minutes, your face will start to feel numb. After a couple of minutes using these methods, you should notice that your voice sounds crisper. If you find it hard to notice, record yourself and listen back to see how it sounds to you. The best way to improve is to spend about five minutes a day going through these exercises. Practice can help you to learn to control this vocal technique. For example, I am generally a loud person. It seems like I don’t have the ability to whisper. For me to control my tones, pitch, and volume, I need practice. Doing simple voice exercises like these can help you to control these voice characteristics. When you speak a sentence in which you want to include a hidden command, and you want to lower your tone, being so subtle that the target doesn’t realize it is imperative. Otherwise, you will alert that person’s subconscious to trigger that something is amiss. If that occurs he may pick up on your attempts thereby shutting down your success. Like most things in social engineering, if a technique doesn’t come naturally, practice is essential. Try this voice technique on your family and friends before you ever attempt it in an audit. From personal experience, when I first started working on the Ultimate Voice techniques I decided my goal was to embed commands into questions. This goal took a while to realize but I would try simplistic things like: “Honey, what do you want to eat for dinner tonight, steak or something else?” To conclude this section, consider three things a social engineer should focus on when studying NLP: Vocal tones. As stated previously, the tones of your voice as well as the emphasis you put on certain words can change the whole meaning of a sentence. Using tone and emphasis, you can embed commands inside of the subconscious mind of the target and allow the target to be more open to suggestion. Chose your words carefully. Learn to choose the words that have maximum impact. Match positive words with thoughts you want the target to think positively on and negative words with those you want them to not think of too highly. This technique can also help the social engineer make a target more pliable. Create a list of command sentences that you can use in person or during a phone social engineering audit. Writing out and practicing command sentences will help you be able to recall and use them when in need. Most of all, practice. Controlling your vocal tones, the words you choose, and how you say them is not an easy task. Practice can make this become second nature. NLP is a powerful topic, and, much like microexpressions, this section only scratched the surface. Once you start to master the techniques in NLP and the ability to read facial expressions, a next logical step is using these tools when interacting with a target. Next, this chapter analyzes the same tactics professional interrogators use. Interview and Interrogation Scenario 1: The door flies open and the perpetrator is noticeably nervous. Captain Bad-Mood comes over and grabs the perp by the collar and slams him up against the wall. Getting about an inch from his face he screams, “You’ll tell me what I want to know, one way or another!” Scenario 2: The bad guy is tied to a chair, already bruised from the previous 30 minutes of beatings, and as the interrogator grabs a pair of shiny pliers he says, “You’ll be talking in no time….” Scenario 3: The perp is sitting in a chair and two police officers enter the room. Calmly they walk over to the table and set a file labeled “Evidence” down on the table. Before they sit down they ask, “Do you need a coffee or a soda or something?” Cracking open an ice-cold soda the first officer says, “Thanks for coming in today to help us out….” Which one of the preceding scenarios is a real-life interrogation? If you guessed the third one, you’re right. It is how a real interrogation often goes. The first two have been portrayed in Hollywood movies and television series so much that many of us might think they are real. Outside of wartime scenarios and nations that do not ban the use of torture, the third scenario is most likely the way most interrogations begin. Rarely will you as a social engineer be in a situation where your target is waiting in a room for you to question him. With that in mind, you might ask, how can you use the tactics of professional interrogators and interviewers as a social engineer? Before going further you should know the differences between an interrogation and an interview. The following table presents some of these differences, but this topic has many different angles, viewpoints, and opinions, so more could exist. Interview Interrogation Subject talks, you listen. You talk to subject about his statements. Subject leads direction of conversation; you clarify his statements and listen, then apply NLP skills. You lead direction. Apply NLP skills here. Non-accusatory. Accusatory. Soft in nature. Hard in nature. Subject’s location, subject at ease. Interrogation room, subject is tense. You gather information (who, what, when, where, why, and how). If you reveal certain information, you can learn details. Early in investigation. Final questioning session. The main difference between an interview and interrogation is that an interview is in an atmosphere where the target is comfortable both physically and psychologically, whereas in an interrogation the goal is to put some pressure on the target by creating discomfort with the location or the questions asked, with the goal of gaining a confession or some knowledge the target possesses. Good interrogation is an art that you can master through experience. Many social engineering skills tie into to being a good interrogator. Skills like elicitation (see Chapter 3); reading people, faces, and gestures; and having insight into human behavior can all help you become a legendary interrogator. Interviewing is a great skill to have, but as long as you can master the use of elicitation you can become great at conducting interviews. Interrogation principles are used widely by successful social engineers. Putting a target in some psychological or physical discomfort to make gathering information from them easier is a skill most social engineers will spend a considerable time obtaining. Professional Interrogation Tactics Before conducting any interview or interrogation, the social engineer will need to have done thorough information gathering. You must obtain as much information about the target, the company, the situation, and details of each as possible. You must know how to approach a target and what to say, and have in mind the path you will take with the target. Be careful to observe your surroundings as well as any changes in the target during the conversation and initial approach. One of the mistakes people new to interviewing and interrogation make is assuming every behavioral change has major meaning. A target’s crossing her arms doesn’t just mean a closed thought; she could also be cold, have underarm stink, or feel increased stress because of your questions. Watch not for only one sign; watch for groups of signs. For example, a target crosses her arms, turns her head, and places her feet flat on the floor. This is a closed person; in other words, her body language indicates that she will divulge no more information or cooperate any longer—this door has been shut. A group of changes is the most important thing to watch for, so note the topic that was being discussed when the group of changes occurred. When starting an interview or interrogation here are areas to observe for changes in the subject: Body posture: Upright, slumped, leaning away Skin color: Pale, red, white, changes Head position: Upright, tilted, forward/back Eyes: Direction, openness Hands/feet: Movement, position, color Mouth/lips: Position, color, turned up/down Primary sense: Visual, aural, kinetic, feeling Voice: Pitch, rate, changes Words: Short, long, number of syllables, dysfunctions, pauses Changes can indicate a question or line of questioning that needs more attention. For example, if the body posture is very relaxed when you ask, “Is Mr. CEO in? I would like to leave this information packet for his review,” and then the body posture changes to a defensive posture—the torso pointing away and the eyes averting from looking at you—it may be a good indication that there is some untruth coming up and further questioning might reveal the truth on this topic. Especially be sure to pay attention to the words a target uses. During the interview or interrogation process, pay particular attention to the subject’s voice and how she answers questions. When you ask a question, how long does it take for her to answer? Blurting out answers quickly is believed to be a sign of practicing the answer. If she takes too long, maybe she was thinking up the answer. Response time depends on each person, though, because you have to determine what is “natural” for each person. Determining what is natural in a target (that is, the baseline ) is not a small matter in a social engineering gig and must be done very fast. Being very observant is the key to success with this skill. One method of creating a baseline involves asking questions that cause the suspect to access different parts of his brain. The interrogator asks nonthreatening questions that require simple memory and questions that require creative thinking. Then look for outward manifestation of his brain activating the memory center, such as microexpressions or body language cues. Another area to listen for is changes in verb tense and pronoun use. These shifts from past tense to future tense show areas you might want to investigate further. Switching tense can indicate deception. When a target switches tense they may be fabricating an answer or thinking of a past statement to fabricate an answer. Further questioning can reveal the truth here also. Other areas of change you should listen to are the pitch of the voice (is it going up with stress?) and the speed of speaking. You don’t have to learn how to do all this at the same time. The more practice you get actively listening and observing people the easier it becomes for you to do it without thinking. Professional interrogation is comprised of a number of parts. The following sections discuss each one, in the context of how it pertains to a social engineer. Positive Confrontation In law enforcement positive confrontation doesn’t mean anything positive and good; on the contrary, it means the officer is telling the suspect he is the one who committed the crime; in other words, the officer is making a strong accusation. In a social engineering audit, though, you already have identified the “target” you want and now you are going to tell (maybe using the NLP tactics previously mentioned) that target that he will do what you are asking of him. You confront the target with the objective of starting him on the path to doing what you want. For example, a social engineer may approach the receptionist and ask, “Is Mr. CEO in? I have a meeting with him.” Or, to use a positive-confrontation angle, “I am here for my meeting with Mr. CEO at 11 am.” Notice the second example positively states the meeting as being set, expected, and in such a way that you are sure it is happening. Theme Development Theme development in police interrogations is when the interrogator develops a story to postulate why the suspect may have committed a crime. Many times that story is relayed to the suspect during the interrogation. “So he insulted you and you got so mad, you grabbed the pipe and began hitting his windshield with it.” While the officer is telling the story, he or his partner is watching the body language and microexpressions of the suspect to see if there are any clues that would constitute agreement. Although social engineers can use this method, I also like to state that from a social engineering viewpoint, theme development needs to be seeing your pretext from the eyes of the target. What would a “tech support rep,” “manager,” or “fellow employee” look like, say, and do? How would he act? Theme development for social engineers is when your supporting evidence that is displayed feeds directly into the theme of who you are portraying. Your approach to a target, whether on the phone or in person, often involves a pretext of some sort. The pretext, of course, supports your storyline or theme. This part of the interrogation is where you offer reasons or support for the pretext (see Chapter 4 for a refresher on pretexting). For example, in one audit my pretext was very simple—I was just an employee who belonged. Armed with a trade publication I found in the trash, I followed a few employees through the door and past the security guard. As we approached the security guard I began a very simple conversation with one of the employees about an article in the journal. All of my actions contributed to theme development. Your goal is to give the people who would normally stop you justification for not doing their job. The more you fit in, the less you stand out, and the easier it is for security guards and the like to justify not stopping you and letting you in. Handling Denials and Overcoming Objections Whether on the phone or in person, what is the plan of action if you are denied access to the place or information you are seeking? I like to call these conversation stoppers. People use them with salespeople all the time, “I’m not interested.” “I don’t have time right now.” “I was just leaving….” Whatever flavor of stopper targets throw out, you must have a plan to overcome it and handle the denial of access. I like to preemptively dismiss objections if I feel the situation warrants. When I was in sales, I worked with a man named Tony who had a tactic that involved knocking on a door and introducing himself, and without pausing saying, “I know you might want to say you are not interested, but before you do, can you answer this one question: Is five minutes of your time worth $500?” At this point, the person was much less likely say, “I’m not interested.” By diminishing the possibility of denial and following up with a question, Tony was able to get the target to think about something else besides her objection. In a social engineering engagement you can’t walk up to the security guard and say, “I know you don’t want to let strange people in the door but…” because it would raise way too much suspicion. Using this methodology to overcome objections is much more complex for social engineers. You have to think about what objections might arise and organize your theme, story, dress, and person to pre-empt those objections. Yet you still have to have a good answer to give for when objections come up. You can’t just run out the door or hang up the phone. A good exit strategy enables you to come back to attack later on. An exit strategy can be as simple as, “Well, ma’am, I’m sorry you won’t let me in to see Mr. Smith. I know he will be greatly disappointed because he was expecting me, but I will give him a call later and set up another appointment.” Keeping the Target’s Attention If you handled your social engineering move correctly up to this point and you are in front of the target, then the target may start to think about what would happen if she does not allow access, take the file, or do what you are asking. You need to feed off of that inherent fear and use it to continue to move the target to your goal. A few short statements like, “Thank you for your help. I was so nervous about this interview that I obviously put the wrong date down in the calendar. I hope that Mrs. HR Manager is some place warmer than here?” Allow for a response then continue, “I want to thank you for your help. When will she be back so I can call to make another appointment?” Presenting an Alternate Route When you are interrogating the target in a social engineering audit, the possibility exists that your first path will not be greeted with smiles, so having a lesser but just as effective path of action ready is a good idea. Maybe you have used all these tactics to try to get Sally, the receptionist, to let you in to see Mr. Smith. The tactics are all failing and you are being shut down. You should have an alternative path prepared, such as, “Sally, I appreciate you have to make sure things are done by appointment only. I am just not sure when I will be back through the area. Can I leave you with this CD of information for Mr. Smith and then I can follow up with a phone call tomorrow to see whether he will set up an appointment?” Having a few CDs prepared with some maliciously encoded PDFs can help to make this path a reality, as well as having practiced and then using interrogation tactics quickly. A contact I have sent me a document, entitled “Interview and Interrogation,” that is used by the Department of Defense to train its staff in passing the polygraph. It outlines the different approaches that professional interrogators use, and I have provided them here. Looking at these different approaches one can learn a lot about different methods that might make sense for a social engineer. Direct approach: The interrogator assumes an air of confidence in this approach. The attitude and manner of the interrogator rules out that the suspect is innocent at all. Without threatening, the interrogator disarms the suspect by telling him anyone else would have done the same thing. As a social engineer, you can utilize this approach depending on your pretext. Maybe you are management, a consultant, or another person who has power over the target. This means you must have an air of confidence and assume that the target “owes” you the response you seek. Indirect approach: The suspect is allowed to tell his side of the story in detail and the interrogator looks for omissions, discrepancies, and distortions. The interrogator’s job is to let the suspect know that the best course of action is to tell the truth. As a social engineer you can use this approach by not approaching the target in any role, but maybe as an elicitation, a question designed to elicit information from the target. The social engineer can gather information from the target by letting him do most of the talking. Sympathetic approach: The DOD manual offers some excellent thoughts on this approach. The interrogator drops his voice and talks in a lower, quieter tone that gives the impression he is an understanding person. He sits close to the suspect and maybe puts his hand on the suspect’s shoulder or pats him on the arm. Physical contact at the right time is very effective. The social engineer can use this approach in the very same manner as the interrogator. Maybe you overhear some employees complaining about the boss as you are waiting to tailgate in the door. Or maybe you have followed the target to the local bar and get into a conversation where you can show empathy to a situation. You can use this approach all around, and it is very effective. Emotional approach: This approach plays on the morals or emotions of the suspect. Questions such as, “What will your wife or kids think about this?” are used in this interrogation tactic. The thoughts that are aroused emotionally upset him and make him nervous; as these emotions manifest themselves, the interrogator can capitalize on them. You can use this approach in a similar manner to the preceding, in which you play on a weakness identified in the target. In one engagement, I knew the target was partial to charities for children who suffer from cancer. Playing on those emotions I was able to get the target to take an action he should not have taken, and it compromised his operation. Logical approach: This non-emotional approach presents strong evidence of guilt. The interrogator should sit erectly and be business-like, displaying confidence. You can use this matter-of-fact approach when presenting evidence of your legitimate reasons for being present—for example, such as being dressed and armed as an IT repairman and having the air of confidence that you belong there. Aggressive approach: For an interrogator, a fine line exists between gathering information and infringing on the target’s rights that must not be crossed. The voice should be raised, and the look and act should be aggressive, but the suspect’s civil rights should never be violated. The social engineer auditor needs to keep this fine line in mind. As in the case of Hewlett-Packard, discussed in Chapter 4, being hired to social engineer a company does not give you the right to break civil laws. Most of the time the company hiring you has no right to allow you to tap home phones, read personal e-mails, or invade people’s privacy. Combination approach: One interrogator may combine two approaches to have maximum effect. This would be decided upon based on the suspect’s personality. As a social engineer you may use the same technique—combine your attacks and approaches for maximum effect. For instance, after you discover some personal details about a target—such as their favorite local bar—you can approach the target and start a conversation. Such a tactic, especially when employed in a relaxed atmosphere, can go a long way toward opening people up. Indifferent approach: This approach is very interesting because the interrogator acts as if he does not need the confession because the case is solved. At that point the interrogator may try manipulating the suspect into giving his side of the story. As a social engineer you may not be able to use this approach unless caught. If you’re caught in an area or situation you should not be in, you can act indifferent instead of afraid that you are caught. Acting indifferent can cause the person who caught you to not be alarmed as much and afford you an opportunity to dispel any worries. Kevin Mitnick (see Chapter 8 for more on Mitnick) was great at this technique. He had the ability to think quickly on his feet. Also, acting indifferent when he was in a precarious situation allowed him to get away with a lot. Face-saving approach: The interrogator should rationalize the offense, giving the suspect a way out and an excuse to confess and save face. An interrogator should not make the excuse so good, however, that the suspect can use it in court as a defense. A social engineer can really utilize this approach. An interrogator does not want to give someone too good an excuse, but a social engineer does. You want the excuse to be so good the target doesn’t even need to think before rationalizing it as an excuse for complying with you. One approach is to say a higher-level person asked you to be there. You can follow this up by saying, “I can understand how you might feel now, but I don’t even want to imagine how upset Mr. Smith will be if I don’t fix that massive e-mail blunder before he returns on Monday.” This approach gives the target the ability to save face and comply. Egotistical approach: This approach is all about pride. For it to work you need a suspect who is very proud of an accomplishment. Bragging on good looks, intelligence, or the way the crime was performed may stroke his ego enough that he wants to confess to show that, indeed, he was that smart. In social engineering gigs this method is often used. Playing up someone’s accomplishments gets them to spill their deepest secrets. In the case of the U.S. nuclear engineer in China (refer to Chapter 3), social engineers loaded the man with compliments, and he spilled the beans and divulged information he shouldn’t have. Exaggeration approach: If an interrogator overexaggerates the case facts, the suspect may admit to what was real. One example would be if an interrogator accuses a thief of wanting to commit rape and saying, “Why else would someone break into a bedroom in the middle of the night?” This often causes the suspect to admit to only wanting to steal and not commit rape. You can also use this approach by overexaggerating the task you are there to perform. By overexaggerating the reason for being there you can give the target a reason for providing you lesser access. For example, you can say, “I know Mr. Smith wanted me to fix his computer personally because he lost a lot of data, but if you don’t feel comfortable with that, I can potentially fix his problem from another computer in the office.” Wedging the alibi: A suspect seldom confesses his transgressions all at once. Getting him to make minor admissions, such as he was on the site, owned the weapon in question, or owned a similar car, can move him toward admitting more and more, eventually leading to a complete confession. Maybe you get stopped at the door during a social engineering gig and the gatekeeper refuses you access to the building. See whether you can “gain access” by using a line like this: “I understand Mr. Smith is busy and can’t meet with me. Would you mind giving him this CD of information about our products and I will follow up with a phone call later on today or tomorrow?” It is a lesser admission, but nevertheless would get if not you, then one of your tools in the door. The End Goal To prepare to use proper interview or interrogation tactics, as a social engineer you may want to answer a few questions of your own. I encourage you to write these down in a notepad because doing so can help you prepare for your encounter with the target. Plus, writing down your answers makes them real and gives you a path to work on during the preparation for your interrogation. Answer these questions: Who: With whom is the interrogation or encounter being conducted? What role does he play? List names, titles, and other information about him that is relevant to the interrogation. What: Exactly what preparation has been done and what is going to be your goal during the interrogation? You must have a definite aim. When: What is the timeframe of the interrogation? What time of day or night? What are the circumstances at the business that lead to this decision about when to make your move? Is there a party you overheard about? Is it a time when a large portion of the employees are on vacation? Is it during lunch time? Is it during the changing of the security staff? Where: What is the location of the interrogation? Are you going to be at the target’s location? Are you tracking the person to his or her gym, local bar, or daycare? Where is the best place to try to obtain the information you need from the target? Why: People hear this question often enough from their kids, but it must be asked. What is the purpose of this interrogation? To make the target admit to the location of something? To make him give out information he should not? For you to gain access to a room or a server? How: What methods will you use in this interrogation? NLP? Embedded commands? Human buffer overflow (discussed at the end of this chapter)? Microexpressions? Of course, in a criminal interrogation the goal is confession to a crime. With interrogation as a social engineer the goal is a confession of a different sort. You want people to feel comfortable giving you information, and using the interrogation tactics discussed earlier you can make that easier to do. In the end, your social engineering interrogations should be like smooth interviews. However, a social engineer can use some other techniques to help while using interview and interrogation tactics on a target. Gesturing Gestures have a wide variation due to the fact that they are very much culturally dependent. Unlike microexpressions, which are universal, gestures from the United States can actually be insulting in other parts of the world, or have no meaning at all. Here is an exercise to help you better understand gesturing differences. If you want you can write down your answers to refer to in a few minutes. Depending on what culture you’re from, the answers will be interesting to see. Write down what you think this gesture means and whether it is rude in each case: 1. Holding your palm facing upward, point at someone with your index finger and beckon to him. 2. Make a “V” sign with your index and middle fingers. 3. Sit with the soles of your feet showing. 4. Make the “ok” symbol with your fingers. 5. Wave a hand with your palm facing outward. 6. Nod your head up and down. If you wrote down your answers, compare them to some of the following interesting cultural differences: 1. In the U.S. this gesture simply means “Come here,” but in the Middle or Far East, Portugal, Spain, Latin America, Japan, Indonesia, and Hong Kong, beckoning someone this way is considered rude or insulting. Beckoning someone with the palms facing down and using all the fingers to beckon is more acceptable. 2. In the U.S. this gesture is a “peace sign,” but in Europe it means “victory.” If you put the palm toward your face it actually means, “Shove it.” 3. In the U.S. this is a comfortable way of sitting and doesn’t denote any bad intent. Yet in other countries, such as Thailand, Japan, and France, as well as countries of the Middle and Near East, showing the soles of the feet demonstrates disrespect. Exposing the lowest and dirtiest part of your body is insulting. 4. In the U.S. this gesture means everything is okay. But in other parts of the world it has much different meaning. In Brazil and Germany it is an obscene gesture, in Japan it means “money,” and in France it means “worthless.” 5. In the U.S. this is a greeting, a way to say hello or good-bye. In Europe it can mean “no,” and in Nigeria it is a serious insult. 6. In the U.S. nodding your head is a way of saying “yes.” The same is true for many places, but in some areas, such as Bulgaria or Greece, it is a way of saying “no.” These are just a few examples of gestures that can have varying meanings depending on where you are or who you are talking to. Understanding the different meanings of gestures is important because communication is often much more than what is said. This section is intended to show that, during an interaction with a target, not only can these principles be observed but they can also be utilized to manipulate the target into a path of least resistance. Understanding the culture of the targets you approach will also keep you from performing a gesture that can have undesirable results. Anchoring Gestures can have some powerful effects when used properly. Some of these principles come from the study of NLP but can have a lot of power when you’re trying to set your target’s mind on a path you control. One such method is anchoring , which is a method of linking statements of a like kind with a certain gesture. For example, if you are talking to a target and he describes something positive and good, you can repeat it back while gesturing with your right hand only. If it is something bad you can gesture with your left hand only. After doing this gesture a few times you begin to “anchor” in your target’s mind that right-handed gestures are linked to good things. Salespeople use this method to further solidify that “their product” or “their service” is excellent and the competitor’s is not. Some politicians use this method to anchor positive thoughts or thoughts they want their audience to think of as positive with certain gestures. Bill Clinton was a great example of someone who understood this. To see this in action (albeit not former President Clinton) visit www.youtube.com/watch?v=c1v4n3LKDto&feature=player_embedded . Mirroring Another tactic when it comes to gestures is called mirroring , where you try to match your gestures to the personality of the target. Of course, this is not as easy as it sounds. But what can you discern about the target from just observation? Is she timid? Is he loud and outgoing? If you approach a timid person with large, loud gestures you will surely scare her off and potentially ruin your chances of making your social engineering attempt. By the same token, if you are more timid you will need to mirror “louder” gestures when dealing with “louder” people. Mirroring not only involves mimicking a target’s body language but also using gestures that make it easy for a person to listen to you. You can take this principle to another level. Seeing gestures a target is familiar with can be comforting to him or her. However, you must strike a careful balance, because if your target has a particular gesture he seems to be using a lot and you use it exactly the same way, then you run the risk of irritating him. You want to mirror him, but not exactly. If the target ends a thought by placing his hand on his chin you can end a thought by placing your hand on another part of your face or raise a finger to tap your chin a couple times. The following section analyzes the topic of gesturing a bit further by discussing the importance of the position and placement of a target’s arms and hands. Arm and Hand Placement Law enforcement officers are trained to notice the placement and position of the arms and hands during both interviews and interrogations. An increase in movement or “fidgeting” during an interrogation can show an increase in stress levels, signifying that the interrogation is having the desired effect. This is, of course, in a law enforcement setting; in a social engineering setting you would watch for these same signs, but signs of stress in the target might indicate you need to back off (unless your goal is to stress him or her out). Certain law enforcement officers are taught to pay attention to a couple of signs: Elbows generally hang free next to the body when a person is relaxed. When you feel threatened or scared your body’s natural reaction is to pull the elbows in towards the rib cage. In essence this position serves as a layer of protection to one’s internal organs that might be threatened. Hand gestures often can be very revealing, too. A target may describe something with his hands that he doesn’t say. For example, in a crime interrogation suspects may make a gesture that describes the activity (that is, strangling, shooting, stabbing, and so on) but just say the word crime or incident . Watching for the subtle hand gestures your target may use is important. Taking note of signs that the target is feeling threatened or scared can help you to adjust and put them back at ease. When you approach a target, much can be said with body language and arm and hand gestures before the first word is even spoken. Other gestures to take notice of include: An open palm might indicate sincerity. Steepled fingers could indicate the person feels authoritative. Tapping or drumming fingers can indicate anxiety. Touching the face can indicate thought; touching hair can indicate insecurity; and touching ears can indicate indecisiveness. Taking note of these gestures in your target can tell you a lot about his mindset. On the other hand, performing these gestures can help you to portray one of these images if this is your pretext. From a social engineering standpoint here are a few key points about gestures, which can be imperative if you are a “big” gesturer like me: No one should remember the gesture, but only the message attached to it. If people tend to say, “Wow, that guy gestures a lot” you need to calm down a bit. The message is important, not the gesture. Avoid monotony. Even in gestures you can be so bland, boring, and repetitive that the gesture can adjust the target’s perception of you to be negative. Be very concerned about exhibiting anxiety, such as tapping or drumming your fingers or making jerky movements. They tell the target you are nervous and detract from your message. Too much is too bad. Overgesturing can also detract from your message. Remember that using facial expressions, gestures, and posture is a package deal. They must all blend together, be balanced, and support your pretext. As good as all this information is, one tool in the interrogation arsenal can make or break the way you use this knowledge in your social engineering skills. Listening Your Way to Success Probably not one skill exists that can be as encompassing as listening. Listening is a major part of being a social engineer. What you have to realize is a major difference exists between hearing and listening . It is commonly believed that people retain much less than 50% of what they hear. That means if you are talking to a person for ten minutes he will remember only a few minutes of what you said. Although people eke through life this way, it is not acceptable for a social engineer. Often the little things that are said can make or break how successful you are in a social engineering endeavor. This area is where massively improving your listening skills comes in, and not just listening to what is said, but how it is said, when it is said, and with what emotion. All of these factors contribute to your perception of the information relayed. Being a good listener might sound easy, but when you are in the heat of the moment, your end goal is to gain access to the server room, and you are listening to a story by a few employees out for a smoke break who you plan on following into the building, truly listening can be hard. Yet it is during these times you might want to really listen. Maybe Susan starts to complain about her manager in HR, Mr. Jones. She tells a story about how short he has been with her lately and how she is fed up with it. Then her fellow smoker, Beth, says, “Well you should come over to the paradise of accounting. It is filled with jerks there, too.” Maybe this just sounds like the complaining chatter of two tired and ticked-off employees. Or is it more? You have both of their names, the name of a manager, the names of their departments, and some idea of the general demeanor of some of the employees. This information can be very valuable later on if you need to provide proof of your validity for being inside the building. Often the way someone says something can tell you a lot about the person, but applying this will require a lot of listening. Is the person angry, sad, or happy? Did she speed up or slow down in her delivery? Did he get emotional or did his emotion trail off? Paying attention to these types of things can tell you a lot more than the words at times. So how can you become a great listener? The following steps can help you perfect your listening skills. These tips can assist you not only in social engineering but also in life, and when applied to a social engineering audit can make a world of difference. 1. Pay attention. Give your target your undue attention. Do not fiddle with your phone or other gadget. Do not drum or tap your fingers. Try to focus intently on what is being said, looking at the person speaking. Do this in a very inquisitive way, not in a scary, “I want to stalk you” way. Try hard not to think ahead and plan your next response. If you are planning your next response or rebuttal you will not be focused, and you may miss something important or give the target the impression you don’t really care. This can be very hard to control, so perfecting this tendency will take some serious work for most people. Also try to not be distracted by environmental factors. Noise in the background or a small group laughing about something can shift your focus; do not allow that to happen. Finally, pay close attention to what the speaker is not saying, too. The body language, facial cues, and other aspects of communication should be “listened” to intently. 2. Provide proof that you are listening. Be open and inviting with your body language and facial expressions. Nod once in a while, not too often, but often enough to let the target know you are there. You don’t want to look like a bobble head doll, but you want to let the target know you are “with him.” Don’t forget the all-important smile. Smiling can tell the target you are with him mentally and you understand what he’s saying. As with paying attention mentioned earlier, add small smiles when appropriate. If the person is telling you her dog just died, nodding and smiling will most likely get you nowhere. 3. Provide valuable feedback. Letting your personal beliefs and experiences filter the message coming your way is all too common. If you do that you may not truly “hear” what the speaker is saying. Be sure to ask relevant questions. If she is telling you about the blue sky then you say, “So how blue was the sky?” will not be effective. Your questions must show you have been actively listening and have the desire to gain a deeper understanding. Every now and then mirroring or summarizing what you have heard can work well, too. Don’t recite the conversation like a book report, but recapping some of the main thoughts can help the target see you are in tune with the message. 4. Do not interrupt. Not much more needs to be said on this tip. Interrupting your target shows a lack of concern for his feelings and stops the flow of thoughts. Letting him finish and then speaking is better. However, circumstances do exist where interrupting can be useful or even a tactic. If you want to see an example, watch the movie Sneakers . When Robert Redford is trying to gain access to a locked door that he must be buzzed into, he interrupts the doorman in a heated dispute over some delivery items. He does so a few times, eventually frustrating the doorman and causing him to unlock the door with no authorization. If you think it will get you somewhere, interrupting might be a good idea. Most of the time however, it is not. 5. Respond appropriately. This is the pinnacle of good or bad listening skills. If you were focused on your rebuttal or next statement, or you were thinking about the very attractive blonde that just walked by, you might put your foot in your mouth. I was once training a group of people and was telling them some aspects of very detailed manipulation tactics. I could tell two guys were not listening. I put in a random thought like, “So then you bake the lion at 350 degrees for 15 minutes til crispy.” The rest of the group broke out in laughter and I turned to one of the two and said, “What do you think, John?” He responded with a blank stare and a stuttered, “Um, yah, sounds perfect.” Do not ever do that to a target. It is a death blow to rapport (discussed later in this chapter). Be respectful, keep your emotions in check, and respond appropriately at all times when conversing with a target. Paying attention, providing proof, giving positive feedback, being careful to never interrupt, and responding appropriately can make or break you when it comes to listening. They especially come into play during extended social engineering engagements, such as when I had to interact with the gentlemen at the Chamber of Commerce social gathering by “meeting” him at the bar and then talking to him about his business. Much of the information I was seeking would have been divulged in normal, mundane conversation. Make sure you practice these tips at home or the office before the time comes for the conversation to take place. You want good listening to become second nature as part of your arsenal of talents, not something you have to think about. Your own emotions are another aspect of listening you must take into account. For example, I was raised in a strict, religious Italian family. I was taught that you didn’t disrespect women, and I shudder to tell you of the one time I called my mom a disparaging name. I will tell you that it did not end too well for me. One day many years after that incident, I was working an engagement and was talking with a guy from whom I was trying to obtain some information. I approached him in a social setting and we started a conversation. He started to talk about a woman he worked with, in a very inappropriate way. Being raised the way I was, I found a lot of anger boiling up inside me. I had a hard time containing those feelings and it must have shown on my face and in my body language, leading to that particular vector being blown. In that failure I learned a very valuable lesson��when it comes to listening during social engineering engagements, you must try your hardest to not let the built-in filters you have get in the way. Also, remember to react to the message, not the person. If you don’t agree with a person’s beliefs or stance, affording him or her dignity will go a long way in making that person feel comfortable with you. Even in situations where you might not agree you can find something empathic to say. For example: Target: “This job stinks. They make me work this horrible shift and for low pay, too.” SE: “It sounds to me like you are overwhelmed by your situation here.” Although you might be thinking “Try Harder,”™ by responding this way you let the target know you were listening, as well as empathizing with her plight in life. This technique is known as reflective responding . Reflective responding has some basic principles to it: Listen actively, as described earlier. When it’s time to respond, be aware of your emotions. Knowing what you feel as the target is speaking can help you to react properly. Repeat the content, not like a parrot, but in your words. Start your response with a non-committal phrase such as, “It sounds like,” “It seems like,” or “It appears that.” These phrases ease the message you are trying to deliver. If you need proof of this, the next time you get into an argument with your mate, boss, parents, or whomever say, “You are mad at me because…” and compare the person’s reaction with what you get when you say “It appears you are mad because of…” instead. You will see which one is taken better. Reflective responding used with active listening is a very deadly force in the trust and rapport-building skills arena. As you learn to listen better and it becomes part of your nature you will enhance your ability to react to the message you hear. A social engineer’s goal is to gather information, gain access to someplace or something you should not have access to, or cause the target to take an action he should not take. Thinking that you must be perfect at manipulation often stops people from learning and practicing great listening skills, but this is the exact reason you need to be a great listener. Consider these two scenarios: One of your neighbors comes over and asks whether you have time to help him with a project in his garage for about an hour. This neighbor has a dog that has gotten into your garbage a few times and tends to like to use your yard as a bathroom. You are just about to sit down to relax at the end of a long day and watch some TV or read a book. Your childhood friend comes over and tells you that he needs some help moving some furniture. He just got a place about five miles from you and he can’t get the couch up the stairs. You are just about to sit down to relax a bit. For which scenario are you more likely to put aside relaxing? Most people will put aside relaxing for the second scenario, but will come up with an excuse or reason to not help out in the first scenario or at least try to postpone it to another day when they are not “busy.” Why? People are very open and free with friends. When you feel comfortable with someone, you have no boundaries and will put aside your own wants and needs at times to help them out. One naturally trusts the message coming from a friend, whereas with the stranger one might start to double-guess what’s being said, trying to determine whether it is truthful or not. In the case of the relationship with the friend, this connection is called rapport . For years rapport has only been talked about when it comes to salespeople, negotiators, and the like. Rapport isn’t just for salespeople; it is a tool that anyone can use, especially the social engineer. If you are wondering how to build rapport instantly, then read on. Building Instant Rapport My former coworker, Tony, used to say that building rapport was more important than breathing. I don’t really believe that to be true, but it does have a ring of truth in that rapport building is vital. Wikipedia defines rapport as, “One of the most important features or characteristics of unconscious human interaction. It is commonality of perspective: being ‘in sync’ with, or being ‘on the same wavelength’ as the person with whom you are talking.” Why is rapport discussed in this chapter? It is a key element in developing a relationship with any person. Without rapport you are at an impasse. Within the psychological principles behind social engineering, rapport is one of the pillars. Before getting into the aspects of how to use rapport as a social engineer you must know how to build rapport. Building rapport is an important tool in a social engineer’s arsenal. Imagine that you could make people you meet want to talk to you, want to tell you their life story, and want to confide in you. Have you ever met someone like that, someone you met recently but feel totally at ease telling him or her very personal things? Many psychological reasons may play into why that may be the case, but the case may be that you and that person just had good rapport. The following sections outline important points about building rapport and how to use rapport in social engineering. Be Genuine about Wanting to Get to Know People How important are people to you? Do you enjoy meeting new people? It is a mindset about life, not something that can be taught. The prerequisite to building rapport is liking people. People can see through a fake interest. To be a good social engineer and to be able to use rapport, people need to be important to you. You must like people and enjoy interacting with them. You have to want to learn about people. People can see through fake smiles and fake interest. Developing a genuine interest in your target can go a long way toward building rapport. Take Care with Your Appearance You cannot change some things that may affect your interaction with others. Unfortunately, people can still hold your skin color, gender, or age against you before you facilitate any interaction. You can’t control those things, but you can control aspects of your appearance such as clothing, body odor, and cleanliness, as well as your eye contact, body movements, and facial expressions. I read a statement once that I have seen proven true too many times to ignore: “If a person is not comfortable with himself, others will not be comfortable with him either.” Be aware of your pretext and your target. If your pretext is the janitor, make sure your demeanor, dress, attitude, and words reflect someone in that position. If your pretext is a manager of a business, then make sure you act and dress appropriately. This takes research but nothing kills rapport easier than not looking the part. Your goal in some instances is to keep people in the autopilot mode that will let them not question you. Having your dress, grooming, or demeanor out of place removes the target from autopilot and hurts your chances at success. Be a Good Listener See the earlier section for more details. The importance of good listening can’t be overstated. Whether you are trying to make a friend or make a social engineering move, listening is a skill you need to master. Be Aware of How You Affect People One time I saw an older woman drop an item as she left a grocery store. I picked it up and followed her out to the parking lot. By the time I caught up with her she had her trunk open and was loading groceries into her car. I came up behind this short, little elderly woman and with all 6’ 3” of me looming over her said, “Excuse me, ma’am.” I was obviously too close for her comfort and when she turned around she screamed out, “Help! He’s trying to mug me. Help!” I obviously needed to think about how my presence might affect this woman during my interaction with her. I should have realized that an elderly woman all alone in a parking lot who was not expecting a huge man to walk up behind her might freak out. I should have come around and approached her from a different angle. Be aware of how your appearance and other personal aspects might affect those you will be in contact with. Do you need a breath mint? Make sure no food is on your face or in your teeth. Try to be relatively sure that nothing is glaring in your personal appearance that will turn the person off. UCLA Professor of Psychology Albert Mehrabian is known for the 7-38-55 Rule, which states that statistics show that only 7% of normal communication is the words we say, whereas much more lies in the body language and vocal tones. Try to be aware of yourself, but also pay attention to the first few seconds of interaction with a person. His or her reaction to your approach can tell you whether you possibly missed something, or whether you need to change something to be more effective. As a social engineer, be aware of how you affect people. If your end goal is all that is on your mind you will affect the people you come into contact with negatively. Think about how your appearance, words, and body language may affect your target. You want to appear open and inviting. Keep the Conversation off Yourself We all love to talk about ourselves and even more so if we feel we have a great story or account to share—it is human nature. Talking about yourself is one way to kill rapport. Let the other person talk about himself until he gets tired of it; you will be deemed an “amazing friend,” a “perfect husband,” “great listener,” “perfect sales guy,” or whatever other title you are seeking. People feel good when they can talk about themselves; I guess we are all a little narcissistic, but by letting the other person do the talking you will leave that interaction with his liking you a lot more. Keep the conversation off yourself. This point is especially cogent for social engineers. You have a definite goal in mind and sometimes your judgment and direction can be clouded by what “you” want. Taking that focus off of the target is dangerous as far as success goes. Let targets talk about their jobs, roles, and projects, and be amazed at how much information they release. Remember That Empathy Is Key to Rapport Empathy—defined by Random House Dictionary as “the intellectual identification with or vicarious experiencing of the feelings, thoughts, or attitudes of another”— is lacking in many people today and is especially hard to feel if you think you have the solution to someone’s problem. However, really listening to what someone is saying, trying to identify and understand the underlying emotions, and then using reflection skills can make a person feel as if you are really in tune with him. I felt it necessary to provide the definition of empathy because understanding what it is you have to do is important. Notice that you must “intellectually identify” with and then experience “the feelings, thoughts, or attitudes” of someone else. These aren’t always serious, depressing, or extreme emotions. Even understanding why someone is irritated, tired, or not in the best mood can go a long way. Imagine you go to the bank drive through and the teller lady gives you a monster attitude because you forgot to sign your check and she now has to send it back. You also forgot a pen and need to ask her for yet another favor. Your reaction might be similar to mine, especially if she gave you the eye roll and the irritated glance—you want to tell her that she is here to serve you. Instead, try saying this, “It appears you might be a little irritated. I understand that; I get irritated when I have to deal with my forgetful clients, too. I hate to ask this, but could I please get a pen?” It’s important to not be patronizing when attempting to show empathy. If your empathy seems to come off haughty or arrogant, you can make the target feel like you are patronizing them. You acknowledged her being upset but without accusation, showed that you have the same feelings, and then made a request. Empathy can go a long way toward building rapport; one caveat is that rapport cannot be faked. People need to feel you are genuinely concerned to build that trust relationship. If you are not a natural at displaying empathy, then practice. Practice with your family, friends, coworkers, teachers, or classmates. However and wherever you do it, practicing being empathetic will greatly improve your relationship-building skills. Empathy is a tool of the social engineer. Unfortunately, it is also used often in malicious social engineering. When a catastrophe hits somewhere in the world a malicious social engineer is often there to “empathize” with you. The thing that probably makes this tool so easy for malicious social engineers to use in many cases is because they truly are from bad, poor, or impoverished places. Being in bad straits themselves makes appearing empathetic to others’ plights in life easy and therefore creates rapport automatically. Nothing builds rapport more when people feel like you “get them.” This is proven very true when someone is a victim of disaster. It’s a scary thought, but those who have been victims of abuse, crime, rape, natural disasters, war, or other atrocities on earth often can “understand” the feelings of those who are experiencing them. This opens victims up to trusting the wrong type of people if that rapport is built. As mentioned before, when the 9/11 attacks happened in New York City, many people claimed to have lost family or friends in terrorist attacks. That made people empathize and therefore these “victims” were given money, fame, or whatever they were seeking. As a social engineering auditor, you must be able to have a broad range of emotions that you can tap. Being closed in your emotions makes being empathetic very hard. This point goes along with really liking people. If you do, you won’t have a hard time getting to know them and their stories and empathizing with them. Be Well Rounded in Your General Knowledge Knowledge is power. You don’t have to know everything about everything, but having some knowledge about some things is a good idea. It makes you interesting and gives you something to base a conversation on. Knowledge is power. The old hacker mantra comes back to you as a social engineer. A social engineer should be a reader and a studier. If you fill your head with knowledge then you will have something to talk about when you approach a target. Don’t neglect reading, researching, and studying about the topic of the target’s occupation or hobbies. Your goal is not to be a “know-it-all” and become an expert on every topic, but rather to have enough knowledge that you don’t look at the target with a blank stare when she asks, “Did you bring an RJ-45 connector with you to fix the server’s network connection issues?” Develop Your Curious Side People normally feel a little self-righteous when it comes to their beliefs or thoughts on the way things should be done. That self-righteousness or judgmental attitude can change the way a person reacts to something being said. Even if you don’t say anything you may start to think it, which can show in your body language or facial expressions. Instead of being self-righteous, develop a curiosity about how other people think and do things. Being curious keeps you from making rash judgments. This can be applied by being humble enough to ask for help or ask for more information. Be open minded enough to look into and accept another’s thoughts on a topic, even if those thoughts differ from yours. Curiosity did not kill the social engineer. This point doesn’t change much from a non–social engineer perspective. When you become curious about others’ lifestyles, cultures, and languages you begin to understand what makes people tick. Being curious also keeps you from being rigid and unbending in your personal judgments. You may not personally agree with certain topics, beliefs, or actions but if you can remain curious and nonjudgmental then you can approach a person by trying to understand why he is, acts, or portrays a certain way, instead of judging him. Find Ways to Meet People’s Needs This point is the pinnacle of the list and is one of the most powerful points in this book. Dr. William Glasser wrote a book called Choice Theory in which he identified four fundamental psychological needs for humans: Belonging/connecting/love Power/significance/competence Freedom/responsibility Fun/learning The principle behind this point is that creating ways for people to get these needs met by conversing with you builds instant rapport. If you can create an environment to provide those needs for people, you can create bonds that are unbreakable. Let me tell you a brief story about how powerful meeting people’s needs can be. I was in a minor car accident. A young driver pulled out in front of me and then decided to stop. I had a split second to decide between hitting him going 55 mph or veering off away from him then launching my car over a small ditch into the side of a mountain. I chose in a second to not kill the three young people in the car. My car went airborne until it was stopped by solid rock. I watched my beautiful little customized Jetta crumple under the weight, and my face smacked off the windshield. I barely nicked the other driver’s rear bumper but I was moving fast enough that his car was sideways in the highway. When I was able to get my bearings we called the cops and an ambulance. The young man had a different insurance company than I did. The next morning I got a call from his agent, who politely asked me questions. He told me that an adjuster would come out to see my now-crumpled Jetta, and within 48 hours I was handed a check and a letter stating they would cover all medical costs for my recovery. I was then given up a follow-up call from his insurance agent to see whether I was okay. How many calls from my insurance company do you think I got? I got one, just to tell me how to answer questions. I understand that caring about each person is not the job of these large companies. But the other agent called me just see whether I was okay. I fought no battles to get paid and I was given a very fair price for my car. Two days after that I cancelled my insurance and went to see Eric, the insurance agent who called me, from the young man’s company. I told him I was so impressed that I wanted what he was selling. It has been 12 years now and I use Eric for every insurance need I have. About two years ago I got a call from an insurance company offering me rates that were substantially lower than what Eric and his company offer. I couldn’t even think about doing that to Eric. Why? Rapport—plain and simple. Eric is my friend, my helper, someone I can call about questions on insurance, and someone who will always give me the best advice. He cares, he knows my family, and he never tries to hard-sell me. He doesn’t have to, because I will buy whatever he has, because I trust him. This is the power of rapport. I don’t know, maybe Eric’s end game in checking on me was to get me to move to his insurance practice, although I doubt it. Knowing him, he actually cares and anyone who knows him says the same thing. His brother and he run a solid business. Rapport can create bonds between people that transcend cost or loss. Filling a need for the person you are talking to drastically increases the chances of building rapport. Do it without appearing to have an end game, do it with a genuine desire to help, and be amazed at the results. Perhaps no other avenue is more valuable for social engineers than being able to meet these needs. Learning how to create an environment that allows the target to feel comfortable and get one of the basic four fundamental needs met is a sure way to ensure unbreakable rapport. Spies use this principle of filling a need or desire often. In a recent trip to a South American country I was told that its government is infiltrated all the time via fulfilling the basic need of “connecting or love.” A beautiful woman will be sent to seduce a man, but this is no one-night stand. She will seduce him for days, weeks, months, or even years. As time continues she will get bolder with her requests for where they are intimate, eventually making their way to his office, where she gains access to plant bugs, Trojans, or clone drives. This method is devastating, but it works. Social engineers fill desires through phishing emails also. In one test 125 employees of a very reputable company were sent fake image files labeled BritneyNaked.jpg, MileyCyrusShowering.jpg, and other such names, and each image was encoded with malicious code that would give the social engineer access on the user’s computer. The results were that more than 75 percent of the images were clicked. What was found was the younger the star mentioned in the picture, the higher the click ratio. These disgusting and devastating facts show how well fulfilling people’s desires can work. In person, too, it is no different. Police interrogators use this tactic for building rapport all the time. One time I interviewed a law enforcement agent for a podcast I did at social-engineer.org ( www.social-engineer.org/framework/Podcast/001_-_Interrogation_and_Interview_Tactics ). The guest told a story that proves this point about the power of rapport to make people comply with requests. The officers had arrested a man who was a peeping tom. He had a fetish where he loved to invade the privacy of women who wore pink cowboy boots. The law enforcement, instead of judging him for the freak he is, used phrases like, “I like the red ones myself,” and “I saw this girl the other day wearing short shorts and high cowboy boots, wow!” After just a short time he began to relax. Why? He was among like-minded people. He felt connected, part of the crowd. Their comments put him at ease and he began to spill his guts about his “habits.” The preceding is a nice example of how to develop and build rapport, but how can you use it as a social engineer? You can build rapport in a matter of seconds by applying the principles of building rapport discussed earlier. To prove this, imagine you need to grab some cash, you don’t have your ATM card on you, and you forgot your account number, so you have to go in and ask someone for some help. Maybe you feel a little embarrassed about having to ask for your account number. You walk into a local branch of your bank you have never been into. No one is in the bank and you have your choice of tellers. Maybe you don’t think about it, most people don’t, but you will look over all the open lanes and choose the person who makes you feel the most comfortable. You will get the same results from each lane, but you will choose the one that makes you feel okay. Maybe you choose the most attractive person, or the one with the biggest smile, or the one who greets you first—whomever you choose and however you choose them you make the choice either consciously or unconsciously, but a lot of it has to do with rapport. The same principle will prove true when it comes to you and your target. As you walk up to a target she will make instantaneous snap judgments of you based on your personal appearance, demeanor, facial expressions, and, of course, her mood. Most of these factors you can control, so take pre-emptive action on them to ensure success. Building rapport properly creates a bond like strong glue that can withstand minor inconvenience and even some misunderstanding. Rapport allows a person to say and do things that only close friends can do, because he or she is brought into that inner circle of trust. It is a powerful force without which salespeople, friendships, employment, and many other situations are much more difficult. Remember Chapter 4 on pretexting? You learned that pretexting is more than just playing a part, it is living, being, and becoming the person you are portraying to the target. Having a strong pretext is imperative to building the right kind of rapport. In many social engineering engagements you will not have the time to build a storyline and use long-term seduction or rapport techniques, so your success will be based on many of the non-verbal things you will need to do. Using Other Rapport-Building Techniques Other rapport-building techniques exist that are based in NLP research. As you now know, rapport is basically connecting with someone and putting him or her at ease; some NLP techniques used by hypnotists and NLP practitioners can put people at ease instantly, as discussed next. Breathing at the Same Rate as Your Target Breathing at the same rate as someone doesn’t mean you closely listen to every breath and try to breathe in and out when your target does. But some people have very defined breathing patterns: Some have fast and short breathing, and some have long and deep breathing. Notice how the target breathes and mirror that pattern, but without parroting (that is, doing it at the same exact time). Matching Your Target’s Vocal Tone and Speech Pattern I was born in New York and raised in an Italian family. I talk fast, loud, and with my hands. In addition to being 75 percent Italian, I am 25 percent Hungarian. I am big, tall, and loud and gesture like a professional sign language translator on speed. If I approach a timid, shy, slow-talking southerner I can kill rapport if I do not slow down, put the hands away, and change my communication style. Listen to your target’s vocal tone and match yours to his, whether he is a slow, fast, loud, quiet, or soft speaker. As for accents, a good rule is: Don’t try. Unless you can do it very well don’t even attempt it. A poorly done accent is a rapport killer. Along these same lines, you can also try to listen for key phrases. People use terms like “okie dokie” or “yepper.” Listen for any key phrases, and even if they are out there, you might be able to work them into a sentence. Once I was talking with a target who would say things like, “It’s six of one and half dozen of another.” I don’t use that phrase a lot and didn’t want to screw it up, because that would create a lack of rapport. Instead, I would mix in some of the key words of that phrase and say things like, “I must have done that a half dozen times.” How someone talks is also an area where you should restrict your personal judgments. Some people are close talkers, some are whisperers, some are touchers—if you are not, you need to allow a person freedom to talk the way he or she is comfortable and then mirror it. Matching Your Target’s Body Language Matching body language is a very interesting avenue of rapport building mainly because it can work to create very strong bonds but at the same time it can kill all your rapport in a matter of seconds in the case of a mismatch. If you notice someone standing a certain way, maybe with both arms crossed, don’t assume she is shutting you out—maybe she’s just cold. Can you cross one arm across your body to mirror her stance, or fold your hands into a steeple? When sitting across from someone who is eating a meal you can take a few sips from your drink while he eats to mirror him. Don’t do everything he does, but make similar actions. People like people who are like themselves. That is just human nature. It makes them feel comfortable. Bill Philips was the genius behind the Body- for -Life program that changed the way workout programs were developed. He promoted something that was heavily tied to the mirroring principle. If you are fat and you only hang out with fat people, the chance of your changing is slim to none. Why? The answer is that you are comfortable with being fat and with people who are also comfortable with it. If you want to change, then hang out with skinny people and a mental change will quickly happen. This principle is the same in social engineering. You don’t want your targets to make a change, so you need to be like them. You want them to feel good with you. Testing Rapport Using these alternative rapport-building techniques as well as matching energy levels, facial expressions, and the like can build strong rapport on a subliminal level. After trying some of these tactics you can test your rapport by making a movement, like scratching your head or rubbing your ear, and if in the next minute or two you see your target make a similar movement you probably have developed some strong rapport. These techniques can work wonders in many parts of your life when developing, building, and starting relationships with others. Learning how to use the psychological principles included in this chapter can make a huge difference in your social engineering practice. For years, there has been a myth that the human mind can be overwritten like a program. Is it just a myth? Can the human mind be mastered? The next section reveals some of the most mind-blowing information in this book. The Human Buffer Overflow A glass can only hold so much liquid. If you have an 8-ounce glass and you try to pour 10 ounces of liquid into it, what will happen? It will overflow and spill all over the place. If you try to force the container to hold more liquid that it is meant to you can eventually break the glass due to pressure. Computer programs work in a similar manner. Imagine you have a small program that has only one purpose and two fields: User Name and Password. When the program opens you see a little screen where you type in admin in the User Name field and password in the Password field. A little box appears that says “OK,” signifying all is good. The developer allocated a certain amount of memory space for the User Name field, enough to hold the word admin a couple times. What happens if you put 20 A’s in that field and click OK? The program crashes and gives you an error message. Why? The input entered is longer than the allocated space and without proper error handling the program throws an exception and crashes. The goal of software hackers is to find the address that the program will call upon in a crash and insert malicious code into that address. By controlling the execution flow the hacker can tell the program to “execute” any program he desires. He can inject commands of any type into the memory space of that program because he now controls it. As a penetration tester few things are more exciting than seeing a program execute commands you tell it to. The human mind runs “software” and over the years you build instruction sets, buffers, and memory lengths into your “software package.” Before applying this to the human mind, definitions of a few technical terms are necessary. A buffer is an area of space that is given for something to happen or to hold data. As in the simplistic glass-of-water example, the password field is given a buffer, which is the number of characters that it is allowed to have. If a larger number than the buffer is entered the programmer needs to tell the program to do something with the larger than necessary data set. If he doesn’t, the computer crashes and your program shuts down. Often what happens in the background is the program didn’t know what to do with all the data so it overflowed the allocated space, crashed the program, and exited. Hence the term buffer overflow. The human mind works in a similar way. Space is allocated for certain datasets. If a certain dataset does not fit the space we have for it, what happens? Unlike a computer, your brain doesn’t crash, but it does open up a momentary gap that allows for a command to be injected so the brain can be told what to do with the extra data. A human buffer overflow is basically the same principle. The goal is to identify a running “program” and insert codes into that program that will allow you to inject commands and in essence control the movement of thought to a certain direction. To test this concept, take a look at a very simplistic example (see Figure 5-16 ). Because the picture in this book is black and white, I have put a color copy up on the website at www.social-engineer.org/resources/book/HumanBufferOverflow1.jpg . Here is the gist. Open that URL, and then as fast as you can try to read the color of the word, not what the word spells. Figure 5-16: Human buffer overflow experiment 1. This game is not as easy as it looks. If you successfully get through it, then try to do the exercise faster and faster. What will happen to most, if not all, of us, is that at least once you will read the word and not the color, or find yourself struggling through it. Why do we have such a hard time with this exercise? It is because of injected commands. Our brains want to read the words not the colors. It is the way the human mind is wired. Our brain sees the color but it reacts to the word being spelled first. Therefore, the thought in our minds is the word not the color. This exercise shows that having “code” execute in the human brain that might be the opposite of what the person is thinking or seeing is possible. Setting the Ground Rules In a paper entitled “Modification of Audible and Visual Speech” ( www.prometheus-inc.com/asi/multimedia1998/papers/covell.pdf ) researchers Michele Covell, Malcolm Slaney, Cristoph Bregler, and Margaret Withgott state that scientists have proven that people speak 150 words per minute but think at 500–600 words per minute. This means that most people you talk to can jump around your conversations in their heads. So overflowing the brain through fast speech seems almost impossible. You must also understand how people make decisions in life. People make most of their decisions subconsciously, including how to drive to work, get coffee, brush their teeth, and what clothes to wear without really thinking about it. Have you ever driven all the way to work and when you get there, you can’t remember what billboards you passed, what route you took or that traffic accident on the news? You were in a state of mind where your subconscious took over and did what you always do without your consciously thinking about every turn. Most decisions people make are like this. Some scientists even believe people make decisions up to seven seconds earlier in their subconscious before making them in the real world. When people finally do make a decision consciously they do it from more than just what they hear—sight, feelings, and emotions become involved in the decision. Understanding how humans work and think can be the quickest way to creating a buffer overflow, or an overflow of the natural programs of the human mind so you can inject commands. Fuzzing the Human OS In actual software hacking, a method called fuzzing is used to find errors that can be overwritten and give control to a malicious hacker. Fuzzing is where the hacker throws random data at the program in differing lengths to see what makes it crash, because it cannot handle the data. That gives the hacker a path to inject malicious code. Just like fuzzing a program, you must understand how the human mind reacts to certain types of data. Presenting people with different sets of decisions or different sets of data, then seeing how they react can tell us the “programs” they are running. Certain laws in the human mind seem to be inherent that everyone follows. For example, if you approach a building with two sets of doors (one outer and one inner) and you hold the first set open for a complete stranger, what do you think he will do next? He will either hold the next set open for you or make sure that set stays open until you get inside. If you are in a line of merging traffic and you let a complete stranger merge in front of you, most likely if you needed to merge later on he would let you in without even thinking. Why? The reason has to do with the law of expectations , which states that people usually comply with an expectation. Decisions are usually made based on what that person feels the requestor expects him or her to do. One way you can start sending your malicious “data” to the brain program is called presupposition . By giving the target something first, the request you make next will be “expected” to be followed. A simple example for you to test is with the doors. Hold a door for someone and most likely that person will at least make an attempt to ensure the next set of doors is open for you. A social engineer can do this by first giving the target a compliment or a piece of information they deem valuable, before the request is made. Giving that over first creates in them the need to comply with a future request as it is expected. Presupposition can be described best via an example: “Did you know my next door neighbor, Ralph, always drives a green Ford Escort?” In this sentence you presuppose: I know my neighbor. His name is Ralph. He has a driver’s license. He drives a green car. To use presupposition effectively you ask a question using words, body language, and a facial expression that indicates what you are asking is already accepted. The basic gist of this method is to bypass the “firewall” (the conscious mind) and gain access directly to the “root of the system” (the subconscious). The quickest way to inject your own “code” is through embedded commands, discussed next. The Rules of Embedded Commands Some basic principles of embedded commands make them work: Usually the commands are short: three to four words. Slight emphasis is needed to make them effective. Hiding them in normal sentences is the most effective use. Your facial and body language must support the commands. Embedded commands are popular in marketing with things like: “Buy now!” “Act now!” “Follow me!” In a real buffer overflow, exploit writers use padding, which is a method of adding some characters that do not interrupt the execution but allow a nice little “landing pad” that leads to the malicious code. Social engineers can utilize phrases that are like padding, to help the next command have a soft place to land when it is injected, such as: “When you…” “How do you feel when you…” “A person can…” “As you…” All of these statements create an emotion or a thought that allows you to inject code into the subconscious. Many examples of embedded commands exist, but here are a few to ponder: Using quotes or stories: The brain tends to process stories differently than other information. Some of the greatest teachers who have ever lived—Aristotle, Plato, Gamaliel, Jesus—all used stories and illustrations to teach those listening to them. Why? The unconscious mind processes stories as direct instructions. Bandler, one of the fathers of NLP, taught that NLP practioners need to learn to use quotes. He knew the power of stories or quotes would give the speaker power over the thinking of his listeners. Reading quotes, using quotes, and then embedding commands into quotes can be a powerful use of this technique. For example, in one situation I needed to manipulate a target to give me an old password so I could “change” it to a more secure password. My pretext was a support rep and they automatically questioned why there was a need to change old passwords. I used something like, “A recent study by Xavier Research Inc. stated that 74% of the people use weak passwords in corporate America. That is the reason we launched a program to change the passwords corporate-wide. I will perform that password change for you; I need for you to give me your old Windows password and then I will make that change now.” By quoting a research facility it added weight to my words about why this change had to occur. Using negation: Negation is much like reverse psychology. By telling the target to not do something too much, you can embed a command into the sentence. For example, if I tell you “Don’t spend too much time practicing the use of embedded commands,” I can slip the command “practice the use of embedded commands” into my sentence. I also can presuppose that you will practice it to some extent, and if you are stubborn you might say, “You can’t tell me what to do, I will practice all I want.” Telling a person that something is not important or relevant makes his unconscious pay extra attention so he can determine whether it is relevant or not. You can embed commands in negative sentences like the earlier example that will leave the listener no option but to take action. Forcing the listener to use his imagination: This method works when you ask the listener a question, using phrases such as “What happens…” or “How do you feel when…,” for which he must imagine something to answer it. If you ask, “What happens when you become rich and famous?” The listener has to internally imagine the time he might be rich and famous to answer that question. If I ask you, “What happens when you master the use of embedded commands?” I am forcing you to imagine becoming a master and how you will feel when that happens. Think of it this way: If I tell you, “Do not imagine a red cow,” you have to picture a red cow first to tell yourself to not think about it. Your unconscious mind is responsible for interpreting each word in a set of commands into something it can represent and then give meaning to. By the time your brain has understood the sentence, your unconscious has imagined it. The unconscious mind processes statements directly, with no regard to the context. The other great part is that the unconscious can track body language, facial expressions, voice tones, and gestures, and then connect each of them to the message being spoken. While it is connecting the dots, so to speak, the unconscious mind has little option but to comply if an embedded command exists. What’s important when using embedded commands is to not mess up your tones. If you overemphasize the words then you will sound odd and scare the person off instead of embed commands. As with a software buffer overflow, the information must match the command you are trying to overflow. Summary As you probably have already imagined, embedding commands is a vast field with a lot of room for error. You must practice to be very successful at it. Although I do not promote using this information for seduction some decent videos exist about seduction that show how embedded commands can work. Using these principles can create an environment where the target is very receptive to your suggestions. Just because you tell the person, “You will purchase from me” does not mean he always will. So why use these commands? It creates a platform to make social engineering easier. Using these types of commands is also a good lesson for companies you work with to educate them about what to look for and how to spot someone who may be trying to use this type of social engineering tactic against them. If you were to write out this principle of embedded commands as an equation, you could write it this way: Human Buffer Overflow = Law of Expectations + Mental Padding + Embedded Codes. Start a conversation with a target using phrases, body language, and assumptive speech. Presume the things you ask for are already as good as accomplished. Next, pad the human mind with some statements that make embedding commands easier, while at the same time embedding the command. In essence this is the equation for the human buffer overflow. Use this equation sparingly, but practice a lot before you attempt it. Try it at work or home. Pick a target at work that might not normally comply with simple requests and try to see whether you can get him to serve you coffee: “Tom, I see you are heading to the kitchen, will you get me a cup of coffee with two creams please?” Escalate your commands to larger tasks to see how far you can get. Try to use this equation to get commitment from people. Eventually use this equation to see how much information you can get and how many commands you can inject. This chapter covered some of the deepest and most amazing psychology principles in social engineering. This chapter alone can change your life, as well as your ability as a social engineer. Understanding how people think, why they think a certain way, and how to change their thoughts is a powerful aspect to being a social engineer. Next on the docket: how to influence your target.",
        "char_count": 170345
      },
      {
        "heading": "Chapter 12",
        "text": "Chapter 6 Influence: The Power of Persuasion If you would persuade, you must appeal to interest rather than intellect. —Benjamin Franklin The epigraph sums up this entire chapter. You might be wondering why I didn’t include this within Chapter 5’s discussion of psychological principles of social engineering. Psychology is a science and a set of rules exists in it that, if followed, will yield a result. Social engineering psychology is scientific and calculated. Influence and persuasion are much like art that is backed up by science. Persuasion and influence involve emotions and beliefs. As discussed in some of the earlier chapters, you have to know how and what people are thinking. Influence and the art of persuasion is the process of getting someone else to want to do, react, think, or believe in the way you want them to. If you need to, reread the preceding sentence. It is probably one of the most powerful sentences in this whole book. It means that using the principles discussed herein, you will be able to move someone to think, act, and maybe even believe the way you want him to because he wants to. Social engineers use the art of persuasion every day and, unfortunately, malicious scammers and social engineers use it, too. Some people have devoted their life to researching, studying, and perfecting the art of influence. Those such as Dr. Ellen Langer, Robert Cialdini, and Kevin Hogan have contributed a very large repository of knowledge in this field. Mix this knowledge with the research and teachings of NLP (neurolinguistic programming) masters such as Bandler, Grinder, and more recently Jamie Smart, and what you have is a recipe to become a true artist. True influence is elegant and smooth and most of the time undetectable to those being influenced. When you learn the methods you will start to notice them in commercials, on billboards, and when used by salespeople. You will start to get irritated at the shoddy attempts of marketing people and if you are like me, you will begin to rant and rave at terrible commercials and billboards while driving (which does not make my wife very happy). Before getting into how social engineers will use in influence and persuasion, the chapter begins with a short tour of some of the key elements of persuasion and influence that I have compiled and used. This chapter will discuss things like reciprocation, manipulation, and the power of setting goals, just to name a few of these key elements. Influence and persuasion can be broken down into five important aspects, as discussed in the following sections. The Five Fundamentals of Influence and Persuasion The five fundamentals of persuasion are crucial in obtaining any type of successful influence upon a target: Setting clear goals Building rapport Being observant of your surroundings Being flexible Getting in touch with yourself The whole goal of social engineering is to influence the target to take an action that may or may not be in their best interest. Yet they will not only take the action, but want to take the action and maybe even thank you for it at the end. This type of influence is powerful and can make a social engineer who possesses these skills legendary. World-renowned NLP trainer Jamie Smart once said, “The map is not the territory.” I love that quote because it blends perfectly with these five fundamentals. None of them are the whole sum on their own, but individually they are like points on a map that show you the whole territory of what you want to accomplish. The following section delves deep into the first fundamental: why setting clear goals is very important. Have a Clear Goal in Mind Not only should you have a clear goal in mind, you should even go so far as to write it down. Ask yourself, “What do I want out of this engagement or interaction?” As I discussed in Chapter 5, especially in relation to NLP, a human’s internal systems are affected by his thoughts and goals. If you focus on something, you may be more likely to become it or get it. This doesn’t mean that if you focus on the thought of getting one million dollars, you will get it. In fact, it is unlikely. However, if you had a goal of making one million dollars and focused on the steps needed to make that money, your goals, education, and actions would increase the likelihood of you achieving that goal. The same is true with persuasion. What is your goal? Is it to change someone’s beliefs? To get him to take an action? Suppose a dear friend is doing something terribly unhealthy and you want to try and persuade her to stop. What is the goal? Maybe the end goal is to persuade her to stop, but maybe little goals exist along the way. Outlining all of these goals can make the path to influencing that person clearer. After setting the goal, you must ask yourself, “How will I know when I have gotten it?” I once listened to a training program offered by Jamie Smart, one of the world leaders on NLP, and he asked each person in the classroom these two questions: What do you want? How will you know when you have it? At this point, I paused the CD for the first question and answered for myself out loud what I wanted from this course. Then I pressed Play again and when he asked that second question, “How will you know you have gotten it?” I paused the CD again and was lost. It was clear to me that I didn’t have a roadmap. I knew what I wanted out of that course, but I didn’t know how to gauge when I had gotten it. Knowing what you want out of your engagements is an important aspect of influence and persuasion tactics. When you approach a target knowing what your goals are and what the indicators are that you are getting what you want, then you can clearly identify the path you need to take. Clearly defined goals can make or break the success of the influence tactics used by a social engineer as well as make the next step much easier to master. Rapport, Rapport, Rapport Chapter 5 has a whole section on rapport building. Read it, study it, and perfect your rapport-building skills. Developing rapport means that you get the attention of the person you are targeting and his unconscious mind, and you build trust within that unconscious portion. Mastering the skill of building rapport can change the way you deal with people, and when it comes to social engineering, it can change your whole methodology. To build rapport, start where the person you want to influence is mentally—try to understand their frame of mind. Are they suspicious? Are they upset, sad, or worried? Whatever emotional state you perceive them to be in, start from there. Do not focus on your goals as much as focusing on understanding the person. This is a very vital point. This means a social engineer must understand his target enough that they can imagine where they are consciously. What are the target’s thoughts and state of mind? For example, imagine you want to influence your dear friend to want to quit smoking or doing drugs or something else. Notice you don’t want to convince her to quit, but convince her to want to quit. Your goal cannot be about you , right? It must focus on the target. You can’t start your conversation with what her addiction is doing to you and how much you hate the smell, and so on. The argument has to be what is in it for her . You cannot start the conversation with a verbal attack about what the person has done to you with their habit, but you need to understand where that person’s frame of mind is, accept it, and come into alignment with it. Social engineering is much the same: you can’t start where you are mentally. This is going to be struggle for many people. Do you know why she smokes? Do you understand the psychological, physical, or mental reasons why? Until you can really get into her shoes, you cannot build a strong rapport and your efforts at influence will fail. In addition, you cannot always base the idea of building rapport on logic. I once was in the hospital with a dear friend who was dying from throat cancer. He had smoked for more than 40 years and one day he found out he had cancer. It spread fast, bringing him to the hospital to live out his last days. His children would come to visit and every now and then they would leave the room. I thought they were overcome with emotion. One time after they excused themselves I went out to comfort them and they were outside the hospital smoking! I was dumbfounded. I don’t smoke and have no desire to, and although I can understand how strong an addiction can be, I couldn’t understand how after seeing the pain their father was in, how they could raise a cigarette to their lips. Logic would not win in this case. Telling my friend’s children why smoking is bad and how it will kill them would do no good—this information was useless because it was combative and only made me feel good in saying it, but did not align with their present frame of mind. Until you understand the person you cannot successfully build a good enough rapport to influence him or her. Getting someone to want to do something is a blend of emotion and logic, as well as understanding and humility in many cases. Once I walked into an office I was going to do some work for and I had heard a funny comment outside, so when I walked in the main lobby I was chuckling. The woman behind the desk must have just done something embarrassing because when she saw me she immediately got angry and yelled at me, “It’s not very funny and you are a jerk.” Now I didn’t know this woman and to tell you the truth I had a goal in mind that this interaction was not going to help. In addition, I felt insulted that she assumed I was laughing at her, and wanted to lash back at her. But instead, I saw she was upset. I got close to the counter so as not to embarrass her anymore, I looked her in the eye, and with sincerity said, “I am so sorry if you thought I was laughing at you. I was in the parking lot and some of your workmates were telling a story about a party over the weekend and I thought it was very funny.” She looked at me and I could tell she was now even more embarrassed, so to save face for her, I loudly said, “Ma’am, I am sorry for laughing and embarrassing you.” This allowed her to save face to those around us. She understood that I “took one for the team” and she responded with extreme kindness. A minute later she apologized and it worked to my benefit as I was given all the data I asked for, data I normally would have had to work very hard to get. A teacher I had once used to tell me to “kill them with kindness.” That is a pretty powerful statement. Being kind to people is a quick way to build rapport and to establish yourself in the five fundamentals of persuasion and influence. One method to influence people using kindness and rapport is to ask questions and give choices that lead them to a path you want. For example, once I was influenced to take a job I really didn’t want as part of a team effort. The team leader was very charismatic and friendly and had the “charm factor” that allowed him to speak to anyone. He approached me and said, “Chris, I wanted to talk to you separately from the team. I need a right hand for a small project. But the person needs to be a go-getter, self motivated. I think this is you, but I don’t want to assume; what do you think?” I was excited and flattered by the compliments and the potential to be “important,” so I responded, “I am a very self-motivated person. Whatever you need, tell me.” The team leader continued, “Well, I am a big believer in leading by example. And I think you have that leadership quality. The problem is, some on the team do not, and they need a strong person to show them how it is done.” Before the end of the conversation, what he wanted appeared as if it was my idea, which made it impossible to back out of. Powerful indeed, and all started with the power of persuasion. Be in Tune with Yourself and Your Surroundings Being aware of yourself and your surroundings, or sensory acuity , is the ability to notice the signs in the person you are targeting and yourself that will tell you that you are moving in the right direction or not. Many of the principles discussed in the previous chapter apply to persuasion. Reading body language and facial signs can tell you much about your influence on the person. To really master the dual art of influence and persuasion, you have to become a master watcher and master listener. Chris Westbury, a cognitive neuropsychologist at the University of Alberta, Canada, estimates that human brains process information at 20 million billion calculations per second. Those calculations are represented by facial expressions, microexpressions, gestures, posture, voice tones, eye blinks, breathing rate, speech patterns, nonverbal utterances, and many more types of distinguishing patterns. Mastering influence means to be aware of those subtle things in yourself and others. I found, for myself, the ability to be observant proved to be easier for me after receiving some training from Dr. Ekman in microexpressions. I found afterward that not only did I become much more aware of what was going on with those around me, but also myself. When I felt a certain expression on my face, I was able to analyze it and see how it might be portrayed to others. This recognition of myself and my surroundings was one of the most enlightening experiences of my life. NLP experts promote minimizing your internal dialog when trying to influence others. If you approach the target thinking about the next stage of the attack, the end goal, or comebacks for potential conversation stoppers, that internal dialog can cause you to miss a lot of what is going on around you. Being observant takes a lot of work but the payoff is well worth it. Don’t Act Insane—Be Flexible What do I mean by not acting insane and being flexible? One definition of insanity that’s been floating around for years is “doing the same thing over and over and expecting different results.” Being willing and able to flex is one of the keys to persuasion. You can think of this flexibility in terms of physical things. If you were tasked to persuade or bend something, would you rather it be a branch from a willow tree or a steel rod? Most people would say the willow branch because it is flexible, easier to bend, and makes the task accomplishable. Trying to persuade others while being unyielding and inflexible doesn’t work, and neither does persuasion if you are not flexible. Many times, an audit will not go as planned. A good social engineer will be able to roll with the punches and adjust their goals and methods as needed. This does not go against the idea of planning ahead; instead, it bespeaks the point of not being so rigid that when things do not go as planned you can move and adapt so the goal is not lost. The way a person would view an insane person is the way a target would view the inflexible social engineer. The social engineer would look unreasonable and you would most likely never reach endgame. Get in Touch with Yourself By getting in touch with yourself, I am not suggesting some Zen meditation avenue, just that you understand your emotions. Emotions control practically everything you do, as well as everything your target does. Knowing your emotions and being in touch with yourself can help you lay the groundwork for being an effective social engineer. Going back to the earlier example of you and your smoking friend—approaching your friend if you have a deep-seated hatred for those who smoke affects your approach. It can make you act, express, say, or do something that will close the door to persuasion. You may never compromise on certain things, and being aware of those things and your emotions about them can help you to develop a clear path toward influencing a target. These five fundamentals are key to understanding influence and persuasion. Being able to create an environment where a target wants to do what you are requesting is the goal of persuasion, and these five fundamentals will help you create that environment. The next section examines how social engineers use these fundamentals. Influence Tactics As mentioned, social engineers must practice the skill of persuasion until it becomes part of their everyday habits. This doesn’t mean that they must influence everyone in everything they do, but being able to turn this skill on and off at will is a powerful trait of a good social engineer. Influence and persuasion have many aspects you can use and many that fit easily into an audit. Other aspects might not fit too easily, but hold a very powerful position in the world of influence. The following sections cover eight different techniques of influence that are used often by media, politicians, government, con men, scammers, and of course, social engineers. Each section provides an analysis of each technique to see how it is used in other areas of influence besides social engineering, as well as takes a closer look at how it can apply to a social engineer. Reciprocation Reciprocity is the inherent expectation that when others treat you well you respond in kind. A simple example is when you are walking into a building—if someone holds a door open for you, he expects you to say thank you and then make sure that next door stays open for him as he comes in. The rule of reciprocity is important because often the returned favor is done unconsciously. Knowing this means that you now have a step up on how you can use it as a social engineer. Before getting into that, though, here are a few examples where reciprocity is often used: Pharmaceutical companies will spend $10,000–$15,000 per doctor (yes, per doctor) on “gifts” that might include dinners, books, computers, hats, clothing, or other items that have the drug company’s logo on it. When the time comes to choose a drug to support and buy, to whom do you think the doctors are more likely to go? Politicians are influenced in much the same way. It is no secret that many times politicians or lobbyists are more favorable to people who helped their political campaign than those who did not. Reciprocity is often used in business, especially when it comes to matters of contracts. Maybe the sales guy will pay for a meal, then later on ask for a concession in the contract. The client is compelled to give this concession. A fellow employee filled in for you one week when you needed a day off. Now she asks you to return the favor, but you have plans. In this situation, people will reschedule and honor the request. All of these are examples of reciprocity. Sociologist Alvin Gouldner wrote a paper called, “The Norm of Reciprocity” ( http://media.pfeiffer.edu/lridener/courses/normrecp.html ) in which he states: Specifically, I suggest that a norm of reciprocity, in its universal form, makes two interrelated, minimal demands: (1) people should help those who have helped them, and (2) people should not injure those who have helped them. Generically, the norm of reciprocity may be conceived of as a dimension to be found in all value systems and, in particular as one among a number of “Principal Components” universally present in moral codes. Basically, his research led him to see that reciprocity works despite cultural backgrounds. Reciprocity, used under the right circumstances, is all but impossible to resist. Think of reciprocity as the process shown in Figure 6-1 . Figure 6-1: The cycle of reciprocity. The following sections expand on some key points of the preceding idea. Give Something Away The thing you give away can’t be some simple piece of junk. The thing given must have value—to the recipient. Giving away a beautiful hardcover novel written in a language the recipient does not read or collect is useless. The item can be a service, a physical item, some valuable information, assistance, or anything else that the receiver will deem as a value (even something as simple as holding the door or picking up something dropped). Some sales organizations promote this method but then fall short by offering something that has no value. Imagine you are at a trade show and at each table is a giveaway. If you walk up to a table and notice a pile of cheap-looking pens you might just walk by. The next table has an interesting puzzle-like game. You are intrigued so you pick it up; after you spend a few minutes playing with it a salesperson approaches and says, “You want a hint?” After showing you a small hint he asks whether you have a minute so he can show you a service you might really love. How can you say no? You get an intriguing game and a free hint, and now all he wants is a minute of your time? It’s a perfect setup. Create Indebted Feelings The more value the gift has to the recipient and the more unexpected it is, the greater the sense of indebtedness. Not allowing the gift to be used in an obvious manipulation tactic is important. Don’t say or act like, “I gave you this great gift now you owe me.” Even thinking it can take away any feelings of indebtedness. The “gift” should be totally free and of great value to the recipient. The Humane Society of the United States, for instance, gives away personalized mailing labels as a free gift. No strings are attached and many people use them for holiday cards or personal letters. They are attractive and good quality. You sign up for them, and many months later you will get a call asking for a donation to support your local Humane Society. The recipient’s sense of obligation is usually too great to not contribute even a little. By way of another example, Fortune Magazine offers college professors free issues of its magazine to try out in their classes with no strings attached at all. Many examples of reciprocity like these exist. On the flip side, many companies fail at reciprocity by thinking things like the following are good gifts: Sharp-looking and colorful corporate brochures Useless and junky toys Sales literature about your products or company These things do not build indebtedness. The recipient must deem the “gift” valuable. Another source of “gifts” that can build true indebtedness is information. Giving away a valuable, beneficial, or useful piece of information can literally be of more interest than a physical gift to some. Ask for What You Want On one occasion as I was entering a building, I saw a man who looked very much to be the “boss” get out of his car parked in the spot marked “For CFO Only,” and he was on his cell phone. He was not a happy guy, and I overheard him telling someone that he was upset because he had to go inside and let some people go. I assumed from his tone that he was on with his wife or girlfriend and he didn’t like the job he was about to do. I walked past him and went to the front desk and as I walked up I saw that the girl behind the desk was playing Minesweeper. As I approached the counter she gave me the standard, “How can I help you?” She had a look on her face that said she was bored and not in the mood. I said, “Look, I am here for a meeting, but your boss is about to walk in and he is in a bad mood…” I then trailed off and just stood there with a folder in my hand. A few seconds later the boss stormed in the front door and I said loudly, “Thank you so much for your assistance.” She looked over and said to me, “Excuse me, sir,” then said to her boss, “Good morning, Mr. Smith, I have your messages,” and then handed him a small pile of paper as he walked by. When he disappeared to his office she thanked me profusely. I just saved her and she knew it. The information I gave her was invaluable, and my next words would be imperative: “I need your help. I wanted to see the HR manager just for a brief meeting. Can you get me into her office real quick?” She walked me back to the manager’s office and introduced me as “her friend” that stopped in. Within minutes my plan was launched, and all thanks to reciprocity. As a social engineer, look for little opportunities to give out information that will make you valuable to the recipient and more importantly, make the recipient indebted to you. Be aware of your surroundings and what little things you can do to make your targets indebted to you. Remember it doesn’t have to be something amazing, just something that they value. A good point to keep in mind is to not “stalk” the target. Standing and staring at him or her waiting for an opportunity to do or say something can be off-putting. These principles should be natural. Naturalness means you start doing these principles in everyday life. Hold doors for people, be very polite, and look for opportunities to do good things for others. These actions will become second nature and you will have fewer struggles doing them in an audit. Reciprocity is a powerful influence tactic, and the next two principles discussed are closely tied into it. Obligation Obligation has to do with actions one feels he needs to take due to some sort of social, legal, or moral requirement, duty, contract, or promise. In the context of social engineering, obligation is closely related to reciprocation but is not limited to it. Obligation can be as simple as holding an outer door for someone, which will usually make him hold the inner door for you. It can be escalated to someone giving you private info because you create in them a sense of obligation to you. Obligation is a common attack vector used when targeting customer service people. You can also use obligation in small doses by utilizing smart complimenting. For example, compliment the person, then follow it up with a request. This technique is very easy to do wrong if you are new or inexperienced and can come across so fake that it alerts the target’s inner sense and has the wrong effect. But if done properly, it can lead to obtaining even little pieces of valuable information. An example of complimenting in the wrong way would be something like, “Wow, you have beautiful eyes, can I get into your server room?” Sounds stupid, huh? Be sure to say your method out loud to see how it sounds. If it sounds like a cheap pickup line then it has to go. A small conversation like this, on the other hand, can be a proper way to compliment: As you approach the receptionist’s desk you see some pictures of a couple of little children at Disney World and after you introduce yourself you say, “Are those your kids? They sure are cute.” Regardless if they are the receptionist’s kids or her nephews, she will most likely enjoy your compliment. Then you follow up with, “I have a couple of my own. They keep us young, huh?” “Yes, my two kids. And I am not sure about young,” she chuckles, “but they do tire me out.” “I haven’t taken mine to Disney yet,” I say. “Did you find they enjoyed it at that age?” “Oh yeah, they loved every second of it,” says the receptionist. “As long as my daughter is with her Daddy, she is having fun.” “Ah, yeah, I have my little princess too,” I reply. “Well, I could stand here and talk about my kids all day, but I am wondering if you can help me out. I called in and spoke to someone last week about a new HR software package and I said I would drop off this information packet, but I lost the paper I wrote her name on. I am terribly embarrassed.” “Oh, that’s probably Mrs. Smith,” offers the receptionist. “She handles all of that.” “You are a life saver. I owe you one. Thank you.” These types of compliments go a long way to opening the target up to be more agreeable to influence. The golden rule—treat others as you would wish to be treated—is a key principle in creating obligation. Treating people kindly and giving them something they may need, even if it is as small as a compliment, can create a sense of obligation to you. Psychologist Steve Bressert makes this point in his article “Persuasion and How To Influence Others,” in which he states, “according to the American Disabled Veterans organization, mailing out a simple appeal for donations produces an 18% success rate. Enclosing a small gift, such as personalized address labels, nearly doubles the success rate to 35%. ‘Since you sent me some useful address labels, I’ll send you a small donation in return.’” If you want to prove to yourself the power of this principle try this simple exercise. Even something as small as a question can create obligation. The next time someone asks you a question, say nothing. Just stay silent or ignore it and move on in the conversation. Notice how awkward that is; something as simple as a question creates a sense of obligation to answer. Simply asking the target a question can lead to amazing results. If your first action creates a feeling that there is an expected follow-up, then fulfilling that expectation can lead to strong feelings of obligation. When the person with whom you are interacting expects a result, fulfilling it can create a strong sense of commitment in him or her to do the same for you. This method can be used, for example, by sending the CFO of a company a piece of technology, maybe an iPod loaded with malicious software. When he gets the gift he is obligated to plug it in. One successful attack vector I saw in play was where the social engineer sent a small relevant gift to the CFO or CEO with a card that said, “Please accept a small gift from our company. All we ask is that you browse our products at www.products.com and download our PDF catalog here at www.products.com/catalog.pdf . I will call you next week.” This method was successful every time. Concession A concession , or the act of conceding, is defined as “an acknowledgment or admission,” or “the act of yielding.” Concessions are used often within the social engineering context as a play on the reciprocation instinct of humans. Humans seem to have a built-in function that makes them want to “do unto others as they do unto” you. A social engineer can use the “something for something” idea or the “I’ll scratch your back if you scratch mine” principle. There are basic principles to concessions and how to use them properly: Label your concessions: Make it known when and what you are conceding, which makes it difficult for your mark to ignore the urge to reciprocate. This will take balance because you don’t want to blow a trumpet, so to speak, while you announce a concession, but a simple statement like, “OK, I’ll give you this one,” or “I will meet you halfway,” show you are willing to concede. Demand and define reciprocity: You can start by planting the seeds of reciprocation and this increases your chances of getting something in return. An easy way to start planting these seeds is through nonverbal communication showing that you are flexible, and also by being a good listener. These little things can make a big difference when building feelings of reciprocation in your target. Make contingent concessions: You can use “risk-free” concessions when trust is low or when you need to signal that you are ready to make other concessions. What I mean by this is a concession that does not come with a “now you can do something for me” attitude. By giving in to something the target wants or needs with no counter demand, you can build a very strong bond with the target. Make concessions in installments: The idea of reciprocity is deeply ingrained in our minds. Most people feel that if someone does them a favor then they are socially contracted to eventually return that favor. Similarly, if someone makes a concession, say in a negotiation or bargaining agreement, then one instinctively feels obligated to “budge” a little bit, too. Since this is a fact, you do not have to feel that all your concessions must be at one time. You can make “installments” with your concessions, where you give in a little here and a little there over time to keep your target reciprocating. Concessions are used daily by salespeople, negotiators, and social engineers. A successful social engineer can use and abuse this instinctual tendency by not only resisting the manipulations being placed on them by others but also by trying to take over the situation completely. Concession and reciprocation skills play well with many of the other social engineering techniques discussed within the pages of this book. An example of how many people fall for concessions can be illustrated with telemarketers who call for donations. They use a strategy for gaining concessions after someone is first given the opportunity to turn down a large request. The same requester counteroffers with a smaller request that you are more likely to accept than the large request. Large request: “Can you donate $200 to our charity?” Response: “No, I cannot.” Smaller request: “Oh, I’m sorry sir, and I understand. Can you donate only $20?” People who are not aware of this technique might feel like the burden is taken off of them and realize they can part with a mere $20 rather than the initial asking price of $200. Another great example appeared in an article ( http://ezinearticles.com/?How-to-Negotiate-the-Salary-Using-the-Power-of-the-Norm-of-Reciprocity&id=2449465 ) written by David Hill: The power of this norm can be felt in most bargaining situations. Assume a buyer and a seller are haggling over the price of a car. The seller starts out with a bid at $24,000. The buyer finds this offer unacceptable and makes a counter bid at $15,000. Now, the seller lowers his bid to $20,000, i.e., he makes a concession. In this case, the buyer will most often feel inclined to increase his bid, maybe to $17,000. The reason why the buyer will feel this inclination is because of the presence of the norm of reciprocity. This norm now demands that the buyer responds to the seller’s concession with another concession. As with most of the principles discussed so far, the concession must be valuable to the receiver. You can’t concede something that is valuable only to you or you lose the power you gain with a good concession. As a social engineer, not giving a concession that will cause you to lose face, rapport, or your position is also imperative. A delicate balance must exist between the concession and your standing with the target, and finding it is half the work. Find it, though, and concessions can be a very serious tool in your hands. Scarcity People often find objects and opportunities more attractive if they are rare, scarce, or hard to obtain. This is why you will see newspapers and radio ads filled with “Last Day,” “Limited Time Only,” “Only 3-Day Sale,” and “Going Out of Business Forever” messages that entice people to come from all over to get a share of the soon-to-be-never-seen-again product. The use of scarcity in the sales context is best known with the catch phrase “Act now! Supplies are limited!” Other techniques are the common “The first X callers get a free widget,” or having an intentional short supply of a popular product. In recent times, this practice was most popularly alleged with the Nintendo Wii. Jason Dobson, a writer for Gamasutra, said, “But I think [Nintendo] intentionally dried up supply because they made their numbers for the year. The new year starts April 1, and I think we’re going to see supply flowing” ( www.gamasutra.com/php-bin/news_index.php?story=13297 ). Where I live, a car dealership ran an ad on a Thursday stating it had to get rid of X number of cars due to new stock arriving. The prices were so low and some of the cars—wait for it—were no longer being produced, and that weekend was the last weekend ever that you could come in for a piece of auto-selling history. The sales went through the roof that weekend, so the sale was over right? Nope, that ad ran every Thursday for more than three months. I often wondered how people just didn’t catch on to it, but the dealership sold a lot of cars using this method. Social events can often appear to be more exclusive if scarcity is introduced. The perceived social benefit of attending these events often goes up in these circumstances. In advertising, this point is driven home with ads for music events that point out how the last concert was quickly sold out. Many popular restaurants have been known to close off sections of the restaurant to appear busier than they really are. The perception that they are extremely popular can often trigger a heightened desire to eat at that establishment. To see an ad that actually mentions the use of scarcity in promoting an event, go to www.social-engineer.org/wiki/archives/Scarcity/Scarcity-Advertisment.html . This ad played on four major components of scarcity: The launch is limited access. The application is not public and only limited. Promoters are handpicked and limited. The e-book is free to those lucky enough to be chosen to come. All of these points use scarcity by making the would-be partygoers feel that getting into this event is so difficult that only the elite, the few, and the proud can even have a remote chance of stepping foot onto that hallowed ground. The basics of economics are made up of the allocation of resources that have alternative uses. This allocation is driven by the scarcity of the objects that are being allocated. The rarer the resource, the higher the perceived value the object retains. This rarity is why gold is worth more than salt, which is worth more than clay. Also, within daily interactions scarcity is often used. Scarcity can be introduced into social situations in an attempt to make something one has go up in value. For instance, one might act like he is very busy on a regular basis, and free time is hard to come by. This action may excuse him from not spending time with someone he may have an obligation to spend time with, and at the same time make time that is spent seem that much more valuable. You can manipulate attention through the use of scarcity as well. Think of how many people complain about salesmen bothering them in a store when there is no scarcity of salespeople’s attention, yet they are just as upset when they are ignored by salespeople when their attention is scarce. On the whole, people are driven to desire that which is hard to obtain, because it is viewed as having more value. This holds true for attention as well. Scarcity is often used in social engineering contexts to create a feeling of urgency in a decision-making context. This urgency can often lead to manipulation of the decision-making process, allowing the social engineer to control the information provided to the victim. This is done commonly by using a mixture of authority and scarcity principles. For example, saying something like, “The CFO, Mr. Smith, called me before he left for the long weekend and told me to come down and fix his email problem. He said he was sick and tired of the crashes and wanted it fixed before Monday.” This creates urgency alongside scarcity in that the CFO is not available to speak to and time is the scarce item. Using scarcity mixed with other principles can also make the attack even deadlier. Either way, scarcity creates a desire and that desire can lead someone to making a decision he might regret later. This was proven to me recently when a truck pulled into my driveway with a freezer in the back. This decently dressed young man approached my wife and explained that he is a meat salesman. He delivers meat to customers and was just about to head back to the office and saw her working in the yard. He began talking about meat prices and how expensive things are in the store. My wife is a very price-conscious shopper, so this built rapport. Plus he had a very pleasant southern accent and called her “ma’am” and was very respectful. After a few minutes of talking, she blurts out the question that usually stops salesmen dead, “How much do you want?” Without missing too much of a beat he says, “Listen, I have been selling these all day for $400 per box, but this is my last box. I would love to just go back to the office with an empty freezer and give you some high-quality meat in the meantime.” Oh no, the last box! He told her before he only comes through once every two months. The desire has been raised, but my wife is no dummy. She knew she was being manipulated. She excused herself and came to get me. He went through his spiel and laid on the scarcity thick. Of course, this type of an account can be a lesson on how to not fall for this tactic. The problem is that emotion gets involved. He sees that I have a grill outside that looks used, so he knows I love to cook outside and he plays on that. He then talks about the quality of meat and quickly makes comparisons to restaurant quality and what is in his boxes. Many people could easily fall for the emotional aspect of his sales pitch. “What if it is his last one?” “He is right, this is much cheaper than eating out.” “He comes to me…I don’t even have to drive to the store.” Instead, I whipped out a calculator and asked him for the amount for the two last boxes, divided by the weight and then asked my wife how much she normally pays per pound for a Delmonico or ribeye in the store. When her price came in lower by $3.00 per pound I simply just shut up. Now his emotions get involved. He scrambles to save face. He lowers his price by $150 off the bat. I again do the math and he is still $.50 more per pound. He tries to talk about quality, convenience, and all those aspects that make it worth the $.50 more. I shift my posture and position to be away from him and to show disinterest. Without saying anything, he trails off at the end of a weak spiel and offers me another $50 off. I tell him, “Sorry, I just don’t think it’s worth it.” He then does the classic mistake that shows how his claims of scarcity were false—he caves in more. “How much do you want to pay for these boxes?” “I probably could do $100.” “If you can give me $125 we can call it a deal.” Now mind you a little bit ago he was at $400 per box and they were the last two in this area for two to three months. This should have been a bidding war for that value, but instead, I sent him packing with his two boxes of meat and no cash. The lesson in this story for social engineers is that for scarcity to work it either has to be real, or you have to stick to your guns to give the appearance of reality. People will perceive the value higher when something is really in need. A malicious example of this is how the petrol companies raised the prices of fuel after Hurricane Katrina. The claim was that fuel was in shortage due to the destruction, which caused terrible price increases. Of course, if this were true then the fuel would be worth a lot more than it is; instead it was an example of the claim of scarcity used to make money. Yet at the same time, when BP’s error caused millions of gallons of oil to be lost in the Gulf of Mexico, ruining the ecosystem, instead of fuel prices skyrocketing due to lack of supply, they dropped. How? Well I won’t get into that here, but it proves the point that for scarcity to work, it has to be believable, and this where the oil companies fail and where social engineers can fail, too. From a social engineer’s standpoint, the more limited or difficult it is obtain an opportunity the more value it will have to people. If information is deemed as private, restricted, and hard to come by, and you are willing to share it with someone, you have just gained a lot of value in their eyes. A social engineer can leverage scarcity with information by using a statement like, “I am not supposed to be saying this but…” or “I am not sure if you heard this news, but I overheard…” Statements like these spoken in hushed tones imply that this information is scarce. Authority People are more willing to follow the directions or recommendations of someone they view as an authority. Finding a person who has enough assertiveness to question authority directly, especially when that authority holds direct power over him or is face-to-face with him is uncommon. Children, for example, are taught to obey adults such as teachers, counselors, priests, and nannies because they have authority over them. Often, questioning authority is deemed as disrespectful and abject obedience is what is rewarded. These principles carry over into adult life because we are taught to respect authority figures and not question rules or orders given to us by those whom we deem authorities. Unfortunately, it is this principle leads many children into the hands of abusers and molesters. Of course, not this principle solely, but those who prey on children realize how children are taught about authority and often seek out those who appear to be more compliant. Similarly, malicious social engineers use this principle to manipulate their targets to take some action or inaction that can lead to a breach. Understanding how authority is used from a social engineering aspect is important. German sociologist and political economist, Max Weber, defined authority into categories that I have adapted to fit more closely into the realm of social engineering. Legal Authority Legal authority is based upon government and law. This generally applies to law enforcement officers or others who enforce the laws of the land, area, or facility you are presently in. As a social engineer, pretexts that involve law enforcement or other government officials are usually illegal. However, security guards, bank security, or other types of enforcement authority figures can be well represented and are often used by social engineers. In one episode of the BBC television program The Real Hustle, Paul Wilson and his cohorts dressed up like the guards who collect the money. When someone shows up in the uniforms that look similar to the real ones and acts as a normal person in that authoritative position would act, targets have little reason to doubt the imposter is who he “says” he is. Acting as an authority figure is a major ploy used by social engineers to gain access to a company. Another ploy that can be effective is posing as a lawyer who is seeking certain information. Playing a role that is generally feared or respected by the masses can be one way a legal authority ploy is used. Organizational Authority Organizational authority is quite simply any authority defined by means of an organization. Typically, this refers to a supervisory hierarchy. Someone within a position of power in an organization has more power and access to more information than someone at the bottom of the hierarchy. In a social engineering audit, a consultant may impersonate the CIO or someone else with clearly defined organizational authority. The consultant may then be able to obtain passwords or other information from the help desk or any other employee who may perceive that the impersonated person has authority over him or her. In a paper entitled “The ‘Social Engineering’ of the Internet Fraud” Jonathan J. Rusch of the U.S. Department of Justice writes, “People are highly likely, in the right situation, to be highly responsive to assertions of authority, even when the person who purports to be in a position of authority is not physically present” ( www.isoc.org/inet99/proceedings/3g/3g_2.htm ). This ploy is used in other ways, by not acting as if you are the CFO, but instead sent or authorized by the CFO. The authority the name and title wields may be enough to grant that power to the attacker in the eyes of the target. Rusch cites an experiment performed by Robert B. Cialdini and recorded in his book Influence (1993), which showed 95 percent of nurses within 22 stations from three different hospitals were willing to administer patients a dangerous dose of medication based upon a phone call from a researcher purporting to be a physician the nurses had never met. This experiment clearly shows that based upon orders and the perceived notion of authority, people might take certain actions despite their better judgment. This type of authority can and is often used to exploit companies into giving away valuable data. Social Authority Social authority refers to the “natural-born leaders” of any social group. A social group could consist of co-workers, college friends, or any other gathering of people. In Influence , Cialdini writes, “When reacting to authority in an automatic fashion there is a tendency to often do so in response to the mere symbols of authority rather than to its substance.” For social authority to occur, an extraordinary amount of time or structure may not be needed to define an authoritative figure. In any setting, a quick flash of social proof , where people are influenced by a group of people taking the same action, may help provide a person social authority. Social authority can be used to an advantage in social engineering by asking or pressuring the target for information. If the target refuses and is therefore not liked by the leader of the group, the target may fall out of favor with the entire group. Complying with the leader’s social authority is perceived to be advantageous. Social authority is successfully used when either directly stated or implied that a previous person or group reacted the way that the attacker is asking. “Yesterday the CFO sent me down to take care of this problem and Joe let me through and he checked all my credentials, did he put them on file?” A simple statement like that utilizes a few forms of authority. If you comply with authorities mindlessly, you may respond to symbols of authority rather than to reality. Three authority symbols are particularly effective in Western countries—you may reward people with any one of these (and no other evidence of authority) for their compliance: Titles Clothes Automobiles In an interview I conducted with Dr. Ellen Langer, Harvard psychologist and researcher of persuasion and influence ( www.social-engineer.org/episode-007-using-persuasion-on-the-mindless-masses ), she talked extensively about mindlessness. She stated that people often do much of their work in a state where there is not much thought; in other words, they are in autopilot. In those positions, the abuse of the authority role is very dangerous. Perceived authority can make someone on autopilot react without limits. Using the right clothes, body language, and even having a fake business card printed has worked for many social engineers in presenting an authority stance and keeping their targets in autopilot. Other forms of authority may come into play for a social engineer than the ones outlined here, but these are the most commonly used. Authority is a powerful force when it comes to influencing others, and with a little bit of reasoning and information gathering a social engineer can effectively use an authority pretext to his or her advantage. Commitment and Consistency People value consistency in others, and they also want to appear consistent in their own behavior. Generally people probably want their words, attitudes, and deeds to be consistent and congruent. Consistency reduces the need to reprocess information and offers shortcuts through complex decisions. Gut feelings—those moments where you sense that an action is good or bad, or right or wrong, based on past experience—are often indicators that a decision being made might be against previously committed feelings and beliefs. These signals often indicate that you feel pushed to agree to something that you don’t want. Gut feelings can also occur when it comes to making commitments. Gut feelings may indicate that you are uncertain of whether your commitment was a mistake. You can ask yourself, “ Knowing what I now know, if I could do that again, would I make the same commitment? ” Before looking at how a social engineer can use consistency to gain someone’s commitment, take a look at three examples that might help hit this point home. Marketing: Companies often spend extraordinary amounts of money to gain market share. There is no real return, but they fight to remain in that share that they believe to be profitable. Coca-Cola and Pepsi are great examples of using marketing throughout the decades in the fight to remain visible, yet often a commercial will not sway a person to switch from Pepsi to Coke. Because the two companies have been “committed” to the war against each other it seems that when one of them comes out with a new product or marketing idea, the other is not too far behind. Auctions: The increased popularity of online auction houses such as eBay has this principle more visible. People feel a level of commitment to something they place a bid on and if someone outbids them it is as if they are compelled to bid again. At times they will even increase the bid way past their comfort zone because they feel committed. One classic example of this is when Robert Campeau bought Bloomingdales. He paid $600 million dollars more than it was worth. Max Bazerman, author of Negotiating Rationally quoted a journalist from the Wall Street Journal as saying, “We are not dealing with price anymore, but with egos….” Carnivals, game houses, and so on: Anytime gambling or game houses are involved a greater risk exists of commitment and consistency being used to persuade people. One columnist, Ryan Healy, an online marketing consultant, wrote a story about when he took his daughter to a circus ( www.ryanhealy.com/commitment-and-consistency/ ). He spent $44 on the tickets, $5 to park his car, then 40 minutes of drive time to get there. He was committed to being at the circus. His daughter wanted cotton candy so he committed to a yes by giving her $5. How could cotton candy cost more than that? When the vendor came by and said the bag was $12, how could he back out on his commitment now? He couldn’t, and therefore ended up spending the $12 on a single cotton candy. Consistency in this pretense is defined as what is expected based on previous experience or expectations. That experience or expectation can motivate a target to take an action that can cause a breach. For example, when the tech support guy comes it is expected he will go to the server room. That request is consistent with the previous experience and expectation. When access to the server room is requested, it is more likely to be fulfilled because it is consistent with what is expected. Commitment and consistency can be strong influence factors upon most people to take actions, give information, or divulge secrets. A social engineer can make commitment and consistency some of the most powerful tools in his or her arsenal. If a social engineer can get a target to commit to something small, usually escalating the commitment is not too hard. In his book Influence , Robert Cialdini writes: The key to using the principles of Commitment and Consistency to manipulate people is held within the initial commitment. That is—after making a commitment, taking a stand or position, people are more willing to agree to requests that are consistent with their prior commitment. Many compliance professionals will try to induce others to take an initial position that is consistent with a behavior they will later request. The social engineer hoping to employ the technique of commitment and consistency usually tries to get the target to divulge a small piece of information toward the overall intended goal. By getting the subject to remain consistent with things he or she has already said, the attacker may get the subject to reveal even more information. On the other hand, the attacker must remain consistent with what he is asking. The attacker should start off small and escalate the information gathering. To use an unrealistic example, an attacker should never start off asking for the nuclear launch codes. This request will be denied, and the attacker will be left few options but to backpedal the request. However, starting off small and escalating the value of the information requested with each new piece of gathered information will seem like a more natural progression and will not appear so obvious to the victim. Going slowly and progressively can be hard as social engineers are often impatient and want to get the “password” right now. Playing it cool and remaining patient can make this avenue rewarding. Clearly defining, maybe even writing out, a path that you can use on each audit can help you go into the audit with clearly defined goals and a path to accomplish them. I created a chart you can see in Figure 6-2 that shows how a social engineer may be able to visualize this path to obtain information using commitment and consistency. Getting a target to verbally commit to a certain action can force the target into a certain path of action. Cialdini states, “The commitment and consistency rule states that once we make a decision, we will experience pressure from others and ourselves to behave consistently with that decision. You can be pressured into making either good or bad decisions depending on your past actions.” Maybe you have felt this if you ever verbally told your wife or spouse that you wanted to lose weight. That verbal “commitment” leads to a lot of pressure to hold up to your end of the “bargain.” Sometimes, ending up disagreeing with yourself can be hard and almost impossible. Everyone has, at one point or another muttered the phrase, “I’m sorry, I changed my mind,” at least once in our lives. When we do, we hang our head in shame, our voice tones drop, and we sound sad. Why? We have just broken a commitment we made and we feel guilty for doing it. Figure 6-2: Clearly defining your goals can help you to obtain an information commitment. Even small, seemingly insignificant commitments can lead to exploitation. For example, a phone conversation often used by solicitors goes something like this: “Hello, how are you today?” You answer, “I am doing great.” Now, prepare for the exploit: “That is good to hear, because some people who are not doing so great can use your help.” You can’t go back on what you said now, because you are still doing great and committed to it. This is not to say that you need to be so paranoid that you cannot even answer simple questions without the fear of exploitation, but being aware that one commitment does not mean you must commit to everything that follows is vital. I once worked with a guy who could literally get anyone to do the worst jobs and make them think it was their idea. Ensuring their commitment was one method he used. If you committed to a path of agreeing with him on certain things, which was almost impossible not to do, because he got you to say “yes” upfront, then you had to continue to say “yes.” Those yeses lead down one path, and that path was right to where he wanted, agreeing to the job he needed to get done. Being aware that it is okay to say “no” can save you from committing to something that could be disastrous. Yet sometimes we convince ourselves that saying “no” is some form of cardinal sin that needs many prayers to be forgiven. In the earlier example of the frozen meat salesman, my wife is a very self-aware person. Knowing she might be manipulated by a “seemingly good deal” she came inside to get me because I am a “jerk.” One of the best examples I have heard that really shows the power of commitment is a social experiment done by Dr. Thomas Moriarty in 1972. He sent an assistant to the beach as a “victim” with a portable radio. The victim sat in his chair listening to his radio for about 10 minutes, then he got up to go purchase a drink. While he was gone, another assistant, the “criminal” who no one knew was working with him, came by to “steal” the radio. Only 4 out of 20 people—that’s only 20%—stopped the thief from taking the radio. The researchers then upped the ante in the next round. Before the “victim” would leave to buy the drink he would ask one of the neighboring sunbathers to watch his radio for him. What do you think the change was? Now a staggering 19 out of 20 stopped the thief, some even resorting to violence. Why the staggering difference? Commitment and consistency. The researcher obtained commitment from the neighboring sunbathers and that caused them to have to act consistently with that commitment. In my opinion, these are amazing statistics that show the power of this influence method. A social engineer can effectively use this method of influence to get a target to commit to even a small act or small “yes” and use that commitment to escalate it into a larger set of actions. Liking People like people who like them. As tongue twisting as that phrase is, it is a very true statement. Understanding the full depth of that statement gets you much closer to mastering persuasion. When I say understand the depth, I really mean that because that sentence has much more to it than meets the eye. This statement isn’t saying that people who like you will respond well. Salespeople are often taught that people buy from people they like. That is true, but not the point. It also isn’t saying that people must like you—it is saying you must like people and then they will like you in return. This task is not as easy as it sounds because liking someone cannot be faked. As discussed in Chapter 5, smiles and happiness are very hard to fake. You must go into the circumstance genuinely caring for the person who you are trying to influence. Caring for people and their feelings is not a standard practice of the malicious social engineer; therefore, they often rely on charm. Charm can work on a short-term basis, but in the long term, liking people is a practiced and learned skill. Liking is used in marketing extensively. In 1990 Jonathan Frenzen and Harry Davis published a study entitled, “Purchasing Behavior in Embedded Markets” ( www.jstor.org/pss/2626820 ) that examined why Tupperware parties are so successful. All of their research led to this principle of liking. The researchers concluded that most people bought because they wanted the hostess to be happy, to help a friend, and to be liked. How embarrassing to go to a party like this and not buy anything! That fear of not being liked is what will drive most people to purchase at these parties and it has little to do with wanting more Tupperware. Other surveys and studies have compared the trust that people have in receiving “tips or advice” from those they consider friends to the trust they have in complete strangers or worse, people they don’t like. A friend can give bad advice and one may be more prone to follow it than good advice from a person one doesn’t like. From a social engineering aspect the concept of liking is a powerful tool. Not only do you have to be likeable and win their trust, but you also have to genuinely be interested in people. This concept goes back to the discussion of pretexting in Chapter 4. When you pretext, you are not merely acting out an idea or belief—you must become the person you are pretexting; that role is what your life is about. If you can do that then the step of liking can become easier. Your pretext will be truly interested in helping, liking, or assisting that person. One last aspect of liking that is important for you as a social engineer is physical attractiveness. Humans tend to automatically “like” those who we find attractive. As vain as that sounds, it is the truth. Some serious psychological principles back up this idea. What is beautiful is good. In 1972 Berscheid, Walster, and Dion performed a study entitled just that, “What Is Beautiful Is Good,” which unleashed some very profound findings. Participants were asked to rate photos of three individuals ranging from low, medium, and high attractiveness. Based on the photos alone they were to rate the people for personality traits, overall happiness, and career success. They then compiled the ratings and averaged them and found that people who were deemed attractive were more socially desirable, had better occupations, were happier, and more successful. The study proved that people tend to link beauty with other successful qualities and it alters their opinions and ability to trust someone. This study is an example of a phenomenon called the halo effect , where one particular trait influences or extends to the other qualities of the person. It has been proven to bias a person’s decisions with a tendency to focus on the good traits of the other person. I have archived a copy of this amazing study at www.social-engineer.org/wiki/archives/BlogPosts/BeautifulGood.pdf . In other words, if someone views you as beautiful, then that good trait extends to other judgments that person makes about you. This halo effect is often used in marketing. Beautiful people are given products to drink, eat, and wear, and other people will automatically assume these things are good, possibly thinking, “Well it must be good if this beautiful person is using it.” Recently I saw an ad on television that really hit this point home—the ad makes fun of marketing efforts but does it very intelligently. An attractive young female comes on the screen wearing beautiful clothing and says, “Hi, I am a believably attractive 18–24 year old female.” Using an attractive female who is not overly attractive, but believably real, someone we normal people can look up to is marketing genius. We can’t really tell her age but her beauty can place her somewhere between the ages of 18–24. “You can relate to me because I am racially ambiguous.” Again, this is another marketing genius tip. She is not black, white, or Native American—we can’t tell, but she may be a mix, which may be attractive to many races and is non-offensive to most. “I am in this commercial because market research shows girls like you love girls like me.” Her beauty and self-assuredness makes us like her; she is well dressed, well spoken, and we want to know her. The camera then pans to different shots of her doing things like kickboxing, cheerleading, and playing with flowers. By showing viewers she can do all these things while being as beautiful as she is, we perceive her as strong and powerful, and all the things she’s doing as good. “Now I am going to tell you to buy something…” She then goes on to sell tampons. This commercial is genius, because the advertiser actually outlines, uses, and educates the consumer on the methods used to make you want to buy. But despite all that, within this commercial lies this principle of liking and the halo effect. Knowing all this about the importance of liking, what can you do? I have a hard enough time becoming an attractive male, let alone an attractive female. Because endless runs to my local plastic surgeon are out, is there anything a social engineer can do to capitalize on this principle? Know your target. Know what is and isn’t acceptable to him or her. How does he dress, and what does he consider bad and good? Too much jewelry, makeup, or other aspect of dress can turn off a target. Suppose you are auditing a doctor’s office and your pretext is a drug sales representative. You know that most sales reps wear suits; have perfect hair; and look, smell, and act confident, a trait of many attractive people, so walking in with spiked hair and facial piercings would draw more attention to yourself than your goal. You must know your target so you can successfully look the way the target would expect. Wear clothing, hairstyles, jewelry, and makeup that will not shock, surprise, or disgust the target. Putting her mind at ease can go a long way toward creating an atmosphere where she will like you, which will build trust and lead to success. A social engineer can look for things to compliment a target on. When engaging a target, and when appropriate, starting the conversation with a simple complimentary question (such as “Those are nice shoes; where did you buy them?”) is useful. People like positive reinforcement. When one receives compliments from another, he tends to stay engaged in order to receive more positive reinforcement. These compliments tend to reinforce a target’s self image, making him feel as if you have a greater-than-normal understanding of him. The University of Minnesota issued a paper ( www.cehd.umn.edu/ceed/publications/tipsheets/preschoolbehaviortipsheets/posrein.pdf ) about reinforcement which states that too much positive reinforcement can have a negative effect. They call it satiation, which means that when reinforcement is given too much it begins to lose its effectiveness. To combat this effect, you can positive reinforcement backed up by a question. This method reinforces positive behavior or attitudes but also makes people happy as they are asked about themselves. Four steps can help you get people to like you: 1. Project a confident and positive attitude. 2. Establish rapport. 3. Synchronize, or get in tune with the target and surroundings using the methods mentioned earlier. 4. Effectively communicate. In his book How to Make People Like You in 90 Seconds , Nicholas Boothman says that people decide whether they like someone in the first two seconds of meeting him or her. After an impression is made changing it can be hard. He promotes coming into an interaction with a good attitude. Having the ability to speak up and communicate effectively in many different situations can make you more likeable. What you project onto others is what they will feel. Your facial expressions, body language, dress, and so on must all project a good, positive attitude. Boothman says some key things in his book about being likeable, including to ask lots of questions, actively listen, and be interested in what people are saying. Doing these things will help people like you. A social engineer may need to practice it, but being likeable will go a long way toward succeeding in your audits. Consensus or Social Proof Social proof is a psychological phenomenon that occurs in social situations when people are unable to determine the appropriate mode of behavior. You can easily assume a behavior is appropriate if you see others acting or talking a certain way. Social influence in general can lead to conformity of large groups of individuals in either correct or mistaken choices. This behavior is common when people enter into unfamiliar situations and don’t have a frame of reference on how to deal with the situation; they mirror their behavior off of others whom they assume are more familiar and therefore better informed. In his book, Influence: The Psychology of Persuasion , Dr. Robert Cialdini states, “Social proof—people will do things that they see other people are doing. For example, in one experiment, one or more confederates would look up into the sky; bystanders would then look up into the sky to see what they were seeing. At one point this experiment is aborted, as so many people were looking up that they stopped traffic.” I will outline some excellent examples of social proof that will help you to see how powerful it is and if you have ever fallen for it. Social proof is used heavily in marketing. Social proof is utilized in sales when high sales numbers are released, demonstrating to potential customers that the product is popular. Another example is when companies release shirts with logos or slogans printed on them, where the wearer then gives an implicit endorsement. Social proof is not just influenced by large groups, but also by high-profile individuals. For instance, a single celebrity becoming associated with product will make others want to be associated with the celebrity’s positive traits, and they will then use the same product. Many examples exist of celebrity endorsements, but in recent years the company that became a major supplier for berets was able to get Samuel L. Jackson to endorse its product, as shown in Figure 6-3 . Figure 6-3: Samuel L. Jackson endorsing a Kangol hat. In its marketing efforts the company said its hats were some of the hottest on the market and the proof was that Mr. Jackson can be seen wearing them. Advertisers often say things like, “largest selling” or “hottest product” to convince their audience that they have the backing of many of our peers in these claims. In addition, the Media-Studies.ca website posted an article on influencing its targets using social proof ( www.media-studies.ca/articles/influence_ch4.htm ): Experiments have found that the use of canned laughter causes an audience to laugh longer and more often when humorous material is presented and to rate the material as funnier. In addition, some evidence indicates that canned laughter is most effective for poor jokes.” The question is: why does it work, especially when the laugh track is often so obviously fake? To answer this question, Cialdini posits the principle of social proof: “One means we use to determine what is correct is to find out what other people think is correct…We view a behavior as more correct in a given situation to the degree that we see others performing it.” As with the other “weapons of influence,” social proof is a shortcut that usually works well for us: if we conform to the behavior we see around us, we are less likely to make a social faux pas. The fact that canned laughter provokes an automatic response in audiences suggests that auditory cues are powerful stimuli because they influence us at a level of consciousness that is difficult to critique. Other examples are how bartenders or other establishments will “salt the tip jar,” by placing a few bills in the jar. As a patron approaches to purchase food the implication is, “Many before you have tipped me, why don’t you?” And it works, too! One of the most profound bits of research in this field that really stands out was done by Dr. K. D. Craig in 1978. Dr. Craig devoted his life to the study of pain and its effect on people. In 1978 he published a paper entitled “Social Modeling Influences on Sensory Decision Theory and Psychophysiological Indexes of Pain” ( www.ncbi.nlm.nih.gov/pubmed/690805?dopt=Abstract ), in which he did an experiment that he described as: Subjects exposed to social models dissimulating tolerance or intolerance generally exhibit matching behavior in their verbal ratings of painful stimulation. It has been unclear, however, whether these changes reflect voluntary alteration of evidence or genuine changes in distress. This study used alternative measures and controlled for methodological limitations of earlier studies by examining non-palmar skin potential in addition to palmar skin conductance and heart rate indexes of psycho-physiological response to electric shock, and by evaluating verbal expressions of pain with sensory decision theory methodology. Several indexes of non-palmar skin potential and heart rate reactivity exhibited lower reactivity in the tolerant group. Tolerant modeling was also associated with decreases in subjective stress. The results were consistent with the position that changes in pain indexes associated with exposure to a tolerant model represented variations in fundamental characteristics of painful experiences as opposed to suppression of information. To boil this down, what he basically did was shock people and ask them to rate their pain level. Then using similar but varying shocks did the same test in the presence of a person who was “tolerant” to the pain; it was as if a magical cloak was over the subject, because they were now more tolerant to pain. This experiment points to the fact that part of the motivation to show, exhibit, or feel pain is related to how others around you act. The people in the study weren’t just acting like it hurt less: Their skin reactions and heart rate actually exhibited less pain reaction when a tolerant model was in place. For a humorous example of the power of social proof, check out a video from the old television show Candid Camera at www.social-engineer.org/framework/Influence_Tactics:_Consensus_or_Social_Proof . This video shows subjects being influenced to face different directions in an elevator, even at one point facing toward the back because everyone else is doing it. There were four to five participants in the elevator acting as patrons. At set intervals, the participants would all turn to the left, to the right, or face backwards. After a few seconds, a hidden camera would catch the unsuspecting subject complying and facing the same direction, removing a hat, or taking some other action. Using social proof as a social engineer can be a deadly tool. This principle can be used to stimulate a person’s compliance with a request by informing him or her that many other individuals, perhaps some who are role models, took the action or behavior you are trying to get this person to do. Social proof can provide a shortcut for determining how to behave. But at the same time it can make targets vulnerable to the manipulations of others who seek to exploit such influence. Social proof is most influential under two conditions: Uncertainty: When people are unsure and the situation is ambiguous they are more likely to observe the behavior of others and to accept that behavior as correct. Similarity: People are more inclined to follow the lead of others who are similar to themselves. These conditions are where a social engineer can use social proof. Stating or even implying that many people before this target have taken a particular action can increase your chances of success. In one social engineering situation where I was stopped by a leery security guard, I simply acted confused as to why I was stopped and said, “Yesterday, Jim let me in after checking all my credentials. I just figured I was still on record.” The present security guard, hearing that Jim approved me, allowed me to pass without question. Social proof won’t always work so easily, but it is a very powerful force. The principles outlined in this section are some of the deadliest influence tactics used today. These tactics can literally give a social engineer powers to motivate people, move them, and cause them to react in ways that will put them in the social engineer’s control. Remember that influence and the art of persuasion is the process of getting someone else to want to do, react, think, or believe in the way you want them to. Creating this motivation within a target is a powerful force; it is a social engineer’s superpower. The principles outlined in this chapter can make that superpower a reality, but not without consequence and lots of work. What do I mean by that? I have often found that after I practice a certain skill and become proficient at it, “turning it off” is very hard. This trait may sound attractive, but being cautious when it comes to who you are influencing, especially as a social engineer, is a good idea. To ingrain these skills into your personality, use them for helping others. For example, when you start to practice reading microexpressions and even using them to manipulate a target, the initial response might be to think you have some mystical power that allows you to almost read minds. This is where caution is wise. Practice the skill and work toward perfecting it, but don’t assume you know it all. If you can influence someone to stop smoking, to start working out, or to be healthier, then you will learn to tap into these skills at will to benefit others, and using them in your social engineering practice is not a farfetched idea. Many of these skills require you to actually be interested in people, care about them, and empathize with them. If these are not natural abilities for you, then you must work hard to obtain those skills. I urge you to take that time, because the skills in the preceding section can lead you to being a grand master social engineer. Imagine you could alter what you think to the extent that gaining these skills could be easier. Imagine now, too, if you could alter the thinking of your targets so what they experience is exactly what you want them to experience. Literally altering the reality of those you interact with, including yourself, is the next topic, and it will just blow you away. Altering Reality: Framing Framing has been defined as information and experiences in life that alter the way one reacts to the decisions one must make. From a non–social engineer point of view, framing is your own personal experiences and the experiences of others that you allow into your conscious mind to alter the way you make decisions. Grocery stores use framing by putting “75% lean” on a package of ground meat as opposed to “25% fat.” These terms mean the same thing (both have 25% fat content) but one sounds healthier and is more appealing to the buyer, and that is why stores use 75% lean as opposed to labeling the actual fat content. The preceding example is simple, but it is also one that helps to show the power of framing. Simply presenting the facts in a different way can make something seem good that would normally be considered bad. The following sections look at a few areas where framing is often used so you can see how powerful it is. Politics Framing has long been used in politics. Simply the way campaigns or messages are worded can make a huge difference in the way the public perceives a message. Consider, for example, George Lakoff, a professional cognitive linguist. In an interesting observation on framing in politics, he states the difference in how people perceive the use of the phrases “Counterterrorism as law enforcement” versus “Counterterrorism as war.” When the 9/11 attacks occurred, Colin Powell argued that they should be treated as crimes. When the public demanded more action and stricter policies, then President Bush announced the “War on Terror” campaign. Another example is the Social Security program in the United States. The name implies that this program can be relied upon to provide security for the future. Yet another example is the difference in the terms bailout versus economic stimulus . Bailout met with lots of opposition because it can paint a word picture of bailing water out of a sinking boat. But economic stimulus paints the mental picture of helping the economy by stimulating the economy. Both programs did almost the same thing, but simple wording made the latter term more acceptable. Judith Butler, Berkeley professor and author of the critically acclaimed book Frames of War, wrote about how framing is used especially in western cultures when it comes to political agendas and war. In her book she explores the media’s portrayal of state violence: This portrayal has saturated our understanding of human life, and has led to the exploitation and abandonment of whole peoples, who are cast as existential threats rather than as living populations in need of protection. These people are framed as already lost, to imprisonment, unemployment, and starvation, and can easily be dismissed. In the twisted logic that rationalizes their deaths, the loss of such populations is deemed necessary to protect the lives of “the living.” These are just a few examples where framing is used in politics. Using Framing in Everyday Life The term frame of reference is defined as a set of ideas, conditions, or assumptions that determine how something will be approached, perceived, or understood. This definition can be helpful in understanding how framing is used. Anything that can alter people’s perceptions or the way they make decisions can be called framing. A friend tells you that last week she went to town and took a certain route that was backed up for 10 miles due to some construction. You might then take a longer route to avoid the potential delay, even though the news your friend shared is more than one week old. Our minds are designed to not like “clutter” or chaos. When presented with things that are cluttered our brains will try to make order out of them. One interesting example of this is found in Figure 6-4 . Figure 6-4: Can you alter your reality frame to change what you see? In your present frame, what is the background and what is the foreground? Your minds will insist on finding familiar patterns in things. We do it in clouds, space, and inanimate objects. Humans also tend to see faces in these things. In Figure 6-4 can you alter your frame and change what is the image and what is the background? Try by focusing on the opposite of what you noticed first. Another very interesting example of how human brains find order in chaos can be illustrated in an e-mail that circulated over the last few years that looked like this: O lny srmat poelpe can raed tihs. I cdnuolt blveiee taht I cluod aulaclty uesdnatnrd waht I was rdanieg. The phaonmneal pweor of the hmuan mnid, aoccdrnig to a rscheearch at Cmabrigde Uinervtisy, it deosn’t mttaer in waht oredr the ltteers in a wrod are, the olny iprmoatnt tihng is taht the frist and lsat ltteer be in the rghit pclae. The rset can be a taotl mses and you can sitll raed it wouthit a porbelm. Tihs is bcuseae the huamn mnid deos not raed ervey lteter by istlef, but the wrod as a wlohe. Amzanig huh? yaeh and I awlyas tghuhot slpeling was ipmorantt! if you can raed tihs psas it on !! I am not sure whether this is actually Cambridge research, but the interesting part in that forwarded e-mail is how many of us who use English as our main language or are very proficient in reading English are probably able to read that paragraph without much effort, because our brains are very efficient at making order out of chaos. Many times the framing is more subliminal. Companies use this in marketing in hopes that the subliminal messages will alter the target’s perception of their product. Many times companies will use subtle measures of framing to plant an idea. For example, Figure 6-5 shows something you probably have seen many times. Figure 6-5: Can you spot the frame? After I show you this, you will never see the FedEx logo the same way again—there is an arrow in the FedEx logo. In an interview with the creator of the logo, he said he embedded the arrow in the logo to plant an idea about FedEx’s services. It is there to communicate movement, speed, and the dynamic nature of the company. Did you find it yet? Look at Figure 6-6 where I outlined and circled the arrow. Figure 6-6: The arrow indicates quality service that is always moving. FedEx is not the only company that utilizes framing. For decades companies have been embedding messages into logos in an effort to frame the thinking of the viewer to remember, think, and view their company in the way they want. The next few figures show more examples. Did you ever notice Amazon’s logo for its embedded framing message (see Figure 6-7 )? Figure 6-7: Do you see the smiling happy customer? Amazon has two framed messages in its logo. One is the happiness you will feel as a customer, represented by the smile in the image, but the smile is also an arrow. That arrow points from A to Z, indicating the Amazon has everything from both points and in between. Another great example is the Tostitos logo. This is a very social logo, as you can see in Figure 6-8 . Figure 6-8: Does this logo make you want to share a chip with someone? The two T’s in the middle are people sharing a chip over a bowl of salsa. In 2004, Tostitos issued a press release that said, “Tostitos plays a role as a ‘social snack,’ helping to create connections between friends and families, whether it’s at a party, during the ‘big game,’ or at simple everyday get-togethers. The new logo brings to life this idea of making connections.” These examples are just a small subset of how framing is used in marketing. Framing is not all about images; mostly it is about the value that the target perceives . The perception that the target has of an item can increase or decrease its value. Take an expensive clothing store—when you walk in everything is hung neatly, pressed, and perfect. The perception can be that the clothing is worth the exorbitant amount of the price tag. Yet, if you were to take one of the ties, shirts, or other pieces of clothing off the rack; bring it to a discount store; and throw it into a large bin full of other clothes marked, “Discount 75% off” your perception of the value of that item of clothing would go way down. Marketing gurus play off this phenomenon in an effort to frame the public’s perception of value. Many companies have been successful at framing to such an extent that people actually have coined phrases to create a whole genre of words to describe products. For example, everyone has probably said, “Will you make a Xerox of that?” even if the machine is not a Xerox but another brand. Xerox is the brand name, not the type of machine. A more recent example is no matter what search engine you use, people often say, “Did you Google it?” because Google has become synonymous with searching on the Web. And people say, “Hand me a Kleenex please,” when really they want a tissue. Others that you might not even be aware were brand names (unless you are of the generation in which they were introduced) include: Aspirin is a trademarked product of Bayer. Thermos is a product name of Thermos GmbH Company. Band-Aid is a trademark of Johnson & Johnson. Frisbee was a trademark of Wham-O. All of those names became so popular that people’s frame of reference eventually encompassed any product similar to it. I never take aspirin—I usually use another brand—but I will always ask for “two aspirin,” be given the brand I use, and be happy. Volumes of information exist about framing, but boiling down this information to some main principles you can use as a social engineer is necessary. The preceding information set a very detailed stage for what framing is and how it is used in different areas of life. Before moving to the social engineering arena, take a look at the different types of framing alignments. Four Types of Frame Alignment Two researchers, David Snow from the University of Arizona and Robert Benford from the University of Nebraska, wrote a paper entitled, “Clarifying the Relationship Between Framing and Ideology in the Study of Social Movements” ( www.social-engineer.org/resources/book/SNOW_BED.pdf ). Snow and Benford argue that when individual frames become linked in congruency and complementariness, that frame alignment occurs, producing frame resonance , which is key to the process of a group transitioning from one frame to another. Snow and Benford then outline four conditions that affect framing efforts: “The robustness, completeness, and thoroughness of the framing effort”: Snow and Benford identified three core framing tasks, and the degree to which these tasks are attended to will determine how much each participant gets involved. The three steps are: 1. Diagnose the frame for problems. 2. Analyze it for solutions. 3. If successful, a call to action. The more effort put into the frame the better chance the person has to call those he is framing into action. “The relationship between the proposed frame and the larger belief system”: People tend to discount frames or proposed frames if a link does not exist to a core belief or a value of their belief system. Trying to convince a person who holds a belief that eating meat is cruelty to animals to go to the steak place down the road that has a great special will certainly fail. The frame must fall with the core of a person’s beliefs to be successful (unless your goal is to use a frame to change his or her core beliefs); it is imperative to success. A large-scale framing change attempt was made through the controversial anti-smoking commercials where volunteers pile up body bags in front of a tobacco industry building’s front door. The body bags represent how many people die every minute, hour, or day from smoking. The hope is to alter the frame of those who support smoking to think about the death toll for those who smoke. “Relevance of the frame to the realities of the participants”: The frame must be relevant to the person (target). It must be creditable and testable as it relates to the target’s experience. You can’t expect to use a marketing frame that will encourage people to take a luxury cruise in a land where people cannot afford food for the day. No matter how good you are at using framing in marketing, it just would fail. For the frame to align, it must not just be relevant but must also be provable in order to hold value, even if that proof is just in the mind of the target. For example, in 2007 a very popular and trusted news source, Insight Magazine (which is owned by the same company as The Washington Times ) reported that then-presidential candidate Obama had attended an all-Muslim school that was known for teaching a very radical and fundamental form of Islam. When this news report was released many believed it right away—why? It fit into the frame of their reality, it seemed credible, and it came from a “trusted” source. CNN, another reputable source for news, sent out investigators, discovered that story was false, and reported its findings. This is a good example of altering people’s frames on a matter using a very trusted source for “truth”—news media. People who wanted to believe that Obama was a radical Muslim ran with that story, and the news went wild. When research revealed the story to be false, many people’s thinking was altered again. “Cycles of protest; the point at which the frame emerges on the timeline of the current era and existing preoccupations with social change”: What is happening in the world can affect a social frame. Think back a few years ago; if the idea of full body X-ray scans were proposed to companies in the U.S. or other Western cultures, the idea would have been thrown to the wind. Activists for privacy would have fought against the idea and won, simply by using the idea of someone being able to see your private areas and potentially saving that picture to mock or sexually harass you. This argument would have outweighed the sales efforts of the creators of the machines. Yet, after the attacks in America on September 11 and the subsequent rise of terrorist activity, those machines are being installed at airports around the globe despite the cries by activists, even arguing with the power of child pornography laws on their side. Why? The social frame of how to remain safe has been altered, allowing a new breed of decision to enter. Snow and Benford propose that when proper frames are constructed as described in these four points, large-scale changes in society such as those necessary for social movement can be achieved through frame alignment. Their studies focus on society as a whole, but these same principles are effective when dealing on a smaller scale or even one-to-one. The preceding discussion is just the process to frame alignment; actually four different types of alignment can occur after these four conditions are met. Although many of these aspects are geared towards framing groups as a whole, the following sections discuss these four framing alignments on a personal level that will show how you can use them on a smaller scale both as a social engineer and/or just as a person wanting to align frames with others. Imagine trying to align your goal of entry to a building with the frame of the security guard designed to stop you. Bringing his frame into alignment with your pretext can ensure success. One thing to remember about frames is that they are never constructed from scratch. Frames are always drawn on already-existing cultural codes that involve the core of a person’s beliefs and experiences. Knowing this will affect how you use framing. Frame Bridging The Cathie Marsh Centre for Census and Survey Information defines frame bridging as the linkage of two or more ideologically congruent but structurally unconnected frames regarding a particular topic. Bridging is not about tricking people into believing your frame as much as your understanding their frame so deeply that you find the connecting link. You then use that connecting link to bring a target into your frame. The situation could be that you want to gain access to an area, building, or piece of information. Your frame is that you want that to happen. The frame of the person you are approaching is not necessarily to stop you; he may not even know what you are going to attempt. If you were to approach the situation in that frame you may alert him to a problem and thereby shut down your chances. By understanding the target’s job, role, and mental outlook you can understand his frame of mind and maybe find a link that will make his transition into your frame much easier. What is your pretext? How would the person you are about to approach treat a person in your pretext? A good social engineer must understand this to be successful. The “gatekeeper” will treat a sales guy differently from the soda delivery guy. Understanding the frame of the target means knowing how he will treat you—not you as a social engineer, but you as the pretext. A more personal example may be to think of how you want others to view you— maybe as cool, “together,” intelligent, or confident. A professor wants to appear smart. A manager wants to appear in control. An athlete wants to appear calm and strong. A comedian wants the audience to view her as funny. All of these are frames that a person wants others to be in alignment with. In the comedian’s case, what if there is a heckler—a person who doesn’t see her as cool, funny, intelligent, or confident? Because of the heckler’s frame they are angry, not happy, put off, or just not interested? If the comedian persists in his frame he may convert some people around him, but until he delves deep and try to understand where someone is coming from he will not be able to align their two frames and bring that person into his frame. The comedian who can handle a heckler is able to put aside her fears about her frame and use the heckler to her advantage. The frame bridging alignment technique can be one of the most powerful used by a social engineer, but involves some preparation to make sure you get it right. A social engineer can utilize this particular form of frame alignment by helping a target bridge the gap of what they see and what they need to believe through a proper pretext. Again, recall the example of trying to gain access to the building as a tech support rep. Your dress, tools, and language must match the frame that the target expects of a support rep. If they do, the bridge is created and alignment occurs. Frame Amplification Frame amplification, according to Snow, refers to “the clarification and invigoration of an interpretive frame that bears on a particular issue, problem, or set of events.” In other words, you will amplify, or focus on, the values or beliefs of the target. By focusing on those values you can find an area that will align your two frames, or at least drive the target to think there is alignment. This form of alignment has been labeled as the most basic of the four because it is more of a maintenance method. It involves the accenting, augmenting, or punctuating of an event as being more important than others, which allows for this event to be linked with other events with greater ease. An example of frame amplification can be revealed if we do further research into the earlier example about the full-body X-ray scanners. The scanners are being sold now as deterrents for terrorists. The frame that they are being sold under is how the recent terrorist activity caused a need for products like these, and here they are to fulfill that need. Yet research into these devices shows they were being built, marketed, and rejected long before the attacks of 9/11 and other recent attacks. Using the events of 9/11 combined with the fear of flying many people have due to those attacks enables the scanner companies to link their frame with the frame of fear many people have, and thereby gain support for implementing these devices in airports around the globe. One of the other strengths of frame amplification is that it can be successfully used to blur the frame and cause people with a certain belief to distance themselves from that belief. For example, many who believed in privacy and the freedom to choose how to be screened have been brought into a different frame by the x-ray scanner manufacturers focusing on certain aspects of other screening methods being unsafe or incomplete, and to prove their point they bring out stories like “the underwear bomber.” Such tactics amplify their frame that the new x-ray scanners are better and safer, using widely held beliefs regarding the lack of security of other methods. A social engineer can utilize this alignment technique in a few different ways. For instance, a social engineer may want to convince a security guard to give him access to an onsite dumpster area. The pretext of working for a waste disposal contractor is good and it very well may work alone, but it would work even better if you presented the idea that there is damage to one of the dumpsters, which represents a security liability for the company. Amplifying that frame can bring you to an alignment with the security guard that the best solution is allowing you onsite to check it out. Frame Extension “ Frame extensions are a movement’s effort to incorporate participants by extending the boundaries of the proposed frame to encompass the views, interests, and, more importantly, the sentiments of a group.” In other words, by extending your frame’s boundaries to encompass other subjects or interests of your target, you can bring them into alignment. For example, the possibility exists that groups who support environmental or “green” initiatives will extend their frame to antinuclear movements, stating they are under the umbrella of a being concerned about the environmental risks. However, a risk with using frame extensions is they can weaken the stance on the original frame and a certain level of appeal can be lost. This can be done by including too many frame extensions into a certain frame, eventually diluting the main frame and causing interest to be lost. Even on a personal level, simple is best. When using this frame alignment tactic, keep it simple and easy to follow. Don’t make the connecting web so convoluted you lose the interest of the target. A social engineer may utilize this frame alignment technique through the elicitation skills discussed in Chapter 3. When a social engineer approaches a target, she can gather information about the target or their company by not acting interested in that but utilizing chit-chat at a party, or with a pretext as a reporter. This will give the social engineer the “right” to ask for information that they would normally have to work very hard to get. Frame Transformation “Frame transformation is a process required when the proposed frames may not resonate with, and on occasion may even appear antithetical to, conventional lifestyles or rituals and extant interpretive frames.” In other words, a social engineer offers new arguments that point to why their frame is better in an effort to transform the thoughts or beliefs of a target from where they are to where the social engineer wants them to be. When a frame transformation occurs, new values and new understandings are required to keep people involved and keep their support. This type of transformation was done on a large social level in the 1970s where the conservative movement was reframed or transformed into a more progressive environmentalist movement. On a smaller, more personal scale, frame transformations occur every day through religious conversion, in which a person’s frame or whole belief system is altered, changed, and transformed to be aligned with a new frame of thought, that of the new religion. Transforming someone’s frame is not easy; it is one of the most complicated alignment tactics to put into practice because it can take: Time: Changing someone’s whole belief structure is not a quick process and can take the usage of other alignment techniques and lots of time to make it work. Effort: Knowing where the target is coming from and where you want him to be are just the initial steps. What will be his objections and mental blocks? Finding out these things will take some work. Education: Knowledge is power. You must help the target understand the new frame you want him to “convert” to. Logic: The education must be logical and not all emotion. The target must be able to reason and rationalize the action he is about to take. The only way he can do that is with logic. Deep emotional ties: Knowledge is what prepares a person for action, logic convinces him the action is good to take, but emotion is what makes the action happen. If you are emotional about your “cause” the target will feel that emotion. Just make sure the emotion you are expressing and feeling matches the pretext. If your pretext is a guidance counselor and you come in like a cheerleader you will offset the target’s ability to align. Being able to align others to your frame and align yourself with theirs can give people incentive to do the things you ask. Although using any of the four framing methods is powerful, a social engineer who is successful in frame transformation has endless power. Read on to find out how to apply these framing techniques as a social engineer. Using Framing as a Social Engineer Throughout this section I mentioned many ways a social engineer might use framing as a technique. Some of these methods are so powerful that perfecting them can turn you into a master influencer. To truly use framing as a social engineer you must understand four things about framing. These four things will help you to understand clearly how framing works and how to use it as a social engineer. Remember what a frame is. A frame is a conceptual structure that our minds use in thinking. This is a vital piece of information because your goal is either to create a new frame, align with a person’s frame, or bring the target into your frame. One of those three goals needs to be outlined with the following four rules in order to master framing as a social engineer. Rule 1: Everything You Say Will Evoke a Frame People’s minds work by picturing things. This natural fact cannot be altered, but you can use it to your advantage. If I start to talk to you about your boss, your mind will picture him. If I paint a picture with words about how he was outside on the cell phone and he was angry, your mind will start to picture his angry face, body language, and words. You will not be able to control this and that mental frame will cause emotions and reactions. Painting a picture with words is a powerful way to use framing. By choosing your words carefully you can cause a target’s mind to picture things you want him to picture and start moving him to a frame you want. Have you ever heard someone who you thought was a great storyteller? Why? What made her great? She was able to paint a mental picture, make you see things in your mind, which intrigues you and gets you involved. This skill is very important for a social engineer. It doesn’t mean you talk as if you are telling a great story all the time, but you want to keep in mind the words you choose because those words hold the power to paint pictures in the minds of the targets. Here is a simple example: I can tell you that I had spaghetti for dinner last night. If you are not a foodie or not Italian, maybe the last time you had spaghetti it wasn’t that pleasurable. Your mental frame is not that strong and you might be turned off. What if I told you that last night my wife made a sauce of vine-ripened tomatoes and basil she grew in the garden? It also had chunks of fresh garlic and oregano in it, as well as a hint of red wine flavors. She served it over a plate of perfectly cooked spaghetti noodles and with homemade garlic bread. Whether or not you are a pasta fan, you are picturing a restaurant-quality dish. This is how you should plan your words with your targets. They should be descriptive, robust, and full of pictures. Yet the caution is not to be overly theatrical as a social engineer. Your goal should be to build a picture with your words, not to draw attention to yourself or your delivery. Rule 2: Words That Are Defined Within a Frame Evoke the Mental Frame You don’t have to use the exact words to make a person picture the frame you want. For example, what do you think of when you read the following sentence? “I saw the insect struggle to get free from the web, but he could not. Moments later he was wrapped up in a cocoon and saved for dinner.” Notice, I didn’t have to mention a spider to make you think of a spider. If I want to frame you into thinking about a spider, I can do it without having to mention the word spider . This powerful rule of influence and framing gives a social engineer the ability to control the target’s thoughts using indirect speech. Toastmasters, the international organization focused on people’s speaking abilities, teaches its members to move people with their speech by getting their audience’s emotions involved. Delivering a story that causes the target to picture the frame you want while involving them emotionally will solidify your standing in leading that conversation. Again, using this method of framing will take planning. A powerful aspect to this frame rule is that while a target’s brain is processing the information you are feeding it and generating the mental pictures you are painting, there is a time when you can plant thoughts or ideas. Unlike where I painted a direct picture of a beautiful pasta dish, this rule allows the target the freedom to picture something else. I could have ended my earlier spaghetti dinner story with, “My wife then served it on a plate of perfectly cooked pasta. What kind of pasta? I am not telling you, you have to picture it,” and when your brain starts to picture it then I can say, “As I twirled it on my fork, the sauce was so thick and perfect it clung to each noodle.” This description paints the mental picture of spaghetti. What other pasta do you twirl? (I know there are others, but you get the point.) Rule 3: Negating the Frame If I tell you to not picture a spider in a web, your brain has to picture the spider first to tell yourself to not picture it. This technique of negating the frame is powerful. Telling a target to be careful, watch out, or be cautious about something automatically puts them in the frame you may want. This technique is often used by professional social engineers. In one interview I did with a panel of social engineers, everyone agreed that this technique works great. During one audit, I dropped a few USB keys that were laden with malicious code that I wanted someone in the company to run without thinking. I approached one of the employees who I had gained the trust of and said, “John, I heard a memo was issued to be on the lookout for a few USB keys that have been dropped. They are looking for them now.” It just so happens that you are in there as a janitor and you dropped the USB keys laden with malicious files, and now by telling people to look out for them, you are in essence planting the seed for them to do your bidding. This kind of a phrase negates the worry they may feel when finding a rogue USB key and cause them to plug it in to see whose it is. Rule 4: Causing the Target to Think About the Frame Reinforces That Frame Every time the brain focuses or thinks about something it is reinforced. The more you can make the target think about or picture the frame you want him in, the easier it will be to reinforce and move him to that frame. Look back at Chapter 2 on communication modeling and analyze how the messages a social engineer will develop can have amazing effects on your targets. I was once traveling in India. I don’t remember the exact incident in the news, but all I know is that President George W. Bush had lost favor with people in Europe. I was flipping through the news stations and saw how people in certain European countries where hanging dolls that looked like George W. Bush in the streets. After wrapping American flags around the dolls they were lighting them on fire. It was a shocking scene and while I was on the phone with my wife that evening I said, “Wow that news story on what’s happening in Europe is crazy, huh?” She hadn’t heard anything about it. Why? News media and news stations are masters when it comes to framing and manipulation. A social engineer can learn a lot from looking at how media utilizes this skill. By using omissions, or leaving out details of a story or the whole story itself, the media can lead people to a conclusion that seems like their own, but really is the media’s. Social engineers can do that, too. By omitting certain details and only “leaking” details that they want leaked, they can create the frame that they want the target to think or feel. Labeling is another tactic used by the media. When they want to frame something positive they may say things like, “the strong defense of…” or “our healthy economy.” These phrases paint mental pictures of stability and health that can help draw positive conclusions. The same rules can apply for negative frames, too. Labels such as, “Islamic terrorists” or “conspiracy theories” paint a very negative picture. You can utilize these skills to label things with descriptive words that will bring a target into the frame you want. Once, approaching a guard booth that I wanted to gain access to, I walked right through as if I belonged. I was instantly stopped abruptly. I looked at the guard in shock and apologetically I used a phrase like, “Oh, yesterday that extremely helpful security guard, Tom, checked out all my creds and let me pass. That is why I assumed I was still on the list.” Labeling the previous guard as “extremely helpful” automatically puts the present guard in a frame I want. If he wants to receive such a prestigious label, he better be as “extremely helpful” as Tom was. Framing is effective because it bends the truth but not so much that it becomes false, so it remains believable. A social engineer can create a desired impression without departing too far from the appearance of objectivity. I read a white paper called “Status Quo Framing Increases Support for Torture,” written by Christian Crandall, Scott Eidelman, Linda Skitka, and Scott Morgan, all researchers from different universities. In the white paper they supplied a very interesting data set that intrigued me on this topic. In the U.S. it seems many people are against the use of torture in wartime as a tactic for gaining intelligence information. The purpose of this study was to see whether the researchers could get a subset of people to agree that torture is less disagreeable by framing the message differently. They took a sample group of roughly 486 people and asked them to read two paragraphs. The first one read: The use of stress by U.S. forces when questioning suspects in the Middle East is in the news. This kind of stress interview is new; according to some reports, it is the first time it has been widely used by the U.S. military. American forces have used many different methods, including strapping detainees to a board and dunking them underwater, stuffing detainees face-first into a sleeping bag, and long periods of hanging detainees by ropes in painful positions. Detainees are also kept awake and alone for days at a time. This paragraph paints the thought that these are new techniques being employed by the U.S. Government to obtain data. The second paragraph read: The use of stress by U.S. forces when questioning suspects in the Middle East is in the news. This kind of stress interview is not new; according to some reports, it has been used for more than 40 years by the U.S. military. American forces have used many different methods, including strapping detainees to a board and dunking them underwater, stuffing detainees face-first into a sleeping bag, and long periods of hanging detainees by ropes in painful positions. Detainees are also kept awake and alone for days at a time. The status quo version of the paragraph was identical, except that the second sentence in the paragraph was replaced with “This kind of stress interview is not new; according to some reports, it has been used for more than 40 years by the U.S. military.” What were the results in just changing one frame—a frame that these are brand-new methods or that these are tried-and-tested methods that have been used for decades? The paper describes the researchers’ measures. Seven items formed the basic set of dependent variables. These items corresponded to a seven-point “button” scale, with the point labels of very much disagree, moderately disagree, slightly disagree, uncertain, slightly agree, moderately agree, and very much agree. All items were reverse scored so that higher scores reflected greater agreement with each item. The conclusion? “The status quo manipulation had an effect on overall evaluation of torture—when described as a long-standing rather than new practice, torture was evaluated more positively; [m]aking torture appear to be the status quo for interrogations increased individual support and justifications for using it as a tactic.” By changing just one little part of the frame the researchers were able to bring a sizeable group of people into alignment and make them agree (for the most part) that torture can be an acceptable policy. That paper’s remarks continued, “They can apply across many, many domains, and can affect judgment, decision making, aesthetics, and policy preferences,” concluding with, “relatively modest changes in the way ethical choices and value dilemmas are presented, framed, or put in context can have profound effect on political choice and policy.” This experiment proves how powerful framing is because it can change even core beliefs, judgments, and decisions that people may have had for years. As a social engineer that is not even the goal most of the time. You are not trying to convert people; you’re just trying to get them to take an action that with a little thought they would reason is not that good to take. Applying the four framing rules and doing a lot of planning can make framing a devastating force to be reckoned with, which is why, unfortunately, malicious social engineers use this technique every day. In the U.S. and “westernized cultures,” especially, people are trained to accept being framed, to accept being told what to think and how to think it. If I told you 15 years ago that almost every program on television would be about watching real people do real things, you might have laughed at me. Why? Because watching shows like that sounded boring and silly. Yet in 2006, the Los Angeles Times stated that the number of reality TV programs jumped up 128% ( http://articles.latimes.com/2010/mar/31/business/la-fi-ct-onlocation31-2010mar31 ), and it hasn’t slowed down much since then, and it’s because watching them is what’s new and hip, and we are told that watching them is good and fun, and everyone does it. These shows are an example of how one thing can be made to look good that most people would have considered silly just a few years earlier. Framing is definitely an art form that when mixed with the science of communication and influence can become a formidable force on a personal level in the hands of a skilled social engineer, through presenting information in a way that can make aligning with the social engineer “easy” for the target, can make him take action that will not leave him feeling guilty, and alter his perception of reality. Framing and influence are key parts of social engineering, although another skill is often associated with the “dark corners” of social engineering. The book’s introduction mentioned peering into these corners; the following section presents the information that will alter the way you look at influence. Manipulation: Controlling Your Target Manipulation is considered by many to be a very dark topic, a topic that creates a sense of fear because of the way it is often portrayed. Taking a look at a few definitions found on the Internet may help to explain: “exerting shrewd or devious influence especially for one’s own advantage” “influence or control shrewdly or deviously” “control (others or oneself) or influence skillfully, usually to one’s advantage” You can clearly see why many social engineers drool over this topic. Can you imagine being able to use your skills to control or influence someone to your advantage? From something as dark as brainwashing to the subtle hints of a salesperson, manipulation tactics are something every social engineer should study and perfect. The aim of manipulation is to overcome the critical thinking and free will of their target. When the target loses his ability to make a decision based on informed processes, they can be fed the ideas, values, attitudes, or reasonings of the one manipulating them. Manipulation is used in six ways that hold true whether the topic is brainwashing or something less insidious. I will quickly go through each one before we get into this very deep section. Increasing the suggestibility of your target. At its most extreme, sleep or food deprivation increases a target’s suggestibility. On the lighter side, subtle hints that build in intensity over time to make your target more suggestible. Gaining control over the target’s environment. This technique can involve everything from controlling the type and quantity of information to which a target has access to much subtler things like gaining access to a target’s social media websites. In a social engineering context, having access to social media allows you to view your target’s communications as well as exert control over the information he receives. Creating doubt. Destabilizing and undermining your target’s belief system can go a long way toward manipulating your target to take an action you want. From a social engineering viewpoint, this must be done subtly. You can’t just barge in and start degrading your target; instead, questioning the rules they follow, their job, or their beliefs can affect the target’s ability to make rational decisions. Creating a sense of powerlessness. This truly malicious technique is used in wartime interrogations to make a target feel a lack of confidence in their convictions. A social engineer can utilize this tactic by taking away the target’s agency by presenting the “facts” you received from someone with authority, thus creating a powerless feeling. Creating strong emotional responses in the target. Strong emotional responses include everything from doubt to guilt to humiliation and more. If the feelings are intense enough, they can cause the target to alter their whole belief system. A social engineer must be careful not to create damaging negative emotions, but using tactics that create an emotional response based on fear of loss or punishment can prove beneficial to your SE goal. Heavy intimidation. Fear of physical pain or other dire circumstances can be used to make a target crack under pressure. Again, most social engineers will not go this route unless they are using corporate espionage as a tactic, but in normal social engineering, this tactic utilizes perceived authority to build strong fear and feelings of potential loss. Most times, however, manipulation is not so extreme. On its very basic level, imagine you’re in a crowded room and someone calls out your name. What is your reaction? Usually it is to turn around or respond with a “Yes?” You have been manipulated, but not necessarily in a bad way. On a psychological level, being manipulated is even more profound. Notice what happens to make that preceding interaction happen: Your brain hears your name, and you automatically formulate an answer (“Yes?”). The connection between that answer and your vocal response is very short. Even if you made no vocal response or if the name-calling is not targeted to you personally, if a question is asked your mind will formulate an answer. Just being in close proximity of two people conversing and overhearing a question will cause your mind to formulate an answer. The answer can be an image or sound in your mind. If a target overhears two people talking about what someone looks like his mind will form a mental picture. If you hear two people telling a joke about a chicken crossing the road, you may picture the chicken, the road, or the whole scene. This type of manipulation is just the beginning of what you can do. Another manipulation tactic is that of conditioning . People can be conditioned to connect certain sounds or actions with feelings and emotions. If every time something positive is mentioned a person hears a pen click, after a short time the target can be conditioned to associate a positive feeling with this sound. One of the most classic examples of conditioning was Ivan Pavlov and what we call Pavlov’s dog, which was discussed in Chapter 5. The question then becomes whether you can use this type of conditioning on people. Although making targets salivate is not on most social engineers’ priority list (although it would be humorous), are there ways to condition a target to react to certain sets of input the way you want them to react? To find the answer, read the following sections, which provide a few examples of manipulation in business and marketing to set a foundation for discussion and an analysis of how to use manipulation on a personal level. To Recall or Not To Recall In May 2010 The Washington Post reported an interesting story ( www.washingtonpost.com/wp-dyn/content/article/2010/05/27/AR2010052705484.html ). The maker of children’s Tylenol, Motrin, Benadryl, and Zyrtec, among other liquid over-the-counter medicines, discovered a defective batch of Motrin and didn’t want to perform a recall due to the costs of such an action. What was the company’s answer? It used manipulation. The company hired a slew of contractors to go from store to store and buy back all the Motrin in the store, which would then be destroyed. Unfortunately, its plans were foiled when a contractor dropped a paper in one store that outlined the plot, which was then reported to the Federal Drug Administration (FDA). On a side note, the FDA did make that company recall 136 million bottles in just one out of four recalls. Unfortunately, it was too late because 775 cases were reported of children and infants who had adverse reactions to this tainted batch, with 37 ending in death. The reports are not conclusive whether the deaths were a result of the bad Motrin or a reaction to the Motrin. That is not the focus here. This is a very dark example of manipulation, or at least attempted manipulation. To protect this company’s image it was willing to forgo the proper procedures and the safety of children all over the world. It attempted to manipulate the system and in the process people lost their lives. The documentation that was dropped in the store discussed how the contractors were under orders to buy the product back and not mention “recall” at any point in time. When the company was caught it deployed many interesting manipulation tactics. It deflected the situation by saying the reason for the action was its experts didn’t think a significant risk existed to children. It followed this statement by a formal apology and the firing of six top executives. Then the real manipulation came in. While being questioned, the company stated that they were not trying to do a “phantom recall,” as it was being called. The company was testing the alleged damaged batch by having the contractors buy it back to be tested. If it was found faulty the company would have taken the proper procedures. This company attempted to use a manipulation technique called diversion , to divert attention from what they were really doing to make it seem better than it was. In addition, it used a cover-up technique to manipulate the thinking of those who disagreed with their actions by issuing statements that the company was trying to do testing to determine if there was need for a recall. This type of manipulation is worth discussing because a diversion tactic can work on a much smaller scale in a personal setting, too. If you are caught in an area or place you should not be, then having a good cover story that is believable can go a long way toward manipulating the target to allow you safe passage. Diverting the target’s attention to something other than the problem at hand can give you enough time to redirect his or her concern. For example, if you are caught by a security guard, instead of getting nervous, you could simply look at him and say, “Do you know what I am doing here? Did you hear that some USB keys have been lost with very important data on them? It is imperative we find them before everyone comes in tomorrow. Do you want to check the bathrooms?” Many of you probably never heard about the Motrin recall story, showing that the company did a good job of manipulating (so far) the media and justice system to keep the limelight off of it. Regardless, this situation outlines how diversion and cover-up can be used in manipulation. Anxiety Cured at Last In 1998 SmithKline Beecham, one the largest pharmaceutical companies in the world, launched an ad campaign designed to “educate” the masses about something it called “social anxiety disorder.” It planted 50 press stories and surveys with questions like, “Do you have social anxiety disorder?” These quizzes and surveys were geared to “educate” people on this disorder and how to tell whether they suffer from it. Later that year it changed its marketing campaign copy in medical journals from “Paxil means peace…in depression, panic disorder, and OCD” to “Show them they can…the first and only approved treatment for social anxiety disorder.” This change cost the company about $1 million to make. In 1999, a $30 million campaign was launched on print and television announcing that SmithKline Beecham found the cure for social anxiety disorder, and its name is Paxil. Using the data from the surveys and quizzes the company bought spots in some of the “hottest” television shows at that time and spouted statistics that 10 million Americans suffer from SAD (social anxiety disorder), and now there is hope. By 2000, Paxil sales accounted for half of the increase in the entire market: The company “became number one in the U.S. selective serotonin reuptake inhibitor market for new retail prescriptions in 2000.’’ In 2001 it won FDA approval to market Paxil for both generalized anxiety disorder and posttraumatic stress disorder. The 9/11 attacks resulted in a dramatic increase in prescriptions for all antidepressants and anxiety drugs. During this time Paxil’s advertising positioned it as an answer to the uncontrollable feelings of fear and helplessness that many people felt in the aftermath of the attacks. I am not saying that these drugs do not work, or that the company’s motive is malicious, but I find this case particularly interesting in that the manipulation of the market started with education and ended with a massive increase in sales, while creating new disorders along the way. This type of case-building manipulation is often used in marketing, but is also used in politics and even on a personal level, presenting a problem that is terrible, but then presenting “facts” that you have derived as proof of why what you say is true. On one episode of The Real Hustle , Paul Wilson set up a scenario where he had to extract a famous star they were using in a scam to steal some CDs from a store. The store clerk detained the star and waited for the cops to arrive. Paul walked in, identified himself as a cop, flashed his wallet with nothing more than a picture of his kids in it, and was able to “arrest” the star, take the CDs and the money in the cash register as evidence, and leave unquestioned. This story is an excellent example of this type of case-building manipulation. Paul had a problem (the thieving star) and presented himself as the solution (the cop) to the problem. Whatever the scenario, build the case for what a good person you are before presenting your request, and that case makes the request more palatable to the person you’re trying to manipulate. You Can’t Make Me Buy That! Kmart. I felt like just leaving this section at that, but I think I should explain more. Kmart developed an idea it called the planogram , which is a diagram that shows retailers how to display their products based on colors, sizes, and other criteria to manipulate their customers to want to buy and spend the most. Planograms are designed to create optimal visual and commercial product placement. The use of these planograms is a form of manipulation because researchers have studied how people shop, think, and buy. Understanding these things helped them develop mechanisms to control the visual input to increase shoppers’ desire to buy. Software, as well as whole companies, are devoted to planning and executing these planograms for the maximum effect on keeping shoppers shopping. Three different layouts are used to manipulate shoppers: Horizontal product placement: To increase a customer’s concentration on a certain article, a multiple horizontal placement side by side of one product is applied. Some retailers found that a minimum placement range between 15 and 30 cm of a single product is necessary to achieve an increase in customer attentiveness (see Figure 6-9 ). Vertical product placement: A different method used is the vertical product placement. Here one product is placed on more than one shelf level to achieve 15–30 cm placement space (see Figure 6-10 ). Figure 6-9: Placing the same or similar articles in a horizontal row increases customer focus. Figure 6-10: The same products are placed on more than one shelf. Block placement: Products that have something in common are placed in a block (brands). This can be done side by side, on top of each other, centered, or using magnetized hangers (see Figure 6-11 ). Figure 6-11: A block placement of similar products or brands. Planograms are not the only method of manipulating shoppers. One test done involved a shopping mall running specifically designed music loops. The result was that those shoppers stayed in the mall an average of 18% longer than when the music was not running. In the Journal of Business Research , Jean-Charles Chebat and Richard Michon published a study they performed in a Canadian shopping mall ( www.ryerson.ca/~rmichon/Publications/Ambient%20odors.pdf ). The researchers pumped specially designed aromas into the air that were supposed to trigger happiness and the desire to buy. The result there was that an average of $50 more per shopper was spent in that week-long study. Your trips to the shopping malls and grocery stores will never be the same now. However, you can learn a lot from these methods and experiments. Knowing how people group things in their brains can affect how you organize your shelves to manipulate the feelings, emotions, and thoughts of your targets. On the topic of colors, they are a major way to manipulate the emotions of a target. Many of the same principles apply to colors as they do to product placement. The colors you choose to wear or use can affect the target. A lot of research has been done on colors and their effects. The following is a short list of some ways a particular color could affect the thinking or emotions of another person: White: White is often associated with purity, light, and cleanliness. It gives feelings of safety and neutrality as well as goodness and faith. This is why white is often used in weddings or as the color of surrender. Black: Black often denotes power, elegance, mystery, and strength. It is used to denote authority, depth, and stability. Black gives the feeling of calmness and tranquility. Because it contrasts with other colors, it can also be used to enhance other colors. Red: Red is associated with excitement and joy. It is a color filled with celebration, action, and energy. It can denote good health, speed, passion, desire, and love. Red can stimulate emotions as well as increase heart rate, respiration, and blood pressure. Red can trigger strong emotions—use caution when using red. Even though it can denote power and impulsiveness, it can denote force, intimidation, and conquest, even violence and revenge. Be careful how you use red. Orange: Orange gives warmth, enthusiasm, attraction, determination, strength, and endurance. It can stimulate a person to feel invigorated and even stimulate his or her appetite. Orange is another color to be cautious with. Although using orange has many good benefits, like making the viewer feel warm and attracted to you or your product, too much or the wrong combination can create feelings of insecurity, ignorance, and sluggishness. Gold: Gold is usually associated with illumination, wisdom, wealth, and prestige. Yellow: Yellow is associated with energy and optimism, joy and cheerfulness, loyalty and freshness. It can cause a person to feel focused and attentive. Yellow also has an impact on a person’s memory (why are so many sticky notes yellow?). Used in small amounts, it can trigger positive emotions, but too much can cause a target to lose focus or feel criticized. Green: Green is often associated with nature, harmony, life, fertility, ambition, protection, and peace. It can produce a very calming effect, making someone feel safe. Green is another power color but can also make one feel greedy, guilty, jealousy, and disordered if used in the wrong setting or used too much. Blue: Blue is associated with the color of the sky and ocean. It can be linked to intelligence, intuition, truth, tranquility, health, power, and knowledge. It is very calming and cooling and has been known to slow down the metabolism. Blue is the easiest color for the eyes to focus on. It can have many positive effects, but be careful not to make the target feel cold or depressed. Purple: Purple is associated with royalty, nobility, luxury, creativity, and mystery. Brown: Brown is associated with earth, reliability, approachability, convention, and order. It can create emotions of being rooted or connected, or having a sense of order. How can you use all this information? I am not suggesting that with a simple blue outfit you can make someone feel calm enough to hand you her password. Yet you can use this information to plan your attack vectors, ensuring you have the best opportunity to succeed, which includes how you look and how you are dressed. A social engineer would want to analyze the target they will be calling on and make sure the colors they choose to wear augment their ability to manipulate the target and not turn them off. For example, knowing that green may elicit feelings of greed or ambition can help a social engineer decide not to wear green to a meeting with a charity where it might conjure feelings and emotions contrary to the charity’s mission. Wearing something blue to a lawyer’s office, on the other hand, can have a calming effect, allowing the lawyer to open up more. Careful planning and sensible use of these tactics can help ensure the success of your social engineering audits. Conditioning Targets to Respond Positively Conditioning is used in everything from normal conversation to marketing to malicious manipulation. Just like Pavlov’s dog, people have been conditioned to respond to certain items. Human nature is often used to manipulate the majority of people to take actions the manipulators want. When the majority of people think of babies they will smile, we will find talking animals “cute,” and we might even be manipulated to sing a jingle for a popular product in our head. These tactics are so covert that many times we don’t even know they are working. Many times I find myself wondering what a scantily clad, bikini-wearing woman has to do with beer. One example of how conditioning is used is Michelin Tires (see Figure 6-12 ). For years this company has used babies in its ads. Why? “Because so much is riding on your tires.” But these ads have more to them. You see a baby, you smile, and you are happy. That emotion triggers a positive response, and that response conditions you to be agreeable to what is told to you next. When you see the baby you smile; when you see it enough you are conditioned to think of warm, happy feelings when you see Michelin tires. Figure 6-12: Aren’t babies cute? Seeing the baby next to the tire makes you equate positive happy feelings with that brand. This is an example of classic manipulation. Another advertisement (see Figure 6-13 ) that might have had many people wondering from Budweiser—remember those popular frogs belching out “Bud” “weis” and “er”? What do frogs have to do with beer? Along those same lines, think of the more recent Clydesdale horse and his gang of animal friends. These ads are catchy, even funny the first time, but not really explaining why you want to buy their beer. Figure 6-13: Frogs selling lager. This form of manipulation, conditioning, is subtle. You laugh at that commercial, and then later on you pull into your local beer distributor, see a cardboard cutout of the frogs or horse, and smile to yourself, which creates that positive feeling that makes you feel agreeable to buying the product. These conditioning tactics are used often in the world of sales and marketing firms with the goal of manipulating the consumer to buy their products over the competition. Social engineers aren’t really selling a product, but they do want their targets to “buy” the lines they are selling, the pretext they are putting out there, and the actions they want the target to take. But why use manipulation? What are the incentives to utilizing this powerful form of control? The next section covers that very topic. Manipulation Incentives What are the incentives to manipulate someone? This question gets to the root of the methods, thinking, and tactics used in any manipulation. Not all manipulation is negative, but is related to the incentives behind it. But each incentive can be positive or negative. What is an incentive? An incentive can be labeled as anything that motivates you to take an action. It can be money, love, success, or anything—even negative emotions like hatred, jealousy, and envy. The main reasons why people chose to manipulate others can be broken down into three categories: financial, social, and ideological incentives. The following sections look at each of these incentives and how they apply to manipulation. Financial Incentives Financial incentives tend to be the most common, as in the cases mentioned earlier related to increasing sales. Many scams have a financial incentive behind their tactics. How many people play the lottery every day with the hopes of getting that winning ticket? They may spend hundreds of dollars over time, and winning a $20 payoff makes them happy and keeps them coming back for more. A non-malicious example of financial incentive is coupons. If you buy this particular product at this particular store you will get X dollars or cents off. If you are a thrifty shopper or want to try that product you will go to that store. Many commercials that promote furthering your education, career, or skill set use financial incentives by painting a picture that your income will increase after their course or education. The malicious attacker’s incentive for using manipulation is his own financial gain and therefore his motivation and his technique will reflect that. For example, if the malicious social engineer’s goal is to get his target to part with some of his hard-earned money, the social engineer will utilize pretexts that will be “allowed” to ask for money—pretexts like charity organizations are suitable in this scenario because asking for donations or financial information is not out of the ordinary. Ideological Incentives Ideological incentives are the most difficult to describe. Each person’s ideals are different and those ideals can affect the incentive. If your dream in life is to run a restaurant then that is your passion. You will work longer hours and put in more effort than any of your employees. You will also work for less money, because it is your dream or your motivation; for everyone else it is just a job. Dreams and beliefs can be so ingrained in a person that separating them from the person can be almost impossible. When you hear the phrase, “I have a dream,” did you think of Martin Luther King? Some people’s dreams and goals are who they are, not what they think about. People tend to be drawn to those with similar dreams and goals, which is why the phrase, “Birds of a feather flock together” applies so well in this discussion. But it is also why so many people can be manipulated. Look at Christian televangelists, for example. People who have a faith and desire to believe in God flock together. Like-minded people can strengthen each other’s faith and desire to do the right thing, but a televangelist can use that ideology to convince people that God’s desire is for that particular church to prosper, therefore also lining the televangelist’ pockets with cash. The televangelist gives a few motivating sermons and sheds some tears and suddenly people are sending in the checks. These televangelists use the tools of both financial and social ideals (see the following section, “Social Incentives”) to convert their listeners to their ideals so those people part with their hard-earned cash. What is interesting is that if you ask a follower how he feels about the preacher being way richer than he is, he believes it is God’s will. His ideal set has been changed or manipulated. Ideological incentives can also be used for the good by educating people about morals, and even resorting to using fear as the incentive can have great effects on people. Ideological incentives are often taught to children through stories and fables that have meanings behind them. The Brothers Grimm are an excellent example of this type of incentive. Stories that often end in the bad characters suffering physical harm or even death and the good characters, persevering through all forms of hardship, getting a massive reward at the end builds on fear that being bad leads to death or some terrible punishment. Ideological incentives are used in marketing, too, through placing ads where “like-minded” ideals often “meet.” For example, diaper companies market in family magazines, animal shelters market at zoos, athletic gear companies market at sporting events, and so on. This type of incentive gives a greater chance that the goods or services being advertised will be bought by those who share the same ideals. Ideological incentives are used to bring one’s ideals in alignment with those of a like mind. Often, once people are sympathetic to a cause is when the manipulation tactics start. Again, not all manipulation is bad, but it has to be used in the proper way. Social Incentives Social incentives are probably the most widely used and the most complex set of incentives out there, especially when it comes to social engineering. Humans are social by nature; it is what we do in normal daily life. Social incentives also encompass all the other types of incentives. The right relationship can enhance your financial needs and can also adjust, align, or augment your ideals. It could be argued that social incentives are stronger than the other two types of incentives. The power that peer pressure holds over many people is easy to see. For young and old alike, the draw of conformity is powerful. Many times, that which is acceptable is directly linked to a social incentive. One’s outlook on life and self can be greatly affected by his or her social surroundings. In essence peer pressure can exist even in the absence of direct peers. Am I good looking? Well, that depends. If I am in the United States where a supermodel is a size zero and the guys have muscles in places I didn’t know muscles existed, probably not. If I am in ancient Rome where maybe being larger meant I was rich and powerful, then I am. Your whole inner self is framed by your social view of the world. In 1975, the U.S. Air Force ran a study entitled “Identification and Analysis of Social Incentives in Air Force Technical Training” to try to see the power of social incentives on creating leaders during its training drills. It ran four different scenarios with a group and analyzed what effects they had on the students. The end results were that a certain social incentive, usually involving praise or positive reinforcement from peers or authority figures, created a strong bond between the students and instructors: The major conclusion of this entire research effort is that the management of social incentives is a particularly difficult art. While social incentives can be identified and scaled with considerable ease, manipulation and management of the same incentives requires considerably greater effort. The scaling data show high attractiveness value for various social incentives. The results of the field experiment show the positive influence of the acquaintanceship and psychological contract exercise on attitudes toward fellow trainees. Both of these findings underline the importance of social factors. In other words, increasing or decreasing the attractiveness of the social incentive is not too difficult once you know what motivates a person. This phenomenon is particularly evident in groups of teenagers. When they find out what bothers someone, it is often used as a weapon to force compliance. The larger the group that provides the pressure, the greater the chance the target will comply. This is a powerful statement. I wonder how that research would have gone if the researchers had been able to use the plethora of social media sites that exist today. Peer pressure is a strong influence and everyone wants to fit in and be part of the crowd. Social incentives work. In 2007 a group of researchers (Oriana Bandiera, Iwan Barankay, and Imran Rasul) wrote a research paper entitled, “Social Incentives: The Causes and Consequences of Social Networks in the Workplace” ( www.social-engineer.org/wiki/archives/Manipulation/Manipulation-Social-Incentivespdf.pdf ). The report is an interesting study along the lines of the Air Force study, but set in 2007. Basically the researchers analyzed how those who have “friends” at work handle their jobs when they work in groups with their friends. Their conclusion: Our findings indicate there are social incentives—the presence of friends affects worker productivity, despite there being no externalities of worker effort onto their co-workers due to the production technology or compensation scheme in place. Due to social incentives, workers conform to a common norm when working together. The level of the norm is such that the presence of friends increases the productivity of workers who are less able than their friends and decreases the productivity of workers who are more able than their friends. Social incentives are a quantitatively important determinant of a worker’s performance. As workers are paid piece rates based on individual productivity, the strength of social incentives is such that (i) workers who are more able than their friends are willing to forgo 10% of their earnings to conform to the norm; (ii) workers who have at least one friend who is more able than themselves are willing to increase productivity by 10% to meet the norm. Overall, the distribution of worker ability is such that the latter effect dominates so the net effect of social incentives on firm performance is positive. The presence of friends meant that a person would actually work harder or less hard depending on their normal work level. Peer pressure with the absence of the actual pressure can affect people’s work. The pressure is perceived by what is standard. Why? Maybe if a person could work faster or better, she probably didn’t want to appear to be a know-it-all or brown-noser, as these people can be called. Maybe if he is normally more of a slacker, he didn’t want to appear lazy so he pushed up the pace a little. In either case their work ethic was affected by having friends. A good point for management is to always put the hardest workers and natural leaders over the group. But there is so much to learn in this research. This method is how social engineers use “tail-gating.” Being in a large crowd of people coming back from break or lunch and looking like one of the employees minimizes the chance that the security guard will stop you while you walk through the front doors. It is also how whole groups of people can be manipulated into thinking a certain action or attitude is acceptable. You can see this in the entertainment industry as each year the standard of what is acceptable or moral seems to get lowered, yet this drop in standards is sold as “freedom.” These three incentives are not the only types that are used. They can branch off into other aspects beyond the scope of this book, but the question still arises of how you can use them as a social engineer. Manipulation in Social Engineering Manipulation is less about making others think like you do and making them feel comfortable, and more about coercing them to do what you want. Coercion is not a friendly word. It means “to force to act or think in a certain manner” or “to dominate, restrain, or control by force.” Manipulation and coercion use psychological force to alter the ideology, beliefs, attitudes, and behaviors of the target. The key to using them is to make the steps so small they are almost invisible. The social engineer doesn’t want to alert the target he is being manipulated. Some of the following methods may be very controversial and downright horrible, but they are used each day by scammers, identity thieves, and the like. One of the goals of manipulation can be to create anxiety, stress, and undue social pressure. When a target feels that way he is more likely to take an action the social engineer is manipulating them to take. With that in mind, you can see why manipulation is often thought of in a negative light, but it is used in social engineering and therefore must be discussed. Increasing a Target’s Suggestibility Increasing a target’s suggestibility can involve using the neurolinguistic programming (NLP) skills discussed in Chapter 5 or other visual cues. Earlier you read about conditioning people with the use of pen clicks or other noises or gestures that can elicit an emotion even when words are not spoken. I once saw this in action when I was with a person who was manipulating a target. He used a pen click to indicate a positive thought. He would say something positive and then smile and click his pen. Literally, I saw the person begin to smile after about four or five times of hearing the pen click. He then brought up a very depressing subject and clicked his pen, and then the target smiled and felt instantly embarrassed. That embarrassment was the open door he needed to manipulate the target to do what he wanted. Creating a situation where the other person feels susceptible to suggestion can be through repetition of ideas or other means that will soften the target to the ideas you are trying to present. A social engineer can make sure the whole setup is geared towards this manipulation—the phrases used, the word pictures painted, the clothing colors chosen to wear. All of it can make the target more susceptible. William Sargant, a controversial psychiatrist and author of the book Battle for the Mind , talks about the methods by which people are manipulated. According to Sargant, various types of beliefs can be implanted in people after the target has been disturbed by fear, anger, or excitement. These feelings cause heightened suggestibility and impaired judgment. A social engineer can use this device to their advantage by offering the target a suggestion that causes fear or excitement and then offering a solution that turns into a suggestion. For example, in the hit BBC TV show The Real Hustle , the cast ran a scam to show how this works when they set up a booth in a mall that allowed people to buy raffle tickets. People would buy a ticket for a chance to win three prizes worth much more than the ticket they just bought. One woman bought the ticket, and, of course, she won the biggest prize. Her excitement was extreme because she had never won anything like this before. At this point, Paul Wilson gave the suggestion to manipulate her: At the height of excitement he told her she had to call a phone number and provide her bank info to claim her prize. She did it without a second thought. The suggestion made sense, especially in the light of her excitement. Knowing the target and his likes, dislikes, kids’ names, favorite teams, and favorite foods, and then using this to create an emotional environment will make creating a susceptible atmosphere so much easier. Controlling the Target’s Environment Controlling the target’s environment is often used in online social engineering, scams, and identity theft. Becoming part of the same social networks and groups gives the attacker the chance to have “face time” to be able to manipulate targets into acting or thinking the way the attacker wants. Being able to use a target’s social networks to find out what triggers they have is also a powerful tool. I used this method once when searching for an illegal scammer for a client who wanted to get the scammer’s contact details. I was able to gain an account on a forum he used to post his “achievements.” Using this tactic of getting into his environment, then befriending him, I was able to gain his trust, use his social networks to know what he was doing, and eventually get his contact info. Any method used to control the environment of the target can be used in this manipulation technique. Controlling the environment can be as simple as approaching when you know you have the least chance of interruption, or allowing a target to see or not see something that will cause a reaction. Of course, unless you plan on bringing your target to a dark closet, you can’t really control his whole environment, so controlling as much as you can will take planning and research. After you locate your target’s social circles, whether online or in the real world, you will need to spend time planning how you will get an in to control that environment. Once inside, what elements do you want to control? A good social engineer will not come in running for the “kill shot” but will take time to build a relationship and gather information before the final blow is administered. Environment control is often used in police or war-time interrogations. The environment where the questioning will take place will have a certain atmosphere to make the target feel at ease, nervous, scared, anxious, or any other emotion the attacker (or lead officer) wants the target to feel. Forcing the Target to Reevaluate Undermining a target’s beliefs, awareness, or emotional control of a circumstance can have a very unsettling effect on him or her. This tactic is very negative because it is used to make a target doubt what he or she has been told to be true. Cults use this tactic to prey upon those looking for guidance through life. Many times, people who feel lost or confused are convinced that their whole belief system needs to be reevaluated. When the cults have control they can be so convincing that the victims can be thoroughly convinced that their family and friends do not know what is best. On a personal social engineering level you can make a person reevaluate the beliefs he has been taught about what is safe and what is not, or what is corporate policy and what is not. Each day social engineers use similar tactics by presenting one well-thought-out question that can cause the target to reevaluate his stand on a topic and cause him to falter. For example, in this economy, salespeople are hungry to make sales, and you could call the sales department of a company that happens to have a strict policy about downloading PDFs from the web without proper scans and precautions. Yet you can still place this call: “Hi, I am with ABC Company and I want to place an order for your product that could be more than 10,000 pieces. My employer wants me to get three quotes to see whether we can do better. I have uploaded the quote package to our website; can I give you the URL? I am going to a meeting in two hours. Could you look over the package and get me a preliminary quote before then?” Do think this tactic would work? Most likely the salesperson would download and execute that file with little to no thought. You have caused him to reevaluate the policy he has been taught. Making the Target Feel Powerless Making the target feel vulnerable or powerless is another very dark, but effective, tactic. It is often used in social engineering when the pretext is an angry executive or someone who should have power over the target. Angry by the lack of response or the inability of the target to give quick answers, the attacker berates or threatens the target, causing him to doubt his position and feel a loss of power. Another more subtle way this is used is to undermine the belief system using social incentives. In one audit, I was stopped by a custodian while doing scans of the internal network. When she did the right thing for stopping me, I reacted with something like, “Did you know that each year this company deals with a constant battle against network breaches? I am trying to secure you, and you are trying to stop me from doing my job!” My overpowering demeanor caused her to feel powerless and she backed down. Giving a target the impression he has no time to think or there is serious urgency can also make him feel powerless. He cannot take the time to think about how to handle a problem and therefore must make a decision in a way he knows he shouldn’t. This tactic was used after the recent earthquakes in Haiti. A website was launched that claimed to have information on loved ones who might have been lost. Because their claim was that no one was able to provide information on their loved ones but this group who set up the site, they could demand certain criteria be met to obtain this information. Many people, feeling hopeless and powerless, entered too much information and clicked things they knew they shouldn’t and in the end were damaged by it. The BBC issued a story about this and lists some tips to stay protected: http://news.bbc.co.uk/2/hi/business/8469885.stm . Dishing Out Nonphysical Punishment Closely linked to making the target feel powerless is making them feel guilt, humiliation, anxiety, or loss of privilege. These feelings can be so strong that a target might possibly do anything to “regain favor.” Guilt over not giving what was expected can cause humiliation and doubt, which can cause the target to react the way the attacker wants. I don’t suggest using humiliation in most social engineering settings, but I have seen it used on a target in a team effort to open the door, and on another social engineering team member to soften the face of the target, making them more pliable to suggestion. The first attacker approached the target in a public setting trying to get information; he was playing the role of someone important. In the middle of the conversation an underling, who happened to be female (and on the team), came up and asked a question that angered the first attacker. He reacted by saying, “You have to be the dumbest person I have ever met.” In a fit of anger he walked away. The female attacker looked dejected and hurt and was quickly comforted by the target, who fed into her act. The target’s empathy allowed him to be manipulated to give out way more information than he wanted. Intimidating a Target Intimidation is not a tactic that you might think of using in a traditional sense in social engineering. You are not going to tie up your target and go all “Jack Bauer” on him, but you can use intimidation in subtle ways. Suggesting that failure to comply can lead to being laid off or other adverse consequences can intimidate the target to react a certain way. Governments often use this tactic to manipulate society to believe that the economic system is collapsing. This way they can control the emotions of those they govern. You can use it in a social engineering audit even by having an intimidating appearance. Looking busy, upset, and on a mission can intimidate many. Talking with very authoritative expressions can also intimidate people. In business, sending things by certified mail or courier connotes a level of intimidation. Making the person sign for a package whose contents are unknown can make some people intimidated. The goal with this manipulation tactic is to make the target feel uneasy and anxious, which can cause him to react in a way he will later regret, but by then it is too late. These darker manipulation techniques are used successfully by social engineers and professional auditors. Manipulating a person to feel completely helpless causes him or her to feel that giving in to the attacker makes sense. That really is where manipulation differs in a social engineering practice from other forms of influence. With negative manipulation the social engineer leaves and doesn’t care how the target feels later on. Even if a target realizes he has been hacked, it doesn’t matter because the damage is done and the company or person is already infiltrated. Other aspects of social engineering manipulation are just as powerful but not so dark. Using Positive Manipulation Positive manipulation has the same goals in mind as negative manipulation—in the end the target is in alignment with your thoughts and desires. The differences are in how you get there. But in positive manipulation, the target doesn’t need therapy when you are done. Over my years of research, I have compiled some tips about how parents interact with their children to get them to comply with the parents’ wishes. A few of its points on positive manipulation are useful for social engineers. The following sections cover some of these positive techniques. Disconnect Your Emotion from Their Behavior Keeping your emotions separate from your target’s behavior is important. As soon as you let your emotions get involved the target is manipulating you. You can feel emotion, of course, but be in control of what you feel and how you display what you are feeling. You do not want to be the one out of control. You also want to control the negative emotions as much as possible so you can remain in control at all times. Disconnecting your emotions can also put people at ease. This doesn’t mean being devoid of emotion; that is not comforting to people. But if someone is really upset, showing the proper level of concern is good, but if your display of emotion is too much you can offset the target and ruin the gig. Keep your emotions in alignment with the pretext you are trying to achieve. If you do not allow your emotions to get involved you can remain in control at all times. A good social engineer is able to do this despite the actions or attitudes displayed by the target. If the target is upset, mad, belligerent, rude, or if any other negative emotion is displayed, a good social engineer remains calm, cool, and collected. Look for the Positive to Mention Whenever you can, find something to make a joke about or compliment, but without being creepy. You don’t want to walk up to the security guard and say, “So two nuns walk into a bar….” This method probably won’t go over too well. At the same time you can’t walk into the front office and say to the girl behind the counter, “Wow, you’re pretty.” Finding something positive to mention puts everyone at ease, but it must be balanced, controlled, and in good taste. Using the example of approaching a security guard, after introducing yourself, complimenting the picture of her children by saying something like, “Wow, she is really cute; how old, four or five? I have a little girl at home, too,” can go a long way toward opening the door. Assume, Assume, Assume You have probably heard what they say about people who assume, but in this case, assume it all. Assume that the target will act the way you want, assume he will answer the way you want, and assume he will grant you all your requests. Assume with the questions you ask and the statements you make. “When I come back from the server room…” This statement assumes you belong there and you are already granted access. In the security guard situation mentioned earlier, after the compliment maybe offer a follow-up: “When I get back from checking the servers, I will show you a picture of my daughter.” Assuming that what you want will occur is a strong point, too, because it affects your mental outlook. You must have the mental outlook that you are getting what you came for; that belief system will create a new body language and facial expressions that will feed your pretext. If you go in expecting failure you will fail or at best it will affect your body language and facial expressions. If you have the mental outlook that this deal is done, the same will occur. A word of caution, though—don’t take this step so far you become arrogant. For example, going in thinking, “Of course I have this in the bag because I am amazing and the best,” can affect the way you come off and turn off the target quickly. Try Different Opening Lines Starting a conversation with the standard why/what/when is common but try a different approach and see what happens. The research group that runs a popular dating site ( www.okcupid.com ) compiled data that shows the value of starting out with non-traditional openers. Remember the discussion about compliments? Well, the OkCupid guys found that starting off with too “big” of a compliment had the reverse effect than what one would think. Words like sexy, beautiful , and hot had terrible effects on people, whereas words like cool, awesome, and fascinating had a better effect. In usual greetings these guys found that saying things like “hi,” “hey,” and “hello” left the target feeling blah and unmotivated, whereas “How’s it going?,” “What’s up?,” “howdy,” and “hola” were strong openers to use. Of course, these stats are about dating, but the point to be learned is that people react better to nontraditional greetings. Similarly, in a social engineering situation, vary your approach and you may notice an increase in the way the target reacts to the message. Use Past Tense When you want to address anything negative that you do not want the target to repeat, put it in past tense. This technique puts the negative attitudes and actions in the past in his mind, presenting him with the new and improved “clean slate” on which to do good things for you. For example: “When you said I couldn’t get in to meet with Mr. Smith…” as opposed to: “When you say I can’t get in to meet Mr. Smith…. Only verb tense changed, but the effect is very important. It gives the impression that the negative statement is so far in the past, let’s move on to something new and improved. It also makes the target feel that you feel it is in the past. Seek and Destroy Identify, map, and plan how you will handle any disruptive or negative attitudes and actions. Imagine if your pretext is to be a tech support guy who will gain access to the server room. In your previous calls you knew that every day at 10 am a large group goes out for a smoke break. You decide this is a good time as people are shuffling in and out. You go all prepared, but as you enter the building the receptionist has just received some bad news and is an emotional mess. You should have a plan for handling this disruption. If you wait to think about how you will handle potential conversation stoppers, or disruptive influences, until the first time you hear them you will most likely fail to handle them. That presents an interesting thought then. You have to sit back and think like the target: what objections would he raise? When a person he does not know calls or approaches him, what might he say? What objections might he raise? What attitudes would he portray? Thinking through these things can help you to make a game plan for these potential problems. Write down your thoughts and the target’s potential objections and then role play. Have your spouse or friend play the mean gatekeeper or security guard. Of course, he or she cannot imitate elements such as facial expressions and so on. But you can give him or her a small list of conversation stoppers to choose from to test your comeback. Practice until you feel comfortable, but not scripted. Remember the comeback is not to be structured so stiffly that you cannot alter it at all. Positive manipulation can have a very strong effect on the target. Not only does it not leave him feeling violated but if done properly he can feel accomplished and as if he did something good for the day. Summary Manipulation is a key component to social engineering as well as influence. This chapter covered areas of human behavior that spanned decades of research from some of the smartest minds on earth. Common reactions to the thought of manipulating others might be: “I don’t want to manipulate people.” “It feels wrong to be learning this.” These comments represent the way most people think when they hear the word manipulation . Hopefully, you’re now convinced that manipulation isn’t always a dark art and can be used for good. The world of influence has been dissected, researched, and analyzed by some of today’s brightest psychologists and researchers. This research served as the basis of my own research to develop the information in this chapter. The section on framing, for instance, can truly change the way you interact with people, and the concept of reciprocation can shape your thinking as a social engineer and how you utilize influence. Influence is such an amazing topic, though, that volumes of books are devoted to that topic alone. Understanding what triggers a person to motivate him to want to do a certain action and then having that action seem good to the target—that is the power of influence. This chapter illuminated the science and psychology of what makes people tick, and clarified how influence is used by social engineers. Remember, influence and the art of persuasion are the processes of getting someone else to want to do, react, think, or believe in the way you want them to. The power in this statement transcends social engineering and manipulation. It is the key to altering any frame, the key to unlocking any door of manipulation, and the pathway to becoming a master at influence. Social engineers also use many physical tools, some of which might look like they were taken out of a page of a James Bond movie, and they are discussed in the next chapter.",
        "char_count": 175147
      }
    ]
  },
  "cannibal_cap": {
    "meta": {
      "key": "cannibal_cap",
      "title": "Cannibal Capitalism",
      "creator": "Michael C. Hill",
      "filepath": "G:/My Drive/15_E-BOOKS/file007846.epub",
      "subject": "Economics"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Table of Contents Introduction Part One: What’s Wrong with This Picture? Chapter One: The Face of Self-Destruction The Systemic Flaw: Catabolism A House Divided Chapter Two: Putting the Cannibalism in Capitalism Did You Say Ponzi? Sanitized, Institutionalized Selfishness When Capitalism Becomes Cannibalistic The Socialism We Forget We Like Enter Reaganomics China and the World Gaining Villainy and Waste Chapter Three: Suicide-Enabling Case Study: Crash of 2007–9 The Crash Timeline: 2007 Rock Bottom in 2008 Making Sense of It Part Two: How Did We Get Here? Chapter Four: The Evolution of Cannibal Capitalism What Is Normal? Dependencies versus Ideologies New World Economics Genesis of Irrational Exuberance Depression and Recessions When Smith and Keynes Break Down Chapter Five: Devolution of the Real Economy through Cannibal Capitalism Visible Decline of the Middle Class New Deal Gone Wrong Chapter Six: Your Own Opinion or Own Facts? Selective Morality Opposing Parties or Warring Factions? Hypocrisy of Moral Relativists It’s Intrinsic to Democracy Semantics of Social Warfare Part Three: Where Are We Going? Chapter Seven: The Choice of Health The State of Health Health Insurance Conundrum The 2009–10 Health Care Debate Maybe Not “A Right,” but an “Is Right” Chapter Eight: Miseducation of the Masses The State of Education Redesigning How We Teach Needed Function of Public Education Chapter Nine: Power to the People Our Gluttonous Appetite for Energy We’re Addicted to Oil! Where Energy and Environment Collide Impediments to Breaking the Addiction We Need Hydrogen Energy Cannibals Cleaner, Safer, Renewable Energy for All Chapter Ten: Bring the Money Home to Momma Protectionism Won’t Save the Middle Class Embrace Globalization, Spread the Wealth Conclusion We Have to Feed the Middle Class",
        "char_count": 1811
      },
      {
        "heading": "Chapter 2",
        "text": "Copyright © 2012 by Michael Hill. All rights reserved. Published by John Wiley & Sons, Inc., Hoboken, New Jersey. Published simultaneously in Canada. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600, or on the Web at www.copyright.com . Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions . Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Neither the publisher nor author shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages. For general information on our other products and services or for technical support, please contact our Customer Care Department within the United States at (800) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic books. For more information about Wiley products, visit our web site at www.wiley.com . Library of Congress Cataloging-in-Publication Data: Hill, Michael, 1971- Cannibal capitalism : how big business and the feds are ruining America / Michael Hill. p. cm. Includes bibliographical references and index. ISBN 978-1-118-17531-6 (hardback); ISBN 978-1-118-19775-2 (ebk); ISBN 978-1-118-19776-9 (ebk); ISBN 978-1-118-19777-6 (ebk) 1. Income distribution—United States. 2. Industries—United States. 3. Capitalism—United States. 4. Right and left (Political science) 5. United States—Economic conditions—21st century. I. Title. HC110.I5H55 2011 330.973—dc23 2011039742",
        "char_count": 2760
      },
      {
        "heading": "Chapter 3",
        "text": "Introduction There I was, sitting in bankruptcy court. It was all gone. It was over. Why? Why me? What did I do wrong? How was I going to take care of my family? My wife was six months pregnant with our second child, a little sister for our two-year-old daughter. Why did I put their futures at risk? How didn’t I see it coming? I was all in. Everything I had was on the line, but it was all tied up in the “safe” haven of real estate. Everyone said the real estate market only slows, not stops. It was considered more stable than gold. In fact, land is the only property called “real,” and yet there I was. The whole thing had collapsed. They called it a subprime crisis, but the whole economy was in crisis. By 2008, the whole thing had failed. “Dog eat dog world” is just a figure of speech, until you are the one being cannibalized. It was as if the whole country had turned on itself economically; instead of growing through the pain, the pain caused a cannibalization of engines of growth in the economy. Small businesses like mine that produce tangible goods and services and employ regular people were sacrificed, while paper traders who amass vast wealth through the exchange of abstractions derived from the real economy were propped up as too big to fail. It was a panic—a panic initiated by the greatest fear of the super-rich—the fear that they might become a little less rich. For those a little lower on the totem pole, the fear was based on the near reality of losing everything. Just a year earlier, I had won a Custom Builder of the Year award for the Greater Washington Metropolitan region, and my company was valued by an investment bank at $47 million. My homes were featured in magazines, and I was rubbing shoulders with celebrities. We were engaged with a venture capital fund to take the business nationwide and ultimately go public with a stock offering. I thought I’d realized my dream, but it all blew up in my face. Sales froze and I was stuck holding over $10 million worth of real estate that was “underwater,” as they say. I had to retrace my steps. I had to understand the market forces that drove my success, or the illusion of it, as well as its collapse—not just for me, but for everyone caught up in this economy. The old distinctions we once safely made between Wall Street and Main Street have proved to be fallacious. Our money may come from the banks, but the value of that money comes from the real economy of Main Street. When a business fails, they may say, “You win some, you lose some,” but what is a game for some is life and livelihood for so many more. The forces that drive wealth creation and destruction, the flow of capital up and down the socioeconomic ladder, and even the trading of financial instruments that no one understands, govern our lives in ways not easily perceived. I pored over census data, market trends, economic theories and reports, and book after book of analysis of the economy. In the course of my studies, I turned myself into a sort of blue-collar economist, not academically trained in theory, but well practiced in real-world economics and the art of business. I am a career entrepreneur. I have skills in a variety of highly technical areas and very broad work experience. I’ve held jobs ranging from janitorial services to research assistant in a solid-state physics lab, but my life has been business. To understand my predicament, you have to understand my background. My father is a rocket scientist, as turgid as that may sound. This is significant only insofar as the end of his career shaped my view of work, money, and career. He had long dreamed of working for NASA, and that dream came true. He worked on the space shuttle before the time of its first launch. It meant everything to him—perhaps too much. He gave himself fully to the space program, and in the end, it cost him his family. Now, there are many details that I won’t describe here, but in short, when he faced the life-changing choice between career and family, he chose career. Ironically, a short while after my parents divorced, the space program suffered wide-ranging budget cuts, and he was laid off. He played by the rules and got a good education and a good job, but ultimately, his dream was empty. The illusion shattered. If being a rocket scientist—the well-worn cliché for any intellectual challenge—is a guarantee of nothing, then what is? I became determined to chart a distinct course. I would not live my life that way. Think about it—my father’s education and diligence led to a dead end, while college dropouts like Microsoft’s Bill Gates and Oracle’s Larry Ellison number among the richest men in the world. To me, it’s strong evidence that something is very wrong with what we are all generally taught. “Go to school, get good grades, pick a career, get a degree, put your money in a bank, work hard for job security, buy a house, and retire to a warm place.” It’s standard fare, but it doesn’t really work, at least not anymore. Feeding people that garbage may maintain the status quo, but it doesn’t meet the ambitions of overachievers, and it hasn’t led the national economy to a brighter future. The axioms of success sounded hollow to me. The school system has gone to pot. Careers hardly ever last a lifetime. Banks rarely pay more than the lowest recent inflation rate in interest even on certified deposits, which of course means that your savings constantly shrink in value. There is no such thing as job security. And now even your house, the most significant investment regular people ever make, may not be worth what you paid for it. If you are fortunate enough to have home equity, then vultures hover ready to give you a reverse mortgage. 1 No, I was going to find another way. I gave up my earlier goal of pursuing a career in science like my father. Instead of completing an MD-PhD double doctorate, I redirected my training from physics to a degree in medical applications. I worked for a short while in a hospital, but maintained a constant lookout for my first major business venture. I found that the combination of high turnover, 24/7 shifts, vacations, and sick leave makes the entire medical services industry utterly dependent on temporary workers. So I quit my job and started a medical temp service. In short order, I was providing nurses, X-ray techs, and medical assistants to doctors’ offices, clinics, and hospitals throughout the mid-Atlantic. I sold out of that business while it was still on the rise. But I didn’t let go of that vine without a firm grip on a new one. Just in time for the PC revolution, I started an IT consulting and training company. It was a natural fit. I had been programming computers since I was ten years old. Remember, my father is a scientist, and there were always computers around the house. In almost no time, I racked up all of the certifications needed to maintain credibility and acquire contracts. This company also grew and flourished until the dot-com crash. Just before the dot-com crash, the hot thing to do was day trade. A number of online brokerages were bringing the stock market to the masses. Day traders take advantage of online access and cheap fees to rapidly buy and sell publicly traded stocks. I was only too eager to diversify my wealth-building path and join this revolution. For a while, people were making a killing . . . for a while. The dot-com crash affected me on two fronts (both as an investor and as a proprietor of a technology company), and ever since, the market has been anything but a sure thing. All of this made it clear to me and many others that a safer investment vehicle was needed. So, where did I and so many other, far bigger fish turn? It was to real estate. I played it safer than just real estate. I invested almost exclusively in waterfront property. In fact, I bought waterfront property on the Potomac River in the vicinity of the national capital, Washington, DC. Then I searched for builders to help me develop my land. I was repeatedly disappointed by the offerings of the field. The real estate development industry suffered from an embarrassment of riches. Billion-dollar companies were building cracker boxes and selling them for a fortune because there were no alternatives for homebuyers. Now, don’t misunderstand, there was competition, but all of the players were building the same junk. You’ve no doubt seen it yourself: community after community on vast tracts of land consisting of the same house over and over again, irrespective of the name on the street sign at the corner. Real estate developers only really compete over location, not product. I realized every entrepreneur’s dream: I found a vacant niche in a multibillion-dollar business. It was 2001, and the business of new-home construction was dominated by high-volume, low-quality production developers—as it still is today. The builders had been constantly lowering the expectations and standards of new homebuyers with respect to quality, while increasing the size and superficial amenities of their two or three homogenous designs. Individuality was lost in the home-building business, far from the days of building one unique home at a time. The exception to this ubiquity was principally found among a few ultra-elite design-build firms for the “money is no object” consumer. The divergence of these two market segments had opened a gap; a class of consumer was being ignored, one that could afford more and wanted more than the cookie-cutter product, but that couldn’t afford the custom products currently available. The only companies that were targeting this market segment were just giving them bigger cookie cutters. I was determined to give this market what it really wanted—custom homes at a cookie-cutter price. On one hand, you can’t argue with the simple economic advantage of mass production of a uniform product, but there is always a better way. With my background in information technology, I was certain that technology could be used to normalize the costs of building distinct houses, so I could produce them at a price competitive with the typical cookie-cutter home. I also knew that, given the choice, people would choose individuality. I knew this in my heart, but I had to prove it. For the next five years, I devoted myself to developing systems and procedures to build entire communities of new homes without ever duplicating the same house design, and to do it at or less than the cost of the competition. Despite being what we call a mature industry, the inefficiencies in even the “best” building businesses were shocking to me. The industry was bloated, paper-oriented, and totally stuck in the systems of the baby-boom era, despite the fact that so much of the work is brainwork that lends itself to automation and efficiency improvements. Not only was my theory going to be proved correct, it would be easier than I’d at first believed. Easier or not, in order to obtain significant expansion capital from private equity investors, I would have to demonstrate five years of financial proof of my concept and impressive growth. The five-year financial history of my creation began in 2002. If you do the math and you haven’t been under a rock with respect to what has happened to the housing and credit market, you already know where this is going. Nevertheless, before the crash, my concept did work, and it worked better with each successive year. We grew at an average annual rate of 317 percent and had gross profit margins exceeding 50 percent. Our banks loved us, our customers loved us, and Wall Street was next. At the end of 2006, we thought we were moving into the big league. As we were taken on by a reputable investment bank, my company was ramping up to go national. We were holding (actually, trying to sell) about $10 million in real estate, and for the first time, we detected that something was wrong. I had heard rumblings that the hot real estate market was cooling off, so I dropped the prices of the homes I was trying to sell, but the adjustment was too late. Our cash flow slowly dried up as sales went cold, and I mean stone cold. Months went by and there were no sales—none. Halfway through 2007, a couple other local builders went under. We needed our funding and time was running out. I was covering payroll and other business expenses out of my personal funds. I was overextending myself because I never stopped seeing light at the end of the tunnel. But a sad reality of business is that it is hardest to get financing when you need it the most. The credit was drying up. It was as if we were a microcosmic preview of what the U.S. economy would experience in 2008. Even so, I still hadn’t fully come to grips with reality. Our projected financial reports still looked great, but those were based on sales that weren’t happening. We were hemorrhaging all of our cash, but I still believed. I had no choice. Investors and bankers always want to know how much “skin in the game” you have, but I was far beyond skin. Everything I had from all of my previous business pursuits was now tied up in this business. I believed completely in my business plan (frankly, I still do), and so I was “all in,” as poker players say. In the meantime, I was pushing every investment resource that I could. We had passed through due diligence with an investment fund and thought we were just waiting for a check, but when we missed a milestone in our projections because of no sales, they pulled the plug. We still could have made it, but we needed a sale. Months more went by and still no sales. Fear in business is much the same as fear in the animal kingdom. An animal stricken with fear either runs or attacks—the classic fight-or-flight response. Our vendors and subcontractors were beginning to show this kind of response. Hearing rumors of our financial instability, some stopped showing up to work for us. Material suppliers cut credit lines, and before long, our production operations ground to a halt. It was apparent to all that there was blood in the water. With that, the attacks began. The only thing that could change our course toward destruction was a sale, but by this point we were solidly in the worst housing crisis to grip the country since the Great Depression. Why was this happening? I had heard of subprime lending, but how did it become so pervasive? I responded as I’d been trained my whole life to respond. Although I didn’t follow my father’s footsteps, I was raised to be a scientist. Questions demand analysis. Every action has a cause. I was going to get to the bottom of this, hopefully in time to save my company and my economic life. I remembered a conversation that I had with a mortgage banker from California. It was years earlier. He was describing to me a variety of loan programs that he wanted to sell my customers. These loan products have since become infamous, including interest-only mortgages, option adjustable-rate mortgages (ARMs), and other creative loans to reduce monthly payments. He explained that homes were so expensive in California that these loans had become very popular. In fact, many higher-priced markets in California were utterly dependant on these loan products. I hadn’t given much thought to what he had said until the end of 2007, when these were the very loans blamed for the collapse occurring in the mortgage system. These mortgages were in play far more than anyone realized. Even some of my customers had used them. From my perspective as a homebuilder, the old adage seemed to apply; I didn’t want to look a gift horse in the mouth. To some extent, I wondered how people could afford homes at such rising prices, including the homes I was selling, but hey, if the check is good, the check is good. Nonetheless, the reality is that the median home prices in most of the major regional markets were and still are two to three times the nationwide median home price, but the same has not been true of income. What if that California banker’s statement were true about the broader market? What if a substantial percentage of the housing commerce that had been taking place for those last few years had been based on these loans, now toxic and universally viewed as blight on the economy? I wondered what metrics are used to track and compare income to home prices. You always hear about Case-Shiller and the sales reports from the National Association of Realtors (NAR) and the National Association of Homebuilders (NAHB), but these don’t match consumer buying power to home prices. Analysis of these numbers alone assumes that everything else remains static, but things were no longer static. Approaching the issues of housing supply and forecasting a turnaround without considering the buying power of the market would be futile. Fortunately, when I dug deeper I discovered that there is a much more telling index that gets very little attention. It is the Housing Affordability Index (HAI). The HAI is the standard established by the NAR to gauge the financial ability of consumers to buy a home. A reading of 100 means a family earning the national median family income (reported by the Census Bureau) can qualify for a mortgage on a typical median-priced, existing, single-family home, assuming a 20 percent down payment. An index above 100 signifies that a family earning the median income more than qualifies, and conversely an index below 100 indicates the inability of the median family to afford the median home. On Monday, February 11, 2008, after I had analyzed this ratio and its implications, the Washington Post published my findings in an op-ed column, which I started this way: Subprime, subprime, subprime! I am sick of hearing everyone blame the breakdown in the credit and housing markets on subprime loans. The subprime loans were certainly part of the problem, but mainly they are a symptom of a deeper cause. We are not looking at the bursting of a five-year housing bubble. We are looking at the bursting of a forty-year bubble and the failure of a mortgage loan system to meet the need of the marketplace. This is what people don’t want to think about, because the deeper problem doesn’t have a quick fix. The truth is that the subprime lenders were actually the proverbial “thumb in the dike” for the whole housing market. The real problem is affordability and the incongruity between income and home pricing. I went on to document and describe the effects of this incongruity and the implications of what was going on to the greater economy. My point was that the housing and credit crisis of the late 2000s has been instructive with respect to the overall pattern of attrition in the national economy. Forty years ago, the median price of a house was about two times the median household income, and in some parts of the country it was closer to one-to-one. Thirty years ago it was about three times the median income. This three-to-one price ratio was fairly stable nationally until the last decade, when we saw the median house price jump to four times the median family’s income. In most of the major economic centers of our nation, typical families haven’t been able to buy a home for anything near the national median in decades (see Figure I.1 ). While incomes are higher, they have not come close to matching the growth of property values. It’s loans that put any home within the reach of normal people. Figure I.1 Take for example the Silicon Valley area, which was the driving force for our economy throughout the nineties. Today the median price of an existing home is $775,000, but the median household income is only $62,020. That means that a home costs almost thirteen times an annual income. The housing affordability index, based on a 5.75 percent loan, is 35.71. Home prices in that market would have to drop nearly 70 percent or income would have to triple, and interest rates would have to stay low in that market, in order for the index to rise to a neutral level! And that is not the worst index that I have seen. Similarly low HAIs can be seen in Washington, DC, Boston, New York, San Diego, and all of the other areas hardest hit by the current crisis. Without mortgage options that provide lower monthly payments than traditional thirty-year mortgages, the whole economy tanked, because the majority of families could not afford homes, either new or existing, in the major population centers of our nation. The economic crisis of 2007–9 was very different from anything prior to it. This time, interest rates were at historical lows, and many other economic indicators were fairly strong. At other times in our history, the housing market was influenced by and therefore an indicator of other parts of the economy. The problem this time was systemic to the housing market itself. As the foreboding evidence mounted of the actual severity of the housing crisis, there was a consensus of panic between the United States Federal Reserve (the Fed), the global markets, and even our bipartisan government. The fears were not without basis, but they were not understood, nor was there consensus to the remedies required. As is so often the case, our leaders viewed the problem superficially and sought superficial solutions. The larger problem of America becoming unaffordable for regular Americans still has not been squarely addressed. The housing collapse was merely a rapid acceleration of the slow, consistent pattern of a much longer period, and portended the trajectory of the national economy. Figure I.2 shows the affordability data for some of the major markets that most clearly illustrate the housing affordability problem at its peak in 2007. To understand these figures, we will take San Diego as an example, and examine the table column by column. The median home price was $601,800; a thirty-year mortgage could be obtained at an interest rate of 5.75 percent, and an adjustable rate mortgage (ARM) could be obtained at 4.88 percent. The median income in the San Diego area was $47,067, but to qualify to purchase a median-priced home using conventional mortgage requirements, a family would need to make $134,859. This gives us an index of 34.9, well below the parity level of 100. Thought of another way, nearly two-thirds of the market is unaffordable using conventional mortgages, even at historically low interest rates. More frightening from an economic perspective is the fact that home prices would have to drop more than 65 percent to reach parity, and more like 75 percent to reach a healthy level. To a prospective homebuyer, this drop doesn’t necessarily seem to be that bad, but if you bought a home for $600,000 and its value dropped to $200,000, the effects would be devastating. Consider the effects on the bank that lent 80 percent or more of that $600,000; consider the fact that the builder spent $500,000 to build that $600,000 house; consider how many components to the economy depend on the presumption of value in real estate; and you will begin to understand the depth of the economic crisis. Figure I.2 There certainly wasn’t enough space on the opinion page to cover all angles. There is much more to the systemic problems that have brought the world to the brink of economic disaster, and an examination of the unfolding of this crisis is instructive for identifying what the structural problems of our national economy are. Many wrote me or posted comments in response to the article, questioning areas that I didn’t have the space to address. While I was interested in even the fiercest criticisms, many simply rehashed the classic partisan viewpoints, which have been shaped by media pundits using the crisis to push their ideological views. It is a sad fact that people always want simple answers to complex problems, and, if someone can match a problem to a political predisposition, it is catnip for the public. This time, though, the stakes are too serious for empty political blather. I am not afraid to address the criticism, because the facts don’t lie. For instance, the easiest response to the housing crisis was to blame the borrowers who “bought homes that they couldn’t afford,” as so many commentators have repeated. Even respected economists like Bill Wheaton, who runs the MIT Center for Real Estate, made such statements. The fact that I avoided laying blame at the feet of the defaulting borrowers seemed to puzzle some, particularly when you consider the debt accumulation theories of renowned economist Hyman Minsky. There was certainly an epidemic of what Minsky described as “Ponzi borrowers,” or those who borrow in the belief that the appreciation of the asset’s value will be sufficient to refinance the debt, but who could not otherwise make sufficient payments on either the interest or principal. The term “Ponzi scheme” is a reference to the Charles Ponzi scandal, and is widely used to describe any fraudulent investment operation that pays returns to investors out of the money paid by subsequent investors, rather than from profit. Now, of course everyone who signs an agreement is responsible for fulfilling the terms of the agreement, and if you can’t afford to fulfill an agreement, you shouldn’t make it. It is almost pointless to restate something so obvious. Nevertheless, to simply blame the consumers who “recklessly” bought into these loans is shortsighted. Even though I agree that some of these people acted inexcusably, I think that you can’t completely blame homebuyers, who were caught up in the same hype that our large institutions were. All the mortgage brokers seemed to have memorized the same line during the run-up years preceding the housing crash: “When the rate goes up, you can just re-fi.” In other words, Minsky’s “Ponzi borrowing” had become institutionalized! Well, the rates went up, and the mortgage market crashed. You couldn’t “just re-fi” and you can’t just blame ordinary people for all of this. Also, the supposition that “these people” should rent instead of buying is undermined by the fact that the differential between owning and renting has recently become negligible in many markets. For example, in 2010, when the median existing-home price was $173,000 and the interest rate for a thirty-year fixed loan was 4.875 percent, covering this whole amount would only require a mortgage payment of about $920 per month. It may not be the case everywhere, but where I live, you would be hard-pressed to find a two-bedroom apartment in a crime-ridden neighborhood for less than that. The rhetoric is empty. It is also atrocious that the public cares so much about foreclosures and so little about evictions. Eviction is far more shocking and immediate to a family than the months-long process of foreclosure, but banks don’t lose money, property values generally don’t radically decline, and MBS traders don’t lose bets when a family is thrown out of their apartment onto the street at a sheriff’s gunpoint after missing one month’s rent. Another “simplistic” response has been to blame the ever-increasing standard size and features of new homes. Robert Lang, codirector of Virginia Tech’s Metropolitan Institute, a research organization that focuses on real estate and development, told Reuters, “People had in their head, ‘I need a mud room, I need giant columns, I need a media room, and I’m going to do anything to get it.’” 2 At first glance, this seems like a reasonable argument. One person who responded to my article cited the fact that the average size of American homes has increased by 60 percent since 1960. Others drew attention to amenities like granite countertops and hardwood floors that are more common today. Blaming rising prices on the fact that homes have gotten bigger and tastes more exorbitant is also off base, because, as counterintuitive as it may seem, there is really no significant corollary between the growing average size of homes and price inflation. In fact, many “luxury” amenities are actually cheap to produce. Also, it is simply a fact that Americans seek an ever-improving standard of living. In our economy, we always expect everything to go up, up, up—monthly, annually, and so on. This is a fact of consumerism as well. Right or wrong, it is a fact of life that people expect to have more than their grandparents. When you also consider the pound of flesh that it takes to get a home today, it is only fair to want to feel that you have gotten something out of it. It is only natural for the one selling to try to satisfy the one buying. More to the point, builders have been building larger homes because it is more profitable to do so. Counter to what common wisdom would suggest, the bigger the houses are, the cheaper they are to build, particularly on a per-square-foot basis. This is because there are many costs that are fixed per unit, but by throwing up a big, cheap box, builders can seemingly “justify” higher prices by offering space. Small, single-family homes are not viable in most major markets. When inexpensive units are needed, the business solution is to build big structures, which are chopped up into townhomes or apartments. Believe it or not, the home-building business is not necessarily as profitable as people may think, partly because of how many hands there are in the pot. Landowners have gotten savvy enough to build development potential into the land prices; gone are the days when farmers sold their land for a pittance. In many cases now, land developers are middlemen that usher raw parcels of land through the legal processes to create “paper” subdivisions so as to sell land at a premium to the builders. This process involves engaging real estate attorneys and civil engineers to create generic subdivisions, further compounding the costs incurred by the builders as they engineer final development and obtain permits. With the increasing influence of so-called NIMBY (Not In My Back Yard) activists, local governments have created more hurdles in the approval process to develop land. Well-meaning or not, this adds to the ultimate costs of new homes, often on a per-unit basis. Add to all of that the escalating costs of material and labor, the cut that goes to lenders, and real estate agents’ fees, and you have a situation in which the cost of small homes wouldn’t be much lower than what we are seeing for seeming unnecessarily large homes. The truth is that size, granite counters, and other finishes are an excuse to create the illusion of worth in the context of rapidly rising costs. Furthermore, even if you were to run the numbers based on the costs to the builders, you would still find that homes are unaffordable. You can’t decouple the cost of buying homes from the cost of building homes. In addition to the well-known laws of supply and demand, home prices are set by the new-home business. And many of the costs of new-home development continue to rise, even in the face of faltering home values. It is true, as many economists and commentators point out, that the readily available loans backed by the power of Wall Street (what MSNBC’s Dylan Ratigan called a “money party”) caused an excessive demand-side run-up in home prices, but with the exception of the 2003–6 run-up, a significant part of home price inflation was the result of natural market inflation. New homes get their prices from costs plus profit margins (sometimes very slim margins). As I mentioned, there are significant costs in the combination of land, material, and labor. To be more specific, there are many market forces at work when it comes to materials and labor. Building materials are international market commodities. Labor costs are tied to the ever-increasing cost of living. There is a floor on how low these costs can go. In fact, there is a danger implicit in allowing market forces to drive existing-home prices too far below the costs of developing new homes. That could mean devastation or perhaps even the end, as we know it, of the largest business in this country, construction, a hundred-billion-dollar-a-year industry. The 2007 housing crisis has already meant the end of certain niches of the construction business. Of all the comments I have received in response to my Washington Post article, the ones that struck me as most significant were the ones that exuded a disdain for the concept of fixing a credit problem with credit. The outspoken congressman Ron Paul stated in a House Financial Services Committee meeting on February 25, 2009, “We have to come to the realization that there is a sea change in what’s happening. [That] this is an end of an era and that we can’t reinflate the bubble,” and many share his sentiments. In fact, so many have echoed Ron Paul’s words that it became common wisdom in the wake of the 2007–9 economic crisis. Mr. Paul went on to say, “Capital can’t come from the thin air creation by the Federal Reserve System; capital has to come from savings. We have to work hard, produce, live within our means, and what is left over is called capital. This whole idea that we can recapitalize markets by merely turning on the printing presses and increasing credit is a total fallacy, so the sooner we wake up to realize that a new system has to be devised, the better.” That also seems to make a lot of sense. It is to the proponents of these sentiments that I dedicate this work, because I agree with them completely in terms of ideology—even though they are wrong. The right thing to do ideologically is the wrong thing to do practically. Even worse, it is utterly fallacious to moralize ideologically along an artificial line. Too many people are focusing on their delusions of what the system should be, instead of accepting what it is. The affordability of purchases made possible only through financing is an illusion created by the terms and wording of the financiers. The paradox is that as people wake up to financial reality, as opposed to what they imagine things “should be,” they suffer the very crisis of confidence that economists most fear. The frightening thing is that the entire global economy is similarly illusory when you examine credit, leverage, exchange, and even currency. What Congressman Paul says you “can’t” do is precisely what has been done in every corner of the global economy over the course of the twentieth century. People use the term “bubble” as if to designate an aberration in the economy, but frankly, the whole system is a bubble—or rather a bubble bath. Secretly we acknowledge this fact by using terms like “inflation” and “deflation.” The Forbes web site Investopedia, defines a bubble as “a situation where the price for an asset exceeds its fundamental value by a large margin. During a bubble, prices for a financial asset or asset class are highly inflated, bearing little relation to the intrinsic value of the asset.” 3 By that definition, the price of a can of Pepsi is indicative of a bubble, unless you really believe that sugar water has “intrinsic value” anywhere near what we all pay. How about bottled water, for that matter? Frankly, the whole monetary system is a bubble. Currency has no intrinsic value beyond that of its paper and ink. Even its implied value is based on abstractions. For instance, who still uses commodity-based currencies, like our old, silver certificates? It’s all credit—all bubbles. But what makes all of this so disturbing is that there was no choice. The creation of an inflated system of “bubbles” is what ended the Great Depression. We had to switch away from the gold standard to what some consider “funny money.” The notion that currency-backed by gold is somehow more “real” is attractive to many. Unfortunately, “real money” and the “real economy” could never keep up with the demands of the growing world. The January 2009 issue of National Geographic reported: In all of history, only 161,000 tons of gold have been mined, barely enough to fill two Olympic-size swimming pools. More than half of that has been extracted in the past fifty years. Now the world’s richest deposits are fast being depleted, and new discoveries are rare. Gone are the hundred-mile-long gold reefs in South Africa or cherry-size nuggets in California. Most of the gold left to mine exists as traces buried in remote and fragile corners of the globe. Let’s do the math: 161,000 tons is 3.864 billion troy ounces, which, at the crisis-inflated gold price of $1,800 per ounce, amounts to $6.96 trillion. That’s less than half of the annual gross domestic product of the United States. Beginning to see the problem? The global GDP (at purchasing power parity) is over $70 trillion. Even if we leveraged all of the gold in the world, and even if the value of gold were inflated to match the global GDP, the price of gold would need to exceed $18,000 per ounce, and would have to rise and fall with global economic activity. This is a gross oversimplification, but it nonetheless makes the point clear. Such gold prices would distort investment; undermine industry, particularly electronics; perhaps render jewelry too dangerous to wear; and to limited degrees damage medicine and scientific research. In addition to those undesirable consequences, the gold standard would still be untenable, because the current distribution of gold would lead to trading that would undoubtedly drop the price, causing worldwide economic turmoil, deflation, and depression. It just wouldn’t work. The world runs on funny money. Really, if you think about money in the absolute, essentially money is a lie that everyone agrees to. It is based on the credibility of the issuing authority and on very broad market conditions. In our country, bills of currency are clearly identified as “notes” signed by the U.S. treasurer and the secretary of the Treasury. The government declares that these notes are “legal tender for all debts, public and private,” and we all say, “Fine.” Uncomfortable brushes with this tenuous reality cause some to long for the days of gold as currency. Yet even the value of gold is assigned based on sentiment, driven up and down by market trading. At the end of the first decade of the twenty-first century, many economists saw the price of gold as another bubble driven high by panic. In describing the end of the world, the Bible says that people will throw their gold in the streets in recognition of the artificial nature of its value and its inability to save them. Gold as “money” is no more real than our Federal Reserve notes. We can see that the whole system is very fragile if we suspend belief for a minute and look objectively. Money is supposed to be a means to an end, the end of providing a mechanism to exchange goods and services without direct bartering. The problem is that money has increasingly been seen as an end in itself, to such an extent that the value of currency has been elevated above real assets, goods, and services. Analysts such as business network CNBC’s Rick Santelli have lambasted the notion of “debasing the currency” at the very time that the real property values were being debased by policies enacted in the wake of the subprime crash. His perspective is understandable when you consider that he has built his career as a financial expert by focusing on futures, bonds, and currency trading. Frankly, perspective is part of our problem. To those who make money from money, currency is more important. To those who build wealth from stuff , stuff is more important. We need a broader view to see beyond these myopic perspectives. Which is really more important: the value of currency, which is ultimately artificial, or the value of land, homes, buildings, labor, and other real things? This is why the housing crisis is so instructive. It was a smaller version of the global economy of paper wealth and instrument-enabled commerce. By the late twentieth century, real estate was expensive. Building materials were expensive. The skills required to put it all together to produce a modern home were expensive. Middle-class people couldn’t afford it, and that was not going to change. The unaffordability of homes had been a reality for decades, but had become even more excessive. A system had to be devised to bring homes within reach of most people. From the beginning of the era of middle-class home ownership, that system has been the mortgage loan. In order to encourage banks to issue mortgages, “mortgage-backed securities” (a bundle of mortgage loans bought from banks that can be traded by investors) were created. Eventually, CDOs (collateralized-debt obligations, a type of structured, asset-backed security in which components are split into different risk classes) and CDSs (credit-default swaps, contracts in which a buyer gets a payoff if a credit instrument, for example a bundled mortgage, goes into default) made trading mortgages in the form of these complex derivatives very profitable. This created a demand for more mortgages to be issued, irrespective of the quality of the loans or creditworthiness of the borrowers. On the ground, this caused a housing boom. The bust occurred when more loans defaulted than expected, the CDSs didn’t pay, and investors began to regard all of these securities as toxic. What really happened? Overvaluing mortgage derivatives drove the market unsustainably high, and excessively undervaluing them caused the whole housing market to collapse. Sentiment drove it all, because ultimately it is all artificial. To the average Joe, the pain of the housing boom and collapse was very real. When suddenly there was demand for more houses because of the mortgage derivative market, it meant jobs for carpenters, plumbers, electricians, masons, engineers, and architects. Rising home prices meant equity that could be used for everything from consumer activity to investment capital to start businesses. Some thought that their ship had finally come in and trickle-down economics was finally working. To the big derivative traders, though, it was just a game—fun at first, but abandoned when things got tough. In markets where nobody wants to play anymore, the thing traded becomes worthless, burning anyone stuck with it. Fixing the housing market is no longer enough. Now the whole economic system has revealed its fundamental flaws and is in jeopardy of collapsing in a sustained crisis of confidence, or even worse, unraveling because of idealistic policies that fail to match reality. The revelation of the extent to which the economy is leveraged is now known, and there is a moral drive to deleverage the system. The entire system of commerce is on the verge of collapse because the curtain has been rent and we can now all see the wizard. My little business went bankrupt like those of so many other builders, but that was nothing compared to the collapse of so many of the great aggregator-distributors of wealth, like Wall Street giants Merrill Lynch, Bear Stearns, Morgan Stanley, Lehman Brothers, and leading mortgage lenders Washington Mutual, Countrywide, IndyMac, and Wachovia. Even the Federal Home Loan Mortgage Corporation (Freddie Mac) and the Federal National Mortgage Association (Fannie Mae), which had no direct connection to subprime loans, as they were required by law to buy only conforming loans, lost billions and ended up under conservatorship. We all now know who Bernie Madoff is. Even Alan Greenspan lost faith in the system. Why shouldn’t we question a system that has brought us to this point? As dramatic as all of this has been, the one-two punch of the housing and credit crises is not all that is wrong with the economy. We have merely seen symptoms of much deeper problems. The combination of modern communication, the broader practice of democracy, conflicting values and realities, political gridlocks, globalization, and the easy money of arbitrage have perversely combined to catalyze the self-destruction of our economy. Arbitrage is the simultaneous purchase and sale of an asset in order to profit from a difference in the price and thus profit by exploiting price differences of identical or similar financial instruments, on different markets or in different forms. On one hand, it can be argued that arbitrage provides a mechanism to ensure prices do not deviate substantially from their fair values for long periods of time, but on the other, it can be argued that arbitrage is a product of the inefficiencies of complex markets. The real problem is the scale of these inefficiencies and the opportunities that are created by them. Some of the richest people in the world have amassed tremendous wealth through arbitrage or arbitrage-like trading. There is a whole class of hedge funds that profits, not by investing in the success of businesses or even by short-selling potential declines from business failures, but by simultaneously taking both long (hoping the share price goes up) and short positions (hoping the share price goes down) in the stocks they trade. Sounds confusing, huh? Not really, though. The whole objective is to profit from volatility. When the stock price goes up, they liquidate long positions, and when the stock goes down, they cash out the short-sells. They are completely indifferent to the success or failure of the public companies they trade. Such hedge fund managers actually prefer “range-bound” stocks (a stock price oscillates between two points, but neither advances nor declines in a sustained way). How does profiting from systemic inefficiencies benefit the broader economy? It doesn’t—in fact, it may undermine it. This is cannibal capitalism. Investment houses, banks, and the like draw some of the country’s best and brightest talents out of the real economy to create new techniques for extracting wealth from the system. People who could have been using their intellect to develop new, tangible commodities that could advance the real economy are instead drawn to the irresistible lure of obscene wealth that can come from making money from money. This sort of thing is making up an ever-increasing chunk of the GDP, and many banks would rather do this than make loans, particularly since the repeal of Glass-Steagall, the law that, in part, separated investment banks from depository banks. We’ve seen the disaster that results when the scams of these big institutions fail. The paper wealth evaporates, leaving behind only carnage. Will this economy survive? Can it? If it does, what form will it take? Will there still be a middle class or will the expression “jobless recovery” haunt the foreseeable future? Seeking the answers to these questions is not merely an intellectual exercise, for we all depend on the global economy. Trading in London affects a plumber starting a business in Tupelo. The labor costs in Xinjiang, China, can undermine union negotiations in Detroit. The world has changed, and our system has not changed in concert with it. In seeking the answers to economic challenges, we always hear from journalists, academics, and Wall Street bigwigs, but in the weeks, months, and years following 2007-9, these experts remained confused by the slow economic recovery, the persistent stagnation of housing and construction, and the failure of tax cuts, zero-percent interest rates, government stimulus, and other public policies to spur job creation. On July 29, 2010, Reuters reported that St. Louis Federal Reserve Bank president James Bullard said the risk of deflation in the United States had risen, even while many economic and policy leaders were panicking over their inflation fears of loose monetary policy, debt, and deficits. Perhaps the confusion is because the bigwigs all live and breathe in the same echo chamber of narrow views; rich guys sitting around talking to each other about the economic realities of the middle class, which they only understand two-dimensionally. We rarely hear from the little guy or from small businesses. I am a small business owner, employer, and outsider. I have spent the last twenty years practicing economics in the real world, not studying it in a classroom. I am not part of any political party. I have no agenda other than to relate the truth, because the fundamental flaws in a democratic, free market, capitalist economy are now beginning to take a toll on millions of lives, including yours. 1. A reverse mortgage is a home loan available to seniors that, whether disbursed as one lump sum or in multiple payments, defers repayment of the loan until the owner dies, the home is sold, or the owner leaves, whereupon the loan is due in full. 2. Andrew Sullivan, “Foreclosures Come to McMansion Country,” Reuters, April 7, 2008. http://www.reuters.com/article/idUSN0130613220080407 . 3. “5 Steps of a Bubble,” Investopedia, 2010, http://www.investopedia.com/articles/stocks/10/5-steps-of-a-bubble.asp .",
        "char_count": 48797
      },
      {
        "heading": "Chapter 4",
        "text": "Chapter One The Face of Self-Destruction He must be nuts! There is an obviously troubled man standing with a gun to his head. He profanely screams at some enemy, accusing him of ruining his life. But, curiously, no one else is there. The gun is pressed to his own temple. Then, as if shifting gears, he abruptly changes tone and speaks as if responding to his earlier rant. As he utters the most odiously vitriolic speech, you notice that he is facing a mirror. This man must suffer from some mental illness. Perhaps a multiple personality disorder? His enemy is another part of himself. Will he pull the trigger? Will he actually kill himself in order to dispatch his enemy? This scene is illustrative of what is going on in America right now. We are that disturbed man. Political preferences have hardened into factions. The indivisible nation is the most divided it has been since the Civil War. The leaders of our cannibal country use the time-tested war tactic of “divide and conquer” against their own people to attain and maintain power. As a result, the extreme wings of the political spectrum don’t merely disagree, they distrust and seemingly despise their counterparts. Because ideological activists carry so much sway in their respective parties, they restrain their leaders from fully seeking cooperation with political opponents. For that matter, the term “opponent” has become a euphemism for far more severe sentiments; it implies that someone with a different political point of view is a villainous enemy, unworthy of existence. The language of political commentators and activists has become so overheated and hyperbolic that leaders of the opposition must be compared to Hitler, Stalin, Pol Pot, or Mao in order to show dissent. Liberal commentator Al Franken wrote a book entitled Lies and the Lying Liars Who Tell Them: A Fair and Balanced Look at the Right , directed at George W. Bush’s administration and political allies. Franken was later elected to the U.S. Senate. Republican insiders Ken Blackwell and Ken Klukowski wrote The Blueprint: Obama’s Plan to Subvert the Constitution and Build an Imperial Presidency . In 2009, Blackwell was a candidate for chairmanship of the Republican National Committee, who withdrew after the fifth round of voting. These are not exactly fringe characters spewing vitriol. Fringe elements take matters quite a bit further. They use vulgarity to describe their political opponents, burn effigies, and in the extreme, commit violence. The Southern Poverty Law Center (SPLC) claimed in a 2010 report that the number of antigovernment militias, which it referred to as “extremist,” grew from 149 to 512 between 2008 and 2009. 4 Then, as if scripted to validate the SPLC warnings, at the end of March 2010, the nine members of the antigovernment Hutaree militia group were arrested for their plot to kill police officers. Minimizing and dismissing the extremists as harmless would be naive. Lest we forget, Timothy McVeigh, domestic terrorist and murderer of 168 victims in his attack on the Murrah building in Oklahoma City, was a militia-movement sympathizer acting on political motivations. With sociopolitical chaos as the backdrop, economically we see scheme after scheme by the nation’s business leaders to extract more and more wealth from the middle class and from the real economy, further spreading the gap between the haves and the have-nots. The resulting economic malaise feeds people’s anger and frustration as they look for someone to blame. The blame game causes a deepening of ideological rifts, undermining efforts for political accommodation. Then, the apparent incompetence of the political structure undermines confidence in the economy, further hastening the extraction of wealth as investors flee to “safe haven” financial instruments. This in turn increases the sociopolitical chaos, as the downward spiral of cannibalization continues. Where will this go? Will we actually kill ourselves? We already are. Slowly but surely, this country is eating away at all of the things that built it up. This slow destruction comes not from without, but from within. It is as if we were a nation of cannibals feeding on one another, with no regard for the self-defeating nature of such conduct. The Systemic Flaw: Catabolism Catabolism is defined by Random House Dictionary as a “destructive metabolism; the breaking down in living organisms of more complex substances into simpler ones, with the release of energy.” If you think of the nation as an organism, we have seen a destructive breakdown of the means of production and a release of “energy” (wealth) to the rest of the world. At the core of government and economics, there are mortal defects. The disease kwashiorkor is a form of catabolism (the human body eating itself) that occurs when a person is getting what would seem to be adequate caloric intake, but little or no protein. You’re getting calories, but they are empty calories. To get “meat,” your body eats itself. Analogously, the economic system, feeding off itself, has aped the operation of healthy markets while not actually sustaining healthy growth. The system has suffered from the worst kind of malnutrition. There are eight principal factors that make this a sort of “cannibalism”: 1. Selfishness. This is the fundamental human flaw behind all that is evil in the world. Overcoming it is an individual struggle, a war we must each wage within our own hearts. There is nothing we can do about that, but, to the extent that selfishness is the core ethic of our institutions and economy, its effects have far-reaching consequences that are ultimately self-defeating. 2. Suicide-Enabling. With selfishness as a core ethic, short-term profits are always chosen over long-term benefits. Whether you are considering broad-based issues such as energy, arbitrage finance, and international trade, or personal matters of tobacco use, diet, or consumerism, both macro- and micro-level destructive habits are enabled, whether intentionally or not, for fiscal advantage. 3. Money Politics. There is a perverse relationship between politics and economics. Whether or not intended, politics creates opportunity for wealth. Also, our democratic process requires expensive elections, and so it only makes sense that those seeking to benefit from the opportunities afforded by public policy would seek to shape politics, thus forming a corrupt circle of dependencies. 4. Selective Morality. There is no honest debate when there is no consistent standard of truth. The practice of ignoring or obfuscating inconvenient facts is all too common in all ideological corners. Oversimplification of the contrast between capitalism and socialism, liberal and conservative, and right and left overheats rhetoric and stunts potential progress. When an ideology becomes a pejorative, those holding to it cease to exist as your fellows and become something foreign, immoral, even evil. 5. Superpower Coasting. America has been a significant international power for a century, a superpower since World War II, and the only superpower for a generation. It has been resting on those laurels for quite a while. There has been a lack of internal investments to maintain healthy growth. Some of the apparent growth has come by exploiting this attrition. 6. Easy Money. Instead of healthy growth, economic advancement has often been related to the “empty calories” of arbitrage wealth creation, thus creating bubbles and subsequent busts. The lure of easy money has redirected talent and capital away from the real economy to the world of finance. 7. Monopoly Madness. The solution to difficult market situations is far too often business consolidation, which creates monster companies that can become “too big to fail” enterprises that can threaten the national or even global economy. Also, as such companies grow larger, barriers to competition become so high that new business is undermined. 8. School (out to) Lunch. Society undervalues education, as evidenced by the deterioration of public education. American students are scoring below the youth of many other nations in core educational metrics. Whether it is because these other nations are advancing or this one is falling behind, for all intents and purposes the public school system has become little more than national day care. Anti-intellectualism is viewed as a virtue in far too many circles, and erroneously linked to the attractive personal quality of humility. What was once anti-elitism has become a visceral aversion to well-reasoned, logical dialogue in nearly any form. It is considered better to follow your gut than to think a subject through. Snap judgments are viewed as a sign of strength, while careful deliberation is seen as a sign of weakness. Even children are indoctrinated against intellectual development, dreading the label of “nerd.” This growing anti-intellectual culture breeds an utter disinterest in the matters that matter most. Many would rather follow the minutia in the lives of celebrities than engage in the things that shape their world. Few take the time to examine history, economics, sociology, and anthropology, and yet still vote, charting the path of future history, only doing so in ignorance. This is certainly not an exhaustive list, but it gets to the catabolic systemic flaws of our republic. Not mentioned here are the destructive divisions and waste of resources within the nation caused by racial and cultural animosities; a criminal justice system that turns petty delinquents into hardened career criminals; the military-industrial complex; or other societal ills that are far too many to enumerate. A House Divided The focus here has to be the catabolic, systemic flaws of the republic that affect the broadest swath of human civilization—economics and the sociopolitical mechanisms that catalyze the hastening of self-destruction. We can neither wish these away nor ignore them. Ignoring them, as we do now, perpetuates catabolism. The selfish nature of human beings may be immutable, but some of these flaws are possible to correct. Most of these problems are artificially created by public policy, and could be redesigned if confronted boldly. Take, for example, the issue of money politics. Financial interests bankroll the campaigns of politicians, thus ostensibly obligating these public officials to vote for their “benefactors’” preferences. Critics view the government as bought and paid for by the corporations. However cynical it may seem, this is a reasonable conclusion. True or not, it seems rare for a politician to ever violate the interests of his or her benefactors, even when those interests are not aligned with those of the broader public. Politicians need contributors’ cash to keep their jobs. It is in their self-interest to play this game, irrespective of the public good. Do wealthy elites thus really control a nation supposedly ruled by the people? Throughout all human history, mankind has experimented with every conceivable form of government and economics. None has ever worked completely. There are really only three fundamental types of government: rule by one, rule by some, or rule by all. The variances in specific instances are tied up in the who’s, how’s, and why’s. Whether autocratic, oligarchic, or democratic, the attempts to correct one system’s flaws have consistently created systemic flaws in the next. The root problem of all forms of government is human selfishness. The thought of entrusting a selfish individual with ultimate power is what makes the prospect of an autocracy horrifying to all others. Oligarchies may dilute and distribute power, but the result of a group pursuing its self-interests has consistently been the creation of disparate classes, inequity, and even oppression. Pure democracy is chaos—anarchy incapable of producing efficient governance. So for all practical purposes, countries that don’t want totalitarian rule have to live with some variation of democratic republicanism, which wobbles between classism and ineffectiveness. As bad as this may be, history has proved the alternatives to democracy have been far worse. Nonetheless, democracies like ours can be “rule by mob.” More often, power is conferred based on quips exchanged in juvenile popularity contests. Whoever can better shape opinion wins. Logic is rarely given a hearing among the puerile syndicates of party power that behave as sophomorically as high school cliques. The media follow suit as if they were kids chanting “ Fight! ” in the schoolyard. While the adults in the general public are disgusted by such useless adolescent behavior, most are too busy to really engage. Life is stressful enough without reacting to this schoolyard behavior; paying attention to it would only result in insufferable anxiety. “High school” politics can efficiently confer wealth and opportunity upon cronies but is utterly impotent to confront the great crises of the day or match the strategic positioning of international competitors with more unified governments. Even leaders with great rhetorical skill can be immobilized by the fickle whims of a pessimistic public inclined to consider optimism as the most naive credulity. To compound matters even further, there are financial interests backing every possible position on every conceivable issue, many of which hold no fidelity to the truth. The result is indecipherable noise with no meaningful progress coming of it. The public is left only with vague, general impressions that are more cliché than reality—party of this or party of that. There are also endemic flaws in the concept of career politicians. The very fact that political office is a “job” creates a dependency on those who get politicians elected. For the sake of job security, politicians need financial backers to fund their campaigns year after year, leaving them beholden to their backers—and vulnerable to corruption. This is mainly because they cannot rely on regular citizens to get elected every time. There may be times of heightened interest every now and then when issues awaken the general masses, but in the end it is the perennial special interests that are the consistent base of support for most politicians. Who do we mean by “special interests”? We mean influencers—people, groups, or organizations—that levy financial power in attempts to influence leaders in favor of one particular interest or issue. They have money, are always there, and don’t forget. Regular people may or may not have enough money, are only there when passions are aroused, and quickly forget. So, why would a sane politician who wishes to keep his or her job ever really challenge the special interests? They may rail against special interests in the abstract or specifically attack groups that have no influence among their constituencies, but that is about as far as it ever goes. On the other side, you can’t really blame the corporations and other groups for using their money to protect their interests. It is a systemic flaw that makes their money the indispensable support of the electoral process. As unpalatable as the concept of “career politician” may be, what choice is there, really? The alternative of only electing the independently wealthy who need no financial support could create a neo-aristocracy. Ideology makes matters even worse, because ideology insists on purity in politics, as oxymoronic as that is. Add together C-SPAN, talk radio, Internet blogs, and cable news, and politicians have no room or reason to negotiate. Whenever a politician negotiates, he looks like a “politician,” and people hate “politicians.” Politicians would rather be known as “public servants” and will only threaten that elevated status with good reason. As ugly as this truth may be, in Congress, compromise has more often than not been based on “pork”—a Washington term for an appropriation of government spending for localized projects secured solely or primarily to bring money to a representative’s district or state. To negotiate a compromise, both parties to the negotiation must want something, and “pork” creates a reason to negotiate and, ultimately, the political will to pass legislation. Those elected may claim to act in the best interest of the country, and a few may even mean it, but the congressional record belies most claims of eschewing “pork” projects. Take away the pork, and all you may be left with is ideology. Why would any politician accept a compromise to his ideals and those of his constituents in exchange for nothing? The problem is that compromise requires compromise , which is dangerous territory in ideological terms. If all one side wants is for the other side to not get what it wants, you can only succeed at reaching an agreement by giving that side something it wants more. But, in an environment where such deal making is abhorrent and pork is poison, even that “functional” dysfunction fails. This circle of dysfunction is completed not at the top, but at the grassroots level. This is, after all, a democracy. Regular people have to go to the polls and pull the lever. Money does not actually elect anyone. What makes us a cannibal country is not only the greedy exploitation by the powerful of the weak, but also the laziness, selfishness, and stupidity of the public. A person may be smart, but collectively people are stupid. It is the aggregate thinking of the voting public that not only permits or enables one bad decision after another to be made, but which is directly responsible for them. Aggregate thinking can be leveraged by politicians, who appeal to idealists who are unwilling to see things as they are and insist on approaching the world as it should be. Groups organize around idealistic principles. These groups in turn confer power to those who can personify their ideals. Once elected, their commitment to ideology, irrespective of its applicability to circumstances, adds a level of rigidity to the process of governing. A system that depends on consensus is immobilized when there is ideological gridlock. You can blame the elected person of being a rigid ideologue, but the real problem is that many voters are idealistic, too. Constituents of an ideologue can be fiercely loyal, giving him or her absolutely no incentive to ever compromise. Even if a given leader’s nature is to be pragmatic in matters of importance, he will find that there is a severe price to be paid for anything that could be construed as a compromise, and that it’s considered best to follow opinion polls about what’s “right” or “wrong.” There are twenty-four-hour networks and media personalities that hold to particular persuasions and that perceive any dissenters as traitors worthy only of evisceration. When there are greater risks involved in doing something than in opposing everything, progress is immobilized. It is possible to correct this self-defeating pattern—but the question is, for whom. A democracy is made up of individuals. The “public” is not a voter. No one represents the whole public interest. Each individual pursues his or her self-interest, and individuals with common interests form coalitions. The largest coalitions win. You can only hope that either the broad interest will be served or that it will not be harmed too severely. Populism may be in vogue, and railing against the “powers that be” may be a resonant political tactic, but it is the populace that bears the blame. Whether people are duped by misleading campaigns, motivated by specific interests or priorities while ignoring others, disengaged from the political process except for the act of voting (which is then done on a last-minute whim), each voter bears the responsibility for the official he or she elects. The leaders reflect their followers. The danger of aggregate thinking is that it consistently results in bad decisions. This is the real invisible hand: the stupidity of the masses. It is the pursuit of instant gratification at the cost of ultimate success. It is the unwillingness to confront long-term issues. It is the inability or refusal to comprehend complex situations and logical solutions. It is the loathsome attitude that right and wrong must be subjective, unknowable, or relative, except for what I, the individual, believe. While groups may understand certain matters clearly and hold certain sentiments deeply, their inability to effectively convey their thoughts and feelings to reach consensus with other groups leaves a net effect of electoral stupidity. Aggregate thinking is confused, conflicted, distracted, and given to errant reductionism. Yet that is our system. That is yet another reason why this is a cannibal country. We eat each other because, among other reasons, we are too stupid to realize it’s not chicken. Opinion polls are considered indicative of the correct position, even when the majority opinion is ludicrous when viewed objectively. Is it intelligent to say that we should not have prevented the collapse of the largest banks in the world, thereby staving off another Great Depression? Following the onset of the financial crisis of 2007-8, opinion polls consistently indicated just that; that the bailouts should not have been done. This was the will of the people? It is stupid to vehemently suggest that the “too big to fail” institutions should have been allowed to fail just because they caused the crisis. It is stupid to complain as these now-largely-government-owned institutions begin to turn profits. If you own it, you should want it to make a lot of money. The government paid $3.25 per share for its stake in Citigroup during the notorious bank bailout of 2008. The taxpayers should want the stock to double, or even better, return to its precrisis price of $20 per share. Imagine that! What if the taxpayers got back six times their money? That would be smart, but that is not what we get. By the way, starting in 2010, the Treasury did sell Citigroup shares for a profit, but little attention was given to that. Positive outcomes of politically unpopular actions by the government were not, and rarely ever are, part of the media narrative. By late 2009, a majority of the public was irate about the quick rebound of financial giants and the subsequent bonuses paid to the employees responsible for the business decisions that led the recovery. What do they want? That the financial sector remain in a disabled state, teetering on the brink of collapse? It can be argued that this sort of anger represents transference of the troubles in the broader economy, but anger in politics is dangerous. Anger of any kind takes over the political dialogue and stifles any continuity of purpose or direction. Politicians are far too fearful to oppose public anger, irrespective of how incoherent or self-defeating it may be. Instead of focusing on the fundamental flaws in our economic system, it is politically expedient to pick a boogeyman and appear to be in line with the people. Instead of being true to reality, the ideology of what the system “should be” takes the floor. Break up the banks, audit the Federal Reserve, return to the gold standard, throw the bums out, cut spending, cut taxes, create jobs-jobs-jobs, tax the rich, fix health care, stop all greenhouse gas emissions, fight terrorism but get someone else to pay for it, and get it all done right now. The truth is that some of that intentionally won’t be done, some of that can’t be done, some of that shouldn’t be done, and none of that can be done immediately in a free market democratic system. “Indeed,” as Winston Churchill said, in part to the House of Commons in 1947, “democracy is the worst form of government except all those other forms that have been tried from time to time.” It is a sad truth that what is popular is not necessarily right or good, but in democracy you are stuck with it all the same. Worse still, because public opinion can be shaped by money, lies, distortions, and appeals to prejudice, there is no guarantee what public opinion will ever be, even in matters where one would expect the right thing to be obvious. Ads, slogans, sound bites, and imagery win elections and public debate. The system is not only broken, it is destroying itself. As people suffer, they focus their ire on the “villains” they are convinced are to blame, instead of on the devil who is truly behind their pain. They train their sights on their fellow citizens, particularly those who can easily be labeled as the “other,” and as a result get nothing except more pain. It is as insane as putting a gun to your head to kill your alter ego. “ Every kingdom divided against itself is brought to desolation; and every city or house divided against itself shall not stand. ” —Jesus, Matthew 12:25, King James Version There are very serious issues facing the country. Empires rise and fall, and this one isn’t exactly rising right now. It is involved in international wars without conceivable ends, the economy has been increasingly showing signs of systemic flaws, deficits have been rising, the dollar has been falling, there is a looming energy crisis, an entitlement crisis, various moral crises, and our standing in the world is falling on a variety of scales, including business, education, and health—and the list goes on. 4. Mark Potok, “Rage on the Right,” Intelligence Report , no. 137 (Spring 2010), http://www.splcenter.org/get-informed/intelligence-report/browse-all-issues/2010/spring/rage-on-the-right .",
        "char_count": 25517
      },
      {
        "heading": "Chapter 5",
        "text": "Chapter Two Putting the Cannibalism in Capitalism Why does a baby cry? It usually does so because it wants something. Nothing else matters beyond the immediate desires of the young child to have its demands met. The needs of others are irrelevant. Our nature from infancy is utterly selfish. Even the most superficial consideration of others is a quality that must be learned. Unfortunately, many never learn more than negligible consideration of others, and altruism has become a lost quality in a world of superficiality. Did You Say Ponzi? While decorum and civility restrain bad behavior on a personal level for most people, this is not maintained on organizational levels. The institutions of high finance have been revealed to have been caught effectively gambling in a shadow market of derivatives, taking extraordinary risks with overleveraged resources and bringing the global economy to the brink of a global depression. Financial collapse caused the public to revile big business, big banks, and big government, while most of the puppet masters of these entities remain safely anonymous. The fact that these banks were regarded as “too big to fail” created circumstances in which their potential failure threatened and still threatens life as we know it. The big banks and big business cried like babies, until the big government was left with no choice but to rescue them, so that whether these guys win or lose, they win. Thus, some would call the whole process of risk taking by big banks a giant Ponzi scheme in which the taxpayer is the victim. “The whole thing was a fraud and it gets back to the accountants valuing the assets incorrectly,” said Howard Davidowitz of Davidowitz & Associates, a retail consulting and investment banking firm, while complaining that the government’s attempts to better regulate Wall Street were completely off target. “It was a massive fraud. . . . The assets were completely valueless. . . . All the profits didn’t exist. . . . When we say there’s a problem with leverage. . . . They couldn’t have gotten the leverage . . . [but] everybody said it was great . . . all the audit firms signed off . . . that it was fine and it was a gigantic Ponzi scheme, a lie and a fraud,” he exclaimed in a July 2010 interview with Yahoo! Finance reporter Aaron Task. His ultimate argument was that more regulation wasn’t needed, but merely better enforcement of basic laws like those targeting fraud. While many Ponzi references are hyperbolic, there are real Ponzi schemes out there, too. The biggest of these was perpetrated by a billionaire—Bernard Lawrence “Bernie” Madoff. What is the difference between a mugger and Madoff? Prestige, perhaps. The mugger exists at the bottom echelon of our society, while Bernard Madoff luxuriated at the very top. The mugger is reviled, is likely a drug addict, is perhaps the child of poverty and a broken home, if ever there was one to break. Madoff was revered before he was revealed and later reviled, though he too was an addict of sorts. Pimps, prostitutes, drug dealers, and gang bangers are all so easy to loathe, to fear, to pity, and to prosecute. However, the Bernie Madoffs of the world confuse and perplex. We’ve seen documentaries and countless hours of talking heads pondering why a man with so much would do what he did. This man was a Wall Street institution, the once-head of NASD (National Association of Securities Dealers), and cofounder of NASDAQ. Despite all of that, in March 2009, Madoff pleaded guilty to eleven felonies and admitted to turning his wealth management business into a massive Ponzi scheme that defrauded thousands of investors out of billions of dollars. In fact, prosecutors estimated the size of the fraud to be $64.8 billion. This man, who had been one of the most powerful men on Wall Street for decades, did this. Wasn’t he rich enough? He didn’t exactly need the money. It would be simple enough to write off Madoff as just a psychopath, an aberration. But this is not about Bernie Madoff. Think bigger. What does it say about the whole system when this guy, the perpetrator of perhaps the most egregious financial crime in history, was considered a “close personal friend” of the head of the government agency charged with preventing such fraud? People are similarly confused as to why American International Group (AIG) and Wall Street bankers took risks that threaten the viability of the national—no, global—economy. The richest and most powerful people and institutions drove the global economy off the proverbial cliff. While Lehman Brothers was allowed to disintegrate, the rest were only rescued by the “socialist” bailouts of governments around the world. Former Federal Reserve chairman Alan Greenspan, a man who perhaps would have seen it all coming if not for the fact that he was a true believer himself, was shocked by their temerity. Sanitized, Institutionalized Selfishness The society in which we live suffers from the delusion that there exists a form of moral selfishness. Greed and selfishness at their crudest levels are condemned, but when these same principles are institutionalized, sanitized, and connected to a high standard of living, they become not only accepted, but aspired to. Worse still, our whole system is based on the principle of self-interest. Some would even say that it is the cornerstone of free market capitalism. Bernard Madoff was the reification of the unbridled, unregulated pursuit of self-interest. The rub—which true believers will dismiss as proof that he was an aberration—lay in that he clearly and unequivocally lied to his clients about everything. As for the peddlers of complex derivatives, their lies were not so clear, and there was a great deal of equivocation. Yet what was a triple-A rating on a bundle of mortgage-backed securities laden with subprime loans in an overheated real estate market during a period of rising interest rates, if not a lie? How was collecting billions off the top of the unsustainable houses of cards that were the mortgage-backed security, collateralized-debt obligation, and credit-default swap markets anything less than a Ponzi scheme? Some idealistic free marketers would argue that these events were a perversion of our system, the result of greed run amok. They would contend that the pace of innovation was not equaled by the regulations crafted in a bygone era (some of which were repealed, arguably setting the scene for the crash). We need new regulations for a twenty-first-century global economy, they argue. Their point is that greed must be checked, guided, and harnessed to drive our free market to better days. Unfettered free market capitalism is still the solution to the ills of economic malaise. Irrespective of the damaging side effects of capitalism, generally American capitalism is perceived as good . It creates opportunity, drives innovation, and arguably is responsible for the rising standard of living that we have enjoyed. Nevertheless, capitalism is often tantamount to institutionalized greed, or, at least, it could be said that greed is the engine of capitalism. Greed is bad , isn’t it? In our system, it is not enough to win; the goal is to keep winning. It is understood and accepted that there have to be winners and losers in a capitalist system, even if the winners win, not by outcompeting, but by killing the losers through other means. Sadly, more often than you would think, “losers” with fresh ideas, good people, and superior products but less financial heft are killed through the “winners’” anticompetitive behavior. How does that benefit the broader interests? We have to ask, can a system of institutionalized greed really be good? Is it really enough to accept that greed is a powerful force for good, provided that it is managed and moderated? To be clear, when I say greed, I am not talking about inequity. Human beings are not equal in the absolute sense. Some are tall, some are short, some are skinny, some are fat, and while it is not politically correct to say so, some are smart and some are stupid. A person with great talent in one area may be utterly inept in another. It is hardly surprising that some excel beyond others, make more money, amass more wealth, and achieve more in life. Unfortunately, some completely undeservedly make more money, amass more wealth, and obtain “more” in life. The ideal of capitalism may be meritorious, but the reality is that success is often circumstantial. Nevertheless, the pursuit and the achievement of excellence is not in and of itself greed. Greed is the pursuit of “more” (generally money), specifically through the losses of others. Put a different way, it is utter disregard for the damaging effects on others caused by the pursuit of one’s self-interest. It is not the reasonable give-and-take illustrated by economic patriarch Adam Smith’s “butcher, brewer, and baker,” but rather the all-out exploitation by the slave trader in the same era, who kidnapped and trafficked human beings. That is not to say, however, that conduct must reach levels as extreme as slave trading in order to be considered greedy. It can come in far milder forms, and yet still reflect that ultimate spirit. Such greed can be advantageous for the individual, but we must consider its implications in the broader context. Is it really a win when the success of an individual robs the greater majority of prosperity? When Capitalism Becomes Cannibalistic Capitalism encourages individual achievement in the hope that the proverbial rising tide lifts all boats. Yet that is only the case with industries in which there is a significant amount of mutuality. Sometimes individual achievement only benefits the individual, and, worse still, overburdens everyone else. Take for example those who made millions selling subprime mortgages before the subprime crisis. Did they give the money back? Individual bank executives made colossal bonuses playing mortgage-backed securities and collateralized-debt obligations, before the credit crunch that collapsed some of the same banks. Did they transfer their ill-gotten gains to the Troubled Asset Relief Program (TARP) fund? 5 The financial wing of AIG raked in the profits selling credit-default swaps, before AIG went bust because of the very same. Did they make reparations? In these cases, unfettered capitalism failed the greater number. Frankly, that is the point: self-interest does not meet the needs of the many. For that reason, pure capitalism is ultimately self-defeating, even for the individual who sees initial benefits. That is not to say that communism or socialism are any better. In fact, in practice they are worse, for they follow the opposite extreme. The interest of the group takes precedence over the interest of the individual. In fact, throughout the Soviet era, self-sacrifice was deemed a duty to the state. Individual achievement was nullified, if not effectively punished, for the greater national interest, and in the end even that interest was not served. There was no motivation for innovation. It was as if everyone settled for being poor together, though no one was actually happy about it. Centralized planning, as it was practiced in the Eastern Bloc, fails to chart the best course and fails to give the individual any incentive to develop solutions to needs that arise. Too often people confuse communism with socialism. Socialism is when the government owns and controls the means of production and distribution, of capital, land, and the output of their national product. Also, the words “socialism” and “socialistic” are far too often conflated, even though not everything that is “socialistic” rises to the level of full state ownership and control. The Soviet Union and other so-called communist regimes were actually socialistic dictatorships. The same is true in Cuba. Communism in its purest form eliminates the existence of government in favor of the governing principle “from those who can to those who need.” There has never been a pure communistic nation, other than small tribal societies, because theoretical communism would require a selfless population. This is the fundamental problem with communism: people are selfish. An effective economy must struggle to find balance between these extremes, to attempt mitigation of this failure of the human condition. Taken formulaically, communism equates success with the group interest, while capitalism defines success through individual achievement. Perhaps neither extreme is correct, but it is the case that the formula needs a Boolean “and” to really work. In other words, success can only really be achieved when both the needs of the individual and the group are served simultaneously. It is not enough to benefit the group while sacrificing the individual, nor is it appropriate to benefit the individual at the expense of the group. As with so many things, the extremes in both directions are wrong, and moderation is needed. Perhaps the most bitter fruit (economically speaking) of the Cold War has been our subsequent, ubiquitous aversion to socialism—an aversion that prevents us from recognizing the areas in which socialism is appropriate or even in the best interest of the free market. Markets, driven by profit, cannot afford to do everything that the broader community needs, particularly when the benefit horizon is so far into the future that the investment risk is substantial. Quite simply, there are times when centralization is needed. The Socialism We Forget We Like There are many socialistic programs that most Americans enjoy, appreciate, and certainly don’t want eliminated, like public schools, public libraries, Social Security, Medicare, garbage collection, and other municipal services. And there are other programs that have done far more to drive the economy than these entitlement services. The free market did not create the national highway system, microcomputing, or the Internet. The free market leveraged, advanced, and improved all three of these, but it would not and could not have produced any of them as we now have them. While the national interstate highway system has led to great profit, where was the profit in producing it? In inflation-adjusted numbers, the 160,000-mile system cost about a half trillion dollars, with no direct return on investment. Even now, this mostly toll-free transportation infrastructure, which serves nearly all of our major cities, enables trillions of dollars of commerce. At some point or another, the distribution of virtually all goods and services involves interstate highways. There has also been a tremendous impact on living standards and the way we live and work when you consider the role that urban interstates play for commuter travel. Many urban and suburban workers use these highways to travel to their places of work. The vast majority of long-distance travel, whether for vacation or business, uses the national road network created by the Federal Aid Highway Act of 1956 and championed by President Dwight D. Eisenhower. It is hard to find a strong position against this government project, even among those who adamantly believe in “small” government. “Microcomputing” is now an archaic term, but its development led to what we today call computers. Thomas Watson, chairman of IBM in 1943, famously and shortsightedly said, “I think there is a world market for maybe five computers.” While we now consider that one of the dumbest public statements in history, it is actually quite true given the definition of “computer” in that era. At that time, computers cost a fortune and occupied the space of entire buildings. Surprisingly enough, such things still exist. Many think of massive mainframe computers as obsolete, but that is far from the truth. In fact, such computers need to exist, but there is a very limited market for them. Actually, the mainframe supercomputer market of today is much as Thomas Watson described. Most organizations do fine with blade PC servers that approximate the power of centralized computing. Only a handful of governments and research institutions need mainframe supercomputers, the modern equivalent of Watson’s “computer.” What we today call “computers,” then, were only conjured in the imagination of science fiction writers when Mr. Watson made his ignominious quote. If you carry an iPhone, you are carrying more computer power in the palm of your hand than the supercomputers of a couple generations ago. What drove these advances and the redefinition of computing? The free market, right? Uh, no. It was the government, particularly NASA—or, more precisely, the space program, which included what would become the National Aeronautics and Space Administration. You see, you couldn’t fit what was then thought of as a “computer” on a plane, much less on a spacecraft, so they had to develop something a bit more small and sophisticated to get themselves into space. Add to that the development of the transistor, and we have an information revolution. Now, the transistor was primarily the development of a private sector entity, AT&T’s Bell Labs, with some valuable work done by other private organizations, like Texas Instruments, but even considering that, it can’t be ignored that this work of private enterprise was related to government contracts. It was government spending that brought us into the information age. Despite the revisionist history commonly told by free marketers regarding government intervention in business, the U.S. federal government (and therefore the U.S. taxpayer) did the heavy lifting and funding to give us everything from PCs to smartphones. Private entrepreneurs may have pieced together the fragments of government-funded research and development to give us the PC (personal computer) revolution, but the government created the framework and was the engine that initially drove the train. This is especially true of the Internet. The Internet began as a government project. The U.S. Department of Defense laid the foundation of the Internet when, in 1957, the Advanced Research Projects Agency (ARPA) was formed, which led to ARPANET, the network that served as the incubator for the technologies of today’s net. Entities without a profit motive developed these technologies before things were turned over to the free market, which of course ran with it. Another government agency moved the ball forward when, in 1985, the U.S. National Science Foundation (NSF) commissioned the construction of the NSFNET, which would later become the backbone of the Internet. The general public didn’t use the Internet much until after the development of hypertext transfer protocol (HTTP) in the early 1990s. In 1989, after NSFNET had been tied to commercial e-mail networks, three commercial Internet service providers (ISPs) were created: UUNET, PSINet, and CERFNET. Various other commercial and educational networks, such as Usenet, BITNET, Telenet, Tymnet, CompuServe, and JANET were interconnected with the growing Internet. Telenet (later called Sprintnet) was a large, privately funded, national computer network with free dial-up access in cities throughout the U.S. that had been in operation since the 1970s. This network was eventually interconnected with the others in the 1980s as the TCP/IP protocol became increasingly popular (TCP/IP being the communications protocol that the Internet is based upon). The ability of TCP/IP to work over virtually any preexisting communication networks allowed for greater ease of growth. That said, the rapid growth of the Internet was due primarily to the availability of commercial routers from companies such as Cisco Systems, Proteon, and Juniper; the availability of commercial ethernet equipment for local-area networking; and the widespread implementation of TCP/IP on the UNIX and later Windows operating systems. Even the commercial use of the Internet grew from a nonprofit, government-developed core. Before the business community had the slightest inkling of this growing network of networks, the National Science Foundation (NSF) was putting together the information superhighway. In the early days, to become a major player on the Internet, a business would have to physically connect to the NSF network. For that reason, the real estate around the NSF facilities in Northern Virginia became the East Coast’s answer to Silicon Valley. Perhaps you wondered why AOL and other Internet giants’ corporate headquarters were located outside of Washington, DC. It was not a coincidence. They had to be physically close to the NSF. The most powerful, multinational telecommunication companies entered the network as peers, equals. I guess that makes the Internet communistic. I say that facetiously, but some sincerely argue that point. Many of the larger network providers would like to toll all usage, and content providers would like to collect subscription fees, thus seeking ways to monetize the Internet—both in terms of access and content. Most, though, agree that the “free” Internet has driven economic growth in the global economy like nothing else in history. It is understood that the free nature of the Internet creates so much economic activity that it is in the common interest to minimize the cost of its use, even if it means little or no profit for some players, some of the time. Imagine for a moment, however, that the Internet had been the for-profit project of one company. What is the likelihood that Internet users would have ever seen unlimited access for less than ten bucks a month? What if every click on the web cost you money? Would it have cost the same to access a web site on the other side of the planet as to access one around the corner? Would the Internet have grown so quickly? Would there even have been such a thing as a web site? Really, would Tim Berners-Lee, the inventor of web-site technology, have selected a for-profit, limited network as his platform to meet his purpose of free information sharing between scientists? Would the world have ever seen Google, Yahoo!, eBay, Amazon, Facebook, or any of the rest? Nope, no way, forget about it. If Eisenhower hadn’t pushed for a national highway system, if Kennedy hadn’t set the sights on getting to the moon, and if Al Gore hadn’t pushed for the expansion of NSFNET, the world would be a very different place—a lesser place. To create the best results for the market system, government has to do the things that the broader community needs or could benefit from, but for which there is no viable profit initially or for which there shouldn’t be a profit motive. Call it infrastructure, call it framework, or call it direction, but the greatest achievements of this nation have been the results of public/private collaboration, not all free market or all government. Enter Reaganomics Unfortunately, thirty years ago the country bought the line “government is not the solution to our problem; government is the problem.” When President Ronald Reagan said this in his first inaugural address, he crystallized an economic philosophy that was heavily slanted toward privatization and pure capitalism. From there he embarked on a series of policy changes, colloquially referred to as Reaganomics. Previously, the balance may have tipped toward the left more than was healthy, with the social programs of the New Deal and Great Society and the massive defense department coming out of World War II. Reagan headed in the opposite direction. Greatly influenced by his economic advisor, Nobel prize-winning economist Milton Friedman, Reagan relentlessly pursued an agenda that focused on cutting domestic spending, reducing taxes, deregulation, and control of the money supply. While critics would deride this as “trickle-down economics,” these policies sought to stimulate the business and investor sectors. Proponents of these policies claimed (and still do) that if the top income earners invested more in the business infrastructure and equity markets, it would in turn lead to more goods at lower prices, and create more jobs for middle- and lower-class individuals—simple supply-side economic theory. Defense was the only area that was not targeted for ratcheted-back spending under Reaganomics; quite to the contrary. From this we have the basic Republican platform in a nutshell: lower taxes, smaller government, and a strong national defense. Politically, this has worked very well for them over the last thirty years. It’s clear and concise, easy to make into a bumper sticker. The question is whether or not it has actually worked. The growing disparity between rich and poor, explosive growth in the prison population, the cycles of boom and bust, the erosion of wages, the decline in manufacturing jobs, the weakening of the dollar, the growth of the budget and trade deficits, and the falling standing of the U.S. education system in the world all seem to indicate that it hasn’t. Nevertheless, by buying into Reaganomics, we embraced what George H. W. Bush had called at the outset “voodoo economics.” For a while, it seemed to work. By the end of Reagan’s first term, the economy was stronger and the rich started getting richer. But was it solid or was it a bubble? Could it be that the economic successes of the early ’80s were overly credited to Reagan and the supply-siders? Could it be that, while appropriate when applied to a 70 percent top-tax bracket, double-digit inflation, and 13 percent interest rates, the Reagan agenda is not sound fiscal policy generally? Perhaps Bush’s “voodoo economics” descriptor was right after all. The money has been spinning upward ever since, with no significant trickling down. In 1982, when Forbes magazine began its annual list of richest Americans, the richest man was Daniel K. Ludwig. One of thirteen billionaires, his net worth was $2 billion. By 2000, there were nearly three hundred billionaires, and a year earlier in 1999, the perennial richest man, Bill Gates, peaked at a net worth of $85 billion. In 2010, they published an international list of 1,011 billionaires, 40 percent of whom were United States citizens, even as the downward trend of America’s share continued. That’s only the top half of the story. The Working Poor Families Project reports that 29 percent of working families in America are low income. In October of 2009, according to the U.S. Bureau of Labor Statistics, the number of unemployed persons increased by 558,000 to 15.7 million. The unemployment rate rose by 0.4 percentage points to 10.2 percent, crossing the psychological milestone of 10 percent. It was the highest rate since April 1983. The median household income has little more than doubled in this period (from $20,000 in 1982 to $41,000 in 2000), while the net worth of the holder of the top spot on the Forbes list rose by more than forty-two times. Contrary to some politi-speak, it isn’t so much that income hasn’t kept up with inflation on the average. Buying power is about what it was in those terms. (We will talk about how misleading the national averages actually are later. Also, it shouldn’t be overlooked that today the “all-important” data point, household income, is more often the aggregate of multiple salaries from multiple breadwinners.) Yet the explosive growth of wealth at the top has increased the masses’ sense of dissatisfaction and the feeling of being left behind. The standard of living they demand is not the standard they can afford. Furthermore, the cost of living in metropolitan areas has so dramatically increased that a median household income seems little higher than the poverty level. China and the World Gaining While here there is complacency, political infighting, and economic hanky-panky, the rest of the world is strategically positioning for the future. This is most notably the case with respect to Europe and China. In the first year of the administration of William Jefferson Clinton, which was the beginning of the intense political rancor that now dominates the national dialogue, the nations of Europe signed the Treaty of Maastricht (November 1, 1993), forming the European Union (EU) to match the political and economic power of the United States. In fact, “match” may be an understatement, since, as an international organization operating through a hybrid system of supranationalism and intergovernmentalism, the EU now controls nearly a third of the global economy, with a GDP of $18 trillion. Given Europe’s history of colonialism, the EU has ties to developing countries with rich natural resources and is leveraging that international power to position itself strategically. In a short span of time, its currency, the euro (nonexistent a couple of decades ago) grew from a value of little more than half a U.S. dollar to nearly a dollar and a half. Even New York lost its rank as the financial capital of the world to a European city, London (though England is not part of the EU). On October 8, 2009, the Telegraph reported, “The ranking, compiled by the World Economic Forum (WEF), places the UK at the top of a leader board of 55 of the world’s largest financially-focussed countries.” 6 Yet Europe’s advances on America are nothing compared to those of China. In November of President Obama’s first year, his tour of Asia included Japan, Singapore, and South Korea, but he reserved the most time for China. There, Obama stated that the bilateral relationship between the U.S. and China would define the course of the twenty-first century. There is little doubt that he was right, and it seems that the story will be one of the transfer of wealth, power, and international dominance. China, a nation that is not merely socialist, but supposedly communist, is outpacing the economic growth of capitalist nations. In 2007, it saw a growth rate of 11.4 percent, the highest in thirteen years. Since 1991, the lowest annual growth number China reported was 7.1 percent (1999), and the average over that period has been about 10 percent. Technically, it is still a developing nation, but what development! Its official 2009 GDP hit about $4.3 trillion, and its GDP at purchasing power parity is about twice that, $8 trillion. If it maintains this pace of growth, it will surpass us within two decades. It could possibly do it in one. China already outpaces the U.S. in a number of sectors, including auto manufacturing. Of the top four banks in the world, three are Chinese. It has the world’s largest population, with a labor force of 807.3 million, and it has leveraged that labor force to become the world’s leading manufacturing complex. Nearly half of China’s GDP is industrial, compared to 19 percent here; we are an 80 percent service economy. Now, as surprising as it may seem, we are still number one in manufacturing, but China outpaces us on total exports (a difference of $158 billion). Perhaps the most telling statistics are the national account balances of China versus the U.S. The CIA World Factbook , which is available online, defines this as “a country’s net trade in goods and services, plus net earnings from rents, interest, profits, and dividends, and net transfer payments (such as pension funds and worker remittances) to and from the rest of the world during the period specified. These figures are calculated on an exchange rate basis, i.e., not in purchasing power parity (PPP) terms.” 7 On that list, according to 2008 estimates, China was number one and the United States was dead last. The numbers were $426.1 billion for China and −$706.1 billion for the U.S., or a spread of $1.1 trillion. The gap closed a bit in 2009, but we were still on opposite ends of the list. Behind China, the top ten of this list included notable nations like Germany, Japan, Saudi Arabia, Russia, and the whole EU. To me, though, what really matters is the control of natural resources. Once upon a time, wealth was not a matter of manipulating currency, trading pieces of paper, and clever accounting. It was all about tangible commodities, like fuel, food, precious metals, and materials needed to make stuff. In the final analysis, such things will again determine wealth and power, and it seems that China gets that while we don’t. Early in 2009, there were reports that Beijing had begun aggressively trying to extricate itself from dollar dependency. Nobu Su, head of Taiwan’s TMT group, which ships commodities to China, said, “China has woken up. The West is a black hole with all this money being printed. The Chinese are buying raw materials because it is a much better way to use their $1.9 trillion of reserves. They get ten times the impact, and can cover their infrastructure for 50 years.” 8 They have been strategically positioning themselves around the planet. They have been aggressively investing in the parts of the world that are rich with natural resources, most notably in Africa. In 2009, they entered into a multibillion-dollar deal with Guinea to build desperately needed infrastructure in exchange for access to the impoverished nation’s vast reserves of bauxite and iron ore. Earlier in 2007, China announced a $9 billion deal with the Democratic Republic of Congo for access to its giant trove of copper, cobalt, tin, and gold in exchange for developing the roads, schools, dams, and railways needed to rebuild a country roughly the size of Western Europe and shattered by more than a decade of war. In large oil-exporting countries like Angola and Nigeria, China has been building or fixing railroads, and in Congo and Guinea it’s been landing giant exploration contracts. China takes things even further, signing long-term deals for rights to natural resources that allow countries otherwise unworthy of credit to repay their debt in oil or mineral output. How’s that for strategic thinking! It sure ain’t philanthropy. Many found the opening ceremonies of the Beijing Olympics as frightening as they were impressive, considering all of the foregoing. They might find it even more frightening to consider the facts that China’s manpower fit for military service is larger than the entire U.S. population and that in 2009 they increased military spending by nearly 15 percent. (To avoid confusion, let me clarify that their actual standing military forces are about seven million, but, according to the CIA, China has 314 million men and 297 million women ages sixteen to forty-nine fit to be conscripted into military service.) It boggles the mind to think that a nation of 1.3 billion is rising to a middle-class lifestyle and what that could mean for global consumption, waste, and the distributions of commodities. Where is this thing going? We can complain all day about how China is not a free country and that its government controls everything, but in this economic contest, centralized management has an advantage that the West has no way to match. Moreover, any attempt in America to consolidate management or set the direction for the economy is utterly distasteful, would be tagged as socialistic, and would therefore be a nonstarter politically. China is making moves with brutal efficiency; the nations of Europe are increasingly subordinating their respective economic sovereignties to the EU so as to act almost autocratically in economic matters; and America, America is eating itself to death—figuratively and literally. While we are following celebrity Twitter feeds, fighting over minutia, and are immobilized by one political stalemate after another, these autocratic capitalists are positioning themselves like chess masters about to declare checkmate. On November 12, 2009, Time magazine ran the feature article “Five Things the U.S. Can Learn from China.” After acknowledging how politically incorrect it is to present advice modeled on a repressive country, they listed the need for America to (1) be ambitious, (2) improve education, (3) look after the elderly, (4) save more, and (5) look over the horizon. The theme of the article was fundamentally that there are clear reasons for the success of the world’s fastest growing economy. Some of the things that they are doing are worth noting, if not imitating. One of the most interesting and disturbing (from an American nationalist perspective) quotes from the article is the following: Tam, a graduate of MIT and the University of California, Berkeley, says he does deals in Beijing rather than Silicon Valley these days “because I believe this is where these new industries will really take shape. China’s got the energy, the drive, and the market to do it.” Isn’t that the sort of thing venture capitalists used to say about the U.S.? That was the recurring theme. This repressive, communist country is outdoing America in those areas that made America the supposed “bastion of freedom and opportunity.” They have a “can do,” optimistic spirit, manifest in projects throughout their country. For instance, their investment in education has already given China a higher literacy rate than the U.S. America, on the other hand, has become a country of cannibals where the overriding ethic is “I got mine.” American capitalism is not practiced as a team sport. Individualism has been taken to such an extreme that many now find it difficult to see common interests, let alone find common ground. The unemployed are viewed as dead weight. Social programs are viewed as burdensome. Government is viewed as a problem. Our economic superstars are showboats with no concept of passing the ball. China, on the other hand, is operating as a unit, and even Europe is aggressively pursuing a team effort. Even when weighed down by the bad debt and economic shortfalls of member nations like the so-called PIIGS (Portugal, Ireland, Italy, Greece and Spain), the EU has maintained a unity of purpose that is surprising given Europe’s history. How can we counter the growing dominance of China or the EU with the “I got mine” viewpoint? As I mentioned before, it takes a government to do the big stuff to increase national capacity, but there is no political will to do it. Political refrains like “No new taxes,” “we can’t afford this,” or “government is getting too big” are all that is needed to kill any strategic, national economic agenda. In fact, government engagement in the realm of business is anathema to many. Right or wrong, that is what the international competitors are doing, and doing with efficiency. Worse still, we have to deal with numerous species of vulture that prey on the rest of us. Bernie Madoff typifies this cannibalism in our country. His victims were largely from his own community, people he met at synagogue or through personal connections. While Madoff was an overt cannibal capitalist, there are many more subtle forms of this cannibalism. For instance, many of the nations against which America competes have very clear competitive advantages with respect to health care. Health care in America, on the other hand, does not enhance international competitiveness. Frankly, you could say that this nation is being swindled. According to some surveys and studies, the U.S. health care system ranks the lowest among developed nations. In 2000, the World Health Organization (WHO) ranked the U.S. health care system thirty-seventh in overall performance, right next to Slovenia, and seventy-second in overall level of health (among 191 member nations studied). The majority of personal bankruptcies in America are related to medical expenses. The U.S. pays twice as much in such measures as infant mortality and life expectancy, yet lags well behind other wealthy nations. Health insurance costs even pervert or restrain the hiring decisions of countless businesses, thus undermining job creation and full employment. Insurance companies rake in billions of health care dollars in profit without directly providing medical services. They hoard money (collected premiums) from a pool of the insured, while paying for as few services as possible or even denying medical care. They drain resources from every other industry without adding value to the system. What do we get for the money? In addition to a neglected health system, the educational system is suffering similar inequities. Much as the American health care system has some of the best doctors and medical institutions in the world but a subpar overall average because of the limited access and affordability of care, the school system is a dichotomy of outstanding and awful. In much of the country, education is underfunded, mismanaged, and unequal to the task of producing a twenty-first-century, globally competitive workforce. Schools are often first in line for budget cuts and the last in line for increases. Cannibal capitalism has rarely been better portrayed than by a piece by NBC-affiliate WRC, which was about the grand opening of the Hollywood Casino at Charles Town Races in West Virginia’s Eastern Panhandle. Jefferson County voters, in an effort to cover budgetary shortfalls, passed a referendum to expand gambling in November 2009. Their budgetary woes were not unlike those of many communities across the country, but that is not the part of the story that makes the point. What struck the note of cannibal capitalism was an interview with a laid-off teacher who was starting a job as a card dealer. This woman had a master’s degree in education, but was reduced to tending tables in a casino. What does that say about us? The health of the people and the education of the nation’s children are being undermined. What is more fundamental to economic potential than the health and education of a people? Is this some foreign plot to weaken America? No. The villains are not foreign, but Americans. Villainy and Waste What about the villains of the worst economic crisis the nation had seen since the Great Depression? AIG, Lehman Brothers, Bear Stearns, and the rest were American companies. The same is true for the peddlers of subprime loans and their derivatives, who were so focused on short-term gains that they couldn’t have cared less about the toxic assets they were pumping into the broader economy. These were our fellow citizens. When it came time to bail out the economy, though, it was these same Americans who were all for it. Their cannibal nature can be seen in their support of the socialization of their debt and the privatization of their profit. Some want to blame the North American Free Trade Agreement, others free trade practices, outsourcing, illegal immigrants, or some other external threat, but the truth is that we have been doing it to ourselves. We have developed a culture of self-interest, self-gratification, self-aggrandizement, and utter selfishness. We have institutionalized and disseminated these values as never before in human history. The further we go down this road, the worse the prognosis may be. We are eating ourselves to death, while squandering the greatest opportunity in history, the opportunity created in the space following World War II. World War II was not fought on American soil. The cities in this nation were not firebombed, leaving its economic capabilities decimated. The Eisenhower recession was tied to the overcapacity of American manufacturing. But the opposite was the case in Europe and Japan. In the years leading up to the war, the brain trust of Europe fled from fascist pogroms to America, thus building up the intellectual heft of the U.S., while the war itself pumped up its industrial capacity. Our advances in science and technology can be directly tied to these circumstances. Read the lists of names of the scientists who worked on the Manhattan Project, guided the early space program, and taught the subsequent generation of scientists in our universities. You will see a disproportionate number of European names, starting with Einstein himself. After the war, in many respects, no one had the capacity to compete with America’s economic output. Both the Allied and Axis powers alike had to rebuild nearly from scratch. This country had such an embarrassment of riches with respect to industrial capacity that it would have been a shame not to emerge as the powerhouse that it did after the war. It may feel good to believe in American exceptionalism, but, while belief may be an inspirational starting point, believing alone rarely causes things to come true. Though we have been taught to believe that America leads the world economically because of its intrinsic qualities as a free country, being the only game in town for decades after World War II has been a significant factor in our economic growth. What if that were actually the principal reason? Complacently, we have come to simply expect we’ll maintain the dominant role in the world. Worse, in addition to complacency, we have shifted to a consumer-driven service economy, which feeds on the consumerism of a shrinking middle class and which gives us less and less to export to the developing world. Worst of all, America faces competition as never before. I would even go so far to say that this is the first time in the modern era that America has faced economic challengers who are capable of dispatching this country from its position of dominance. Frighteningly, some of these competitors can move their entire economies strategically because of centralized management. While here we see socioeconomic cannibalism, other parts of the world are educating their children, caring for their sick, luring in global business, developing infrastructure, and securing natural resources. This country is not leveraging its current position to develop a stronger future position. Instead, it finds new ways to fake growth and feed on itself while waiting for salvation by an invisible hand. Can this trend be reversed? Will it be? Rather than forever surrendering to the fantasy of a moral selfishness, it is possible, if not probable, for us to turn this around—but it will take broad-based teamwork and some of what I will outline in this book. First, let’s get a sense of what we are dealing with by taking a close look at the housing and credit crises of 2007, which culminated in what some call the Great Recession. Perhaps more than any other economic reversal, this crash speaks to the core of why cannibal capitalism undermines even the good that is possible in a free market system, robs the nation of its potential, and concentrates too much wealth in the hands of far too few, leaving far too many with a future of declining prosperity. 5. TARP was a 2008 government program to purchase assets and equity from financial institutions to strengthen the financial sector in the throes of the credit crisis. 6. James Quinn, “Britain Overtakes US as Top Financial Centre,” Telegraph , October 8, 2009, http://www.telegraph.co.uk/finance/newsbysector/banksandfinance/6272639/Britain-overtakes-US-as-top-financial-centre.html . 7. Central Intelligence Agency, World Factbook (Washington DC: GPD, 2010), https://www.cia.gov/library/publications/the-world-factbook/docs/notesanddefs.html . 8. Ambrose Evans-Pritchard, “A ‘Copper Standard’ for the World’s Currency System?” Telegraph , April 15, 2009, http://www.telegraph.co.uk/finance/comment/ambroseevans_pritchard/5160120/A-Copper-Standard-for-the-worlds-currency-system.html .",
        "char_count": 47251
      },
      {
        "heading": "Chapter 6",
        "text": "Chapter Three Suicide-Enabling Case Study: Crash of 2007–9 Because the U.S. economy had suffered a series of collapses in each of the major sectors, the crash of 2008 is particularly historic, as it was a failure of what many viewed as the last equity-safe havens: real estate and financials. The most recent of the preceding crashes was the dot-com crash, followed quickly by the 9/11 attacks at the physical heart of our financial system. Investors, banks, insurance companies, hedge funds, and entrepreneurs like me all flocked to the seemingly safe haven of real estate. Responding to this demand, in addition to traditional MBS (mortgage-backed securities), CDOs (collateralized-debt obligations) became a popular way of playing real estate assets. In 2001, David X. Li, a quantitative analyst and an actuary, pioneered the use of Gaussian copula models, which allowed for the rapid pricing of CDOs. His approach became the tool du jour for financial institutions to correlate associations between multiple securities and price a wide range of investments that were previously too complex to price, namely these CDOs. The result? Thomson Reuters, Deutsche Bank, Celent, and many others heralded 2006 as “a banner year for the global collateralized-debt obligation (CDO) market.” Some estimated this market at nearly $2 trillion by the end of that year. With this much capital pouring in, a housing boom was certain to occur. Fannie Mae was created in the wake of the Great Depression in order to facilitate liquidity within the mortgage market and thereby enable home ownership. To sustain liquidity, long-term tradable instruments were created to facilitate the exchange sale and resale of mortgages as securities. Both rates of home ownership and home values have steadily risen ever since. Fannie Mae was privatized in 1968, and two years later Freddie Mac was created. Both of these GSEs demonstrated long-term, stable histories of success. It only makes sense that other investment institutions would find ways to get in on the action. That is exactly what they did. Beyond simply buying and selling MBS, investors came to prefer CDOs—including mutual fund companies, unit trusts, investment trusts, commercial banks, investment banks, pension fund managers, insurance companies, and private banking organizations. Essentially, a CDO is a corporate entity constructed to hold assets as collateral and to sell packages of cash flows to investors. An investment in a CDO is an investment in the cash flows of the assets and the promises and mathematical models of this intermediary, rather than a direct investment in the underlying collateral. This differentiates a CDO from a mortgage or an MBS, but also means that, effectively, pools of mortgages are sliced and diced, with the underlying real estate rights decoupled from the income streams received as loans are serviced. This is further complicated by the fact that CDOs are divided by the issuer into different tranches (one of many influxes of cash that is part of a single round of investment): senior tranches (rated AAA), mezzanine tranches (AA to BB), and equity tranches (unrated). Losses are applied in reverse order of seniority, and so junior tranches offer higher coupons (interest rates) to compensate for the added default risk. This being the case, an investor can “own” the subordinate rights to a portion of the interest collected on a group of unrelated mortgages with no way of knowing what, how, or where the real estate fits into the picture. CDOs provided a way for a number of players to profit from mortgages beyond the normal cash flows. For instance, the issuer of the CDO, typically an investment bank, earns a commission at time of issue and earns management fees during the life of the CDO. Rating agencies are needed to rate the tranches, and then there are the credit-default swaps (CDS), which were provided to give investors a false sense of security—but that is another story. The various players were making so much money with these mortgage derivatives that there was overwhelming demand to issue new mortgages. Although this synthetic securities market was not fully monitored or regulated, at least one study estimated the size of the CDO global market was close to $2 trillion by the end of 2006. 9 Virtually everyone owned a piece of these mortgages, even if it was only a derivative of a derivative valued with a complex formula that no one understood. MBS, CDOs, CDS, and other mortgage derivatives had bored deep into the global economy and touched nearly everything. Their failure was certain to have far-reaching effects. The acceleration in the housing market was evident in the upward acceleration of the Case-Shiller Home Price Values Index between 2001 and its peak in 2006 (see Figure 3.1 ). As money was pushed disproportionately from the finance sector to the real estate sector, demand grew at a rate that exceeded the capacity for new development as well as existing resale inventory. The bottom line was that prices rose at an unhealthy rate. Figure 3.1 The collapse, which began in 2007, demonstrated systemic flaws in our economy that run far deeper than a five-year market correction. Frankly, the collapse was precipitated by the Federal Reserve’s series of increases to the federal funds target rate, which started in 2004. By mid-2006, interest rates were at the levels the Fed used to pop the dot-com bubble. Whether or not the Fed meant to pop the housing bubble, the higher interest rates meant that home owners who had kept their homes by periodically refinancing as their rates adjusted—in other words, Minsky’s “Ponzi borrowers”—could no longer obtain mortgages. Millions of families were now facing the prospect of losing their homes as the rates on their loans were now dramatically adjusting upward, whether the loans were typical ARMs or the more exotic reverse-amortization, minimum-payment loans. Individually, these loans were ticking time bombs, but the rapid rise in interest rates detonated them all at once. The problem is that there were millions and millions of loans that fit into this category, far more than the number of textbook subprime loans. The major financial institutions that were playing this market via CDOs and other derivatives saw their values implode as default rates exceeded expectations. It all unraveled. As all of these institutions were dumping these securities while others were “shorting” them (which means selling securities you don’t own but will buy later in order to profit from a decline), the trillion-dollar derivatives market collapsed, and the nonfinance world expanded its vernacular with the phrase “toxic asset.” Let’s take it step by step from the beginning, not from the run-up, which had all the bliss of irrational exuberance, but from the slow crash of 2008, which actually started at the beginning of ’07. By understanding what toxic assets are, how they proliferated, and, most importantly, why, we can grasp the nature of our national economic catabolism. The Crash Timeline: 2007 On January 3, 2007, Ownit Mortgage Solutions filed for Chapter 11. Ownit Mortgage was well known in the industry for providing 100 percent financing on new purchases, hence the name of the company. This type of loan, irrespective of the credit of the borrowers, had become the archetypal subprime loan. As more and more investors got the picture about the implications of buying these loans, they had to steeply discount their packages to such an extent that they went bankrupt. Records show that Ownit Mortgage Solutions owed Merrill Lynch, which had a 20 percent stake in Ownit, around $93 million at the time of filing. That may not seem like much to a company with nearly $300 billion in assets at the time, but with their leverage ratio exaggerating such losses and the forthcoming collapse of the stock market, this was the first milestone on the road to September of the following year, when Merrill would be no more. The next month, on February 5, 2007, another company, Mortgage Lenders Network USA, the country’s fifteenth-largest subprime lender, with $3.3 billion in loans funded in the third quarter of 2006, filed for Chapter 11 bankruptcy. Unlike Ownit Mortgage Solutions, which was tied principally to Merrill Lynch, the collapse of this subprime lender spread panic throughout the industry. Over the next couple of months, the entire subprime industry collapsed. Several major subprime lenders declared bankruptcy, announced significant losses, or put themselves up for sale, including Accredited Home Lenders Holding, New Century Financial, DR Horton, and the behemoth Countrywide Financial. Once word got out that the good times were over, all of the dominoes were doomed to fall. By the end of 2006, subprime loans represented 20 percent of all mortgages issued. If that 20 percent alone had collapsed, it would have been devastating enough, but the risk had spread far beyond that point. The thing about a bubble is that, when it’s on the rise, everyone wants to get in on it before they miss the boat, even the largest institutions. Subprime loans had been bundled together with traditional loans and sold as mortgage-backed securities. Despite the name “subprime,” these loans performed well for years while real estate values were steadily climbing and the players involved were making out like the bandits they were. When a security performs well, it gets rated highly, even rated with a triple A. It seems that virtually everyone owned them, and why not? Everything— everything —else was already in the toilet. When it all hit the fan in March 2007, U.S. subprime mortgages were valued at an estimated $1.3 trillion, but the broader MBS market was around $7 trillion. As lenders and banks began to tumble, fear led to panic, and before long, all mortgage-backed securities were viewed as toxic. As the G20 summed it up in its “Declaration of the Summit on Financial Markets and the World Economy” on November 15, 2008: During a period of strong global growth, growing capital flows, and prolonged stability earlier this decade, market participants sought higher yields without an adequate appreciation of the risks and failed to exercise proper due diligence. At the same time, weak underwriting standards, unsound risk management practices, increasingly complex and opaque financial products, and consequent excessive leverage combined to create vulnerabilities in the system. Policy makers, regulators and supervisors, in some advanced countries, did not adequately appreciate and address the risks building up in financial markets, keep pace with financial innovation, or take into account the systemic ramifications of domestic regulatory actions. In short, after two years of deterioration of the global economy, the world leaders effectively said, “Oops, our bad. We were more concerned about reward than risk.” Nevertheless, on March 6, 2007, in a speech before the Independent Community Bankers of America’s (ICBA) annual convention in Honolulu, Hawaii, Ben Bernanke, quoting Alan Greenspan, warned that the government-sponsored enterprises (GSEs) Freddie Mac and Fannie Mae were a source of “systemic risk” and suggested legislation to head off a possible crisis. The conclusion to his comments is as follows: Legislation to strengthen the regulation and supervision of GSEs is highly desirable, both to ensure that these companies pose fewer risks to the financial system and to direct them toward activities that provide important social benefits. Financial safety and soundness can be enhanced by giving the GSE regulator capital powers comparable to those of bank supervisors and by creating a clear and credible receivership process that leads debt holders to recognize that they would suffer financial losses should a GSE fail. Finally, the Federal Reserve Board believes that the GSEs’ investment portfolios should be firmly anchored to a measurable public purpose, such as the promotion of affordable housing. I believe that this approach provides a reasonable balance of social costs and benefits for the GSE portfolios. In particular, this approach would refocus the GSEs on the affordable housing objectives given to them by the Congress. 10 Bernanke and the other Federal Reserve governors recognized the risk in the market, but they didn’t yet understand it. They were worried about the GSEs trying to get into the subprime game instead of focusing on the pervasiveness of adjustable rate mortgages in trillions of dollars of mortgage-backed securities held by major institutions throughout the world. Wall Street had dwarfed the investments of the GSEs. Greenspan, Bernanke, and the rest still thought of the “subprime” thing as a little, aberrant bubble that just needed to be popped. By the summer, there were many more bank failures, particularly in the subprime sector, and yet the greater crisis was still rumbling below the surface. Most “experts” saw only a localized problem and had no idea of the pending threat. The Federal Reserve had held rates at the recent peak for over a year, and the defaults were racking up as borrowers couldn’t meet their higher payments and couldn’t refinance into new loans. It’s easy to blame the borrowers for their recklessness and lack of foresight, but just because something is possible doesn’t mean that most of these people were expecting their mortgage payments to suddenly reset to levels two to three times higher with no ability to sell or refinance. These may have been bad loans, but there were millions of them, and they were now deeply embedded in Wall Street. These defaulting mortgages would have far-reaching implications. The first signs of the depths of the impending crisis were slowly being revealed. On June 7, 2007, Bear Stearns sent a letter to inform the investors in two of its funds, the High-Grade Structured Credit Strategies Enhanced Leverage Fund and the High-Grade Structured Credit Fund, that it was halting redemptions, which are the returns of investors’ principals in securities. In April, one of these hedge funds had posted an 18.97 percent decline, with 6.5 percent lost just in April. Two weeks after the letter, on June 20, Merrill Lynch seized $800 million in assets from the two Bear Stearns hedge funds—and this was still just the beginning of their problems. Bear Stearns wasn’t the only big investment firm with a hedge fund that ran into trouble making bets on the subprime market. In May, UBS, the Swiss-based banking giant, announced it was shutting down its Dillon Read Capital Management hedge fund after incurring a $123 million loss because of its exposure to the U.S. subprime market. The hedge fund’s woes helped drag down the 2007 first-quarter profit at UBS. On June 25, 2007, Federal Deposit Insurance Corporation (FDIC) chair Sheila Bair cautioned, “There are strong reasons for believing that banks left to their own devices would maintain less capital—not more—than would be prudent. The fact is, banks do benefit from implicit and explicit government safety nets . . . In short, regulators can’t leave capital decisions totally to the banks.” She was very concerned about the more flexible risk management standards of the Basel II international accord and lowering bank capital requirements. Basel II (as the name suggests) is the second of the Basel accords, which are recommendations on banking laws and regulations issued by the Basel Committee on Banking Supervision. The purpose of Basel II, which was initially published in June 2004, is to create an international standard that banking regulators can use when creating regulations about how much capital banks need to put aside to guard against the types of financial and operational risks banks face. Despite the clearly foreboding tremors and warnings, the stock market was still in a period of exuberance, with the Dow Jones Industrial Average closing above 14,000 for the first time in its history on July 19, 2007. Happy was anyone retiring and liquidating his portfolio on that day, because it all went downhill from there. The worldwide “credit crunch” then began in earnest, as subprime mortgage-backed securities were discovered in portfolios of banks and hedge funds around the world, from BNP Paribas to the Bank of China. Many lenders stopped offering home equity loans and stated-income loans. Detecting the situation, in August the Federal Reserve injected about $100 billion into the money supply for banks to borrow at a low rate, but it was too little, too late. On August 6, 2007, American Home Mortgage Investment Corporation (AHMI) filed Chapter 11 bankruptcy. The company expected to see up to a $60 million loss for the first quarter 2007. Two days later, on August 8, 2007, Mortgage Guaranty Insurance Corporation (MGIC) of Milwaukee, Wisconsin, announced that it would discontinue its purchase of Radian Group after suffering a billion-dollar loss of its investment in the New York-based company Credit-Based Asset Servicing and Securitization. The next day, August 9, 2007, French investment bank BNP Paribas suspended three funds that invested in subprime mortgage debt, due to a “complete evaporation of liquidity” in the market. The bank’s announcement was the first of many credit-loss and write-down announcements by banks, mortgage lenders, and other institutional investors, as subprime assets went bad, due to defaults by subprime mortgage payers. This announcement compelled the intervention of the European Central Bank, which pumped €95 billion into the European banking market. The worldwide scope of this crisis was made apparent on August 10, 2007, when central banks coordinated efforts to increase liquidity for the first time since the aftermath of the September 11, 2001 terrorist attacks. The United States Federal Reserve injected a combined $43 billion, the European Central Bank infused €156 billion ($ 214.6 billion U.S.), and the Bank of Japan injected one trillion yen ($ 8.4 billion U.S.). Smaller amounts came from the central banks of Australia and Canada. On August 14, 2007, Sentinel Management Group, a cash management firm based in Illinois that invested for clients such as managed futures funds, high-net-worth individuals, and hedge funds, suspended redemptions for investors and sold off $312 million worth of assets; three days later, Sentinel filed for Chapter 11 bankruptcy protection. As important as this fund was to its investors, this was small potatoes. The next day, on August 15, 2007, the stock of Countrywide Financial, which was the largest mortgage lender in the United States, fell around 13 percent on the New York Stock Exchange after Countrywide announced foreclosures and mortgage delinquencies had risen to their highest levels since early 2002. The next day, they narrowly avoided bankruptcy by taking out an emergency loan of $11 billion from a group of banks. As the collapse was gaining momentum, the next day (August 17, 2007), the Federal Reserve cut the discount rate by half a percent, from 6.25 to 5.75 percent, while leaving the federal funds rate unchanged, in an attempt to stabilize financial markets. The last day of a disturbing August, President Bush announced a limited bailout of U.S. homeowners unable to pay the rising costs of their debts. Nonetheless, on the same day, Ameriquest, once the largest subprime lender in the U.S., went out of business. Matters would not improve in September. On the first three days of the month, the Federal Reserve convened its annual economic symposium in Jackson Hole, Wyoming, to address the housing recession. It was little more than an aimless blame game. Several critics argued that the Federal Reserve should use regulation and interest rates to prevent asset-price bubbles, some blamed former Fed chairman Alan Greenspan’s low interest-rate policies for stoking the U.S. housing boom and subsequent bust, and Yale University economist Robert Shiller warned of possible home price declines of 50 percent. No effective solutions held sway. Worse still, on the next day, September 4, 2007, the London Interbank Offered Rate (LIBOR) rose to 6.7975 percent, its highest level since December 1998 and above the Bank of England’s 6.75 percent base rate. LIBOR-based, adjustable rate mortgages had been “all the rage” for years, but now, with this peak in LIBOR, millions of homeowners would see their payments jump dramatically, and, due to the collapse of the credit market, most would be unable to refinance into more manageable loans. This collision of crises would create the epicenter of the coming foreclosure tsunami that would collapse so much of the world economy. As if this “perfect storm,” as so many have labeled it, were not enough, three days later on September 7, the U.S. Labor Department announced that nonfarm payrolls fell by four thousand in August 2007, the first month of negative job growth since August 2003. Scrambling to respond to the warning of former Fed chairman Alan Greenspan, who said that “we had a bubble in housing” and that “large double digit declines . . . larger than most people expect” were impending, on September 18, the Federal Reserve lowered interest rates by half a point (0.5 percent). It was an attempt to limit damage to the economy from the mounting housing and credit crises. Such efforts were lost on most experts, including television finance personality Jim Cramer, who warned Americans on the Today Show on September 28, “Don’t you dare buy a home—you’ll lose money,” causing a furor among realtors. Sadly, time would prove his warning to be well-founded. On September 30, affected by the spiraling mortgage and credit crises, Internet-banking pioneer NetBank went bankrupt, and the Swiss bank UBS announced that it had lost $690 million in the third quarter. Less than a week later, on October 5, Merrill Lynch announced a $5.5 billion loss as a consequence of the subprime crisis, which was revised to $8.4 billion on October 24—a sum that credit rating firm Standard & Poor’s called “startling.” In an attempt to curtail the spreading disaster, the HOPE NOW Alliance was created by the U.S. government and private industry on October 10, 2007, to help some subprime borrowers. Between October 15 and 17, a consortium of U.S. banks backed by the U.S. government announced a “super fund” of $100 billion to purchase mortgage-backed securities whose mark-to-market value had plummeted in the subprime collapse. Both Federal Reserve chairman Ben Bernanke and Treasury secretary Hank Paulson expressed alarm about the dangers posed by the bursting housing bubble. Paulson said, “The housing decline is still unfolding and I view it as the most significant risk to our economy . . . The longer housing prices remain stagnant or fall, the greater the penalty to our future economic growth.” On October 31, the Federal Reserve again lowered the federal funds rate by 25 basis points to 4.5 percent. The next day, the Federal Reserve injected $41 billion into the money supply for banks to borrow at a low rate, which was the largest single expansion since it had injected $50.35 billion on September 19, 2001. After a whole month with no improvement, on December 6, 2007, President Bush announced a plan to voluntarily and temporarily freeze the mortgages of a limited number of mortgage debtors holding adjustable rate mortgages. He also asked members of Congress to (1) pass legislation to modernize the Federal Housing Administration (FHA), (2) temporarily reform the tax code to help homeowners refinance during this time of housing market stress, (3) pass funding to support mortgage counseling, and (4) pass legislation to reform GSEs like Freddie Mac and Fannie Mae. Nevertheless, the year ended on a sour note when, on Christmas Eve, the consortium of banks officially abandoned the U.S. government-supported “super-SIV” mortgage crisis bailout plan announced in mid-October. They cited the lack of demand for the risky mortgage products on which the plan was based and the widespread criticism that, other complaints aside, the plan would be difficult to execute. Rock Bottom in 2008 The New Year marked the beginning of the major downturn in the stock market, as effects of the worsening economy spread. On January 4, a Labor Department report was released showing U.S. employment growth slowing markedly in December, the job market’s worst performance since 2003. The unemployment rate hit 5 percent, a two-year high, indicating a weak finish for the U.S. economy in 2007. Retailers posted weak December sales figures due to a sluggish Christmas season. Retail store Target reported a 5 percent decrease in same-store sales, while rival Walmart posted a meager 2.4 percent gain, excluding fuel. Department stores, including Macy’s, JCPenney, and Kohl’s all posted declines. Macy’s sales fell 7.9 percent, worse than expected, and Kohl’s reported an 11 percent decline and lowered its earnings outlook. The latest Wall Street Journal survey of economic forecasters saw 42 percent odds of a U.S. recession for the year along with mounting inflationary pressures, an uncomfortable mix, to be sure. The average of the fifty-four forecasts saw the economy growing at slower than a 2 percent annual rate for the first and second quarters of the year. On January 11, the fate of Countrywide Financial, a company that had been teetering on the edge of bankruptcy for months, was determined when Bank of America agreed to acquire Countrywide for about $4 billion. Many hoped the move could build a bulwark against the mortgage default crisis by protecting one of its biggest casualties from collapse. The deal came just months after Bank of America plugged $2 billion into Countrywide during the height of the summer’s global credit crunch. The market value of Countrywide had plunged to about $3 billion amid a continuing surge in defaults and foreclosures afflicting the Calabasas, California, company. This company, which had been the largest lender in the residential mortgage business with assets totaling $211 billion and annual revenue over $6 billion, was now gone. On January 17, a report was released that home construction plunged in December to the slowest pace since 1991, and permit figures showed future groundbreakings had also dropped sharply. Builders had been pulling back because sales for new homes had plunged, while the supply of unsold homes hovered at a high level. Along the same line, a week later the National Association of Realtors (NAR) announced that 2007 was witness to the largest drop in existing-home sales in twenty-five years, and “the first price decline in many, many years and possibly going back to the Great Depression.” More and more writers (myself included), economists, and politicians began making references to the Great Depression in February. The January economic data reported that U.S. employment tumbled in January for the first time in more than four years, fueling worries for the U.S. economy. According to the Labor Department, nonfarm payrolls fell by seventeen thousand in January, the first drop since August 2003, when payrolls slid by forty-two thousand. Retailers reported weak January sales figures, further fanning fears about the U.S. economy. Walmart stores posted same-store sales below its forecast, while Nordstrom, Macy’s, JCPenney, and Gap posted significant same-store sales declines. The inflation data indicated that the U.S. consumer price index rose 0.4 percent in January, matching December’s rise, while the “core” CPI, which excludes volatile food and energy prices, was reported by the Labor Department to advance by 0.3 percent. The numbers, which slightly exceeded Wall Street forecasts, presented a challenge for Federal Reserve officials, who had to balance a sharp slowdown in economic activity with stubbornly elevated price pressures. Separately, the Department of Commerce reported that home construction rose a slight 0.8 percent in January, but an indicator of future groundbreakings fell to the lowest point in sixteen years, suggesting more pain ahead for the housing sector. At the same time, existing-home values continued to decline. Federal Reserve policy makers said downside risks to the economy remained even in the wake of recent interest-rate cuts, according to the minutes of their January 29–30 meeting. In their quarterly economic summary, central bank officials lowered the forecast for gross domestic product for the year from 2 percent to 1.3 percent. In addition, the central tendency for core inflation was revised up, with officials now expecting core inflation in 2008 to range between 2 percent and 2.2 percent. The officials said inflation could tick higher if energy and commodity prices were to weigh on consumers more heavily than expected. The severity of the housing downturn, tightening in the credit markets, and high oil prices were factors leading to the cloudier outlook, the officials said. What a time for the chairman of the Federal Reserve Bank to make his semiannual report to Congress! On February 27, 2008, chairman Ben Bernanke delivered an economic forecast fraught with risks from housing, labor, and credit markets, suggesting policy makers remain on track to lower interest rates further the next month. “It is important to recognize that downside risks to growth remain,” Bernanke told members of the House Financial Services Committee in his prepared testimony on the state of the economy and monetary policy on February 14. Fed officials “will need to judge whether the policy actions taken thus far are having their intended effects,” Bernanke went on to say, adding that the central bank “will act in a timely manner as needed” to keep the economy on track. At times like this, fear and frustration give way to anger and blame. Between March 1 and June 18, 406 people were arrested for mortgage fraud in an FBI sting across the U.S., including buyers, sellers, and others across the wide-ranging mortgage industry. On June 19, ex-Bear Stearns fund managers were arrested by the FBI for their allegedly fraudulent role in the subprime mortgage collapse. The managers purportedly misrepresented the fiscal health of their funds to investors publicly, while privately withdrawing their own money. Alas, while these sorts of arrests feel good, they do very little to correct the broader problem. The pain was still in its early stages. On March 10, the Dow Jones Industrial Average fell to its lowest level since October 2006, a drop that was more than 20 percent lower than its peak just five months earlier. Bear Stearns led the market decline as its shares plummeted. By October 16, Bear Stearns would be acquired for $2 a share by JPMorgan Chase in a fire sale to avoid bankruptcy. Founded in 1923, Bear Stearns had been one of the largest global investment banks and securities trading and brokerage firms. At its recent peak, Bear was worth nearly $16 billion, but the $2 share price amounted to only $236 million. Further, the deal was backed by the Federal Reserve, which provided up to $30 billion to cover possible Bear Stearns losses. The backing was not entirely surprising, considering the leverage ratio of 35.5 to 1 revealed by their 2007 financials. A few months later, in response to fervent protests by shareholders, the sale price was adjusted to $10 per share for a total of just over $1 billion. Nevertheless, another mighty giant had fallen. On June 18, 2008, the Senate Banking Committee proposed a housing bailout to the Senate floor that would assist troubled subprime mortgage lenders such as Countrywide Financial. During the session, the chairman, Connecticut’s Christopher Dodd, admitted that he had received special treatment, perks, and campaign donations from Countrywide, who regarded Dodd as a “special” customer and a “friend of Angelo” (Countrywide CEO Angelo R. Mozilo). Specifically, Dodd received a $75,000 reduction in mortgage payments from Countrywide. The chairman of the Senate Finance Committee, Kent Conrad, and the head of Fannie Mae, Jim Johnson, also received mortgages on favorable terms due to their association with the Countrywide CEO. Just when everyone thought that the loss of Bear Stearns and Countrywide was the worst of it, on July 11, IndyMac Bank, a subsidiary of Independent National Mortgage Corporation (IndyMac), was placed into the receivership of the FDIC by the Office of Thrift Supervision. It was the fourth-largest bank failure in United States history, and the second-largest failure of a regulated thrift. Before its failure, IndyMac Bank was the largest savings and loan association in the Los Angeles area and the seventh-largest mortgage originator in the United States. Indicating the pain to come, major banks and financial institutions that had borrowed and invested heavily in mortgage-backed securities reported losses of approximately $435 billion as of July 17, 2008. However hopeless, you can’t blame them for trying. On July 30, President Bush signed into law the Housing and Economic Recovery Act of 2008, which authorized the Federal Housing Administration to guarantee up to $300 billion in new thirty-year, fixed-rate mortgages for subprime borrowers if lenders would write-down principal loan balances to 90 percent of current appraisal value. A little over a month later, on September 7, the federal government took over Fannie Mae and Freddie Mac, which at that point owned or guaranteed about half of the U.S.’s $12 trillion mortgage market. This effective nationalization of these institutions caused a panic, because almost every home mortgage lender and Wall Street bank relied on Fannie and Freddie to facilitate the mortgage market, and investors worldwide owned $5.2 trillion of debt securities backed by the two enterprises. No one could fully grasp what it would mean for the engines of the mortgage industry to be nationalized. Monday, September 15, marked another terrifying moment in the decline, as Merrill Lynch was dissolved and its assets sold to Bank of America amid fears of a liquidity crisis and the imminent collapse of Lehman Brothers. The same day, Lehman Brothers filed bankruptcy, which would spell the end of the 158-year-old firm. The shock waves felt by the demise of Lehman have extended to such a degree that many have questioned the thinking of the Treasury and the Federal Reserve in allowing it to fail. A week of terrible news continued on the next day, when both Moody’s and Standard & Poor’s downgraded their ratings of AIG’s credit over concerns about continuing losses to mortgage-backed securities. Given the preceding events, the company’s apparent insolvency sent panic across the market. AIG was then effectively seized by the federal government, and on the following day the Federal Reserve loaned $85 billion to AIG to avoid bankruptcy. On Friday 19, the secretary of the Treasury, Hank Paulson, unveiled his financial rescue plan and ending a volatile week in stock and debt markets on a moderately hopeful note. The next week, the FBI revealed that it was looking into the possibility of fraud by mortgage financing companies Fannie Mae and Freddie Mac, Lehman Brothers, and insurer AIG, bringing the number of corporate lenders under investigation to twenty-six. On September 25, Washington Mutual was seized by the FDIC, and its banking assets were sold to JPMorgan Chase for $1.9 billion. The following Monday, after the Emergency Economic Stabilization Act was defeated 228 to 205 in the United States House of Representatives, the FDIC announced that Citigroup would acquire the banking operations of Wachovia. Later, using tax law changes made September 30, Wells Fargo made a higher offer for Wachovia, scooping it from Citigroup. With the apparent failure of yet another major bank, on Tuesday, September 30, the Treasury changed tax policy to allow a bank acquiring another to write off all of the acquired bank’s losses. Incidentally, when it was revealed in 2010 that this policy would lead to a $1.4 billion tax refund for JPMorgan Chase for the losses of Washington Mutual, despite the fact that JPMorgan Chase had paid only $1.9 billion in 2008 for the distressed banking operations, outraged policy makers looked for ways to reverse matters. On Wednesday, October 1, the U.S. Senate passed HR 1424, the $700 billion bailout bill. Then on Friday, October 3, President George W. Bush signed into law the Emergency Economic Stabilization Act, creating a $700 billion Troubled Assets Relief Program (TARP) to purchase failing bank assets. The new law included provisions allowing for an easing of the accounting rules that forced companies to collapse because of the existence of toxic mortgage-related investments. Also key to winning GOP support was a decision by the Securities and Exchange Commission (SEC) to ease mark-to-market accounting rules that require financial institutions to show the deflated value of assets on their balance sheets. Despite the intervention by the Federal Reserve, the Treasury, the SEC, FDIC, the president, Congress, and central banks all around the world, the next week, October 6–10, would be the worst week for the stock market in seventy-five years. The Dow Jones lost 22.1 percent, its worst week on record, down 40.3 percent since reaching a record high of 14,164.53 on October 9, 2007. Standard & Poor’s 500 index lost 18.2 percent, its worst week since 1933, down 42.5 percent in value since its own high-water mark on October 9, 2007. Even as this was happening, on Monday, October 6, the Fed announced that it would provide $900 billion in short-term cash loans to banks. On Tuesday, October 7, it made an emergency move to lend about $1.3 trillion directly to companies outside the financial sector. Also on Tuesday, the IRS relaxed rules on U.S. corporations repatriating money held overseas in an attempt to inject liquidity into the U.S. financial market. The new ruling would allow the companies to receive loans from their foreign subsidiaries for longer periods and more times a year, without triggering the 35 percent corporate income tax. On Wednesday, October 8, central banks in the United States, Great Britain, China, Canada, Sweden, and Switzerland, as well as the European Central Bank, cut rates in a coordinated effort to aid the world economy. Also, the Federal Reserve reduced its emergency lending rate to banks by half a percentage point, to 1.75 percent. Yet none of this could stem the Dow Jones Industrial Average’s worst week ever, which included the highest-volatility day ever recorded in its 112-year history. Paper losses on U.S. stocks now totaled $8.4 trillion from the market highs of a year earlier. On Saturday, October 11, the G7, or rather a group of central bankers and finance ministers from the Group of Seven leading economies, met in Washington and agreed to pursue urgent, exceptional, and coordinated action to prevent the credit crisis from throwing the world into depression. This proved to be little more than empty rhetoric, as the G7 did not actually agree on a concrete plan as had been hoped. The next week, the government began to tap into the $700 billion available from the Emergency Economic Stabilization Act and announced the injection of $250 billion of public money into the U.S. banking system. The rescue was to include the U.S. government taking an equity position in banks that chose to participate in the program in exchange for certain restrictions, such as limits on executive compensation. Nine banks agreed to participate in the program and received half of the total funds: (1) Bank of America, (2) JPMorgan Chase, (3) Wells Fargo, (4) Citigroup, (5) Merrill Lynch, (6) Goldman Sachs, (7) Morgan Stanley, (8) BNY Mellon, and (9) State Street. Other U.S. financial institutions eligible for the plan would have until November 14 to agree to the terms. On October 21, the U.S. Federal Reserve announced that it would spend $540 billion to purchase short-term debt from money market mutual funds. The large amount of redemption requests during the credit crisis caused the money market funds to scale back lending to banks, contributing to the credit freeze on interbank lending markets. They could only hope that the injection would help unfreeze the credit markets by making it easier for businesses and banks to obtain loans. Yet, by November 12, Treasury Secretary Paulson abandoned plans to buy toxic assets under the $700 billion TARP. Mr. Paulson said the remaining $410 billion in the fund would be better spent on recapitalizing financial companies. Many in Congress took this as the worst kind of bait-and-switch scam. If at first you don’t succeed, try, try again. This time the Group of Twenty (G20), which consists of the world’s largest economies, met November 15 in Washington, DC, instead of only the G7. They released a statement of the meeting, but again, no detailed plans were agreed upon. The meeting focused on implementing policies consistent with five principles: strengthening transparency and accountability, improving regulation, promoting market integrity, reinforcing cooperation, and reforming international institutions. Two days later, the Treasury gave out $33.6 billion to twenty-one banks in the second round of disbursements from the $700 billion bailout fund. This payout brought the total to $158.56 billion, without any clear sign that it was working. A week later, on November 24, the U.S. government agreed to rescue Citigroup after an attack by investors caused the stock price to plummet 60 percent over the week. This detailed rescue plan included injecting another $20 billion of capital into Citigroup, bringing the total infusion to $45 billion. The next day, the U.S. Federal Reserve pledged $800 billion more to help revive the financial system. Six hundred billion dollars would be used to buy mortgage bonds issued or guaranteed by Fannie Mae, Freddie Mac, the Government National Mortgage Association (Ginnie Mae), and the Federal Home Loan Banks. The week ended (November 28) with the Bank for International Settlements (BIS), the global organization behind the Basel Accords, issuing a consultative paper providing supervisory guidance on the valuation of assets. The paper provided ten principles that should be used by banks to value assets at fair market value. December began with Federal Reserve Chairman Bernanke saying that further interest-rate cuts were “certainly feasible,” but he warned there are limits to how much such action would revive an economy likely to stay weak well into the next year. Mr. Bernanke also said the Federal Reserve’s powers wouldn’t end with the federal funds rate, and its ability to inject liquidity into markets through its balance sheets “remains effective.” Two days later, on December 3, the Federal Reserve’s Beige Book survey showed that, with few sectors spared from the deepening downturn, nearly every area of the U.S. reported sales declines, drops in manufacturing activity, weakening real estate markets, tighter lending, and deteriorating labor markets. Even the sectors that had been bright spots until recently—such as agriculture and energy—also softened as commodity prices declined. Evidence of the far reaches of the economic meltdown was particularly notable on December 8, when Tribune, a major player in the newspaper industry, filed for bankruptcy-court protection. Tribune had been on wobbly footing for a year, since real-estate mogul Samuel Zell led a debt-backed deal to take the company private. Tribune owned eight major daily newspapers, including the Los Angeles Times , Chicago Tribune , and Baltimore Sun , plus a string of local TV stations. The American automobile industry was also teetering on the edge of collapse. Three days later, a frantic, last-ditch attempt to forge an emergency-relief package for the Big Three automakers collapsed in the U.S. Senate, amid a sharp partisan dispute over the wages paid to workers at the troubled manufacturing giants. Adding insult to injury, on the same day, December 11, details emerged of the worldwide pyramid scheme run by a prominent U.S. financier, Bernard Madoff. The market collapse had dried up the flow of new investors into his Ponzi scheme, and with existing investors looking to cash out, Madoff was exposed. Over the weekend, European banks, including Spain’s Grupo Santander and France’s BNP Paribas, said their clients and shareholders faced billions in losses on investments with Bernard Madoff, underscoring the global reach of the alleged Ponzi scheme run by the veteran New York money manager. The line between what was a criminal scheme and what was merely imprudent fund management was becoming increasingly blurred. Only one major investment bank was still standing, Goldman Sachs. Later in 2010, we would find out how Goldman was able to weather the crisis, when the SEC filed a fraud lawsuit against it, and its executives were brought before the Senate for a tongue-lashing that extended late into the night. Nevertheless, on December 16, Goldman posted its first quarterly loss since it went public in 1999, losing $2.12 billion, or $4.97 a share, during its fiscal fourth quarter. Net revenue was a negative $1.58 billion. The same day, the U.S. Federal Reserve board slashed official interest rates to a historic low range to combat the deepening recession. Further, they signaled that they would keep rates “exceptionally low” for some time, amid rapidly waning price pressures. The Federal Open Market Committee voted unanimously to reduce the target Federal Reserve funds rate for interbank lending from 1 percent to a range of zero to 0.25 percent, the lowest since the Federal Reserve started publishing the funds target in 1990. The market-determined effective Federal Reserve funds rate had already hit record lows. The Federal Reserve signaled in minutes from its meeting that the recession could drag well into the New Year, with economic output contracting for 2009 as a whole and inflation possibly “uncomfortably low.” The new fear was not of inflation, but of a more devastating threat, deflation. Three days later, on December 19, the Bank of Japan lowered interest rates to support an economy increasingly feeling the pain of a global slump, becoming the next central bank to cut rates to rock-bottom levels. Japan’s central bank also announced new steps to provide liquidity to capital markets, aiming to make it easier for cash-starved firms to raise funds. The same day, after failing to get the vote for a bailout through Congress, the White House announced a $17.4 billion rescue package for the troubled Detroit automakers to avoid bankruptcy. Allowing the Big Three to fail, President Bush said, was “not a responsible course” in the midst of a recession. The deal extended $13.4 billion in loans to General Motors and Chrysler in December and January, with another $4 billion likely available in February. The deal was contingent on the companies showing that they were financially viable by March. The end-of-the-year financial data told the tale of how horrible 2008 had been. Retail sales tumbled by 2.7 percent in December, marking the sixth consecutive decline, the Commerce Department reported. The deep, broad drop indicated that worried consumers were adding to savings instead of spending at the height of the holiday season. Nonfarm payrolls tumbled by 524,000 in December, the twelfth straight decline, following a revised drop of 584,000 in November. In all, in 2008 the economy lost 2.6 million jobs, the most since the end of World War II. The unemployment rate jumped to 7.2 percent, the highest since January 1993, but it was a number that would later be dwarfed. U.S. consumer prices rose for the year by their slowest pace in over a half century. Much of the reversal was due to a roughly 75 percent decline in oil prices from their July peak. For December, the consumer price index dropped 0.7 percent on a seasonally adjusted basis from the previous month, according to the Labor Department. Economists had expected a 0.8 percent decline. The core Consumer Price Index (CPI), which excludes food and energy, was unchanged. For the full year, consumer prices rose just 0.1 percent, the lowest increase since 1954, and well below the Federal Reserve’s 1.5 percent to 2 percent reference over the long run. The core CPI, however, was up 1.8 percent for the year, suggesting the U.S. didn’t yet face economy-wide deflation. The median home price was $175,400 in December, down 15.3 percent from $207,000 in December 2007, according to the National Association of Realtors. The median price in November 2008 was $180,300. Home resales rose to a 4.74 million annual rate, but of all sales in December, about 45 percent were distress sales at discounted prices. New-home sales fell 14.7 percent in December to 331,000. The drop capped the worst year for sales since 1982. That was not the only thing that was the worst since 1982. Gross domestic product decreased at a seasonally adjusted 6.2 percent annual rate October through December, the Commerce Department reported. In its original estimate, issued a month before, the government had reported that the fourth-quarter 2008 GDP fell 3.8 percent. They had earlier estimated a rate of 3.8 percent, before sharply lowering the number in a revision that reflected downward adjustments in inventory investment, exports, and consumer spending. The 6.2 percent decline meant the worst GDP quarterly showing since a 6.4 percent decrease in the first-quarter 1982 GDP. Making Sense of It By all accounts, 2008 was a year from hell financially. The World Economic Forum estimated that, by 2009, the crisis had destroyed 40 percent of the world’s wealth. In America, the Labor Department reported 2.6 million jobs lost in 2008 alone, and, according to the Federal Reserve, the nation’s households lost $14 trillion in net worth from their peak in 2007. The country and the world were changed. More than that, our self-image had changed. Looking at the history of what happened is informative, but it is still easy to miss the cause, as so many have. The superficial explanations that we have heard over and over again are radically wrong this time, perhaps because the wrong answer seems obviously right. Ideologues have the mic, and there is a major clash between ideals and reality right now. The right wing and the left wing are saying what they always say, but they are shockingly clueless, blinded by their ideological lenses. Both the general sentiment, based on overly simplistic reporting, and the positions taken by the “best” economic minds reveal fundamental misunderstandings of what is wrong or what is needed. If there is anything that I know well from years in business, it is that financial pain doesn’t exactly make people smarter. More often than not, such pain leads to utterly idiotic behavior and decision making that worsens the worst problems. Leaders have argued and will argue back and forth rancorously and continue to pass legislation that won’t even come close to adapting to the needs of the new global economy or our role in it, just as the many efforts detailed above have fallen flat. Even the premise of “let’s prevent that from ever happening again,” which was so common in the wake of the crash, betrays a lack of understanding of what happened. The entire bubble and bust was the result of investors believing they had a formula to make a fortune without risk and selling the world on that illusion, followed by a slow awakening to the axiom that there is always risk. Once these players stopped believing , they stopped playing, and the game fell apart. Modern economics is often based more on sentiment and emotion than anything else. Nevertheless, the game pushed hundreds of billions of dollars into the real economy, and we all used it. We built, bought, and sold millions of homes, bought all of the latest gadgets, and lived like this money in the economy was a new reality. We all believed it was real . After all, what is the difference between money from a casino and money from hard work? Lots and nothing. Of greater note in the crisis is the revelation of the need for better capital flows into the real economy. There was and is a clear need for more affordable mortgage products. The presence of cheaper mortgages created millions of jobs and stimulated the middle class as never before. The manner in which and the reason that capital flowed into the real economy were the problems. That it stopped so abruptly became a greater problem. Worst of all was the problem that, at the end, there was very little appetite to even return to the capital flow levels prior to 2001. Despite the pain of the crash, we need to take a lesson from the temporary good that was accomplished by capital derivative trading, namely, the capital flow to regular people through their home equity and the demand for housing. The truth is that we must embrace the reality of how our system works and then make it work for the general good. You can’t create and expand a system of fiat currency and credit, and then complain that the real economy uses or even depends on our system of fiat currency and credit. Most people don’t even know what fiat currency is, and worse, if they did they wouldn’t like it. But that is the system we have and need. (We’ll talk about fiat currency and monetary policy later.) My goal is to put a little reality out there from the perspective of the small guy who is not an observer, but a participant in the real economy. 9. Celent, Collateralized Debt Obligations Market , press release, October 31, 2005, http://reports.celent.com/PressReleases/20051031/CDOMarket.htm . 10. In this section, footnotes for widely publicized, well-known quotes will not be provided.",
        "char_count": 53875
      },
      {
        "heading": "Chapter 7",
        "text": "Chapter Four The Evolution of Cannibal Capitalism The slow crash of 2008 will live in infamy. The safest of “safe” havens, real estate, collapsed. What was myopically viewed as a subprime crisis was soon revealed to be a broad-based failure of the global financial system. Freddie Mac and Fannie Mae, the giant GSEs chartered to provide liquidity to the housing market by buying conforming loans (loans meant to be conservative), were brought down, along with everyone else, by the crisis of confidence over the pandemic defaults of nonconforming loans. Default-rate and home-foreclosure records were broken as values steadily collapsed. Overleveraged mortgage-backed securities collapsed, as panic spread through the public and private markets, leading all of the major investment banks to either fail or to become commercial banks. Even by the end of 2008, early efforts to assist troubled homeowners with modified mortgage loans seemed hollow, as redefault rates exceeded 50 percent. Tremendous wealth has evaporated all across the global economy. The losses have amounted to tens of trillions of dollars! Millions of jobs have been lost. And the last vestige of the old U.S. manufacturing base, the auto industry, has teetered on the edge of oblivion. We often hear the questions: How did we get here? Is this just a natural cycle, or are the so-called cycles of the past fifty years also symptoms of a deeper problem? What Is Normal? The fact is that we were doomed to end up here because of structural flaws in the entire economic system. As Shakespeare’s Cassius said in Julius Caesar , “The fault, dear Brutus, is not in our stars, but in ourselves.” It is not the mysterious forces of the market. It is not the work of a secret society pulling the strings behind the scenes. It is not as simple as political demagogues who point fingers at two-dimensional villains would like to characterize it. The problem that has come and is yet still emerging is fundamental and systemic. Perhaps former Federal Reserve chairman Alan Greenspan put it best when he was before Congress in October 2008: he said that the economic crises that had begun to grip the world revealed “a flaw in the model that [he] perceived is the critical functioning structure that defines how the world works.” Many free marketers were deeply offended by Greenspan’s statements, and some accused him of deepening the problem, but I believe that he is exactly right—perhaps far more than even he intended, if you distinguish between the words “work” and “function.” The implication of how the world “works” carries a greater implication than merely the “function” of markets. A self-destructive system can certainly “function,” but only for so long. How long can you use your foundation as a quarry before your home collapses? How long can you eat your young before you become extinct? How long can America feed off the shrinking middle class before the great democracy of recent memory dies a painful death? This was not the first recession, and it won’t be the last. Whether bullish, bearish, or erratically both, the markets do function, but do they really “work” for the best interests of everyone with a stake in the system? Even though recessions cause us to pause for a moment and rethink many aspects of the way our society works, most of the time, because the numbers seem to indicate steady growth, we feel fine. When things are good, we are less than inclined to acknowledge any deep-seated problems with the system. After all, the gross domestic product (the market value of all the output produced in a nation in one year) for the U.S. was estimated in excess of $14 trillion for 2008, nearly a quarter of the world total. And this was the worst contraction of the GDP since 1982. We have generally seen our economy grow year after year, and, even when things are bad, it seems that there is someone who is doing well. In 2008, Amazon saw its profits rise 9 percent, and ExxonMobil broke its own record for the highest earnings of any U.S. company ever, making $45.2 billion in profit. Recessions are often viewed as healthy exhalations necessary to purge excesses from the economy. Even in the area of manufacturing, many would be surprised to know that, according to the BEA (Bureau of Economic Analysis), U.S. manufacturing output has continued to rise even during the last twenty years of free trade and offshoring. All of this lends plausibility to the argument that the ebbs and flows of the economy are natural and healthy. Just as if we suffered from kwashiorkor, we’ve been getting the calories to simulate growth, but they have not been healthy calories. How much of the GDP is connected to bizarre derivatives and amorphous financial instruments? On Sunday, April 25, 2010, Senator Sherrod Brown of Ohio told Jake Tapper of ABC News, “Fifteen years ago, the assets of the six largest banks in this country totaled 17 percent of GDP. The assets of the six largest banks in the United States today total 63 percent of GDP.” His statement was confirmed by Pulitzer-award-winning PolitiFact.com . That reflects kwashiorkor-like attrition, not healthy growth (see Figure 4.1 ). Figure 4.1 More importantly, how many are sharing in the wealth of the economy? How many of the employed are actually underemployed, failing to earn a living wage? In 2010, Gallup reported an underemployment rate of more than 20 percent, but even that number fails to account for millions of Americans who are off of the radar. There is where we see the malnourishing effect of the way our economy is now operating. While manufacturing output has risen and company profits have risen more often than not, manufacturing jobs have steadily declined. Even when you completely factor out China, which became a global manufacturing behemoth upon its entry into the World Trade Organization (WTO), the means by which most Americans benefit from American prosperity, jobs, have been drying up (see Figure 4.2 ). Figure 4.2 The nature of the economic ills facing the nation is most evident in the “muscle” of our economy—the middle class. The middle class must get in on the action. The fact that the wealth and buying power of the middle class has been shrinking with each successive decade since the modern economy was developed in the mid-twentieth century is proof that there is a systemic problem facing the nation. When you examine the causative factors driving the attrition of the middle class, it is not hard to realize that the villain comes not from without, but within. Dependencies versus Ideologies When the Big Three automakers came before Congress to plead for a bailout, many were aggressively pushing the idea of bankruptcy reorganization as the “best” solution to Detroit’s shortfalls. You may remember they had to come to DC twice, because the first time the CEOs were so politically tone-deaf as to fly to Washington in private jets. For a while, it seemed that one or two of the auto giants weren’t going to survive the winter. But they came back, and the second time they drove hybrids. They came arm in arm with the head of the United Auto Workers union and a dealers-association representative. By this point, matters seemed more urgent, and the price tag went up. Still, prospects for the economy appeared bleak, because it seemed that the political will to save the American auto industry was lacking. The ideological gridlock was as intransigent as ever. Laissez-faire ideologues loathe all bailouts and readily label them as socialism, so the request of the Big Three U.S. automakers amped up the ire of the anti-bailout crowd. Across the board, most agreed that the collapse of the automakers could be catastrophic, costing up to three million jobs and perhaps even accelerating the recession downward into a depression. So the lines in the sand were drawn, not between bailout and no bailout, but between bailout and some sort of “prepackaged” Chapter 11 bankruptcy or conservatorship. During the media and lobbying battle that ensued, the devil was, as always, in the details. The bankruptcy camp used the obfuscation of clever wordsmiths to bury the truth behind terms like “legacy costs” and “out-of-date business models.” With what seemed to be unimpeachable reasonableness, the economists and pundits would say, “These companies are weighed down by legacy costs and their costs structures are not even competitive with the Japanese carmakers that build in America!” In the first hearing, sitting next to the Big Three CEOs who were testifying to Congress was the bow-tie-wearing Peter Morici, a business professor at the University of Maryland and self-described macroeconomist. A media darling, he regularly appears as a guest commentator on several news programs. In all of his testimony, he was pushing bankruptcy reorganization as the “only” means to really fix what’s wrong in Detroit. To the committee, he detailed what the “legacy costs” were and described how, through Chapter 11, automakers could shed labor contracts, severance costs, and pensioners’ health care costs. The economist on the panel during the second hearing was not so certain, but “feared” that bankruptcy would be inevitable without intervention. A troubling reality is that from a certain perspective, Professor Morici was right. It’s just that that perspective is one of heartless, cannibal capitalism. In the strict terms of cold business economics, bankruptcy may have been a more efficient way to streamline the American car companies, and not doing so when these companies were on the brink of collapse was a missed opportunity. Yet doesn’t that miss the point? Will the labor expenses of experienced, middle-class, American union workers ever be truly competitive with those of workers in the developing world? Of course not! For that matter, the whole country is carrying “legacy costs,” so to speak. According to cold business logic, the U.S., with its bloated middle class, has an out-of-date business model and should give up, letting the invisible hand confer a leading position on a fast-growing country in Asia. It’s also not fair to compare average salaries in a ten-year-old factory owned by a Japanese car company to average salaries across the board at a hundred-year-old American company. It is neither fair nor in our best interest to permit market forces to shift our wealth overseas. In any case, the real question remains: is the idea of chopping jobs, benefits, and pay of Americans a good thing, particularly in times of economic stress? Bankruptcy could have been a shortcut to a more streamlined auto industry. However, that path would be carved across the backs of thousands, perhaps millions of Americans. Cannibal capitalism is never compassionate conservatism. My fears during that debate were never that consumers would fail to buy cars from a company in reorganization. I correctly believed that, with a well-executed media blitz, they could have convinced the public that there was enough government backing to mitigate risks, particularly given a public that is often uninterested in these sorts of matters. No, what I feared was that bankruptcy provisions would actually allow companies to completely reorganize. As a businessman, even I have to admit that if I were given the chance to completely reshape the American car companies and had no concerns other than profit-oriented business strategy, I’d go far beyond just burying legacy costs: I would shut down nearly all U.S. manufacturing, cut between 70 and 80 percent of the U.S. workforce, and realign to target emerging consumer markets. See, the dangers didn’t lie solely in allowing the auto giants to fail; they also lay in allowing them to leave. The message of the bankruptcy solution proponents was that high-paying jobs, health care for retired career workers, and taking care of the workers in an inactive plant until production could be ramped back up are all things that should be eliminated from the balance sheet by any means necessary. If Big Three autoworkers effectively cost $70 per hour and Toyota workers only cost $40 an hour, the Big Three should fire all their workers, hire them back at the lower wage, and use the bankruptcy court to sanitize this immorality. Indeed, they wanted to take such measures as making workers pay for their own health care through their union dues. That would make business sense, and bankruptcy would have given them the cover to do it, but what’s the morality of that? Is it in the best interest of the nation? What the bankruptcy camp failed to acknowledge is the cold reality that there would be little reason to keep more than a token domestic business after Chapter 11 reorganization. Some of the more determined opponents of the Chapter 11 option, like Senator Richard Shelby of Alabama, pointed to the success of foreign automakers operating in the United States and promoted the notion that there would still be a viable American auto industry even with the loss of the Big Three American companies. “Who cares who owns the company?” some said. How shortsighted! Had they all forgotten why these foreign companies manufacture here? Don’t you remember? Foreign car companies operating in the U.S., now called transplants, were forced to create American jobs to be allowed to grow their American market share. The climate was that buying a foreign car was unpatriotic until those companies set up substantial U.S. operations. It is critical to recognize that the pressure created by a domestic auto industry is ultimately why Toyota and the rest are here. Their U.S. operations are the least efficient for these companies. What would prevent these foreign companies from shutting down U.S. operations if the domestic industry collapsed? Any threat of a lost market share would ring hollow, as there would be no alternative. We could actually lose them all! If you must, use the situation to force innovation down the throats of execs in Detroit, because, frankly, the only way to save the highest-paying jobs in the industry is for these companies to start building the best cars in the world. Fortunately, the bailouts seemed to work, and by the middle of 2010 there was excitement surrounding the rebound of Ford and GM. Some, though, stuck in their ideology, still bemoaned the bailouts and the avoidance of bankruptcy for the car companies. They still don’t get it. Killing these high-paying jobs, whether through bankruptcy or not, would always be a bad idea, because all bulwarks against cannibal capitalism would be removed. People need to reflect on the passionate rebuke from chairman Christopher Dodd in the first hearing with the Big Three automakers: “Taking care of people isn’t a bad thing!” The common view that taking care of people is socialism is part of how we have become a cannibal country. A combination of governmental incompetence, corporate greed, unchecked market forces, trade imbalances, immigration patterns, consumerism, globalization, and declining standards of education have all factored in, and yet these are all problems caused by or contributed to by our own American institutions. In other words, we have been slowly killing ourselves. Like junk food, which may send signals to the “happy” centers of the brain that all is well, bighead-sanctioned economic data sends signals of strength, when the country is in fact weak. Days before we found out that the nation has been in recession for a year, we heard reports that the fundamentals of the economy were strong. Corporate financials cannot be the only guiding line that defines success. This could be the end of the golden age of America, after which this country could fall in line with the status quo of much of the rest of the world, where the gap between rich and poor is immense and the middle class is virtually nonexistent. How did we get here, and how can we get out? New World Economics America was to be the New World, the “great experiment,” and mankind’s best hope for independence, liberty, and opportunity. There would be no peasants here; rather, “that all men are created equal” was held as self-evident truth. As the grandchild of sharecroppers, I cannot ignore the fact that this has been an unrealized ideal. The history of slavery and the genocide of indigenous people discredit any notion that “created equal” means “treated equal.” Nevertheless, in all fairness, an examination of world history elevates the United States of America above every other form of government tried—albeit the monarchies and republics of the past set a rather low bar. Even looking around the globe today, we can scarcely find an equivalent middle class. Yet the system that created this middle class is now at risk. The problem is systemic, and can be found in our fundamental national economic philosophies and our practice of capitalism. Certainly, we must consider the history of the economy to understand our economic woes and to chart a better course. Not only was 1776 the year that this nation declared its independence, it was also the year that Adam Smith published his magnum opus, An Inquiry into the Nature and Causes of the Wealth of Nations . Although Adam Smith, an eighteenth-century British subject from Scotland, is often credited as the father of modern economics for the entire world, he could also be credited as the absent founding father of the U.S. economy. His theories and descriptions of wealth and commerce greatly influenced the architects of our economy, including Alexander Hamilton, our first secretary of the Treasury and an actual Founding Father. More notably, Smithian dogma is at the core of every aspect of the way modern economics is practiced. Now, Hamilton certainly would not have considered himself to be a disciple of Smith; quite the contrary. For one thing, he vehemently opposed free trade as promoted by Smith. Nonetheless, it cannot be doubted that this new republic was shaped by Smith; he was rising into the pantheon just as this nation was being birthed. The core principles in Wealth of Nations , particularly the concept of meritocracy and the invisible hand of self-governing markets, are cornerstones of the U.S. economic system today. While other nations would have to institute reforms to incorporate Smith’s theories and free-trade policies, the fledging republic was a blank slate. Over successive generations, and especially as America’s fledgling economy developed more durable industries, Hamilton’s protectionist approach, which favored government intervention to protect businesses, came to predominate. Hamilton’s approach was modeled on that of Jean-Baptiste Colbert, the French minister of finance under King Louis XIV, who achieved his reputation by improving the state of French manufacturing and bringing the economy back from the brink of bankruptcy. But in time, protectionism gave way to the invisible hand of Smithian free market economics. By the Roaring Twenties, Smith’s theory was the modus operandi of the entire U.S. economy. That is not to say that economists are all of one mind. Not even close! Just as the political right and left war over a variety of social theories, there are equally partisan economic theories. In fact, most of the partisan political battles are rooted in opposing economic theories. Karl Marx castigated the capitalist system he saw around him, which he thought was exploitative and alienating, ultimately leading him to the conclusion that the world needed stateless, classless societies. Communism in theory isn’t so bad, but most would agree that the practice has been deeply destructive and debilitating to normal economic and social progress. Closely related to communism is socialism. Marx viewed socialism as a stepping-stone to true communism. True communism is functionally impossible and has never existed in the real world, since true communism requires that there be no state, no government, and no central authority. Socialism has been applied in a variety of forms and to various degrees. Socialism is, at least theoretically, a system in which the state owns and administers the means of production and distribution of goods, and society is characterized by equal opportunities for all individuals with a fair or egalitarian method of compensation. With that, we have our extremes on the spectrum of economic theory. On the one extreme, we have the laissez-faire free market, and on the other extreme we have socialism where the government fully controls the economy. As with most things, the extremes at both ends are bad. Opposing pundits often take advantage of this obvious fact in order to insult each other; each accuses the other of being at the extreme of his end of the spectrum. A free marketer is quick to call his more liberal counterpart a socialist, which in the wake of the Cold War carries a powerful sting, but when the liberal calls him a capitalist, he takes it as more of a compliment than insult. Ironically, both communists and libertarians believe in the same end, the elimination of the state, although for opposing ideological reasons. Fortunately, American economic debate is not at the extremes, despite the excessive rhetoric. At the end of the laissez-faire Roaring Twenties, the market collapsed and we entered the Great Depression. That period brought forth the great economist John Maynard Keynes. Keynes established the now widely held view that there are times when the economy simply cannot be left to Smith’s “invisible hand” theory. According to Keynesian economics, the state should stimulate economic growth and improve stability in the private sector through, for example, adjusting interest rates and taxation and funding public projects. In Keynes’s theory, certain microlevel actions of individuals and firms can lead to aggregate macroeconomic outcomes in which the economy operates below its potential output and growth. Many classical economists had believed in Say’s law, which states that supply creates its own demand, so that a “general glut” would therefore be impossible. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output. Keynes argued that government policies could be used to increase aggregate demand, thus increasing economic activity and reducing high unemployment and deflation. Keynes argued that the solution to a depression was to stimulate the economy (“inducement to invest”) through some combination of a reduction in interest rates and government investment in infrastructure. He allegedly said that in periods of economic woe, it would be beneficial for a government to employ people to dig holes in the ground and fill them up again. A central conclusion of Keynesian economics is that in some situations, no strong, automatic mechanism moves output and employment toward full employment levels. This conclusion conflicts with economic approaches that assume a general tendency toward equilibrium. Keynes’s theory led to a realignment of classical economic theory, and what emerged is now generally called neoclassical economics. To fully recognize why Keynesian economics became standard, we must consider the environment that led to its acceptance. Genesis of Irrational Exuberance Following World War I, the country entered a time of peace and great prosperity fueled by increased industrialization and new technologies, such as the radio, the automobile, and air transportation. During the Roaring Twenties, the Dow Jones Industrial Average soared. Most economists viewed the stock market as extremely safe, leading a plethora of investors to purchase stock on margin (using a loan). Just as companies in the 2008 crisis exacerbated matters through leveraging, margin users in the ’20s worsened matters by borrowing $9 worth of stock for every dollar they invested. (It is notable that this was ten-to-one leveraging. Mortgage-backed securities involved in the recent collapse were leveraged by major financial institutions by as much as forty to one.) As is the case with all leveraging, margin users saw an exaggeration of not only minor gains, but also minor losses. As you can imagine, if an investment dropped too much, margin holders could lose all of their money and then some. Millionaires were created instantly as the Dow Jones rocketed from 60 to 400 from 1921 to 1929. Stock market trading became America’s favorite pastime, as exuberant investors, intoxicated by the thought of possible gains, mortgaged their homes and foolishly invested their life savings in not only the hottest stocks, such as Ford and RCA, but also in almost any stocks. Viewing stocks as a sure thing, few actually studied the fundamentals of the companies they invested in. Worse still, many companies were formed for the sole purpose of defrauding unsavvy investors overeager to get in on the action. Most investors, even the more experienced, never imagined a crash. Doesn’t this all sound rather familiar? They say hindsight is 20/20, despite the utter failure of the market to ever actually learn from hindsight. So many so-called experts rarely demonstrate wisdom to match their education and experience. Many of these bigheads have built their careers around the lessons supposedly learned from the crash of ’29 and the Great Depression, and yet always seem to be dumbfounded when history repeats itself. It’s not actually that no lessons were learned. There hasn’t been a repeat of the bank runs that actually caused the Great Depression. The most devastating effect of the 1929 market crash was the chaos in the banking system, triggered as banks tried to collect margin calls of investors whose holdings were now worthless. As we’ve seen again and again since then, the banks themselves want in on the action during a boom, so they’ve invested depositors’ money in the market. Inevitably, word spread that banks’ assets contained huge, uncollectable loans and almost worthless stock certificates, leading to a broad-based panic. Depositors rushed to withdraw their savings, and banks began failing by the hundreds in 1932 and 1933. By early 1933, the U.S. banking system, as well as those of much of the rest of the world, had effectively ceased to function, plunging the world into the Great Depression. Thankfully we now have depositors insurance backed by the government. The Federal Deposit Insurance Corporation (FDIC) would prevent another epidemic of bank runs, especially now with the increased limits, but nothing has corrected the systemic flaws that allow real wealth to be exchanged for synthetic wealth, rapidly expanding the economy only to reverse it on an emotional whim. These flaws have caused recession after recession and the slow, painful destruction of the middle class. The banks still share in the irrational exuberance, participating in and exacerbating every bubble. The former chairman of the Federal Reserve Board, Alan Greenspan, once said in testimony to Congress, “While bubbles that burst are scarcely benign, the consequences need not be catastrophic for the economy.” This statement was meant to build confidence in the ability of the Federal Reserve and other policy makers to prevent errors similar to those that caused the Great Depression. Yet in 2008, Greenspan had to return to Congress to essentially apologize for his failure to see the subprime crisis coming. It’s not that surprising that these bigheads are always blindsided when you consider that they still cannot agree on the correlation between the 1929 crash and the Great Depression. There are economic theories to support every conceivable political and philosophical position. Perhaps this is why so many would prefer to trust an invisible hand rather than their colleagues. Nevertheless, the bigheads have at least given us terminology to describe the events that they can never prevent, manage, or correct. For instance, today we call it a “bubble” when the money supply extends beyond what genuine capital investment supports and expanded credit taking the place of an expanded pool of investors. The suspension of disbelief, the expectation of large profits, and ever-rising (and unsustainable) prices in an open market are all now recognized as classic characteristics of the prelude to a crash. Yet the preoccupation with self-interest (and yes, selfish greed) causes markets to repeat the same mistakes over and over again, to the point that both experts and novices consider expansion and recession to be natural cycles of the economy. So, is this an indictment of Adam Smith? Not exactly. But the interpretation and application of his theories have led to the mess we have seen since. Despite the fact that the words “economy” and “capitalism” were not used in Smith’s day, his descriptions persist as the fundamentals of capitalist economics. His main theme was that of an invisible hand that leads to the best results, because opposing self-interests lead to equilibrium. This is best expressed in the most-quoted passage in Wealth of Nations : “It is not from the benevolence of the butcher, the brewer, or the baker that we expect our dinner, but from their regard to their own interest. We address ourselves, not to their humanity, but to their self-love, and never talk to them of our own necessities but of their advantages.” 11 The clear rhetoric with which he describes bargaining (“Give that which I want and you shall have this which you want,” and “It is this manner that we obtain from one another the far greater part of those good offices which we stand in need of”) has proven hard to resist. Depression and Recessions The blind acceptance of this dogma as divine wisdom has led to each and every one of the market crashes and recessions, and to the attrition of the middle class. Just look at the circumstances around each of the major recessions of the last century. We begin with the Great Depression, which is generally viewed as a benchmark for the worst that can happen. It lasted for about 120 months, from roughly 1929 to 1939, though, as a worldwide economic downturn, it ended at different times, in the 1930s or early 1940s for different countries. The usual consensus is that it began with Black Tuesday, the first day of the crash of 1929, and ended with the onset of the war economy of World War II, beginning around 1939. While some ideologues hold the line for Smith dogma at all times, Herbert Hoover, president from 1929 to 1933, proved to many that a government failing to intervene in an economic crisis was almost as bad as a government causing the crisis. Hoover feared that too much intervention or coercion by the government would destroy individuality and self-reliance, which he considered to be important American values. It is not that Herbert Hoover did nothing while the world economy eroded. President Hoover made attempts to stop the downward spiral of the Great Depression. Rather, it’s that his policies had little or no effect. As the economy quickly deteriorated in the early years of the Great Depression, Hoover declined to pursue legislative relief, believing that it would make people dependent on the federal government. His ideology, though perhaps not completely laissez-faire, prevented him from really getting ahead of and thereby shortening the Great Depression. Even though the New Deal under Franklin D. Roosevelt was on the right track, it wasn’t until the nation suspended the gold standard and leveraged itself with bonds to build a war machine that enough liquidity entered the economy to truly end the Great Depression. After the war, the gold standard was never really restored. The Bretton Woods system of monetary management was established to shift from a representative currency system to fiat money, which would in time allow the Federal Reserve to print money without restraint. (We’ll talk more about this later, because monetary policy is also at the heart of the catabolism of our country.) The next major decline was the recession of 1947. This was perhaps the most honest recession of the nation’s history; the market just got too hot. Coming out of the war, there was a combination of euphoria, industrial overproduction, and too much money in the pipelines that led to rapid inflation. More significantly, this was the beginning of a shift away from the New Deal. President Truman had been nominated to be vice president in 1944 under the powerful influence of party bosses who were opposed to the notion of the incumbent vice president, Henry Wallace, becoming president. They viewed Wallace as too liberal. Truman was the beginning of a sea change. Though Truman was a Democrat and voiced support for New Deal policies, he also didn’t view Smith dogma as mutually exclusive with the New Deal. He strongly supported laissez-faire-like policies and had even denounced market controls as marks of a police state, but by the end of 1947, he had reversed himself. This was in many ways the beginning of the inflationary economy that we know so well. Also, one of the most significant lessons of this recession was that the U.S. could not isolate its economy from the world. The year 1947 marked the birth of the global economy in ways that even the Great Depression did not. Not learning from our mistakes, we effectively repeated the 1947 recession in 1953, when, as after a post–Korean War inflationary period, more funds were transferred into national security. The Federal Reserve also contributed to matters by making monetary policy more restrictive in 1952 due to fears of further inflation. Economists agree that this was a demand-driven recession due to poor government policies and high interest rates. It was also the first of three recessions for Smith disciple President Dwight Eisenhower, the most of any president. The Eisenhower years marked the beginning of total domination of Smith dogma in economic thought. These years also illustrated the new political reality that would shape the country for the foreseeable future: voters ignore the economy when there is no boogeyman to fear. Ike’s next recession ran, arguably, from July 1957 through April 1958, and was global in impact. Monetary policy was tightened during the two years preceding 1957, followed by an easing of policy at the end of 1957. There was a contraction in the purchases of both agricultural and mineral raw materials, which hit economically disadvantaged countries the hardest. Unemployment rose across the board, but in Detroit it stood at a high of 20 percent. Auto sales dropped 31 percent throughout 1957, making 1958 the worst auto year since World War II. It is typical for prices to fall during recessions, but this time they went up, not including raw materials. In the U.S., consumer prices rose 2.7 percent from 1957 to 1958, and after a pause they continued to push up until November 1959. Wholesale prices rose 1.6 percent from 1957 to 1959. The continued upward creep of prices became a cause of concern among economists. The budget surplus of 0.8 percent of GDP in 1957 gave way to a budget deficit of 0.6 percent of GDP in 1958, and then to a widening deficit of 2.6 percent of GDP in 1959. A recession from 1960–61 was the mildest of Eisenhower’s three recessions. Economists often scratch their heads at this one, because it lacked some of the indicators of other recessions. With Ike finally out of power, the country entered a period of prosperity under Kennedy and Johnson. Their economic policies harkened back to the New Deal, with initiatives christened as the New Frontier and then the Great Society. Even though these were turbulent times socially, there would not be another recession until Ike’s vice president came to power. On January 20, 1969, Richard Milhous Nixon took the oath of office, and the economic expansion came to a halt in the United States by autumn. Ever the ideologue, Nixon acted on his conservative philosophy of “gradualism” and moved to cut the budget. This, together with an environment of higher interest rates, caused the 1969 recession and a bear market until May 1970. This recession was less severe than the two-year recession that marred Nixon’s second term nearly as much as did Watergate. Nevertheless, Nixon continued destructive economic policies. In 1971, the Nixon administration unilaterally canceled the Bretton Woods system and stopped the direct convertibility of the U.S. dollar to gold. Meeting in December 1971 at the Smithsonian Institution, representatives of the Group of Ten (G10) nations signed the Smithsonian Agreement, thereby agreeing to appreciate their currencies against the U.S. dollar. Although the Smithsonian Agreement was hailed by President Nixon as a fundamental reorganization of international monetary affairs, it led to devaluation of the dollar. To be fair, this was inevitable. By the early 1970s, as the Vietnam War accelerated inflation, the United States was running not just a balance of payments deficit, but also a trade deficit for the first time in the twentieth century. The crucial turning point was 1970, which saw U.S. gold coverage of the paper dollar deteriorate from 55 percent to 22 percent. This theoretically represented the point at which holders of the dollar had lost faith in the U.S.’s ability to cut its budget and trade deficits. In 1971, more and more dollars were printed and then sent overseas, to pay for the nation’s military expenditures and private investments. In the first six months of 1971, $22 billion in assets fled the United States. Relaxed monetary policy, however, could not prevent the recession of 1973, the worst since the Great Depression to that point. Double-digit inflation and unemployment characterized this textbook recession, which ran from April of 1973 until the spring of 1975. On October 6, 1973, Syria and Egypt launched a military attack on Israel, starting the Yom Kippur War. When the members of OAPEC (Organization of Arab Petroleum Exporting Countries, consisting of the Arab members of OPEC plus Egypt and Syria) proclaimed an oil embargo “in response to the U.S. decision to resupply the Israeli military during the Yom Kippur War,” the effect on the U.S. economy was severe. Worsening this oil crisis, OPEC realized its power over the global economy when OPEC members agreed to use their leverage over the world price-setting mechanism for oil in order to stabilize their real incomes by raising world oil prices. Ultimately, oil prices quadrupled. This period also saw a crash of all the major stock markets in the world, particularly the London Stock Exchange in the United Kingdom. The New York Stock Exchange’s Dow Jones Industrial Average benchmark lost over 45 percent of its value. In fact, Pierre Perron of Princeton University argued that the 1973 “oil price shock,” along with the 1973–74 stock market crash, combined as the first event since the Great Depression to have a persistent economic effect. The Iranian Revolution sharply increased the price of oil around the world in 1979, causing the 1979 energy crisis. This was caused by the new regime in power in Iran, which exported oil at inconsistent intervals and at a lower volume, forcing prices to go up. Tight monetary policy in the United States to control inflation led to another recession. The changes were made largely because of inflation that was carried over from the previous decade due to the 1973 oil crisis and the 1979 energy crisis. There was a brief period of relief and positive sentiment during the second Reagan presidential campaign, but it is arguable whether there was actually a reprieve from the oil shock and the recession of the early 1980s. The ’79 recession lasted until the end of 1982. Unemployment floated around 7.5 percent before peaking at 10.8 percent at the end of this recession, and the inflation rate peaked at 13.5 percent. Before the crisis of 2007–10, this was regarded as the worst recession since the Great Depression. In the wake of the 1973 oil crisis and the 1979 energy crisis, “stagflation” began to afflict the economy of the United States. Stagflation is an economic situation in which inflation and economic stagnation occur simultaneously and remain unchecked for a period of time. The concept is notable partly because, in postwar macroeconomic theory, inflation and recession were regarded as mutually exclusive, and also because stagflation has generally proven to be difficult and costly to eradicate once it gets started. Several key industries—including housing, steel manufacturing, and automobile production—experienced a severe downturn, and many of the economic sectors that supplied these basic industries were also hard-hit. Determined to wring inflation out of the economy, Federal Reserve chairman Paul Volcker slowed the rate of growth of the money supply and raised interest rates. The federal funds rate, which was about 11 percent in 1979, rose to 20 percent by June 1981. The prime interest rate, at the time a highly important economic measure, eventually reached 21.5 percent in June 1982. It is generally agreed that the contradictory monetary policy established by the Federal Reserve was a primary cause of this recession. This is particularly disturbing when you consider that the 2008 crisis came amid low inflation and interest rates in the low-to-middle single digits. Volcker’s determination to “wring” inflation out of the system produced the sort of collateral damage that in hindsight seems inevitable. In contrast, in the recent collapse, the monetary policy was the sort that would “normally” cause the economy to overheat. Even the recession of the early 1990s could be directly tied to the rapid decrease of industrial production and manufacturing-trade sales in early 1991. There was a drop in demand caused by a debt buildup in the 1980s by individuals, businesses, and the federal government. Apprehension caused by high structural unemployment of both blue- and white-collar workers slowed the recovery. Some even considered this recession to be a delayed reaction to the Black Monday crash of October 1987, in which the Dow Jones Industrial Average suffered an unprecedented loss of 22 percent. The collapse (larger than that of 1929) initially seemed to have been handled well by the economy and the stock market, but it soon turned out that the quick recovery was illusory, and by 1990 economic malaise had returned with the beginning of the Gulf War and the resulting 1990 spike in the price of oil. For the next several years, high unemployment, massive government budgetary deficits, and slow GDP growth affected the United States economy. The failure of traditional industry was soon muted by a revolution: the PC revolution. By the middle of the 1990s, millions of personal computers had been sold and a previously little-known government project (the Internet) became the worldwide information superhighway. Nevertheless, too much of a good thing is never a good thing, and the idea that the Internet changed everything was overhyped, which eventually gave way to the collapse of the dot-com bubble. Adding insult to injury, the September 11 attacks and accounting scandals of the Enrons and Arthur Andersens of the world contributed to a relatively mild contraction in the North American economy. After the collapse of the so-called “new” Internet economy, we were left where we’d been after the 1987 stock market crash. With each of the crashes and recessions since World War II, the country has subsisted off the ingestion of one after another of its industries. Each recession has left us weaker than we were before it. We have fed like cannibals off mergers and acquisitions, as real productivity has been replaced with accounting tricks. When Smith and Keynes Break Down We should question why residential housing became the linchpin of the global economy. We have to consider the systemic problems. Can we really thrive as a 99 percent service economy? Will the economic model of the Bahamas carry the last remaining superpower? The answer is obvious. Pure free markets can achieve equilibrium in certain circles but cannot achieve broad-based progress. Each of the recessions detailed above demonstrates a breakdown in both the philosophies of Smith and Keynes. The free market would not and could not have created the Internet, for the fundamental reason that it would not have been profitable to create. Its development would have been cost prohibitive for any one company, and, without the benefit of our hindsight, it would have seemed like a highly speculative investment that the shareholders of any major corporation would not have stood for. Interests other than the bottom line created the Internet. Also, we now know that Volcker’s 20 percent interest rates were destructive. Lowering interest rates and raising interest rates do not have balanced, alternate effects, perhaps mostly because there is a limit of zero to lowering rates, but there is no limit to how high rates can go. Despite Keynesian theory, the best role of governments in economics is not to substitute for market interests, but to provide the infrastructure, environment, and regulation for market interests to thrive. That is not to say the government should have as little a role as libertarians would suggest. As with the Internet, the government and not-for-profit organizations must do the heavy lifting of creating a platform for commerce, allowing the private sector to come behind and create the businesses and innovations to drive continual growth. Smith takes for granted that the platform for commerce is already in place. Further, one has to ask if Smith dogma really encompasses the scope of a global, Internet-based, jet-set economy, in which stakeholders sit in the far-flung corners of the world and not necessarily at the bargaining table. Twentieth-century economic history strongly suggests that when large, systemically important entities act purely in their own self-interests, there are damaging effects felt, most often by regular people. In bilateral, arms-length transactions, mutually opposing self-interests may create a fair exchange that is further improved by competition. The problem is that there are many, many more ways in which business takes place. Today, the participation of banks, governments, corporations, labor unions, investment funds, and exchanges has elevated the complexity of economic behavior and transactions. The depths of complexity have given cover to those whose self-interest has led them to commit fraud, distort valuations, pervert markets, and cash out of bubble after bubble. We must look at the underlying morality of the whole system that promotes and encourages the concept that pursuing self-interest is a good thing. Defenders of Smith emphasize that Smith was not advocating a social policy (that people should act in their own self-interest), but rather was describing an observed economic reality (that people do act in their own interest). It may be true that he did not argue that self-interest is always good, but rather that self-interest is not necessarily bad. The problem, though, is not whether self-interest works when it works, but rather whether it excludes—or worse yet, suppresses. Many capitalists believe that without unfettered markets, innovation starves, prosperity weakens, and societies stagnate, and therefore the selfish pursuit of money is good, even moral. While there is some truth to that, is it entirely true? Are the best technologies the most frequent winners? Do the largest companies generally allow competing innovations from small, unknown sources? The fact is that, more often than not, the “real world” application of Smith is to squelch competition to such a degree that even so-called venture capitalists are terrified to back new companies that intend to go head-to-head against entrenched companies. The thing about the butcher, the brewer, and the baker is that they are on relatively even ground, occupying complementary roles. In the modern economy, there are corporations with greater wealth than entire nations. According to an Institute for Policy Studies report, “Top 200: The Rise of Corporate Global Power,” by Sarah Anderson and John Cavanagh, released December 4, 2000, a majority of the world’s largest economic entities are corporations: fifty-one are corporations, while forty-nine are countries in the top one hundred. Some would argue that a number of these corporations actually control some nations. Private enterprises with this much power devote great resources to maintaining the status quo and bolstering barriers to competition from up-and-coming businesses, all with the “justification” of self-interest. In the highly competitive realm of small businesses, Smith works out fine, but let’s take a look at a few examples of what has happened to innovative technologies that were not backed by major corporations and that could actually have threatened the business of large, multinational corporations: The ultrasonic washing machine (U.S. Patent 4727734): Created as an alternative to traditional washers that use agitation and chemicals to wash textile products, the machine, for which the inventor received his patent on March 1, 1988, has no moving parts, can be cheaply mass-produced, needs no chemicals, and most importantly, works arguably better than anything now on the market. Clothes are placed in a basin of water and an ultrasonic wave generator at the base of the machine creates millions of tiny air bubbles to help loosen grime and grit on clothes in a purely mechanical action. The benefits of this invention are too plentiful to enumerate here. Any textile that could be placed in cold water could be cleaned. With no moving parts, maintenance would be negligible, and the reduced use of detergent chemicals would minimize environmental impact. The device could easily be mass-produced, making it cost-competitive with existing machines. So, why has this obviously superior technology been sitting on the shelf for over twenty years? The answer is that the inventor was contacted by several major corporations representing various entrenched interests, each seeking an angle by which they could profit from his invention. Yet lacking any intrinsic obsolescence or external dependencies, they could find none. Did they pay him off to bury it? Who can say . . . or rather, who would say? Assuming that no criminality was involved, and even that they may have achieved an equitable agreement, how was the public good served by the withholding of this technology? Electrolytic hydrogen combustion engine (U.S. Patent 7273044): This hydrogen fuel system for an internal combustion engine is one of dozens of patented technologies to run a car on water. You read correctly! This is one of dozens of patented technologies to run an internal combustion engine on water. Water is, after all, two parts hydrogen and one part oxygen. Hydrogen is ultimately what we “burn” in gasoline, natural gas, or any other hydrocarbon. An engine that splits and combines water to produce all the power (maybe more) of a gasoline- or diesel-powered engine is not just theoretically possible; it is a very real technology that is here now. The patent cited above was issued on September 25, 2004, but the existence of this technology is virtually unknown. There are other “hydrogen-on-demand” vehicles that have been produced that use a chemical reaction to produce hydrogen as needed to run the car or truck. Either way, the idea of engines that don’t pollute, don’t require gas stations, and that can power the same cars (everything from compacts to SUVs) we have today, without depending on some phantom, future technology that is always in the offing, should be a no-brainer. Yet it is the self-interest of entrenched powers that preclude the development and distribution of these technologies. More than 97 percent of the world’s petroleum is used for transportation. Some of the richest nations in the world are rich only because of their oil exports. ExxonMobil made over $45 billion in profit in 2008. Many agree that petroleum commerce is the cornerstone of the global economy. Even governments that are compromised by their nation’s dependence on foreign oil fear the ramifications of a wholesale shift away from it. It is in the self-interest of all of these powers to suppress or destroy any real competition to fossil fuels. It may also be in their self-interest to give lip service to alternatives by promoting untenable energy sources, but not to endorse real alternatives. Short of the dramatic instances above, history has proven time and again that the best innovations are often squelched by more powerful competition. No one who really knows software believes that Microsoft writes the best computer programs, particularly in terms of power, stability, and security. Anyone who knows videography knows that Betamax was superior to VHS. No doubt there are many other examples buried in the files at the U.S. Patent Office. I experienced this reality personally as a callow young investor. More times than I can recall in my early days trading stocks, I lost money investing in companies with remarkable, innovative technologies that were more advanced than the competition. My technical knowledge was my Achilles heel. One such company in which I bought stock was Paradigm Technology, a company that was known in its day by the computer engineering community to produce the most sophisticated SRAM (memory) chips for computers at the time. No reputable source that I can recall or find denied that fact. But the more powerful interests in the industry, companies like Micron and Samsung, instead pushed DRAM memory-chip technology, which everyone in the business knows is functionally inferior to SRAM. I could elaborate on why, but that is not the point. The whole industry followed the big business interests of companies like Micron (still a king of the memory-chip business) instead of delivering the best actual product to the masses. To this day, most computers use the inferior DRAM, and Paradigm has been out of business for years. Some would suggest that history is replete with David and Goliath success stories of business started in garages, like Dell or Microsoft, but a closer examination of this history show almost without exception that the successful upstart always targets an aspect of business that entrenched companies either neglected or hadn’t conceived of. Microsoft targeted a market that IBM had little interest in at the time. In fact, IBM helped them get up and going because they saw the PC market as trivial. Dell pioneered the negative cash-conversion accounting model and a cutting-edge product-delivery system. Much harder to find are examples of small startups that succeeded at going head-to-head against behemoths without such radical innovations. Simply a better product at a better price is not enough for success in a cannibal capitalist system. All of this suggests that the Smith doctrine, when allowed to grow dramatically beyond the scale of the butcher, the brewer, and the baker, breaks down and fails to provide the greatest benefit to the greatest number. On the other hand, Keynesian practices can also go too far and create conditions for unsustainable dependencies. Without clearly charting a course between competing theories and ideologies, we have drifted into cannibal capitalism, a system in which innovation is starved, prosperity has declined, and a stagnant economy subsists on recycled debt financing. A financier from whom I once sought project financing summed it up. After acknowledging that I had a great project that should be very profitable, he asked me, “Why would I tie my money up in a project for a year or more when I can get the same return with a leveraged financial instrument in a couple months?” This is the sort of cannibal capitalist thinking that has devolved the economy from one that makes stuff to one that just grows debt. The word “finance” should more often be a verb, a means to an end, but the reality is that it is more often a noun, an end in itself. Instead of a mechanism to drive the real economy, it is solely a mechanism to make money by draining the real economy of its wealth. 11. Adam Smith, An Inquiry into the Nature and Causes of the Wealth of Nations , 5th edition (London: Hanlins Press, 2007), 122.",
        "char_count": 56472
      },
      {
        "heading": "Chapter 8",
        "text": "Chapter Five Devolution of the Real Economy through Cannibal Capitalism Born into an impoverished family later broken by the Great Depression, he dared not dream for too much in life. He survived combat in World War II and was witness to hopelessness and death, but survived it all and returned home, victorious and determined to make his life count. His sweetheart had fearfully yet patiently waited to become his wife and to raise a family. She too shared his positive view of the future: their life would be better. His name is not important, because you could likely substitute any name I provide with a member of your own family. Ten years later, they had a home in one of those planned communities later described as suburbia, six children, a dog, a new car, and he had a good job earning $4,600 a year, slightly higher than the national median in 1955. The home cost $9,000 with a mortgage payment of about $50 a month. A gallon of milk cost 92¢, a loaf of bread was 18¢, a dozen eggs cost 61¢, and a five-pound pot roast could be bought for $2. With a modest income, he could support his family by himself, build their savings, and set a course for a better future for his children. Fifty-one years later, in 2006, the median salary of a single income family was $45,757. If you lived near a major city, the median cost of a single family home was over $550,000, which at a 6.5 percent interest rate on a thirty-year fixed mortgage would cost about $3,500 a month, not counting escrows for taxes and insurance. With a biweekly take-home pay of $1,400, owning the median home was a pipe dream. A gallon of milk cost $3.75, a loaf of bread was $3, a dozen eggs cost $2, and a five-pound pot roast at $5.99 a pound was nearly $30! While income rose by multiples of ten, the cost of a loaf of bread rose to 16.6 times what it was, and the cost of a home rose sixty-fold. Visible Decline of the Middle Class Any way you slice it, it is simply not possible to reproduce the lifestyle of our parents in today’s economy without earning an income that is substantially higher than the median. Once upon a time in America, a man could support his family working as a door-to-door vacuum salesman. There were “good jobs,” such as milkman or elevator operator, that only required a minimal education. Today, a “good job” is computer programmer, architect, or engineer, all of which require extensive education, though less than that of a doctor or lawyer. Yet even these “good jobs” aren’t good enough. According to Salary.com , at the time of this book’s publication, a moderately experienced computer programmer makes about $60,000 per year, a fully licensed architect makes about $70,000, and a mechanical engineer can make $80,000. What you may find utterly shocking is that, by some measures, the buying power of a mechanical engineer today is less than that of a milkman in the fifties. A mechanical engineer making $80,000 cannot afford a median-priced single-family home in most of the major metropolitan suburbs, where an engineer is most likely to command that kind of income. In these places, an $80,000 income can mean living paycheck to paycheck. I know that, where I live, at that income you are either living in an apartment, a rough neighborhood, or commuting three hours a day. At best, with a spouse that is just as well paid, you can squeak by with a double income. How the heck did that happen? Think about this. You do all the right things. Get good grades, go to college, develop a reputable skill, even pursue a graduate-level degree, and still barely make ends meet. If that is the case for those who are exceptional, what hope is there for the average folk? This is the destruction of the middle class, and we are complicit in this villainy. Our system has cannibalized our people. The wealth of millions is being devoured to such a degree that even the best are doomed to little more than corporate serfdom. Corporate serfdom? Isn’t that an extreme characterization? I don’t think so. Serfdom was the enforced labor of serfs (members of a servile feudal class) on the fields of landowners, in return for protection and the right to work a little for themselves on their leased fields. Serfdom involved not only work in fields, but also various other activities, like forestry, mining, transportation (both land- and river-based), and crafts. Manors formed the basic unit of society during this period, and the lord and his serfs were bound together legally, economically, and socially. Serfs were laborers who were bound to the land; they formed the lowest social class of the feudal society. The serf worked harder than the others and was the worst fed and paid, but at least he had his place and, unlike the slave, he enjoyed the illusion of his own land and property (although it could always be taken away). Serfdom bound not only an individual, but also all of his future heirs. His status and that of his family remained the same or worsened as he enriched the life of his lord. Sound at all familiar? Today, instead of land, working people are attached to the abstract economic system and are indentured to corporations. Corporations are the barons of our day. Corporation employees are now the core economic engine of our society. “Protection” is conferred through salary, benefits, and credit. Your home is actually “owned” by another corporation. In fact, all major personal property is acquired through financial schemes to enrich corporations. Most people are utterly dependent on the corporation. Despite the illusion of independence and self-determination, if one’s employing corporation suffers losses, there is a risk of losing everything. People may struggle and save to build better lives for their children, and yet they raise their children to live the same way, as serfs to corporations. It’s a cliché but true that the more things change, the more they stay the same. The big difference is that the quality of life of the modern corporate serfs is astronomically better than the serfs of the past. For most of the last fifty to sixty years, technology has given rise to an ever-improving standard of living, and people are relatively content despite the subtly felt reality of their decreasing share of the nation’s wealth. The almost imperceptible degradation of the middle class, though shrouded by pacifying distractions, has been constant since its broad-based creation at the end of World War II. One must first recognize that the concept of a middle class is relatively new and is very fragile. Frankly, it is a product of the twentieth century. The combination of industrialization, unionization, early globalization, education, financial ventures, and government programs and subsidies transformed post–World War II America, creating the world’s largest middle class. Since then, changes in each of these contributing forces have threatened to rip us apart. Historically, the modern middle class is an anomaly. Even today, most of the world consists of rich and poor, elites and peasants, as has been the case for millennia. Considering that it has been that way for centuries, we must fear that, without intervention, natural economic forces will continue to drive the economic status of Americans into those extremes. Many agree that income disparity is at an all-time high. Yet because the drift has been moving incrementally, almost imperceptibly, no one but those on the extreme left are outraged. Most take for granted that the middle class will always exist and falsely believe that it always has. Something that has been a certain way for fifty years cannot be assumed to “always” be the same. Frankly, the free market is ambivalent about maintaining and developing the middle class. The invisible hand of the free market seeks a balance between buyer and seller, supply and demand, producer and consumer. Cost is a critical component to commerce, and labor is a component of cost. From a dispassionate, market-centric view, full employment is a terrible thing because it forces employers to compete with others for human resources, thereby raising labor costs and upsetting market balances. Ideally, from that point of view, for every job, there should be multiple, qualified applicants effectively competing to do the job for the least money. Regular workers rarely recognize that. That is why unions are such a force; unions accomplish labor-price fixing through collective bargaining. When various, equally qualified individuals apply for the same job, the employer will generally pick the one who will do the job for the least pay. As an employer, I loved to see high unemployment rates among people with skill sets that I needed. You run an ad, get more applicants than you can handle, and get to have your pick. But is that good for the broader society? I think not. A very tough reality to come to grips with is that the large middle class that was needed in the recent past is not needed anymore. Globalization, automation, and the maturity of the country’s infrastructure and marketplace have all contributed to a lessening of the demand for an unspecialized workforce, historically a large component of the middle class. The transition to a service economy has created jobs, but only in parity with losses, and, generally, these new service jobs pay less than lost industry jobs. Even when the numbers look innocuous or even positive, the reality is often dire for regular people. While economists focus on the means, modes, and medians, the numbers do not reveal the problem. Upper incomes skyrocket and lower incomes crash, but the macroeconomic numbers seem just fine. However, when you divide the population into wealth groups as shown in Figures 5.1 and 5.2 , you begin to see the seriousness of the actual disparities. Figure 5.1 Figure 5.2 Nevertheless, it’s not all bad news. We have seen growth in technology in recent decades, which then drives job creation in supporting industries. It is for this reason that we haven’t seen constant declines, but rather cyclical contractions. Yet with the declines in other areas of the job market, new grads find themselves in a more competitive environment that also suppresses wage growth. The net effect is stagnation. In fact, more recently, the net effect got so bad that mainstream economists finally started to notice. This is all simple supply and demand. We don’t need many factory workers. The best price to market involves outsourcing to India and China. The market is seeking equilibrium. If we mess with the natural market flows, it’s socialism! We’re not socialists! Thus, we have the conundrum: what is the proper balance between (1) leaving the free market alone, unchecked, and (2) direct government involvement or even economic planning, what some decry as socialism? New Deal Gone Wrong Franklin Delano Roosevelt was called a socialist, communist, and fascist, all because he believed that the government had to do something to correct the Great Depression. Between the New Deal and World War II, Roosevelt did manage to lead the country out of the Great Depression, regardless of whether he deserves the credit. Some suggest that the New Deal failed to strike the balance between the extreme left and right, and may even have slowed economic recovery. Particularly, this position is argued by UCLA economists Harold L. Cole and Lee E. Ohanian in their report “New Deal Policies and the Persistence of the Great Depression: A General Equilibrium Analysis,” as well as in other articles. They contended that FDR’s policies prolonged the Great Depression by seven years. The greater number of economists and historians believe that Roosevelt restored hope and self-respect to tens of millions of desperate Americans. Most would agree that his administration’s support of labor unions and upgrades of the national infrastructure greatly helped the struggling workforce and curbed economic decline, if not completely reversing it. Some would even say that FDR saved capitalism in his first term, when he could have destroyed it by going to the extreme of completely nationalizing the banks and the railroads. While many of the New Deal initiatives were foolhardy and were quickly abandoned, others are so widely recognized as necessary that it would be political suicide to mess with them even today. Particularly, the Securities and Exchange Commission (SEC), the Federal Deposit Insurance Corporation (FDIC), the Social Security Administration, and the Federal National Mortgage Association (Fannie Mae) are responsible for greatly improving the economic health and growth of the nation for the last fifty years. The engineers of the New Deal were not all of the same ilk and ideology. Some were political idealists, and others were hypothesizing economists who used the administration in order to experiment with the economy. As is common with scientific processes, some results were entirely unexpected. I believe that FDR just wanted to end the Great Depression, and would have been completely content with a return to the economy of the turn of the century. What he actually did was create the circumstances for the working class of twentieth-century America to live at the standard of the wealthy gentry of the past. Working people would no longer be peasants, as they’d been as recently as a generation earlier. Minimum wage and maximum hours; the elimination of child labor; weekends; the increased economic output started by World War II; labor unions backed by the power of the government in the form of the National Labor Relations Board; and other reforms all combined to cut the labor supply and raise wages and the quality of life for millions. The modern middle class emerged as a major force, which then drove the creation of new industries and a service economy. So remarkable was the recovery that many of the bigheads chalked it all up to the American way, as if it were inevitable that we would create the world’s largest middle class and highest standard of living. Between the ’50s and the ’90s, the median income nearly doubled during each successive decade. Through bubble and bust, this persistent progress has fostered the belief that this is just the way it is and will always be. Nevertheless, with the exception of a few cornerstone programs, the New Deal has been dismantled piece by piece ever since. Worse still, the thinking of Roosevelt has been demonized progressively to such a degree that re-creating or reenergizing the factors that created this economy is politically unviable. It seems that President Obama would like to be the next Roosevelt, but the political positions that developed in opposition to the New Deal have calcified to such a degree that, beyond revisionist economists like Cole and Ohanian, there is powerful institutional opposition to anything that remotely smacks of socialism. Between 1970 and 2000, there has been a slow-moving wave of deregulation, reversing not only the policies of the New Deal, but reversing its very philosophy. This deregulation reached a crescendo on November 12, 1999, with the Gramm-Leach-Bliley Act, which effectively repealed provisions of the Glass-Steagall Act that prohibit a bank-holding company from owning other financial companies. Many experts claim that this repeal directly led to the housing crash and thereby the global economic collapse that followed it. Deregulation gained momentum in the 1970s, influenced largely by Chicago School of Economics theorists Ludwig von Mises, Friedrich von Hayek, and Milton Friedman, among others. Picking up on this, political think tanks in Washington, the Brookings Institution, and the American Enterprise Institute enthusiastically held seminars and published studies advocating deregulatory initiatives throughout the 1970s and 1980s. What followed? Deregulation of transportation, energy, communications, and banking. The Railroad Revitalization and Regulatory Reform Act of 1976 was the first in a series of acts that deregulated transportation in the United States. It was followed by the Airline Deregulation Act of 1978, the Staggers Rail Act of 1980, and the Motor Carrier Act of 1980. The Emergency Natural Gas Act, which was signed on February 2, 1977, in an effort to contend with OPEC price hikes and the 1973 oil crisis, deregulated a significant area of energy production. The Telecommunications Act of 1996 was a major overhaul of United States telecommunications law that had remained relatively unchanged since 1934, aside from the breakup of AT&T. The act was claimed to foster competition, but it actually continued the historic industry consolidation begun by Reagan, whose actions reduced the number of major media companies from around fifty in 1983 to ten in 1996. By 2005, that number fell even further, to only six. For obvious reasons, we should all be concerned about concentration of media ownership resulting from the deregulation of controls that were designed to safeguard diversity of viewpoint and open discussion across society. Yet, of all the economic sectors that were intended to be addressed by New Deal reforms, the most important were those focused on the financial sector. The conservative movement successfully dismantled many of these controls, as the nation forgot the lessons learned in the crash of ’29 and the Great Depression. The junk bonds and M&As of the ’80s and the booms and busts of the ’90s ultimately climaxed with the crash of 2007–8. All of this deregulation and the profiteering that followed has decimated the middle class. It is ultimately cannibalistic, because the many industries that subsist on the consumerism of the middle class are ultimately undermined. The harder it is to feed your kids, the less likely you are to use hard-earned money on anything not absolutely necessary. If the middle class isn’t supported—or rather, promoted—the contraction of the economy will exceed the nightmares of those who have taken for granted that the way things have been is the way things will always be. Is it time to plan or still trust in the invisible hand? While the middle class is the victim, it is a complicit victim, even if the complicity is based on ignorance. Everyone learns to read and is encouraged to do so. That so many don’t is a pity, but hardly an excuse. The meritocratic elements of the system make it entirely possible for a person born into the modern serfdom to be elevated to the upper echelons of society. This is perhaps uniquely American. For those who flow with the current of the system as it is, there is guidance to direct them where to go, what to think, and how to live. The status quo is well maintained. From early childhood, you are shunted into an education based on memorizing rules and compliance with the system. It’s not too hard to sum up what people are conditioned to view as the ideal life. Think about what we have all been told. You know the rules. Walk in single file, memorize facts and patterns (after all, you will be tested and graded on how well you memorized those facts and patterns), get good grades, go to college, get a good job, work hard as a loyal employee, save your money in a bank, marry your high school sweetheart, buy a house, plan for retirement with a 401(k), and retire to a warm place before you die. In fact, many would sincerely feel that getting that all done constitutes a very successful life. Yet rarely do the most successful people follow those rules. To the contrary, because of our preoccupation with sports and entertainment, some of the highest paid people were, as adolescents, class clowns or otherwise disengaged from academics. Some of the richest men in the world, including such billionaires as Microsoft’s Bill Gates and Oracle’s Larry Ellison, are college dropouts. As we discussed in the previous chapter, “good jobs” don’t really cut it. Loyalty in the workplace is generally a one-way street, demanded from employees but rarely shown by employers. A typical savings account pays less than 1 percent interest, and even the best certified-deposit accounts rarely pay more than the inflation rate. In other words, our savings constantly lose value. While we put our money in the banks for negligible interest, the banks leverage forty to one with our money to pursue risky investments, which in good times reap colossal returns and in bad times are covered with tax dollars. The divorce rate for first marriages is the best when compared to those of second and third marriages, but unfortunately, it is still at about 50 percent. So, while your best shot may be your high school sweetheart, your chances still aren’t that good. The one thing that people have always thought they could count on is home ownership, but even that isn’t as trustworthy as you would think. Need I go on? There is no new deal. It is the same old raw deal. It is a system-wide scam to use the strong backs and eager minds of the masses as fodder to build up the rich and powerful. That they don’t realize their commonality with the rest of us only makes them ignorant cannibals.",
        "char_count": 21080
      },
      {
        "heading": "Chapter 9",
        "text": "Chapter Six Your Own Opinion or Own Facts? Selective Morality When Johnny Carson left late night television, a three-way ratings battle ensued. Jay Leno and David Letterman continued a much longer rivalry, but at its beginning, there was a third contender—Arsenio Hall. Other than such highlights as having Bill Clinton play the sax with the show’s band during the 1992 presidential campaign, Hall’s show failed to sustain the sort of content that the remaining kings of late night have become known for. Nevertheless, there was one bit that I often enjoyed. He called it “Things that Make You Go Hmmm.” He would generally cite some irony of popular culture or satirize politics. A lot of what he would say would miss the mark, but now and then he would nail something or someone. Maybe it would offend, inciting a groan from the crowd, or maybe it would just provoke a hearty laugh, but when it was good, it did make you think. Much of what I am about to say is in that spirit. Why is it that the very conduct we expect, in fact demand, from children is so rarely followed by us as adults, and certainly not by our institutions? Hmmm. Why do we choose political positions and parties based on unrelated social issues that may never come up, instead of factors germane to policies that are certain to come up? Hmmm. Why is this melting pot of a multicultural, pluralistic society tearing itself apart over cultural identity? Hmmm. Opposing Parties or Warring Factions? It is noteworthy to recognize that most of the big debates of our day are not really argued consistently, honestly, or even logically. Political opponents will get up in arms, whine like children, fail to seek common ground, lie, and demonize each other over artificially drawn lines of conflict. Even when the lines are real, they are rarely relevant to the most serious matters confronting the nation. Everyone claims the Constitution and the moral high ground as they each verbally eviscerate one another. The most consistent victim of this rhetorical warfare is the truth. Collateral damage is done to the needs of the nation, which remain unaddressed in the midst of the fiercest political battles. Sadly this cannibalism is moored to our tradition of freedom, particularly freedom of thought. While we cherish our freedom, we suffer with its unpleasant side effects—moral relativism and its attendant hypocrisy. There is no moral authority universally accepted, no “parent,” so morality is subject to perspective. Morality that is flaccid cannot help but give birth to controversy, and controversy is something we have in a debilitating abundance. Much of the political rancor and intransigence that immobilizes the democratic process can be traced to the immorality that certain groups decide to selectively ignore, while at the same time condemning other forms of immorality. The demagoguery that is so prevalent in today’s news debates is most frequently based on selective moralizing. You’re a villain for these “sins,” but those “sins” are completely understandable. If you don’t agree, there is something wrong with you, and all of your opinions should be devalued to nothing. The opposers should be devoured; it’s as if politicians were like those cannibal tribes who felt that killing your enemies was not complete until you feasted on their corpses. This is the nature of our biggest, most controversial public debates. Matters with the greatest socioeconomic significance that are critical to the health of the nation are neglected, while we fight over irreconcilable social views tied to cultural identity. These socioeconomic fights have become so vitriolic, as the “socio” overwhelms the “economic,” that to seek common ground with the opposition is akin to making a deal with the devil. Meanwhile, these battles provide space for the pirates who exploit the confusion to cannibalize the nation’s wealth. Factions are economically aligned against themselves, while only superficially pitted against each other over matters of exaggerated importance. Ironically, this social war is rife with hypocrisy and inconsistent logic. Each side does precisely what it hypocritically accuses the other of doing with respect (or rather disrespect) to the facts. It is this hypocrisy that often creates inexorable rifts after the debate. Unrelated subjects become the basis for political identity. With a democratic process that relies on the organization of coalitions, the hypocrisy borne of moral relativism divides even those with common interests, making enemies of socioeconomic peers. These divisive issues undermine the pursuit of common needs. Will we ever see how self-destructive it is to devour the “others” who are none other than ourselves? Hypocrisy of Moral Relativists Theoretically, adherence to moral relativism should disqualify one from moralizing. Think about it. If you believe that truth is discovered in an individual’s life course and that what is true for you may not be true for me, how can you condemn anyone for what he believes, even if it violates your moral sentiments? If you believe that right and wrong are subject to perspective and circumstances, how can you moralize about what other people do? Unfortunately, very few see it that way. Instead, most are perfectly content to hypocritically condemn certain wrongs while supporting or even committing other wrongs. For instance, as the nation divides itself politically, you find some groups that focus intently on sins of a personal nature, and yet, inconsistently, will attack anyone who points out national sins. At the same time, others’ priorities are the absolute converse. In Harvard professor Michael Sandel’s course “Justice: A Journey in Moral Reasoning,” students are engaged in thought-provoking discussions on some of the most hotly contested issues of the day, including abortion, affirmative action, income distribution, and same-sex marriage. The careful analysis of these topics reveals that, very often, accepted standards of morality are not applied consistently, and in some cases opposing views are both valid and could thus never be reconciled. The very concept of consensus is nearly implausible in an environment of moral relativism. So, how can we work together to build a “more perfect union” when the parameters of the world in which we each live are subjective? Moreover, when irreconcilable conflicts perpetually displace meaningful discussion of the serious problems that threaten our progress, but are otherwise solvable, how could we ever halt our economic attrition? Yet we continually allow ourselves to be driven by emotional inconsistencies, by hypocrisy. We need to take a more honest look in the mirror if things are to improve. What inconsistencies am I talking about? Many who would proudly sing “my country right or wrong” would impeach a leader for marital infidelity. Some even criticized the president for merely mentioning regrettable American actions before foreign audiences, such as in President Obama’s heralded June 2009 Middle East speech. The hypocrisy can be particularly overt if shrouded in patriotism. Patriotism can justify torture, napalm attacks, nuclear weapons, preemptive war, oppression of minorities, overthrowing governments, and many other atrocities, just as assuredly as it can unify a people, provide a sense of identity, and urge sacrifice and service for the greater good. Nor is it consistent to lament public plights while completely ignoring personal morality. The very ones who weep over the plight of the poor also vehemently oppose any who would suggest a connection to moral conduct. Leftists who cry out for the legalization of marijuana completely ignore the proliferation of drug-related violence and prisons full of convicts who started down their dark path by smoking pot. They use the spurious reasoning that since everyone who uses recreational drugs doesn’t become a criminal, drug use is not to blame. Many bleeding hearts who have disavowed eating meat, who protest against cruelty to animals, and who may even go so far as to attack those wearing leather or fur, rarely show such concern for fellow humans beyond mock sympathy. Many will still wear diamonds mined by oppressed people, don clothes and other products produced in sweatshops, and subscribe to an overall system that destroys lives. Among those who find it very politically correct to decry animal abuse, it is not very politically correct to consider an unborn human life as anything more than a condition of the pregnant woman. On the other side, you have vigilante anti-abortion activists who consider themselves a sort of child-protective service while they bomb women’s clinics. Inconsistencies? It’s all crazy. No one enjoys getting into the hard stuff, but let’s take a stab. Our culture promotes sexual freedom while utterly failing to see how sexual immorality is the root cause of countless societal ills. Even those who publicly decry sexual promiscuity rarely practice what they preach. There have been far too many sex scandals among conservative politicians to give any weight to the right’s professions of moral superiority in sexual matters. Whether politicians are rhetorically or physically hypocritical, as a matter of empirical fact, sexual promiscuity has its negative impact on society. Premarital sex leads to ill-advised relationships. In turn, such relationships lead to bad marriages, single-parent families, or even abusive relationships, all of which degrade society by adding to stress and economic hardship of those involved. Extramarital sex undermines committed relationships. Even the prospect of adultery creates stress inside of a marriage, but when divorce actually occurs, the psychological, emotional, and economic turmoil is undeniable. As incendiary as it may be to say so, from a dispassionate, biological, and anthropological perspective, recreational sex, whether heterosexual or homosexual, does nothing to promote—and if practiced exclusively actually inhibits—healthy population development. Just because no one may have the right to dictate what you can or can’t do in the privacy of your bedroom doesn’t negate societal implications. One should ask what the crime rate would be if every child were born into a loving family with a committed father and mother. What would the divorce rate be if all marriages were based on deep compatibility instead of good sex had while dating? The implications of sexual morality are real. But who wants to mess with people getting their freak on? It is easier to be a hypocrite, even if the hypocrisy on all sides leads to a cannibal society where we all devour one another. It is not to say that these and related matters could easily be remedied. They can’t be. To the contrary, there is never a solution to a sensitive matter like any of these that would satisfy all. It is necessary, however, to recognize the damage caused to our system by the battles fought and lines drawn over these conflicting views. People demand their constitutional freedom to pursue happiness according to their independent views, but are not always content to permit others the same. Because of the absence of a central moral authority and thus the subjectivity of morality, social fragmentation is unavoidable in our society. Our founding documents may demand neutrality in matters of conscience, but conscience is hardly ever a neutral matter to an individual whose heart tells him strongly that something is right or wrong. One’s convictions may be intensely powerful, shaping one’s view of the world and one’s view of those with conflicting opinions. It’s Intrinsic to Democracy Many would take moral relativism as an axiom, in great part due to the lessons provided by centuries of abuse by moral authorities (particularly religious authorities) given absolute power. The famous quote “power tends to corrupt, and absolute power corrupts absolutely” was made with respect to a pope. Nevertheless, ubiquitous distaste for the concept of absolute right and wrong doesn’t cause different people to prioritize and weigh morals in the same way. Various factions pick and choose from morals a la carte, giving some heavy significance in one context while completely ignoring violations to the same moral principle in other contexts. Virtually every major issue that we debate in our country is rife with hypocrisy as we draw artificial lines with the ebbs and flows of common sentiment. Many of those who wish to present themselves as favoring small government and completely unfettered individual liberty, when examined more closely, actually seem to favor libertarian government for themselves and a restrictive, authoritarian government for the “others.” Many of those who subscribe to a socially active form of government bristle at the notion of paying the taxes needed to facilitate such, but want someone else to pay for it. The only consistency is consistent hypocrisy. No particular faction has the monopoly on pharisaisms. The greater the controversy surrounding an issue, the greater the hypocrisy in the public debate of that issue. Pundits and politicians conjure up the noblest-sounding phrases to define their political positions relative to their cultural views—pro-life versus pro-choice, marriage equality versus defense of marriage, equal opportunity versus state sovereignty, and individual freedom unhindered by small government versus government by the people that works for the people. All of these sound good. Why would anyone oppose any such ideals as they are packaged? It is hard to imagine that such labels are used by diametrically opposed positions in the most hotly contested debate of our modern era. And that’s to say nothing of the pejorative expressions used to characterize the other side in these arguments. Representative Randy Neugebauer of Texas shocked observers of the passage of the health care reform on March 21, 2010, by shouting out “Baby killer!” as pro-life congressman Bart Stupak announced a deal struck with the president in order to vote in favor of the bill. It has become the norm to shroud one’s side with a cloak of nobility while defaming the other side as the spawn of demons. Rarely does either side fully hold up to objective scrutiny as entirely free of inconsistencies. The most acute areas of hypocrisy are seen in matters where religion asserts itself. The very concept of sin causes moral relativists to cringe. But fear not, because religion is where we find the greatest concentration of hypocrisy. Ironically, many religionists too subscribe to moral relativism. Just look at all of the hoopla over gay marriage and gay rights. “Church folks” get particularly up in arms about homosexuality, and the Bible certainly does condemn homosexual sex acts, but no more than it condemns fornication, idolatry, lying, and many other acts that these people are all too ready to make excuses for. Moralizing about homosexuality while ignoring adultery and premarital sex is hypocritical. The hypocrisy is even more egregious when you consider the materialism, self-righteousness, discrimination, xenophobia, intellectual dishonesty, and intolerance that have come to characterize the stereotypical religious right. Semantics of Social Warfare Some of the fiercest arguments of our day boil down to semantics. Perhaps the two most divisive battles of the public dialogue hinge on the definition of “marriage” and “when life begins.” In almost every case, the definitions to these terms given by candidates seeking public office are the most fundamental tests applied to qualify him or her in the eyes of the electorate. Elections have become proxy wars for social factions attempting to impose their menu of moral views on society. The social wars of abortion and homosexuality do nothing to advance the prosperity of the nation. Yet these battle lines determine who hold offices of leadership, the direction the nation takes, and the management of so many things that have nothing to do with marriage or abortion. Never mind competence, experience, or temperament; what is the candidate’s view on. . . ? I am not making moral assessments here, and do not intend to suggest equivalency among all sides in all debates. I only suggest that there are problems with the framing of these debates and the distractions they cause. My complaint is not about the substance of any of these arguments. I don’t care who or how people love. No one on earth has the right to interfere in the personal decisions of others. It’s no one’s business. If there is anything that is a fundamental right, it is the right to physical self-determination. The problem is the inconsistency and hypocrisy of the arguments, to say nothing of the way the arguments materialize into policy. There seems to be very little interest in finding the proverbial happy median, even on the rare occasions when such exists. Interestingly, on the issue of gay marriage, when Bill Maher, social critic and host of HBO’s Real Time with Bill Maher , made what may be the most balanced policy proposition to heal this breach to a panel of guests representing opposing political positions, he didn’t get the response you might expect. He asked why all marriages aren’t civil unions and why the government is involved at all in a religious institution. Neither his right-wing nor left-wing guests leapt at that suggestion. Really, do these factions actually want a solution or what? Probably not. The issue of abortion is likely irreconcilable. It is not merely based on differences in lifestyles, but on contrary views of life. Instead of accepting the reality of these irreconcilable differences and focusing on matters where cooperation is possible, these issues have come to dominate political identity, often contrary to economic interest. Moreover, it is the nature of hypocrisy to want your opinion enforced against your opposition instead of compromising with them, and it is this sort of intransigence that locks us in a purgatory of economic torpor. How can we as a nation deal with the issues of real importance, like war and peace, business and employment, health and welfare, or our place in the world in the era of globalization, when people are at each other’s throats over bedroom politics? We fight to the death over God, guns, gays, and abortion, all while our leaders instigate these destructive fights to maintain power. Wall Street cannibalizes our real economy to drive their fake one, and China and the rest of the world gain economic advantages over us. These hypocritical fights are killing us. Along this line, one of the greatest areas of utter hypocrisy is with regard to the role of government versus that of the free market. It is the ultimate left versus right debate, and even it is not argued honestly, consistently, or logically. Even libertarians who would say that government is the problem and should be excised from nearly every aspect of life would still expect a government-managed military, police protection, prisons, judicial arbitration, emergency management, basic civil services, and infrastructure. Those who do not tolerate such hypocrisy in their ideological views become intolerable to their political kin. Take Rand Paul, who, as a senatorial candidate from Kentucky, felt compelled to defend private businesses’ pre-civil-rights era “right” to refuse service to whomever they may choose. He told the Louisville Courier-Journal that the Civil Rights Act of 1964 should not apply to private businesses. While claiming that racial intolerance is abhorrent to him, his libertarian purity puts him in the position of supporting the notion of whites-only lunch counters, restaurants, or any other private establishment. The political sphere requires hypocrisy, instead of recognizing the inherent flaws in each and every corner of public debate. The hypocrisy is apparent when we consider the arbitrary nature of the lines drawn and the self-interested selection of what should and should not be regulated; of what should be left to the invisible hand of the free market. Out of the 2007–9 U.S. economic crisis came what some call corporate socialism. The government ended up owning majority stakes in one of the world’s largest insurance companies and what was once the world’s largest carmaker. The expression “too big to fail” was the rationale for billion-dollar bailouts and the radical expansion of the government’s role in the economy. Yet many long-time free marketers were silent about their handouts. On the other hand, any assistance for “regular people” is a form of socialism that is unacceptable by this same lot. Debt financing of the wars in Iraq and Afghanistan is perfectly acceptable, while expanding the deficit for infrastructure, jobs, green initiatives, and health care reform is labeled as “plunging into Eurozone socialism” by the likes of Joe Scarborough, author of The Last Best Hope: Restoring Conservatism and America’s Promise . Most of these areas of institutional hypocrisy pit citizens against one another, degrading the civility of the civilization. There may even be damaging economic effects of duplicity in these areas. But there is one component of the system where hypocrisy routinely costs lives. It undermines countless businesses, threatens international competitiveness, and even threatens the solvency of the nation. The inability of a cannibal country to fully address health care honestly could prove fatal, in spite of the legislation Congress passed in 2010.",
        "char_count": 21540
      },
      {
        "heading": "Chapter 10",
        "text": "Chapter Seven The Choice of Health Whenever the words “health care” and “national” are combined, a third word invariably comes up,: “socialism.” “Socialized medicine” has been a stinging, pejorative characterization of any involvement of the state in medical services, and that pejorative has helped maintain the status quo of the health care industry in the U.S. for more than a generation. This, combined with the isolationist tendencies of many Americans, makes it very easy to get traction with horror stories of problems with the health care systems in countries where the government is involved. Finally, add buzz phrases like “government between you and your doctor” and you have a formula to mount a serious battle against health care reform, which of course the cannibals did vehemently in 2009 and 2010. They all claimed to want to solve the health care crisis and even passed a historic bill, but any attempts to truly root out the systemic flaws of the American health delivery system were lambasted. This self-defeating hypocrisy is a core characteristic of cannibal capitalism, and it has metastasized to all corners of our culture. Opponents eat each other alive, laying waste to the facts. While criticizing the health systems of other countries is commonplace, the facts don’t speak well of the American system. You can’t have an honest discussion without facing facts. What facts? The State of Health The U.S. spends more on health care per capita than any other U.N. member nation. It also spends a greater fraction of its national budget on health care than Canada, Germany, France, or Japan, all of which have national health care systems. Recent estimates put health care spending in the U.S. at approximately 17 percent of GDP. In 2008, health care spending in the United States exceeded $2.3 trillion (that’s about $8,000 per person), and was projected to reach $3 trillion by 2012. 12 Health care spending is 4.3 times the amount spent on national defense. 13 In fact, the United States spends the most money on medical care of all advanced industrialized countries, but it performs more poorly than most on many measures of health care quality. 14 The U.S. is 33 percent worse than the best country on mortality from conditions amenable to health care—that is, deaths that could have been prevented with timely and effective care. 15 The infant mortality rate in the U.S. is nearly seven deaths per thousand live births, compared with 2.7 in the top three countries. 16 Recent studies show that only a little more than half (54.9 percent) of adult patients receive recommended care. The level of performance is similar whether it is for chronic, acute, or preventive care and across all spectrums of medical care—screening, diagnosis, treatment, and follow-up. 17 Underuse of care is sometimes a greater problem than overuse. Patients do not receive recommended care (as prescribed in national medical specialty guidelines) about 46 percent of the time. Another 11 percent of patients receive care that is not recommended and potentially harmful, according to practice guidelines. Thirty percent of sick Americans report that their doctor did not review or discuss all of the medications they had taken in the last two years. 18 Quality of care varies considerably by medical condition. People with cataracts receive about 79 percent of recommended care. Patients with alcohol dependence receive only about 11 percent of recommended care. People with diabetes receive only 45 percent of the care they need. Fewer than half of patients with diabetes have their blood sugar levels measured on a regular basis. Nearly a third (32 percent) of patients with coronary artery disease receive recommended care, and less than half (45 percent) of patients who suffer a heart attack receive medications that could reduce their risk of death by more than 20 percent. Evidence-based medicine indicates that when a patient has a heart attack, the likelihood of that person’s dying from a second heart attack can be reduced by more than 40 percent through the use of beta-blockers. 19 These sorts of statistics translate into very real, very preventable risks and even deaths. Since more than 40 percent of heart-attack patients do not receive beta-blockers, that noncompliance rate puts 450,000 Americans at substantially higher risk every day. Likewise, since only 65 percent of older adults are vaccinated against infections that commonly lead to pneumonia, nearly ten thousand deaths from pneumonia occur each year that could be prevented through regular vaccinations. Similarly, because patients with colorectal cancer receive only half (54 percent) of recommended care and less than two-fifths of adults are screened for colorectal cancer, nearly ten thousand deaths occur each year that could be prevented through routine screening and follow-up care. Patients with hypertension receive less than two-thirds of recommended care. Poor control of high blood pressure results in nearly 70,000 preventable deaths each year. 20 I could go on with these details, but it would be easier for you to visit the web site of the National Coalition on Health Care. I do not share their agenda, but they have compiled a fairly comprehensive list of references. There are many other sources of the growing statistics demonstrating the flaws in the health care system. Pick your own. Whatever the source, the facts are facts. Health Insurance Conundrum From the early days of the Obama administration, despite other concerns gripping the nation, what to do about the quality, affordability, and access to health care was front and center. As always, the various factions came out in battle formation, and the rhetoric of those who either supported or opposed health care reform was often misdirected, if not disingenuous. Unlike many subjects of public debate, health care is something everyone needs. It is a deeply personal matter that can, without exaggeration, even be of life-or-death importance. The importance of access to and affordability of quality health care cannot be overstated. The cost of health care is one of the greatest impediments to job creation. From personal experience as a small businessman, I honestly can say that there were job roles that I outsourced principally to avoid the cost of health benefits. Think about the numbers. At the time of this book’s publication, a low-level office assistant typically makes less than $20,000 per year. That is about $800 per pay period, or roughly $1,600 per month. If such an employee is a woman of childbearing age, the monthly premium can cost up to $800 or more. Adding that to payroll taxes and other costs, and you will have nearly doubled the cost of a low-level employee. I actually used a company in India to do my bookkeeping to avoid these costs, as I am sure other businesses have. Universal public health care would be a boon to small business and job creation, but then again, it would also decimate the trillion-dollar health insurance industry. There has always been a lot of money to be made in the health care business. That means there are a lot of jobs and a lot of wealth to be protected. Depending on your perspective and proximity to the insurance industry, there were legitimate arguments against what some derided as “Obamacare,” but to simply suggest that the government is incapable of paying for health care or that government involvement is worse than greedy corporate involvement is hypocritical propaganda made for political expedience. Health care, socialized or not, will be as good as its funding. There is the rub! In our system, it seems that it is the job of the Democrats to create social programs and the job of Republicans to cut the funding to those programs, ensuring their failure regardless of whether they were well intended or well planned. Perhaps it is hopeless to expect a real solution to these real problems. We are, after all, a cannibal country where the good ideas of one side are decimated by the opposition. Compromise is both the greatest success and the greatest failure of the democratic process, as the health care legislation Congress passed in 2010 makes very clear. During the 2009 health care debate, New York Congressman Anthony Weiner once left “Morning Joe” Scarborough speechless during a guest appearance on his MSNBC show with a simple question: “What value do health insurance companies add to health care?” His point was that while doctors, hospitals, pharmaceutical companies, and medical equipment manufacturers actually add value to justify their profits, health insurance companies profit merely due to their position between patients and health care, and not because of any value added to the system. It is a strong argument, and Morning Joe had no reply. Truth be told, insurance companies do provide a very valuable service. They provide a social bureaucracy to aggregate wealth and use it to pay for the health care services needed by the participants in that bureaucracy. The extent to which health care is affordable to regular people is accomplished by health insurance. If there were no alternative to paying for health care directly without health insurance, then only the wealthiest would receive anything more than the simplest of medical care. The health insurance model does make health care (somewhat) affordable to the masses, at least theoretically. Nevertheless, because nearly all American health insurance companies are now for-profit businesses, the interests of these businesses are not actually aligned with the interests of the greater public. The gamble these types of businesses make is that they hope to collect more revenue (premiums and other charges) than they have to pay out in benefits. This business model means that it is in the interest of the business to avoid covering sick people. Ideally, the goal would be to only pay enough in benefits to maintain credibility, retain healthy policyholders, sell new policies, and avoid paying anything more than that to anyone. It’s funny how patients occasionally find services that were denied are suddenly covered when the public finds out through some news coverage (e.g., Alex Lange, a fat baby denied health care in 2009 due to the preexisting condition of “obesity,” who was later covered after significant publicity). With trillions coming in, every percent retained means tens of billions pocketed, even though the moral implication of those retained earnings is that people may die from the lack of care. Though it can be sugarcoated and dressed up, the truth remains that every dollar not spent on overhead or someone’s health becomes profit for someone. The incentive is to deny, deny, deny coverage. Nevertheless, since everyone needs health care and the alternative of paying directly for medical services is unrealistic, the whole country is stuck with this system or nothing at all. Idealists have begun to ask if this is the best way. Is aggregating and redistributing wealth best handled as a capitalist enterprise? The stats above suggest not. Worse still, with our employer-based system, where health insurance is connected to payroll, the insurance companies take a piece out of every other business. These costs so weighed down General Motors that some called it a health plan that builds cars too. Policy that was really in the national interest would seek to eliminate misaligned interests. Logic would indicate that you shouldn’t have a health care system where the principal incentive is to deny health care. Due to the fact that businesses in other countries are not burdened by the health costs that our employer-based health insurance system is, our international competitiveness would seem to require that we unshackle our businesses. The fact that we allow one sector of our economy to act as a parasite on every other business doesn’t seem reasonable. The insurance industry is just one small segment of our economy, and health insurance is a subset of that. It’s just not in the common interest to give so much for so little. Why must they get a piece of everyone’s action? Why shouldn’t this one niche, the health insurance companies, take one for the team? Oh yeah . . . I almost forget. There is no team. It’s every man for himself around here. This is cannibal country, after all. We are talking about hundreds of billions of dollars in profit raked in as these guys shuffle the money around and deny coverage. What capitalist would ever walk away from that kind of money for the greater good? No way! It’s not gonna happen. The very notion is laughable. The 2009–10 Health Care Debate With the election of a Democratic president who had health care reform as a cornerstone of his national agenda, it was only to be expected that the health insurance companies would arm and align their troops for the battle that would precede any legislation. Reports indicated that in 2009, a half-billion dollars was spent on lobbyists, largely to undermine, if not prevent, any meaningful health care reform. That money was not funneled to just one party. The way the debate took shape, it seemed that there was no earnest debate at all. You had to either believe that the pro-reform side was utterly inept at making a solid case for their agenda, or that at least some of them were in cahoots with their “opponents.” Otherwise, what is the explanation for the reality that proponents never made—in fact, deliberately shied away from—the strongest arguments and best solutions? The best case never made prime time, but the most duplicitous opposition was given a broad audience. Instead, the pro-reform arguments were weakly framed from the beginning as “we have to do something” and “the status quo is worse,” versus opponents’ strong ideological tag lines, like “government takeover of health care,” “moving toward socialism,” or “unaffordable burden on our children.” Some proponents took up the moral and nationalist arguments that it is unacceptable that this country has millions of uninsured and that we have fallen behind other countries, but these points fell flat against clearly focused opposition, whether or not grounded in reality. Very few proponents of health care reform approached the matter economically, never mind that taking the burden of health care costs off of businesses would be far more significant than tax cuts. Tax cuts apply to profits. Health care costs are overhead. Lowering the cost of doing business is much more significant than just allowing a business to keep slightly more of its profit. Business financials include health care costs, and these costs are in the EBITDA (Earnings Before Interest, Taxes, Depreciation, and Amortization), which literally means that these are considered before taxes and many other economic factors. This accounting metric is used by businesses in capital planning, resource allocation, and pursuit of financing. Worst of all was the ground given up in the public debate. When opponents said, “The government messes up whatever it touches,” the point was allowed to stand. The premise that competition was the only way to lower costs was not only conceded, but actually embraced by proponents as the argument for why the public option was needed. This ridiculous approach actually created sympathy for the insurance companies, since it is not really fair for private enterprise to have to compete head-to-head against the central government, just as it is not fair for a mom-and-pop shop to have to compete head-to-head with a multibillion-dollar megacorporation. Instead of debating whether for-profit health insurance was best for the nation, the health insurance business was allowed to stand as a proxy for the entire free market system. Using free market rhetoric to promote a government health insurance program rang as hypocritical. The problem in making dramatic improvements to health care a reality was that the real problems never reached the center of the debate. The environment was perfectly set for major health care reform, but those who promoted it showed apparent ineptness in connecting with the public and selling it. Democrats controlled the White House and both houses of Congress, and yet they lost the debate for major health care reform and had to settle for something that many considered so watered-down as to be almost worthless. Others have argued (with merit) that the final product was so riddled by political compromise that it could live up to the worst fiscal complaints levied against it in the debate. Elimination of for-profit insurance in favor of what was commonly referred to as “single-payer health care” was off the table from the very beginning. This idea of centrally aggregating health care dollars transparently and without a profit motive was never compared head-to-head against the current system of aggregating health care dollars in the coffers of private corporations that get to rake a percentage off the top. That is not a debate that would have ended well for the private insurance business, and both sides moved early on to avoid it. Honest debate or hypocrisy—what do you think? It may very well be by design that Democrats seem to have never come to grips with how to win the public debate. Some say that the left-wing party (Democrats) and the right-wing party (Republicans) are actually parts of the same bird. Each side feigns support for various segments of interests and ideologies, but thinly veiled is the more loyal support they maintain for big campaign contributors, most of which are common to both sides. Quips and sound bites rule the dialogue of the nation and do more to shape public opinion than the truth. People want chants, not nuance. When they really want to win, the left can use them as well as the right. “Yes we can” did far more for the election of President Obama than did his more professorial discussions. Yet the simple phrases like “the government between you and your doctor” and “socialized medicine” went largely unanswered, even when such statements were accompanied by hypocritical defenses of the “socialistic” Medicare and Social Security programs. If so-called proponents of major health care reform had really wanted to win the debate, they could have done so with six simple tactics: 1. Don’t confuse them with the facts . We all know that health care spending in the United States reached $2.4 trillion, and was projected to reach $3.1 trillion by 2012. It will likely reach $4.3 trillion by 2016. We know that we could go on about how health care spending is 4.3 times the amount spent on national defense. We pay far more than anyone else, and yet there are forty-six million people uninsured, and another one hundred million are underinsured. Yes, about half of the U.S. population has inadequate health care. It may be intellectually compelling that the U.S. is 33 percent worse than the best country on mortality from conditions amenable to health care—that is, deaths that could have been prevented with timely and effective care. If empathy were regarded as it should be, people would respond to the fact that, despite paying more than anyone else, the infant mortality rate in the U.S. is about seven deaths per thousand live births, compared with 2.7 in the top three countries. All of that is compelling and provides a sound basis for pursuing change, but it doesn’t win the fight against the line “you want to nationalize health care!” In the sound-bite battle, numbers sound like a lot of blah, blah, blah. Yet proponents of health care reform never attempted to match rhetoric. 2. Quip-for-quip . When opponents said “socialized medicine,” proponents of health care reform could have responded with “privatized medicine.” When they said “government between you and your doctor,” very few answered “greedy corporation between you and your doctor.” When they talked about “nationalizing health care,” proponents could have taken the moral offensive with “profiteering off the sick and dying.” Quips and one-liners always win the day in this system, but all we heard was “we need to do something.” 3. Message sync . By nature, progressives like nuance, intellectual depth, and individuality. Rarely will two progressives interpret the same view in the same way. Even when the entire movement is of one mind on a matter, the message comes through as confused noise, because everyone says things his or her own way. Any media-marketing expert will tell you that it takes consistent repetition to get a message across to the public. Proponents needed to say the same thing the same way. Perhaps they felt sullied by using this tried-and-tested Republican tactic, and refused to go with what works. 4. Moralize, moralize, moralize . As contrary as this may be to my earlier point about moral relativism, in the real world, assuming the moral high ground, whether or not legitimately, wins debates. Those in favor of caring for the health of the nation had the moral high ground, but didn’t effectively use it. Arguments against health care reform were all financially motivated: the nation couldn’t afford it, they would have to raise taxes, and it would squeeze private enterprise out of the market. Another missed opportunity considering that, down deep, most Americans are not comfortable with decisions being made just for money. Neither of the Iraq wars could have gained public support if it had been clear that it was all about the oil. At the very least, there must be a pretense of moral justification. People hate to been seen as money-grubbing even when they are, because most people are moored to a tradition that holds that money is the root of all evil and that those who do immoral things for money are bad. Shining the spotlight on the money-grubbers would have drawn a stark contrast. Packaged questions like “are corporate profits more important than a human life?” or “why should some people get rich off the sick and dying?” would have been quite compelling. 5. Health care as a public safety issue . One argument that consistently got traction was that the government shouldn’t be involved in this or any private enterprise. In addition to the moral argument against profiteering on the injured, sick, and dying, advocates could have drawn parallels to other government institutions that opponents would be disinclined to oppose as “government-run.” Few would have argued that the military, police department, or fire department should not be run by the government. Why? They care for matters of life and death. So, what’s the difference? Isn’t health care often a matter of life and death? Who would tolerate a police force that only protected those whose security premiums were paid up? Would you stand for a fire department that would get your cat out of the tree but would not deal with catastrophic fire damage unless you could afford excruciatingly high costs? It is hard to even imagine a military that acted out of a profit motive. (It may be a little easier to imagine in the wake of the Blackwater scandal.) Yet that is precisely what happens in the realm of health and medicine. Recasting health care as a public service would have undercut arguments against government involvement. 6. Insurance as the wrong model for health care . When you really think about it, the business model of insurance is antithetical to health care. The term “health care” denotes taking care of your health, a constant, consistent need. Insurance is intended to mitigate risks, to deal with events that may or may not occur. While insurance makes sense for accidental injury or even the onset of a debilitating disease, it is not really conceptually appropriate for preventative or chronic care. People are shocked and disturbed that insurance companies only want to insure healthy people, but that is only indicative of their business model. It is based on actuary tables and the gamble that you won’t need health care most of the time. That makes it the wrong system for a nation’s health care, but no one really made that case. The insurance business was protected throughout the “revolutionary” health care debate. Only fringe idealists came close to making these arguments, and perhaps that is why they are fringe. Honest arbiters are never invited to play. Contending parties are bought and paid for in advance. Was it all a fake debate? In boxing, gambling interests used to pay favored fighters to intentionally lose high-stakes bouts to extend their control of the sport, avoid losses, and simply to make more money. The big health care debate looked a lot like a thrown fight; like the self-righteous supporters of health care reform deliberately lost the fight. Insurers paid off both sides, and in return got a mandate in the congressional bills for millions of more customers, many paid for with government funding. Other than a few good-sounding but ineffective reforms, everything else stays fundamentally the same. It looked like a good fight. It went twelve rounds. Most are convinced that this was the best that could be done, but it was all an act. Billions upon billions of health care dollars will continue to line the pockets of people who don’t provide health care, but merely shuffle the money around. I don’t have a dog in the fight, other than being an employer. I am not a member of any political party. As a neutral observer, it just looked like theater to me. It is the same show every time. One side stands up to proclaim advocacy for the little guy, whom they believe is best helped by free market capitalism and lower taxes; the other side professes their support for the little guy through the direct assistance of the government. Meanwhile, the little guy is being eaten for lunch by the cash supporters of both sides. It’s a scam! Those who put their trust in these noble leaders are the dupes. Like gamblers on a fixed fight, the public picked sides, allowed their emotions to be manipulated by artful stagecraft, and, irrespective of the outcome, their hard-earned money lined the same pockets of the schemers behind the scenes. What is the difference? Maybe Not “A Right,” but an “Is Right” There are the true believers who are convinced that the liberal notion of universal health care is a right of all. Others believe just as fervently that such a notion is not only wrong, but contrary to American values. Sadly, we hardly ever hear a symmetrical debate clearly contrasting the views of the true believers on each side. This is most likely because such a debate would undermine the rigging of the game. Misdirection from the facts most pertinent to the public, conflation of cultural biases with invented reality, and obfuscation of true motives driving the politics of the moment are easier to manage than a meritorious debate. Nevertheless, it is always very interesting to juxtapose antithetical arguments. At the end of 2009, Jacob Sullum, a nationally syndicated columnist for Reason magazine, which is a monthly magazine geared toward a libertarian perspective, lucidly argued against the idea that health care should be considered a “right” of all. It certainly has been a rhetorical dictum of the left that health care should be a right irrespective of employment, wealth, or station in society. That may sound good in a speech or campaign rally, but is it really a “right” for citizens to have access to the services of the medical professionals, the products of pharmaceutical companies, and the use of medical equipment? Mr. Sullum argues that it isn’t, going so far as to say that this suggestion is “a radical assault on the traditional American understanding of rights.” 21 In his article, he said that the Founding Fathers only had in mind “preexisting rights” that people have “simply by virtue of being human” and “can be violated (by theft or murder, for example) even in the absence of government.” He asked, “Did Paleolithic hunter-gatherers have a right to the ‘affordable, comprehensive, and high-quality medical care’ that the Congressional Progressive Caucus says is a right of ‘every person’? If so, who was violating that right?” Building on this premise, he continued, “While liberty rights such as freedom of speech or freedom of contract require others to refrain from acting in certain ways, ‘welfare rights’ such as the purported entitlement to health care (or to food, clothing, or shelter) require others to perform certain actions.” What actions? “They represent a legally enforceable claim on other people’s resources. Taxpayers must cover the cost of subsidies; insurers and medical professionals must provide their services on terms dictated by the government. A right to health care thus requires the government to infringe on people’s liberty rights by commandeering their talents, labor, and earnings.” That last point bespeaks the motive of his argument and is the driving force behind many others on his side of the issue, but we’ll get to that later. He ended his argument by contending that considering health care a right forces equivalency in the standard of care, even if that means a lowering of that standard for everyone. While much of Sullum’s argument served his political predisposition, his fundamental point is true. Health care is not a fundamental right. To suggest that it is for political expedience is nearly as hypocritical as the arguments of those opposed to universal health care along the same lines as Mr. Sullum. By definition, a right is a just claim or title, and no one has just claim to another’s talents, produce, or property. Hypocrisy is evident in the inconsistent application of this perspective of most in Sullum’s camp. No one has a “right” to roads, police protection, national defense, any municipal or federal services, or anything at all that a government may do. For that matter, there is no right to even have a government. Most people don’t believe, however, that a government should refuse to do any and everything except that for which we have a natural right. When your house is on fire, you expect your government to have someone come to put it out. Yet even fire protection is not without exception. In Obion County, Tennessee, if you live outside an incorporated city or town and do not purchase an annual subscription, you do not legally have any fire protection service. It may be hard to believe that there are places in the United States of America where, if you can’t afford the subscription, the fire department will not respond—or if they do show up, they do so to protect the property of neighboring subscribers. This is the shocking end toward which the logic of Sullum and like-minded conservatives point. No, rather than logical consistency, most conservatives prefer to pick and choose government services to support or rail against. Typically, they support the services they need or fear the absence of, and oppose those that could support or benefit their fellow citizens but for which they have no personal need. It is this myopic selfishness that undermines the potential strength of the nation. Sullum’s argument flies in the face of the very reason for the existence of government. Ancient hunter-gatherers may not have had quality health care, but they understood safety in numbers and the benefit of aggregating assets. Families became tribes, tribes became city-states, cities became nations, and nations became empires because of the mutual benefit of cooperative effort. This is the case made with the phrase “in order to form a more perfect union” of the preamble to the United States Constitution. The preamble states: We the People of the United States, in Order to form a more perfect Union, establish Justice, insure domestic Tranquility, provide for the common defence, promote the general Welfare, and secure the Blessings Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America. As inconvenient as it may be to free market capitalists, libertarians, and conservatives, the words “general Welfare” appear right next to “common defence” (the British spelling of defense used in the original manuscript). Arguing over the difference between “provide” and “promote” is a more valid basis for discussion than the suggestion that developing a system to facilitate health care for all citizens is “a radical assault” on American tradition or contrary to the intent of the Founding Fathers. Taxation in the interest of the general welfare is absolutely constitutional, even if distasteful to some. It is the cost of being part of a nation. The alternative is to buy an island and do everything yourself—defense, commerce, health, education, and the rest. Do you really think that you could create an equivalent environment for the “Blessings of Liberty,” as the preamble puts it? Hardly. Sullum may consider taxes to pay for health care that benefits all to be “commandeering” his assets, but then the same would have to be said for everything that the government does for the common good, even the things that he likes. No matter how much libertarians wish it were so, as the cliché goes, no man is an island. Such shortsightedness is pitiable. In truth, social programs benefit everyone. What would the condition of our workforce be, if not for public education? Would your child be safe from smallpox, tuberculosis, and diseases that are far worse were it not for the Public Health Service and federally funded research for vaccinations? A healthy population benefits everyone and an unhealthy one hurts everyone. Unfortunately, such a broad view doesn’t really fit into the self-interest model of cannibal capitalism. If forty-five thousand people a year (the number estimated to die because of inadequate access to health care) were to die in terrorist attacks, the nation would be fully united, willing to engage whatever resources we could muster. Trillions in debt-financed dollars would be committed to the war against such terror. This is not hyperbole, for it is precisely what happened after 9/11. Why is it so easy to commit trillions in response to the death of three thousand, and yet so hard to do so for the sake of many times more? Perhaps it is because the victims of terrorism are so random, affecting rich and poor alike. In the case of the attacks on the World Trade Center, many of the victims were quite rich. Those who lack health insurance tend to be the working poor. People fail to see the urgency without the “it could be me” sentiment. If the poor all carried airborne, communicable diseases that threatened to kill the rich, the will would exist to end poverty, but short of that, we fail to make the connection between the risks to the few undermining the state of all. Will we ever learn to subjugate politics to the best interests of the masses? I fear not. The system is based upon far too much shortsighted, selfish, contradictory, and hypocritical rhetoric. It is this sort of political self-mutilation that undermines any basis for hope. The ideologues in power refuse to admit any flaws in their views and deny any advantages of opposing ideologies, never mind that socialism is neither all bad nor capitalism all good. The process of consolidating power is at odds with solving problems, as constituents demand ideological purity. Even when some progress is made, you find that the pendulum swings both ways, sometimes even to the extreme. In our democracy, what is done by one side is sooner or later undone or undermined by the other. This would be innocuous if compromise (a fundamental tenet of moral relativism) always yielded the best results, but, more often than we’d like, one side is right and the other is wrong. We are thereby cursed to water down what is needed with what is not. And when compromise fails utterly, it fuels further furor in the ideological extremes. This is yet more of what makes us a cannibal country. 12 Department of Health and Human Services, National Health Expenditure Fact Sheet , http://www.cms.gov/NationalHealthExpendData/25_NHE_Fact_Sheet.asp . 13 California Health Care Foundation, CHCF Releases Annual Health Care Costs 101 Snapshot , press release, March 2, 2005, http://www.chcf.org/media/press-releases/2005/chcf-releases-annual-health-care-costs-101-snapshot . 14 World Health Organization, World Health Statistics 2009 , May 2009, http://www.who.int/whosis/whostat/EN_WHS09_Full.pdf . 15 Juan G. Gay, “Outcomes of Health Systems: Towards the Development of Indicators of Amenable Mortality,” Organisation for Economic Cooperation and Development , October 9, 2009. 16 World Health Organization, World Health Statistics 2009 . 17 Elizabeth A. McGlynn and others, “The Quality of Health Care Delivered to Adults in the United States,” New England Journal of Medicine 348, no. 26 (2003): 2635–45. 18 Elizabeth A. McGlynn, “Localize the Remedy: Community Efforts Can Ameliorate Poor Quality of Care,” RAND, 2004, http://www.rand.org/publications/randreview/issues/summer2004/remedy.html . 19 RAND, “Landmark Study Finds American Adults Often Fail to Get Recommended Care, Posing ‘Serious Threats’ to Health,” news release, June 25, 2003, http://www.rand.org/news/press.03/06.25.html . 20 Ibid. 21 Jacob Sullum, “There Ain’t No Such Thing as a Free Lumpectomy: The Folly of a ‘Right to Health Care,’” Reason , December 23, 2009, http://reason.com/archives/2009/12/23/there-aint-no-such-thing-as-a . Unless otherwise noted, all references to Sullum in this section are from this article.",
        "char_count": 37519
      },
      {
        "heading": "Chapter 11",
        "text": "Chapter Eight Miseducation of the Masses Every loving parent takes a strong interest in the education of his or her children. We know that there is a direct link between a child’s education and future prospects of success. Most want to see their children exceed their own achievements in life. They will sacrifice to ensure that their children get the best shot through good education. But this ethic is not seen on the national scale. Our children are seen more as a market demographic to be exploited for profit than as the key to the future of the nation’s economy and security. Toy and video game companies control the entertainment geared to the youngest. Children in their preteens have their tastes, self-image, and worldview shaped by the least worthy public figures. Magazine editors, merchandisers, and materialists show no restraint in exploiting our most vulnerable. The worst form of cannibalism is feeding on one’s own young. We feed on the profit opportunities of their juvenile impulses, when we should be feeding their minds. The State of Education Despite the nationalistic pride in American exceptionalism and the fact that the U.S. spends more money per pupil on elementary and high school education than most developed nations, this country’s standing with respect to the education of its young has fallen behind those of all of its major competitors—China, Japan, and the EU. More surprising are the smaller or poorer nations that also exceed the performance of American children in math and science. According to the NCES, the United States falls below the international average in both science and math— the average ! In fact, we are 25 points below the international average in math. That puts us behind Azerbaijan, Estonia, Lithuania, Latvia, and the Slovak Republic in math. In science, we fall behind such former Soviet bloc countries as Slovenia, Croatia, Estonia, and the Czech Republic. The NCES reported: On the 2006 Program for International Student Assessment (PISA), the average score of U.S. fifteen-year-olds in mathematics literacy was 474, which was lower than the Organization for Economic Cooperation and Development (OECD) average of 498 (table 403). (Possible scores on PISA assessments range from 0 to 1,000.) The average mathematics literacy score in the United States was lower than the average score in twenty-three of the other twenty-nine OECD countries for which comparable PISA results were reported, higher than the average score in four of the other OECD countries, and not measurably different from the average score in two of the OECD countries. In science literacy, the average score of fifteen-year-olds in the United States was lower than the average score in sixteen of the other twenty-nine OECD countries, higher than the average score in five of the other OECD countries, and not measurably different from the average score in eight of the OECD countries. 22 It doesn’t take much imagination to see where these statistics point and what position it leaves the country in with respect to international economic competitiveness. In addition to international statistics, the internal statistics of the Department of Education are also not so promising. The national dropout rate stood at 8 percent in 2008. Among Hispanic children, the rate has been more than one in five. In 2008, the U.S. Bureau of Labor Statistics reported what seems at first glance to be a fairly good college enrollment rate. Of the 3.2 million youth who graduated high school from October 2007 to October 2008, 2.2 million (68.6 percent) were attending college in October 2008. Not bad, right? Look closer. According to the Department of Education figures for 2000 through 2006, 30 percent leave in the first year, and an astonishing 50 percent never graduate. This trend only seems to be worsening. Putting together the dropout rates at each of the levels of education, we find that more than two-thirds of our kids never achieve a degree, even though college graduation is precisely what is needed to compete in the new global economy. In fact, some schools, like the University of Louisville, have targeted the dropout rate as a fiscal matter, and with good reason. Unfortunately, as a country we don’t invest much to ensure better results, even when it comes to qualifying young people to get into college. There are fundamental failings in the basic public education system. Many politicians and others pay lip service to the needs of the education system, but the facts don’t lie the way politicians do. The NCES polled to determine the extent to which various environmental factors interfered with classroom instruction. Forty-four percent of public school principals reported at least some interference. Heating and air conditioning were the most frequently reported interferences, but respondents also cited physical condition of ceilings, floors, walls, windows, doors, and more. And then there is the failure to provide a safe learning environment. In another NCES study, it was found that 29.8 percent of students in grades nine through twelve reported property stolen or deliberately damaged on school property; 28.7 percent were offered, sold, or given an illegal drug on school property; 12.8 percent engaged in a physical fight on school property; 9.2 percent were threatened or injured with a weapon on school property; and 5.4 percent felt too unsafe to go to school. It is not just the students who are at risk, either, as 9.6 percent of traditional public school teachers reported being threatened with injury in the past twelve months. Declining academic performance, substantial dropout rates at various levels, poor environmental conditions, and even the risk of violence paint a troubling picture. What is going on in the world’s only superpower? We could go on and on elaborating on these statistics, but the most telling facts are revealed through an examination of the country’s labor force. For your convenience, I’ve included the summary of the NCES report “Comparative Indicators of Education in the United States and Other G8 Countries: 2009,” which shows that even the value of our education system is in decline: In all reporting G8 countries, adults with a high level of education tended to earn more income than those with a relatively low level of education (i.e., those whose educational attainment was lower secondary education or below). Among U.S. twenty-five- to sixty-four-year-olds whose highest level of educational attainment was lower secondary education or below, 16 percent earned more than the country’s median income in 2006. This percentage was lower than in all other reporting G8 countries, which ranged from 20 percent in the United Kingdom to 38 percent in Germany. Two percent of U.S. twenty-five- to sixty-four-year-olds with this level of education earned more than two times the country’s median income. The corresponding percentages in the other G8 countries ranged from 2 percent in the United Kingdom and Germany to 7 percent in Italy. In contrast, 42 percent of such U.S. adults earned at or below half of the country’s median income. This percentage was higher than in all other reporting G8 countries, which ranged from 17 percent in France to 39 percent in the United Kingdom. Among U.S. twenty-five- to sixty-four-year-olds whose highest level of educational attainment was upper secondary education, 38 percent earned more than the country’s median income in 2006. This percentage was lower than in all other reporting G8 countries, which ranged from 42 percent in the United Kingdom and Germany to 56 percent in Italy. Italy was the only reporting G8 country where more than half of adults with this level of education earned more than the country’s median income. Seven percent of U.S. twenty-five- to sixty-four-year-olds with this level of education earned more than two times the country’s median income. The corresponding percentages in the other G8 countries ranged from 4 percent in Germany to 14 percent in Italy. In contrast, 24 percent of such U.S. adults earned at or below half of the country’s median income; in the other G8 countries this ranged from 10 percent in Italy to 28 percent in Canada. Among U.S. twenty-five to sixty-four-year-olds who had completed academic higher education, 68 percent earned more than the country’s median income in 2006. The corresponding percentages in the other G8 countries ranged from 66 percent in Canada to 75 percent in the United Kingdom. Twenty-eight percent of U.S. twenty-five to sixty-four-year-olds with this level of education earned more than two times the country’s median income. The corresponding percentages in the other G8 countries ranged from 27 percent in France and Germany to 32 percent in Italy. In contrast, 12 percent of such U.S. adults earned at or below half of the country’s median income; in the other G8 countries this ranged from 7 percent in France to 18 percent in Canada. 23 Decades of research reveals that one of the biggest problems with U.S. public schools comes down to ineffective teaching. As a nation, we have little regard for the profession of teaching children. This is evident not only in the pay, but in the entire system of education. In many colleges, those who take up teaching as a profession are cynically viewed as either rejects from tougher programs or idealists who will come to their senses after screaming, whining, undisciplined, unteachable reality shocks them to their senses. That cynical brand of reality is part and parcel of the education system’s failure. It’s been more than thirty years since Time magazine displayed the cover “Help! My Teacher Can’t Teach!” (June 16, 1980), and yet nothing has dramatically changed, at least not for the better. Far too often, teachers are unmotivated to do what should be done, and who can blame them? In the extreme cases their classrooms are crammed full with unmotivated, cheating, rowdy, disrespectful, and occasionally violent people over whom they have no real authority. Their job may be thankless—but more damningly, it is also incentiveless. Pay raises are rarely tied to performance but more often to tenure. Instead of being viewed as the meaningful, world-shaping profession that it is, teaching is viewed as just another union job, where uniform mediocrity is valued over individual achievement. One has to question the logic of a system that gives teachers lifetime job security after one or two years of work. The original intent may have been noble, since giving teachers tenure rights theoretically insulates them from the fickle political interests of school board members or other elected officials. However, it is hard to argue that this rationale outweighs the unintended consequence evident in the declining quality of education that tenure enables, especially when you consider the many federal and state laws protecting teachers from termination. As things stand, schoolteachers are assessed before they are hired, not based on evidence of effectiveness as a teacher, but based on certification, degrees, and other pieces of paper that do not predict good teaching. To be fair, that is generally true when you hire anyone for any job. Nevertheless, the critical lack of quality teachers arises at least partly from the fact that there is no trustworthy, follow-through system to ensure that they are as good as they looked on paper; after they’re hired, we pay them the same regardless of their effectiveness. School districts and individual schools are evaluated based on test scores; administrators generally evaluate teachers. No one ever asks the people who see the teachers at work day in and day out: the students. I don’t suggest that children be given hire-fire authority over their teachers, but rather that their voices, together with their parents’, the peer review of other teachers, test scores, and administrator evaluation should all be considered, backed up by full accountability. The victims of this flawed system are the students, our children. It is not at all unusual to hear school-age children say that school is boring, useless, with the only benefit being the social outlet that it provides, including group sports. After early grade school, full intellectual engagement of our children is all but nonexistent. If you ask a kid what he or she learned in school on any given day, you will see the gravity of our failed system reflected in the blank stare and glazed eyes of this custodian of our future. The workplace is where we see the greatest evidence of the damaging effects of the declining system of education. Employers frequently complain about their workers’ lack of productivity, honesty, and integrity. Employees often are more interested in “getting it over with” rather than getting done with their work. Even when unemployment is high, the notion that a large pool of qualified candidates exists for any given job is a fallacy (except for unskilled jobs), especially when you consider the reality that the jobs needed in our modern economy require knowledge, skill, and judgment far above what our educational system typically confers. One small-business owner told me that most job seekers he interviews are simply unemployable. It would be one thing if his business depended on highly skilled technical experts, but this was not the case. His business was selling auto parts, and he was looking for basic support staff. If an auto parts dealer is finding our workforce unqualified for such basic tasks, one must ask what that portends for the future. As an employer myself, I have to concur with my friend’s assessment. In fact, my experience has been more extreme than his. With my businesses, I have always outsourced tedious work. The people that I actually hire as employees are expected to be capable of thinking and making good judgments, but our education system doesn’t teach how to think, and over and over I have found it necessary to create idiotproof processes for everything. The offensive term “idiotproof” is a common cliché among employers, managers, and those who create systems and procedures, but, really, who wants to hire idiots? From every angle, the systemic failure of education in America can be clearly seen. Teachers aren’t happy, students aren’t happy, employers aren’t happy, and, as we export unskilled jobs, we have to import educated technical professionals. These are not the signs of strength. Worse still, they forebode a collapse of the nation’s dominance in the information age. How do we turn this around? Redesigning How We Teach Several years ago, I was in Britain teaching a group of educators how to better use technology, and I got into a discussion with a lifelong career teacher about the failings of the education system. Despite what the “bell curve” people preach, his theory was that all children are born with roughly the same potential, but vary in the timing of their development, be it physical or mental. It intuitively makes sense; the tallest child in first grade may not be particularly tall among his or her peers once reaching high school. Just as there are readily apparent growth spurts at varying times in lives of individual children, it stands to reason that mental development would be the same, meaning that not every child is ready for the same material at the same time. On the other hand, some subjects are belabored for so long that some students rebel against the tedium. Our system is so standardized that students are held back when they are ready to thrust forward, and are moved ahead when they need more time. Does this really make sense for distinct human beings? Worst of all, our children are labeled early on and shunted into a particular path that may or may not be the best path for them farther along. Children who develop early physically are encouraged to be athletes; those who are earlier achievers in reading and math are heralded as “smart” kids, and those who are not yet ready for the so-called grade level are demoralized and set on a defeatist path. Who is really to say that these early categorizations are correct? His point was that we need to eliminate the grade system altogether and match education to the developmental path of each child’s mind. The grade system works against the best interest of each child by placing too great an emphasis on age. We expect every child to learn the same thing in the same way through some cookie-cutter curriculum, and to get to the same place at the same time, as evidenced by taking the same test on the same day. We end up pitting negative risks against negative risks, which leaves us to choose the lesser evil according to the politics of the day. For instance, we must either risk the self-esteem of some children or curtail the achievement of others. Imagine if you had been categorized and labeled for life based on the date when you were potty trained. While undermining the self-esteem of some, we discourage the achievement of the more capable. But this predicament is created by the system and is wholly avoidable. There are points in a child’s development where two or more grade levels could be covered rapidly, but during other periods, particularly the hormone-inflamed early adolescent years, there should be less emphasis on academics and more on socialization and physical development. Optimal educational effectiveness has been sacrificed in favor of the operational efficiency of a standardized educational system. This teacher’s ideas are not far off from the consensus of many other education experts. In small towns and rural communities, it has often been a matter of necessity to group children in ways other than by age. In some cases, the results have confirmed my friend’s thesis. A report that summarized the findings of several studies noted, Gutierrez and Slavin (1992), 24 Pavan (1992) 25 and Miller, (1990) 26 found that children in nongraded classrooms fare as well or better than children in single-graded classrooms on standardized measures of achievement. Pavan’s review (1992) found that students in multigraded settings did as well as, or outperformed, students in single-graded classrooms. This is noteworthy because many have challenged the view that students in multigrade settings could achieve at a par with students in traditionally graded classes. 27 Some private schools, even in urban and suburban areas, seem to concur with the benefits, and practice multi-age grouping according to pedagogical criteria to maximize academic achievement. Some researchers attribute the problems with the public education system to three fundamental flaws: (1) the failure to recognize and adapt instruction to facts of pediatric neuroscience; (2) the utter absence of a clear, understandable objective of education and its relevance to life in general for the individual who is being taught; and (3) the overemphasis on memorization and the inadequate focus on developing critical thinking skills such as analysis, synthesis, and evaluation. The ignorance of neurobiology cuts both ways, in that younger children’s potential is often underestimated, while the effectiveness of group learning for young teenagers is often overestimated. Anyone with small children can attest to their rapid intellectual development, and yet in most elementary education programs we slow them down to a crawl of rote memorization and waste a period in life in which the mind is most receptive to new concepts. On the other hand, with older kids we completely ignore the whirlwind going on within them. Institutionally we fail to recognize that the emotionally driven behavior of adolescents, including sexual promiscuity, angry outbursts, drug and alcohol experimentation, and even dangerous, risk-taking behavior, all have neurological causes. During this phase of neurological development, the amygdala, the center of the brain that drives emotional impulse and behavior, is more influential than the part of the brain responsible for careful judgment. Having peers around makes the situation worse. My opinion is that, for most kids, there are a couple years in which a hiatus from school should be taken, preferably to live on a farm of some kind far from the emotionally charged and socially challenging environment of the twenty-first-century teen world. Since the serenity of farm life is hardly at arm’s reach for most, at the very least, adults need to recognize the need to assist children in this period to develop control of themselves, which is one of the most important life skills we can ever pass on to our progeny. Really, that is the point of education: passing on the knowledge and skills necessary for success for the next generation in a competitive world. It is pathetic that this meaning is utterly absent from the education we give our children. It is a joke of late-night comedians to say that something they learned in school, like algebra for instance, has been useless in life—but this is no laughing matter. Think about it. After reading, writing, and arithmetic, what materials in the thirteen years of a typical K–12 education turn out to be indispensable in life? If you’re honest about it, you’ll struggle to identify one thing. Even when material has relevance in the real world, those real-world connections are rarely taught. This shows that even teachers are unclear about the mission of education. Everyone is mindlessly following rules and memorizing steps. There may have been efforts to redirect the education system away from this, but memorized learning is deeply seated in our system, which was designed for the industrial age, not the information age. Mindless repetition was a part of life for a turn-of-the-nineteenth-century factory worker. How, though, can that prepare the heirs of the nation to advance this technologically driven economy? With so much time (more than 20,000 hours from kindergarten through grade twelve) wasted on meaningless, rote memorization, we are missing the more important things that would lead to a more prepared generation. Legendary education psychologist Benjamin Bloom classified how learning works in his renowned taxonomy, which is used to objectively measure whether a desired new behavior has or has not been acquired by the learner. The critical-thinking-domain classifications (analysis, synthesis, and evaluation), which are most important to the needs of the information age, are given very little attention in our education system, and most of that is in math classes that are taught without a practical context. Analysis is the ability to separate materials or concepts into component parts, so that their organizational structure may be understood and one can distinguish between facts and inferences. Synthesis is the process of building a structure or pattern from diverse elements, thus building a whole from parts. Evaluation, often associated with analysis, is the ability to judge the value of ideas or materials. It is this faculty that allows a person to rationally decide between competing options based upon clear metrics. Defenders of the status quo often cite improved standardized test scores, curricula, and multimedia resources to claim that the public school system has actually improved over the past fifty years. Yet this fails to recognize that the world has changed. The twenty-first-century economy depends on knowledge workers, and the education system must meet this challenge. Needed Function of Public Education The era of the rote job is over! There is little place left in the emerging economy for punching a clock, grinding through routines mindlessly, executing idiotproof policies and procedures, and still picking up a paycheck that meets American materialistic expectations. Computer automation and foreign labor just make too much business sense. Smart businesses will increasingly hire brainpower and outsource muscle. It is inevitable. It is all about business now. We need people who can analyze situations and make smart decisions, who can piece together solutions, and who can prioritize accurately. We need people who can think. The problem is that our education system does not teach our children how to think. Thinking is relegated to the “means to the end” of memorization and repetition, when memorization should merely be the “means to the end” of assembling the tools and variables for applying logic to problems and synthesizing solutions. The key to a better economic future will depend largely on our ability to conduct business in the developing world. We need people who can manage the process of opening new commercial channels, develop relationships with new trading partners, create and exploit new business opportunities, and bring the money home. The economic expansion of the second half of the twentieth century was driven by the growth and consumerism of the middle class in America. Now there are billions of people all over the planet who are primed to enter the middle class in their respective countries. There are trillions of dollars to be made, but will they be made by America or China? China is already positioning itself to win such a contest. That really shouldn’t be the case, though. China may be leveraging its liquidity to invest in the developing world, but the American way of life sells like no other. In 2009, reporter Maziar Bahari, who was held captive for 118 days in an Iranian prison, recounted his trying ordeal of a torture session in which his vicious interrogator revealed that he thought New Jersey was heaven on earth. Even our enemies have bought into the American dream. Yet this fact has yet to be fully leveraged to secure its profit potential. Modern cities need to be built, followed by every conceivable business that we are familiar with in the more developed world. Global development will occur whether or not we participate in and profit from it. Transforming the developing world is not merely a humanitarian effort, but a way to rejuvenate the domestic economy. China has set the model for rapidly transforming a poor nation into a rich one. As the standard of living rises, there is a growing consumer base to profit from. The growth of the developing world (really, their purchases of our exports) is partly what staved off the Armageddon that the Great Recession of 2007–9 could have been. Instead of narrowly benefitting our economy, our populace must be educated to better capitalize on the needs of the global economy. Feeding off ourselves is just not adequate. The economic cannibalism that threatens our posterity is attributable to a lackadaisical pattern of following the path to the easiest buck and grasping short-term gains irrespective of the consequences. Adding solid critical thinking skills to the can-do spirit of Americans is just the recipe needed to maintain economic dominance. Early education is the crucial first step to developing a workforce better prepared for the twenty-first century. A study of schoolchildren in England, described in the article “Preschool Influences on Mathematics Achievement” published in the August 2008 issue of Science, found that the benefits of early education are “sufficiently large to be important for any government wishing to maximize educational achievement.” 28 Findings also indicated that any type of preschool education was beneficial to children, but high-quality preschool programs were the most effective. Next, the entire public education system has to be reengineered to produce a higher yield of qualified technical workers. To that end, a resurgence is needed in vocational training and a new standard of technical training within the public school curriculum must be established. Finally, and this is the most important, college needs to be included as a part of free public education. Irrespective of how socialistic this may sound to many, it is a loss to the entire system whenever someone with the potential to be a great contributor to the economy falls short because he or she can’t afford tuition. There would still be room for quality private schools, but a core of architects, engineers, doctors, scientists, and many other professionals could be produced in order to greatly benefit our international competitiveness. The reward would surely outweigh the cost. A U.S. Census Bureau report titled “The Big Payoff: Educational Attainment and Synthetic Estimates of Work-life Earnings” estimated that over a lifetime, a college degree results in about a million dollars of additional earning power on average. The report stated: [For] full-time, year-round workers, the forty-year synthetic earnings estimates are about $1.0 million (in 1999 dollars) for high school dropouts, while completing high school would increase earnings by another quarter-million dollars (to $1.2 million). People who attended some college (but did not earn a degree) might expect work-life earnings of about $1.5 million, and slightly more for people with associate’s degrees ($1.6 million). Over a work-life, individuals who have a bachelor’s degree would earn on average $2.1 million—about one-third more than workers who did not finish college, and nearly twice as much as workers with only a high school diploma. A master’s degree holder tops a bachelor’s degree holder at $2.5 million. Doctoral ($3.4 million) and professional degree holders ($4.4 million) do even better. The difference in total economic productivity is undeniable. It is therefore in the general interest to see to it that the greatest possible number of students who are capable of achieving a higher education, and thus greater earning power, do so. No one should be forced to muddle through life short of his or her potential purely for economic reasons. It is not in the national interest. The less people earn, the less they consume, and the less they pay in taxes. When a person with the aptitude and desire to become a doctor, engineer, or scientist is restrained from this goal by money matters, it is a loss to all of us. It is also a painful disappointment on an individual basis. I know the tragedy of the millions of smart young people who never get to college because of economics on a very personal level. I was not able to go as far in school as I had hoped because I needed to make money instead. But don’t pity me for not getting my PhD in physics. I probably did better financially than I would have. No, I am talking about my mother. She didn’t get to college at all. When she told her mother and any of her eleven brothers and sisters who would listen about her college aspirations, they laughed in her face. Even though she earned a full scholarship, there was no way she was going to get the ancillary support she would need. She was one of twelve children born just two generations out of slavery. It didn’t matter that she had a higher IQ than my father, who was a rocket scientist. But, really, don’t pity her either. Pity the country, which lost out on the economic potential of someone who could have contributed so much more than she was able to, having never earned more than a $30,000 salary in her life. The United Negro College Fund got a lot of mileage out of the slogan “a mind is a terrible thing to waste.” In our cynical era, it now sounds like fodder for a joke. Yet it is very true. Unfortunately, instead of recognizing wasted minds and potential in terms of the incalculable national economic loss that they are, we relegate this reality to mere sentiment anecdotes in the realms of charity. This is not a charity case. It is a matter of “promot[ing] the general Welfare” to again quote the Constitution. States are reducing their secondary school funding, and tuitions are rising, in many cases at faster rates than health insurance premiums. Reducing our intellectual output could easily result in a reduction in our economic output. Even China has come to recognize its population as an asset to be leveraged to advance its national economy. Here, in contrast, we often exploit the uneducated in one way or another, even as we support some of them through welfare. There are innumerable schemes and scams to extract the limited amount of wealth from the poor, from high-yield payday loans to the lotto. Instead of driving upward mobility with the understanding that the more valuable we make people, the more they can contribute to the economy, cannibal capitalism seeks only to redirect public assistance funds into the hands of private enterprise. We expect little and get little. We don’t even have the good sense to fatten up our turkey before Thanksgiving. We’re just glad that many of the uneducated are spendthrifts who will blow much of the little that they have at Walmart. Instead of a fragmented education system with twenty thousand separate boards of education and disparate outcomes, there is a need for unified effort and coordination with the goal of improving education across the spectrum. It is a national concern that requires a national effort. Instead of cannibalizing our young, revolutionizing the education system would put the country back on the offensive. Instead of complaining about the loss of the middle class, the stagnation of wages, the trade deficits with other nations, and the outsourcing of jobs to the developing world, we could actually build the workforce needed for the times. This is not even to mention the social benefits of moving millions out of economic despair. Unfortunately, this sounds too much like socialism. The reasoning that taxpayers shouldn’t have to pay for poor children to go to college will most likely rule the day. The cannibalism will continue . . . and continue . . . unless . . . 22. U.S. National Center for Education Statistics, 2008 Digest of Education Statistics , http://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2009020 . In the following seven paragraphs, all statistics are from this source. 23. National Center for Education Statistics, Comparative Indicators of Education in the United States and Other G-8 Countries: 2009 , http://nces.ed.gov/fastfacts/display.asp?id=71 . 24. R. Gutierrez and R. E. Slavin, “Achievement Effects of Non-graded Elementary Schools: A Best Evidence Synthesis,” Review of Educational Research 62, no. 4 (1992): 333–34. 25. B. N. Pavan, “The Benefits of Non-graded Schools,” Educational Leadership 50, no. 2 (1992): 22–25. 26. B. A. Miller, “A Review of Quantitative Research on Multi-grade Instruction,” Journal of Research in Rural Education 7, no. 1 (1990): 1–8. 27. Kathy Unrath, Tara Robertson, and Jerry Valentine, “Is Multi-age Grouping Beneficial to Middle School Students?” National Middle School Association , 1999, http://www.ncmsa.net/ressum15.htm . 28. Edward C. Melhuish and others, “The Early Years: Preschool Influences on Mathematics Achievement,” Science 321, no. 5893 (2008): 1161–62.",
        "char_count": 34854
      },
      {
        "heading": "Chapter 12",
        "text": "Chapter Nine Power to the People Your electric alarm clock startles you awake. You reach over for a remote control to turn on your television, which is in standby mode (technically on, drawing power) just to be available for this moment. As you barely listen to and occasionally glance at the morning news, you muster yourself to your feet and, realizing that it is a bit chilly, you scurry over to the thermostat and crank the heat up to full blast. Without turning off the television, you make your way to the bathroom and fully open the shower valve to get the hot water going. The shower, together with the TV, becomes background noise as you brush your teeth. Just then you realize that, if you are going to be on time, you need to start the coffee. You flip on the light in your closet, grab a robe, and rush to the kitchen. While you fix the coffee, you flip on the kitchen TV, watch a few seconds hoping to catch the weather and traffic reports, before heading back to the bathroom, where the steam-filled shower is still running. After you and the rest of your family get dressed, you are ready to go. Your spouse takes one car, your teenager takes another, and you load the two youngest into the SUV. As you strap your toddler into the car seat, you reassure yourself that you turned off the lights and televisions, but forget that you turned up the heat. Off you go in your gas-guzzling behemoth, first to day care to drop off the toddler, then to the elementary school to drop off your middle child, and finally to work. You make your way through forty-five minutes of rush-hour traffic at twelve miles per gallon. This is just the beginning of your day. Our Gluttonous Appetite for Energy This is not an atypical scenario. How much energy was consumed? How much was wasted? How much did these questions even briefly enter the mind of the consumer of this energy? According to the U.S. Energy Information Administration, each person in America consumes 327 million BTUs on average each year. Our gross consumption of power is reflected in every aspect of the American way of life—where we live, where we work, how we entertain ourselves, everything. The United States leads the world in electricity consumption at 3.873 trillion kWh annually. We lead the world in oil consumption at 19.5 million barrels (or 819 million gallons) per day, and we lead the world in the consumption of natural gas, at 657.2 billion cubic meters a year. We consume an obscene amount of energy in this country, using about one hundred quadrillion BTUs, and the majority of this energy is derived from fossil fuels. (Only about 15 percent of our energy is from nuclear and renewable sources.) Without even considering the environmental implications (which we will), the economic impact is nearly overwhelming. Theoretically, there are many ways to provide the energy that we need, but practically, as the world now works, the energy issues primarily come down to one source: petroleum. That may seem like an overstatement when you consider that petroleum only makes up 40 percent of the total energy consumption of the United States and is responsible for only 2 percent of our electricity generation. Nevertheless, as important as electricity is, it is not the fulcrum of the energy issue. The world turns on transportation. Nearly all commerce depends on moving things from point to point, and, as obvious as this is, a realistic recognition of this fact is far too absent from the public energy debate. Fuel for transportation is the point of vulnerability that can and has undermined the national economy. The generation of electricity is done by stationary power plants. We could transform our entire electrical infrastructure to clean sources like wind, solar, geothermal, and hydroelectric, and that would still do nothing for transportation. Despite laudable advances in battery technology, for the foreseeable future, most electric vehicles will be limited to small, lightweight, short-range, passenger vehicles used mainly for commuter travel. To traverse long distances and transport anything more than a couple of people, a more portable source of power generation is needed. It is no wonder that 90 percent of vehicular fuel needs are met by oil. Ninety percent is an improvement over what our dependence used to be, but it’s still woefully inadequate. Our need for oil is a big problem. 29 At 307 million, we make up just 4 percent of the world’s population, but our oil demand is 25 percent of the global total. We consume well more than twice the oil that we produce, which leaves us with a significant dependence on foreign sources. Our entire economy and way of life is dependent on the accessibility of oil, and we are dependent on other countries to get it to us. You don’t have be a conspiracy theorist to recognize that this is a precarious situation, to put it mildly. At $80 per barrel, the country spends $30 billion a month on foreign oil, importing 13.5 million barrels a day. In 2008, when oil prices peaked above $147 per barrel, the nation spent nearly a half trillion dollars on oil from foreign nations, and this drove the Great Recession of 2007–9 as much as did any subprime loans. Yet, as bad as those oil prices were, with the continual instability of the nations that produce our oil, it could get that bad again or far worse. The implications are frightening, particularly when you factor in competition driving up the cost for this resource as China and India, each with populations over a billion, move closer to an American-like standard of living. The combined population of these two emerging economic giants is over 2.5 billion. If the petroleum consumption of these countries were to equal ours (24.8 billion per year per capita), it would amount to sixty-two billion barrels of oil used per year. That is twice the world’s total production at its peak in 2005! The law of supply and demand suggests that we have seen nothing close to what the price of oil may soon be. We’re Addicted to Oil! The implications of statistics like these have converted even life-long oilmen like T. Boone Pickens. Despite a career spent capitalizing on the importance and limited supply of oil and natural gas, Mr. Pickens has become a fervid advocate for alternative energy sources, such as wind and solar, and one of the most outspoken voices in the national dialogue for energy independence. In recent years, he has spent millions promoting his so-called Pickens Plan, which proposes replacing the 22 percent of the electricity that the United States gets from natural gas with wind energy, in turn enabling natural gas to provide 38 percent of the nation’s fuel for transportation. As T. Boone Pickens says, “America is addicted to foreign oil. . . . It’s an addiction that threatens our economy, our environment, and our national security. It touches every part of our daily lives and ties our hands as a nation and as a people.” 30 He goes on to state that this “addiction” has worsened over the recent decades. At the peak price of $147.27 per barrel in July 2008, the weight of oil prices (reflected in gasoline prices) smothered the American people. You couldn’t fill up an average car for less than fifty bucks. SUVs and other large vehicles could cost well over $100 to fill up. I remember spending $85 gassing up my four-door sedan. These prices literally put the issue of energy right between the eyes of everyday people. Nevertheless, oil prices came down from those staggering highs, as did the short attention span of our people. As Pickens later said, “Lower prices have not reduced our dependence on foreign oil or lessened the risks to either our economy or our security. . . . We are in a precarious position in an unpredictable world.” He has repeatedly been quoted as saying that if America continues on its current track of importing energy, “it will be the greatest transfer of wealth in the history of mankind.” Despite the gravity of the situation, it is not the nature of our cannibal country to effectively tackle long-term, systemic problems that call for radical change. There is little appetite even for the bipartisan Pickens Plan. Election cycles come along far too frequently for most politicians to be willing to risk short-term political losses for long-term national gains. Voters are unlikely to reward legislation that costs billions to fund a new energy infrastructure without recognizing clear and immediate benefits. Even pain at the pump is ultimately short-lived once prices retreat from the highs. Prices that would have been thought of as intolerable a few years earlier are eventually tolerated and accepted because they provide relief from the highest prices. The urgency of the summer of ’08, when gas prices peaked, was lost to the other stresses and effects of the recession. Restoring jobs and addressing the economy became the top priority of our nation. Despite rhetorical attempts by some leaders, polls show that the public has not come to see the connection between solving this energy crisis and economic prosperity. In a Gallup poll published at the end of October 2009 (just over a year after record high prices), respondents were asked which matter should be treated as a priority by the president. The economy was chosen by 41 percent, 18 percent selected the situations in Iraq and Afghanistan, 17 percent indicated health care, 14 percent felt the deficit was the priority, but only 2 percent identified energy as the top priority. In the minds of millions of Americans, the energy crisis was over, at least as an overriding antecedent to all else. Sure, most would like to see gasoline prices back below $2 a gallon, but most are resigned to the higher levels. Sadly, this thinking is suicidal. The reality, attested to by the facts, is that this period following 2008 of lower-than-peak oil and gas prices is merely a respite. Any recovery of the global economy is certain to be accompanied by increased oil consumption. The addiction has not been broken, and the inescapable increases in use will inevitably mean increased prices. Increased oil prices in turn will put downward pressure on the economy, trapping us in a vicious cycle of economic purgatory. Pickens says, “There is nothing more important to the present and future of our economy than energy. Any effort to address our economic problems will require a thorough understanding of this issue and willingness to confront our dependence on foreign oil and what domestic resources we can use.” I have to agree. Where Energy and Environment Collide That is just the economic argument. Most advocates of shifting our energy infrastructure away from petroleum hold their position for environmental reasons. They may use the economic argument to curry favor and broaden political support, but this is revealed as insincere rhetoric whenever the subjects of coal and nuclear power generation come up. Environmentalists’ disinterest in the economic implications of energy costs are further revealed when you consider the support among Al Gore disciples for a carbon tax. The thinking is to use the pain caused by excessive energy prices to spur reductions in carbon emissions and innovations in alternative energy. This is nuts in my opinion, but I do understand that it stems from the frustration from years of their calls for change falling upon deaf ears. Nevertheless, the environmental arguments are not to be ignored. If you have seen Al Gore’s An Inconvenient Truth , then you know the basics. If not, the principal environmental argument against burning fossil fuels for energy is that it appears to be a significant contributing factor to potentially devastating planetary climate change, informally referred to as “global warming.” Scientists have studied the natural cycles and events that are known to influence the climate of our planet and have discovered a quantifiable pattern of global warming that can’t be explained by naturally occurring factors alone. The empirical evidence strongly suggests that the climate is being changed by greenhouse gases emitted by human activity. To establish the facts and build consensus, the United Nations organized a group of scientists called the International Panel on Climate Change (IPCC). The IPCC meets periodically to review the latest scientific research and report on global warming, documenting the consensus among hundreds of leading scientists. From the outset, the IPCC’s conclusions have been that mankind is indeed changing the composition of the atmosphere through the introduction of greenhouse gases produced by the combustion of fossil fuels in cars, planes, factories, and electricity production. Another human activity, deforestation, is also a culprit that raises greenhouse-gas levels in the atmosphere. Carbon dioxide (CO 2 ) is the gas most responsible for the warming. Deforestation effectively contributes to increased CO 2 levels substantially, though indirectly, because of the absence of plants, which absorb CO 2 and emit oxygen as a byproduct of photosynthesis, thus allowing otherwise-mitigated carbon dioxide to remain in the atmosphere. Additionally, the process of deforestation itself directly releases the CO 2 stored in plants and trees in various ways. In addition to CO 2 , there are other contributors, including methane produced through human causes like waste, nitrous oxide from fertilizers, and gases used for refrigeration and industrial processes. Some of these other greenhouse gases have more damaging effects than CO 2 when compared molecule-to-molecule, but because of the significantly greater concentration of CO 2 in the atmosphere, it is the greatest culprit behind global warming. Greenhouse gases are at levels higher than at any time in the last 650,000 years, and the levels are still rising. As I have discussed throughout this book, the rest of the world is catching up with us in many ways, including energy usage and waste. In the last twenty years (since 1990), the same period in which China surpassed the United States as the greatest greenhouse-gas emitter, CO 2 levels have increased by 20 percent. It only takes common sense to see where that trajectory is leading. Nevertheless, even these dramatic changes in the climate happen at an imperceptible rate and in inconsistent patterns. For instance, the decade of 2000–9, according to Michel Jarraud, secretary-general of the World Meteorological Organization, “is very likely to be the warmest on record.” 31 Then 2010, a year characterized by heat waves in America, monsoons in Pakistan and India, and a huge glacier breaking off of Greenland, topped them all as the warmest year on record, but that is not to say that every year and every season in every region has seen a steady pattern of warming. 32 This is why many climatologists favor the term “climate change” over “global warming,” even though the latter evokes a more visceral response and is therefore more politically expedient. One has to step back to see the overall pattern and direction of warming. When you do, though, you see glaciers are melting, sea levels are rising, rain forests are drying, and wildlife is scrambling to keep pace. While I don’t mean to endorse the position or agenda of Al Gore, to me, the most dramatic element of An Inconvenient Truth was not the lecture, rhetoric, or even the facts, but the comparison of pictures clearly depicting various landscapes changing over time. The fact that the deserts are growing, the glaciers are melting, and the seas are rising is incontrovertible. The question of whether we are causing it is a bit tougher. The fact that warming happens when certain gases in earth’s atmosphere trap heat has been understood since 1824, when Joseph Fourier calculated that the earth would be much colder if it had no atmosphere. We call this the “greenhouse effect” because, like the glass walls of a greenhouse, these gases let in light but keep heat from escaping. Without this effect, life as we know it on earth would not be possible. However, the more greenhouse gases are in the atmosphere, the more heat gets trapped, and this is what forces us to look closely at man-made greenhouse gas emissions. Research confirms that greenhouse-gas levels have gone up and down over the earth’s history. Nevertheless, for the past few thousand years, both global average temperatures and greenhouse-gas levels have stayed fairly constant, until recently. There has been no significant environmental or natural phenomenon noted to account for the recent spike, other than the burning of fossil fuels and other man-made emissions. The year 2009 ended as the fifth-warmest on record, replacing the year 2003. According to the U.S. National Aeronautics and Space Administration (NASA), the other warmest years since 1850 have been 1998, 2002, 2003, 2006, 2007, and 2009, all recent years indicative of a trend. NASA says the differences in readings among these years are so small as to be statistically insignificant. As I mentioned, 2000–9 was the warmest decade on record, and 2010 the warmest year of all. The U.N. panel reported that the global combined sea surface and land surface temperature for the January–October 2009 period was estimated at 0.44°C (0.79°F) above the 1961–90 annual average of 14.00°C (57.2°F), with a margin of error of plus or minus 0.11°C. The Gore film depicted near-apocalyptic consequences of climate change, but even if the reality is far less severe, we cannot know all of the effects of the climate changing faster than some living things may be able to adapt to. The global ecosystem is far more complex, and in some ways far more fragile, than we can know. Unpredictable climate changes could pose unique challenges to all life on earth, if not threaten its existence. The increasing rate of glacial loss is alarming, as earth’s remaining ice sheets (such as those of Greenland and Antarctica) are starting to melt. The extra water could potentially raise sea levels, dramatically affecting (or destroying) habitable coastal cities, towns, and villages around the globe. Furthermore, changing the temperature and composition of earth’s oceans would most likely change the climate in other unexpected ways. Just based on current meteorological scientific knowledge, we can surmise that such changes would result in more extreme weather with more intense, major storms. This could include the extremes of more rain followed by longer and drier droughts, jeopardizing crops and undermining agricultural economies. Millions of people could be displaced, plants’ and animals’ habitual ranges could shift drastically. . . and entire ecosystems could be destroyed. The Internet is full of calamity-howlers who could further elaborate on the impending gloom and doom, but the sad reality is that scientists are already seeing some of these predicted changes occurring more quickly than they had expected. In 1995, the IPCC issued a report that contained various projections of sea-level changes by the year 2100. They estimated that the sea will rise 50 centimeters (20 inches) with the lowest estimates at 15 centimeters (6 inches) and the highest at 95 centimeters (37 inches). The rise will come from thermal expansion (like all matter, water expands as temperature rises) of the ocean and from melting glaciers and ice sheets (melting ocean ice does not raise the sea level). Now the estimates appear in need of upward revision. In 2007–9, the summer melt reduced the Arctic Ocean ice cap to its smallest extent ever recorded. Satellite imaging of the Arctic Ocean taken March 2009 (at the end of winter) revealed that the ice sheets were only slightly larger than the record low measured in 2006. Science News reported on May 9, 2009: The spring melting of the Arctic Ocean’s ice cap has already begun, and data suggest that the ice is more vulnerable than ever: The ocean area covered by ice is one of the lowest ever measured by satellites, and a record high fraction of that area is capped by thin, first-year ice that’s more prone to melt than older, thicker ice is. 33 Of even greater concern are the ice sheets of Antarctica, Greenland, and other glacial land areas. Antarctica is covered with ice at an average of 2,133 meters (7,000 feet) thick, which equates to 90 percent of the world’s ice and 70 percent of its fresh water. If it were all to melt, it would be enough water to raise sea levels a staggering 70 meters (230 feet). In the International Polar Year 2007–9 project, researchers found that Antarctica is warming more than previously believed. Almost all glaciers worldwide are retreating. Various studies and data from NASA have shown that Antarctica’s western ice sheet has been under siege from global warming for some time, with billions of tons of ice melting into the ocean each year and contributing to rising sea levels. Until recently, however, East Antarctica had seemed stable. Discovery News reported: Now a new set of satellite measurements indicate the East may have begun to succumb to warmer temperatures, losing as much as fifty-seven billion tons of ice a year since 2006. There is still a lot of uncertainty in the readings, but if the readings hold up under scrutiny, it would mark an important change in the world’s largest ice sheet. . . The team’s results in western Antarctica match up well with previous studies, which have found that the region is shedding around 196 billion tons of ice each year. 34 The realities of global warming are clearly evident in zoology. The predictions of habitat loss and threatened species are already becoming reality. Bill Fraser, an ecologist and penguin expert working as part of the Long Term Ecological Research Network, a program launched in 1980 by the National Science Foundation to chronicle environmental changes in twenty-six ecosystems around the world, travelled to Litchfield Island in the Antarctic, to see what remained of the once-thriving Adélie penguins, the classic tuxedoed penguin. Over the years, the number of Adélies had fallen to a few dozen breeding pairs on the island, and a census conducted earlier that season indicated that the colony was on the verge of disappearing. Fraser has personally seen their numbers decline from thirty-two thousand breeding pairs to eleven thousand in thirty years. With 87 percent of the nearby glaciers in retreat, Frasier cited the steady loss of sea ice along the northwestern Antarctic Peninsula as a principal cause of the decline of the region’s Adélie. Meanwhile, such destructive species as jellyfish and bark-eating beetles are moving northward out of normal ranges. More than just a nuisance, jellyfish are viewed as barometers of the ocean. “There is evidence of jellyfish explosions around the world that appear related to the adverse impact of human activities, and those include global warming,” said Sarah Chasis, the senior attorney for the New York City–based Natural Resources Defense Council. 35 Evidence shows jellyfish species invade places where fish, coral, and other marine animals once thrived. They procreate more quickly in warmer water, tolerate pollution, and escape commercial fishing nets that decimate almost every other marine species. As the planet warms, “there are suggestions that the whole oceans are turning to jellyfish,” said Larry Madin, the director of research at the Woods Hole Oceanographic Institution. 36 Across the globe in many tourist destinations, a plague of jellyfish has become the latest environmental hazard to be blamed on global warming. 37 Spruce beetles have boomed in Alaska, thanks to twenty years of warm summers. Nearly four million acres of mature white spruce forest on the Kenai Peninsula in Alaska have been killed by a growing population of spruce beetles ( Dendroctonus rufipennis ) since about 1987. Scientists, including Dr. Edward Berg of the U.S. Fish and Wildlife Service and Dr. Kenneth Raffa of the Department of Entomology at the University of Wisconsin, attribute the beetle infestation to rising average temperatures in south-central Alaska in both winter and summer. More beetle larvae can survive, and higher summer temperatures allow the insects to mature faster and complete a two-year life cycle in one year. The trees, which previously lived in balance with the beetles, do not have enough natural defenses against this assault. Beetles are not the only insects on the move; a study by the University of California, Santa Barbara, clearly demonstrated changes in species ranges as butterflies shift north to track a changing climate as the planet warms up. Camille Parmesan, who conducted the research while she was a postdoctoral fellow at the National Center for Ecological Analysis and Synthesis at the university, and her coinvestigators, found that out of fifty-seven species studied in Europe and North Africa (thirty-five of which there were data for both the northern and southern range boundaries), two-thirds had shifted northward. 38 She said, “This puts the nail in the coffin.” As climate change melts sea ice, the U.S. Geological Survey projects that two-thirds of polar bears will disappear by 2050. 39 Polar bears are not the only Arctic wildlife threatened by global warming. Scientists have discovered that Arctic foxes also struggle as the ice disappears, because they rely on the frozen seas to survive the bleak winters. Nathan Pamperin, a scientist at the department of biology and wildlife at the University of Alaska Fairbanks, who led the Arctic fox study, said: “With reduced access to sea ice, it is possible that, in the years when foxes would normally travel on the ice, they may face tougher conditions on land, and possibly lower survival.” 40 Other evidence of climate change is reflected in increased average precipitation (rain and snowfall) across the globe. There is also some evidence that glacier melt is encroaching on low-lying island states. Some may cynically ask, “So what? What makes the extinction of Arctic foxes and polar bears a tragedy for us?” Some even believe the loss of Arctic sea ice could be a blessing in disguise, opening up the “Northern Passage” and allowing northern-hemisphere cargo ships to cross the globe in fractions of the time and expense. They may argue that the world has gone through changes before and we could adapt to this one. This is a change, not an apocalypse. Who is to say that that’s not true? We don’t know. The loss of polar bears, as tragic as it may be, affects humans more sentimentally than directly, because we think they are cute, especially as cubs. In truth, we have lost many more species of greater importance to the ecology without any hoopla. It’s that we are losing species, losing habitat, losing rain forests, losing coastline, losing farmland to deserts, and we don’t know what this all may do to life on earth. Life is a fragile thing, and the disruption of delicate balances could be catastrophic. Environmental changes to our planet in the past were in some cases extinction-level events. Even if changes were far less dramatic, the elimination of habitable regions of the world would have unfathomable economic and social effects. It’s only common sense to try to avert such a disaster. The current warming trend is firmly in place. Even if we stopped emitting greenhouse gases today, the earth would still warm by another degree or so. But what we do from today forward will make a big difference. Depending on our choices, scientists predict that the earth could eventually warm by as little as 2.5°F or as much as 10°F. The latter could prove to be catastrophic. The difference between average global temperatures today and during the ice ages is only about 9°F (5°C). 41 To mitigate the effects of global warming, a commonly cited goal is to stabilize greenhouse-gas concentrations at around 450–550 parts per million (ppm). This would amount to about twice preindustrial levels, which, according to the consensus, would avert the most damaging predicted impacts of climate change. According to the IPCC, greenhouse-gas emissions would have to be reduced by 50 percent to 80 percent of the current growth rate to reach this level. Unfortunately, some of the global warming crowd have been put on their heels by controversy. The credibility of climate scientists has been called into question. The incident, dubbed “Climategate” by skeptics of anthropogenic climate change, came to light in November 2009, with the unauthorized release of thousands of e-mails and other documents obtained through the hacking of a server used by the Climatic Research Unit (CRU) of the University of East Anglia in Norwich, England. The University of East Anglia described the incident as an illegal taking of data. Allegations were made that the e-mails showed climate scientists colluded to withhold scientific information; interfered with the peer-review process to prevent dissenting scientific papers from being published; deleted e-mails and raw data to prevent data being revealed; and manipulated data to make the case for global warming appear stronger than it is. Even though the scientists were later mostly exonerated, this controversy produced the dark cloud of suspicion that skeptics had hoped for. It is hard to gain momentum to conquer this colossal problem when science can be politicized and overzealous researchers give credibility to the “flat earth” crowd who deny reality. Incomplete research is rarely conclusive, but the consensus of the broad scientific community is that global warming is real and that we are accelerating it, if not causing it. When you consider all of the interests at stake, consensus may very well be impossible. Someone once said that it is futile to debate with a person whose livelihood is dependent upon disagreeing with you. It is only fair to state that this incident, as damaging as it has been to the public debate, involves only a very small percentage of the scientific community. By design, the IPCC draws from a large pool of scientists to develop the consensuses that they do. With or without the Climategate data manipulation, there is a preponderance of evidence demonstrating climate change. Impediments to Breaking the Addiction All of the foregoing shows that there are both strong economic and environmental arguments for shifting away from petroleum as our principal source of energy. Building a new energy economy would certainly create economic opportunities, and who can really argue against cutting air pollution dramatically? There are also security interests at stake. It certainly isn’t a coincidence that nearly all of the national interest threats and engagements since the end of the Cold War have had a connection to the Middle East. Something has got to give. So, what do we do? Everyone agrees that we need to modernize our electrical grid. Most of our infrastructure is from the early post–World War II era, and some of it is much older than that. Updating this system is a no-brainer, though easier said than done. Also, there is a great deal of focus on improving efficiency and conservation of energy by improving electronics, appliances, and home and building insulation. It is well understood that retrofitting homes and commercial buildings with proper insulation can dramatically reduce electricity use. Pickens cited studies that show that the equivalent of one million barrels of oil per day in energy would be saved, as proper insulation would slash both air conditioning costs in warm weather and heating costs in winter. Transitioning to compact fluorescent lights, which use 20–33 percent of the energy used by equivalent incandescent lamps, is another practical energy policy that could cut electric power use by up to 7–10 percent, according to General Electric. But there is little new to talk about in this area; only a need to follow through. The Obama administration has already put forward many initiatives to conserve energy and promote these kinds of improvements with billions of dollars from the Recovery Act. These are laudable goals, which in time could make a measurable impact, and should by all means be followed through, but they miss the “elephant” that poses the greatest threat. More than anything else, we have to bolster our weak spot and get away from petroleum-based transportation fuels. To this end, an uncomfortable alliance has been formed between political isolationists and environmentalists. The environmentalists are most concerned with averting the disastrous consequences of global warming, and the isolationists simply want to eliminate dependencies on other nations for critical resources. Unfortunately, where there is a fault line in the alliance, political opportunists in favor of the status quo have fertile ground to undermine any substantive progress. In the spring of 2010, there was an earthquake on this political fault line when the domestic oil drilling mantra “drill, baby, drill!” collided with the reality of the catastrophic oil spill from a BP offshore drilling rig in the Gulf of Mexico. Any compromise on the subject of domestic drilling, a priority for the energy independence crowd, was arrested by the environmental disaster of millions of gallons of oil dumped into the Gulf off of the coast of Louisiana. BP, a cannibal capitalist corporation of the nth degree, was accused of cutting countless corners in their deep-well-drilling practices leading up to the Gulf disaster (accusations made even more convincing by the many media reports stating that BP has more safety violations than all the other major oil corporations combined). Yet, as horrendous as the effects of millions of barrels of oil gushing into the Gulf of Mexico have been and will yet be, none of this has really changed the course of oil production and consumption. As one of the largest oil companies in the world, BP’s profitability and future prospects remained strong. The uncomfortable alliance between political isolationists and environmentalists was shattered, as the latter saw impetus to ban all offshore drilling, while the former feared the loss of domestic jobs and an increase in the dependence on foreign oil. Score this as a win for the status quo. There are tremendously powerful economic forces that are interested in maintaining the status quo. The costs of buying land and pumping oil are relatively stable, but the potential price of this diminishing resource could well rise to astronomical levels. During the peak in oil prices, oil company ExxonMobil became the most profitable business in the history of the world. Listening to the news, you’ll hear oil company executives deny that there is any corollary between oil prices and their record profits, and you will hear some politicians even deny that the war in Iraq and the greater instability in the Middle East have anything to do with oil—none of which passes the smell test. It has always amazed me that the most vigorously touted technologies for “going green” are the least viable for all practical purposes. It is as if there were someone leading us on a wild goose chase for the “perfect” plug-in electric car or a cheap biofuel to supplant gasoline. It is as if there were a concerted effort to only promote the technologies that are ill-equipped to truly supplant fossil fuels for combustion in the near term. As we’ve already begun to see, ethanol would strangle agriculture. Even now, some denounce ethanol with the well-rehearsed line “burning food for fuel.” Other biofuels have similar problems or would pollute just as badly as burning gasoline. Incidentally, all biofuels are hydrocarbons—emphasis on “carbons.” While some may argue that biofuels are neutral because the sources of biofuels ultimately derive their carbon from the atmosphere, they are not a solution for reducing greenhouse gas emissions. In short, electric vehicles are an overhyped crock! They might be viable for daily commuters who drive to work and back and run errands within a narrow radius, but not for the overall transportation needs of American families. All experts agree that only the smallest vehicles are feasible for plug-ins or even fuel cells in the reasonably foreseeable future. Electric engines are really weak on performance, and yes, that includes hydrogen fuel-cell cars. Although many would point to examples like the Tesla Roadster, let’s keep it real. It’s an extremely expensive, extremely small, and extremely lightweight vehicle. The Tesla Roadster is no family vehicle! What about the Chevy Volt? It’s a sedan, right? According to Chevrolet, the Volt, like other new electric cars, is only good for 40 miles after an overnight charge up. Show me an electric vehicle today that I could use to take my family of six on a road trip from the Giant Forest, Sequoia National Park, through Yosemite, and down to the Grand Canyon. There is no such vehicle, even on the drafting table, and if ever there is, you can be sure that it will depend on a battery with extremely toxic and potentially explosive components. Hybrids are a fake-out as well, especially the hybrid SUVs, which get only slightly better fuel economy than conventional SUVs. Doubling or even tripling gas mileage doesn’t solve global warming, and it certainly doesn’t end the dependency on oil. If anything, hybrids extend the dependence on petroleum. Despite the fact that policy debate in our cannibal country tends to be argued from polar extremes, I am not an extremist. I would never suggest that we toss out hybrids and forget about plug-ins. We absolutely should continue to pursue the potential of electric-powered vehicles, but to tackle the transportation issues of today, we must be honest about the current limitations of these technologies. We Need Hydrogen Everything from lawn mowers to commercial trucks run using internal combustion engines that burn some kind of hydrocarbon fuel. The entire automotive industry and infrastructure is based on this reality. The most efficient and effective solution would be to put something else in the fuel tanks of our existing and emerging transportation fleet. There are some out there, like T. Boone Pickens, pushing for a transition to natural gas, and to be fair, trucks, buses, or any other conventional vehicle could be adapted to run on natural gas, which is mainly methane (CH 4 ) as opposed to gasoline (octane, or C 8 H 18 ). I don’t mean to lose you in the science, but just looking at the chemistry, you see that hydrocarbons are hydrocarbons. The difference is mainly in the size of the molecule. It is the hydrogen that we want out of these fuel molecules. The carbon is the waste, and the problem of carbon is still there with natural gas. With four hydrogen atoms to each carbon atom, it may be slightly better than gasoline, but it is not good enough to really address climate change. So I have to ask, what about just hydrogen? You know, the “hydro” without the “carbon.” Hydrogen is only the most abundant element in the universe. It’s the “H” in H 2 O. It’s the stuff that we launch rockets with. It’s the stuff that, when burned, produces water as waste—no carbon. Hydrogen is found everywhere on earth: in water, fossil fuels, and all living things. Most significantly, it has the most powerful impulse in combustion of any element, which means that it has the potential of being the most efficient fuel of all internal combustion fuels. We are usually so wasteful in our view of energy. We look for something to burn and couldn’t care less what happens next. We put fuel in and pump out waste. We think of energy linearly, while the physical universe works with cycles of energy exchanges. There is no waste in these cycles; everything is recycled. Nature is an efficient system where what is waste to one component is fuel to another. Many of the most elegant cyclical energy exchanges found in nature are currently beyond our technology to reproduce, but not the cycle of water to hydrogen and oxygen and then back to water again. We know how to do this! We have the technology to design a closed-system, non-polluting, hydrogen combustion engine to drive our vehicles. It amazes me that, with all of the talk of alternative fuels, there is so little talk of hydrogen outside of fuel-cell technology, a technology for producing electricity, which doesn’t easily produce nearly the power of hydrogen combustion. Incidentally, NASA has been using hydrogen fuel cells for more than forty years, so this technology is far from new. BMW has produced its Hydrogen 7, a seven-series sedan that runs on hydrogen combustion and maintains driving performance that is comparable to the gasoline-powered version. California has been quietly moving forward with its hydrogen highway, an infrastructure for hydrogen-powered vehicles. In the early 2000s, Airbus Deutschland announced a hydrogen-powered version of the A310 Airbus, also called the “Cryoplane.” This information is out there if you look for it, but it is surprising that, given the mainstream media attention to the overall themes of gas prices and “going green” initiatives, there is hardly any attention paid to the most obvious and immediately viable alternative transportation fuel—hydrogen. Hydrogen received a fair amount of hype in the early 2000s, due in part to the success of the best seller The Hydrogen Economy by Jeremy Rifkin. More recently, though, there has been a very broad campaign to discredit hydrogen as a solution. Frankly, I’ve noted more opposition to hydrogen than any other alternative fuel. Both ends of the political spectrum have united to tamp down any momentum toward realizing a so-called hydrogen economy. One has to wonder why so much effort has been committed to opposing a theoretical solution to so many problems. It is certainly not scientific to shun a potential discovery and dogmatically preach a prejudiced disregard for a vast field of study. That is the modus operandi of corporate or political interests, not of science. On a scientific basis, hydrogen is the answer. That’s not to say that hydrogen is completely without problems. It may be the most abundant element in the universe, but it is virtually never found in its bare state. Because it is the simplest element, it bonds with other elements like carbon and generally has to be extracted from larger compounds. Also, because it is the smallest and simplest element, it reacts with nearly everything and can even pass right through larger molecules, making storage and transport difficult. And, right now, since its production is very limited and demand is limited mainly to scientific research, the current unit cost to purchase hydrogen is high. This problem, however, could be quickly remedied by mass production. Despite what antagonists would have you believe, hydrogen can certainly be mass-produced. Instead of searching the world for an underground reservoir, dealing with fractious foreign governments, drilling while hoping to avoid another BP disaster, and finally refining oil, ready-to-burn hydrogen can be produced from water through a process called “electrolysis.” In this process, passing an electric current through water separates the hydrogen from the oxygen (and the electricity required for electrolysis could just as well come from wind power or solar). Hydrogen has been criticized as an inefficient and expensive replacement for gasoline, with some even citing the fact that there is more hydrogen in a liter of gasoline than in a liter of liquid hydrogen. For this reason, physics professor Richard A. Muller labeled hydrogen a “nonsolution” in his book, Physics for Future Presidents . He is certainly not the harshest critic and actually agrees that more research on hydrogen as a transportation fuel is warranted, particularly if fuel efficiency can be improved. He notes that hydrogen has “2.6 times the energy of gasoline per pound—but because hydrogen is so light, a pound of it takes up a lot more space.” 42 That was a simple way of noting that liquid hydrogen has less than a tenth of the density of gasoline. In a way, you could think of gasoline as an efficient “suspension” for hydrogen. All else being equal, cars would need gas tanks three times larger and designed to store liquid hydrogen at the requisite −423°F. I agree that this is a problem, but not an inscrutable one. All other things need not be the same. Yet while honest onlookers are confused and buried under a mountain of “facts” about how hydrogen is less efficient than gasoline and electric according to different metrics, no one remembers to restate the fact that we can “make” hydrogen from water. That’s something we cannot do with gasoline, natural gas, or biofuels. This is the perspective that is so often lost as the “experts” argue in the weeds. Hydrogen is a high-energy fuel that we can manufacture in unlimited supply. Further, arguments against hydrogen are somewhat disingenuous, because when you look at all of the electricity that is wasted in transmission or during hours of underutilization of the power plants, there is also a great deal of inefficiency in our present method of power conversion. There is certainly wasted fuel and resources in every oil spill, in every political complication in the supply chain, and in the overall process from well to tank. The disastrous BP oil spill of 2010 certainly was not an ideal picture of waste-free conservation. Its costs were far more than the price of the lost fuel. Yet you still hear complaints about the inefficiencies in the power conversion of the most abundant element in the universe, one that we can obtain from water through a very simple process. Hmmm. The thing is, all the problems with hydrogen can be solved with effort. Indeed, considering that hydrogen has three times the energy per pound as gasoline and produces high-pressure steam as exhaust, greater fuel efficiency in hydrogen engine cars is not only theoretically possible, it’s already patented. So where is the effort? Even if you strongly believe that theoretical hydrogen fuel-cell technology is a better solution than the current hydrogen combustion model, why not start now, building the hydrogen infrastructure that both technologies need? Isn’t the idea of leveraging our entire global energy infrastructure off of the most abundant element in the universe worth the effort of solving what are fundamentally logistical problems? Where is the media attention to create the political will? Oh yeah, politics. I almost forgot that we live in the real world, and politics is at the heart of any real solution. There are massive economies based entirely on petroleum. Some say that the entire global economy is based on it. Didn’t I just say that the most profit ever collected by a single company in the history of the world was by ExxonMobil, an oil company? People die every day for reasons that are, in one way or another, related to oil. So, I have to believe that there are people who would be willing to kill to prevent the obsolescence of gasoline any sooner than is inevitable. I think that the greatest reason for ignoring the potential of hydrogen and hoping that people forget about it is its potential for destabilizing the economic status quo. After you build an infrastructure of electrolyzers and a distribution system, there is no way profiteers can centralize control of this infinite resource. How do you profit from a fuel that anyone with access to water and electricity could make? Just as many farmers abandoned cheap crops for so-called cash crops, energy companies lack a profit motive to pursue hydrogen. Energy Cannibals Is there no coalition powerful enough to counter this opposition and make hydrogen happen anyway? You would think so, with all of the groups clamoring for energy independence or an end to pollution. Then again, maybe that is another overriding problem: too many conflicting efforts supposedly attempting to do the same thing. First, you have the purists out there; you know, the ones who can find a million uses for hemp and who are often at odds with the practical realities that people don’t want to drive slower, use less power, or live in smaller homes. These are people who believe that you must replace gasoline with nothing less than a perfect solution. If that means everyone must drive small electric cars limited to a forty-mile range between charges, people should just suck it up, never mind the families with enough kids and pets to fill a GMC Suburban. (Incidentally, Professor Muller also listed electric automobiles as a “nonsolution.”) These ascetics have been easily swayed by the critics and have thus been slow to embrace hydrogen combustion. They are typically not knowledgeable enough to see through the disinformation. The objections over hydrogen’s inefficiencies seem reasonable enough, despite the reality that none of our energy sources are very efficient. The truth is that internal combustion engines capture only 15 percent to 20 percent of the energy in gasoline, and the conventional electric-power grid is only 33 percent efficient. The difference with hydrogen is that we can “make” it! If we make it strategically, we could actually increase the efficient use of our power plants. Then you have contrarian scientists. You know, the ones hired to say that smoking is good for you and global warming is a myth. They’re out there programming people with the line that hydrogen is not a source of energy, but only an energy carrier, which is silly because all matter is such. Before buying that line, people should brush up on the law of conservation and the relativity of mass to energy. All matter has potential energy, whether or not we’ve discovered the technology to release it in a controlled process. Just because some matter is easily combustible and some isn’t doesn’t change the relativity of matter to energy; but I digress. There are a plethora of reasons to replace petroleum fuels, and the most immediate, carbon-free alternative to gasoline is hydrogen. It is the unfortunate nature of cannibalism to only look as far as the next meal, never mind the long-term implications of obfuscating the best solutions. Why is it a virtual secret that BMW has cars that drive on it, Airbus has a plane that flies on it, and California has fuel stations that pump it? If this is news to you, it’s news for many others. It’s time that these facts make the news. Enter oilman T. Boone Pickens and his plan. This may be just the turn to make the dream of a hydrogen economy a reality. The Pickens Plan, like the rest, does not include hydrogen, but, as I mentioned, he wants us to switch our transportation fuel from gasoline to natural gas. The notion of converting to a natural-gas-based transportation system would lay the groundwork for the transition to pure hydrogen combustion as the alternative to gasoline. There are a lot more headaches in converting from gasoline to gas than from one gas to another. There is a good chance that converting a car from natural gas to hydrogen could be a shop procedure that could be done at the neighborhood service station. In the meantime, someone needs to push a plan to install electrolyzers at fuel stations across the country to make hydrogen on-site. Prices would drop, and the oil companies would have to focus on plastics. Hydrogen is the only readily available resource that could completely replace gasoline, diesel, and jet fuel without compromising power and performance. The car companies could adapt to this now . The way the engines of today work would remain fundamentally unchanged. Cars, SUVs, trucks, and all other forms of transportation would still be in play. Then you’d have the potential for innovation that cannot yet be imagined. Cleaner, Safer, Renewable Energy for All As I have said, hydrogen is the most basic element in the universe, composed of one proton and one electron. It is everywhere. If properly harnessed and made from renewable sources, it would be what Peter Hoffman, author of Tomorrow’s Energy: Hydrogen, Fuel Cells, and the Prospects for a Cleaner Planet , called the “forever fuel.” Its only byproducts are heat and pure water. The simple circle of water to energy and back to water is as elegant as it is infinite. It just makes sense. Some might be inclined to wonder whether water, something so essential to life, would then be commoditized to replace the revenue made from oil. In fact, water is already becoming a major geopolitical hot button. The United Nations and many new outlets have given a lot of credence to the notion of a global water crisis, despite the fact that we all know the planet is mostly water and water regularly falls from the sky. There is in fact no water crisis, but rather a clean water crisis. The process of electrolysis doesn’t require clean water, just water. Industry wastes far too much drinking water for purposes that don’t strictly require it and pollute far more water, rendering it undrinkable, but these issues are beside the point. Sure, we break the hydrogen out of water, but when we burn hydrogen, it reunites with oxygen, creating water. Hydrogen as fuel is no threat to the water supply. And where there is water, whether clean or dirty, there is potential fuel. In 2009, when NASA bombed the moon, they were looking for water. Why? Water (H 2 O) is the key to moon colonization, because, in addition to being drinkable, H 2 O gives you hydrogen for fuel and oxygen to breathe. It is mendacious to suggest that hydrogen is perfect for supporting the operations of a permanent moon base, but all wrong for energy applications on earth. As Hoffman writes in his book, hydrogen can “propel airplanes, cars, trains, and ships, run plants, and heat homes, offices, hospitals and schools. . . As a gas, hydrogen can transport energy over long distances, in pipelines, as cheaply as electricity (under some circumstances, perhaps even more efficiently), driving fuel cells or other power-generating machinery at the consumer end to make electricity and water. As a chemical fuel, hydrogen can be used in a much wider range of energy applications than electricity.” 43 There are some who speculate that hydrogen is simply too dangerous to ever be safely used for cars, but hydrogen may still be safer than gasoline. Gasoline is a stable liquid, viscous enough to adhere to other materials (like your skin and clothes), and it pools on surfaces, creating explosive risks. Hydrogen, however, is lighter than air, has to be pressurized to be stored or transported, and immediately evaporates if it escapes its container. When hydrogen is spilled, it doesn’t puddle, presenting an ignition hazard, but simply escapes upward. It’s odorless, its flame is invisible, and its heat rises quickly, thus emitting very little radiant heat. Unless you’re in physical contact with a hydrogen fire, it won’t hurt you. Yes, hydrogen burns, though. That is the point! But those who attempt to invoke fear as a mechanism to obviate the hydrogen solution are being disingenuous at best. The potential energy that we can leverage from burning hydrogen is substantial, and fuel cells have tremendous potential without combustion. Those who use images of the burning Hindenburg are not making a logical case on scientific grounds, but are appealing to ignorant emotion. Hydrogen is not more dangerous than gasoline, natural gas, or a host of other common chemical compounds. Producing and storing hydrogen effectively could usher in a real hydrogen economy, to the benefit of this nation and the rest of the world. Of course, if we really did this, it would eventually put most of the oil companies out of business and collapse the economies of certain OPEC nations, which, I believe, is the actual reason why we never hear this through mainstream channels. Hydrogen may be the linchpin to resolving the transportation fuel question, but, unlike fuels that merely need to be refined, hydrogen has to be produced from water or some other compound. It can be produced in a substantially centralized system (at major hydrogen plants), through a decentralized system (at neighborhood fuel stations), or via a completely decentralized system (most people could produce and store their own hydrogen at home). The real question, then, is one of costs, particularly the cost of producing hydrogen. At present, the electricity needed to electrolyze water to produce hydrogen is more expensive than other methods of hydrogen production. In time, though, after a significant hydrogen infrastructure is developed, I believe the cost of hydrogen production could be nearly negligible. Some fear, though, that the carbon-emission benefits of hydrogen will be lost, because the cheapest way to produce hydrogen is from natural gas, at least for now. Improvements to the power grid are necessary to reduce the cost of electrolysis. Making electricity cheaper and more abundant is a critical component of solving our energy issues. Otherwise, economics will follow the path of least resistance, and dependencies on fossil fuels, with their greenhouse gas emissions, will continue. To complete the circle of clean energy, the cost of hydrogen production from clean sources must come down. Wind, hydropower, and biomass power (generated by burning plant material such as wood waste and agricultural residue) are already cost competitive in many parts of the world and can be used to generate electricity for the electrolysis process. Wind power, for instance, is now the fastest-growing new source of energy; it averages 6–8¢ per kilowatt-hour at the wind generator, down from 40¢ in the early 1980s, though collection and transmission costs must be added. Photovoltaic (solar) and geothermal costs, however, are still high, and will need to come down considerably to make the process competitive with the steam-reforming process of natural gas now used most often in the production of hydrogen. We need to design an overcapacity system for electricity generation, which would greatly reduce the cost of producing hydrogen or charging electric cars. Strategically located new power plants need to be built, together with an improved-efficiency transmission system. Without compromise, the entire country can be powered without fossil fuels. This will, however, require a significant investment in a new energy infrastructure. The geography of the country comes equipped with what some new energy enthusiasts call the great wind corridor. This area, the Great Plains, covers parts of Colorado, Kansas, Montana, Nebraska, New Mexico, North Dakota, Oklahoma, South Dakota, Texas, and Wyoming, totaling approximately five hundred thousand square miles. Windmills as a strategic energy solution may have seemed like a fanciful notion, but a 2007 Department of Energy study showed that developing the infrastructure to fully capture the estimated potential of the so-called U.S. wind corridor would produce as much as 20 percent of our needed electricity. Further political incentives are the estimated 138,000 new jobs that would be created in the first year of making this transition, and the more than 3.4 million new jobs that would be created over a ten-year period. Similarly, our otherwise-barren deserts provide significant potential for solar power generation. Pickens predicts, “Building out solar energy in the Southwest from western Texas to California would add to the boom of new jobs and provide more of our growing electrical needs—doing so through economically viable, clean, renewable sources.” We also need to explore the use of geothermal energy production for our electrical grid. The term geothermal means “earth’s heat” and is derived from two Greek words, geo (earth) and therme (heat); the earth’s thermal energy is also called geothermal energy . As we learned in elementary school, the core of the earth is very hot, upwards of 9,000°F. The concept of usable geothermal energy is based on the principle that, if water descends to lower levels of the earth’s crust through deep fissures, it will heat up and return to the surface, thereby transferring heat from inner layers to the surface. Natural instances of this process appear on the surface as geysers or hot springs. The idea behind geothermal energy production is to mimic this natural process by drilling down to where the temperature rises approximately 17 °C to 30 °C for every kilometer deeper (50–87°F every one mile deeper), pump water in, and utilize the high-pressure, returning steam to drive electricity-generating turbines. With the hot water and steam used for initiation of generators, there’s no combustion of fossil fuels. As a result, there are no harmful emissions of gases into the atmosphere. Only water vapor gets released. Generally, though, geothermal plants require strategically located sites at the borders of the earth’s tectonic plates, where magma may leak into the upper layers of the earth’s crust. Some have suggested that geothermal energy has the potential to provide fifty thousand times the energy that can be gained from oil and coal across the world. 44 There are naturally occurring geothermal resources, from shallow, surface vents all the way to a couple of kilometers-deep reservoirs of hot water and steam, which could be brought to the surface and exploited. The most commonly considered disadvantage of exploiting geothermal energy is the fact that there aren’t many areas of high volcanic and tectonic activity that are naturally suitable for exploitation. Actually, although volcanoes and hot springs are the simplest sources of geothermal energy, drilling technology is such that we could tap into the earth’s heat in far more locations than merely where the crust is thinnest. Perhaps what are most needed for our electrical grid are a few well-located nuclear power plants. Nuclear is clean, it can be produced anywhere, and it is virtually inexhaustible. Of course, ever since the Three Mile Island accident of 1979, the subject of nuclear energy has been rather controversial. Really, it could be said that there is an irrational level of fear surrounding nuclear for this reason. In truth, the opposition to nuclear energy has principally been rhetorical, symbolic, and largely without foundation; after thirty years of study, the actual harm done by Three Mile Island or even Chernobyl, the worst of all nuclear accidents, is markedly less than that of other energy sources. The Paul Scherrer Institute in Switzerland found that, between 1970 and 1992 (a fairly narrow time frame including both the Chernobyl and Three Mile Island incidents), nuclear power had the best safety record of all major energy sources, both in terms of total deaths and deaths per terawatt of energy produced each year. The results for the top four sources were: coal, with 6,400 total deaths and 342 deaths per terawatt per year; hydroelectric power, with 4,000 total deaths and 884 deaths per terawatt per year; natural gas, with 1,200 total deaths and eighty-five deaths per terawatt per year, and nuclear power, with thirty-one total deaths and eight deaths per terawatt per year. This is not to suggest that nuclear energy is a panacea. There are very significant caveats. First, there are dramatic, long-term health hazards associated with mining uranium. Then, there is the matter of what to do with nuclear waste. The hysteria over these concerns, though, far exceeds the actual risks. It is really a matter of choosing the lesser of evils. Compared with nearly any other system currently in use for generating power, nuclear is most equipped to provide the continuous supply of electricity that our civilization requires. Whether you burn coal, oil, natural gas, or the like, you are dealing with finite resources. Wind and solar solutions are inconsistent. Hydroelectric and geothermal are generally geographically bound. You can build a nuclear power plant virtually anywhere and produce power indefinitely. Really, when you compare nuclear power to other power-generation systems in terms of the facts, it is hard to see why we don’t use nuclear as our main source of electricity, unlike the French and others, who use nuclear almost exclusively. Just considering our existing use of nuclear power, we find that its use substantially mitigates the emissions of greenhouse gases. A report, The Keystone Center Nuclear Power Joint Fact-Finding, published in June 2007 with funding from the Pew Charitable Trusts, the National Commission on Energy Policy, and nuclear industry representatives, reported that failing to replace existing nuclear power plants over the next half-century would actually increase carbon emissions by 12.5 gigatons. We have to consider the tremendous weight that nuclear is now pulling for the environment. Nuclear fission energy actually has a lower greenhouse-gas emission rate than photovoltaic electric generation (solar power). Even cost effectiveness favors nuclear, which is nearly a third less costly in terms of operation, maintenance, and fuel per kilowatt-hour than fossil fuel, steam-power generation, and two-thirds less costly than either gas turbine energy or small-scale photovoltaic or wind energy. Yet, according to the Department of Energy, only 20 percent of the electricity in the U.S. comes from nuclear plants, and “more than 90 percent of the power plants to be built in the next twenty years will likely be fueled by natural gas.” 45 No new nuclear plants have been built in thirty years. Why? The short answer is fear. The slightly longer answer is politics. The Cold War has given many the impression that all things nuclear are bad, but there is actually very little validity to most of the anecdotal indictments against nuclear power. Detractors will cite the expense of building nuclear power plants, the risks of nuclear meltdowns, the fact that the technology can be used for bombs, the toxicity of plutonium, or the unusual notion that it is bad for humanity to have an unlimited abundance of energy, because it would spur overutilization and waste. But the only substantive counterargument is that there isn’t much of a long-term solution to nuclear waste. In most cases, nuclear waste can be reprocessed for future use, at least theoretically, but this is a complicated and politically charged issue. In any case, there are several fully sustainable solutions for generating electricity without emitting so-called greenhouse gases. From these stationary generators, we can produce transportation fuels in the form of hydrogen and charged batteries for electric vehicles. Conserving and harnessing renewable forms of electricity not only has incredible economic benefits, but is also a crucial piece of the oil-dependence puzzle. In addition to improving the volume of electricity generated, we need to enhance the efficiency of the distribution of energy with what some call a “smart grid.” A smart grid would deliver electricity using a bidirectional, digital monitoring system to keep track of all electricity flowing in the system, control appliances at consumers’ homes, and thereby more efficiently use electricity. Theoretically, a smart grid should incorporate transmission lines that reduce power loss and integrate alternative sources of electricity, such as solar and wind, from distributed locations. In our current system, electric utility companies are only concerned with delivering electricity to client sites. By adding data communications and application logic to the system, a smart grid could selectively turn on those home appliances and factory processes that can run at arbitrary hours (such as washing machines, in the case of home appliances) during off-peak hours. At peak times, such a system could selectively turn off appliances to reduce demand. And if appliance manufacturers worked with power companies on standards, they could eliminate the standby mode feature on countless appliances, thus avoiding drawing power to unnecessarily maintain a clock or respond to remote controls or electronic switches. The system would be capable of routing power in optimal ways to respond to a very wide range of conditions. It may not be the “granola way,” but we will continue to need more and more energy. We live in the Information Age. We have to accept that reality. Even the notion of all-electric vehicles requires more power. To concentrate national energies on energy, divide-and-conquer politics, which is cannibalizing our internal resources, will have to be replaced by a united effort. Otherwise, energy costs will continue to bankrupt our businesses, immobilize our sprawling nation, pollute our planet, and fund our enemies. One step to avert the total disintegration of our cannibal country is to give the power to the people. 29. For the official energy statistics from the U.S. government, see the web site of the Energy Information Administration at http://www.eia.gov . 30. http://www.pickensplan.com , accessed August 9, 2010. Unless otherwise noted, all references to Pickens in this book are to his web site. 31. Charles J. Hanley, “UN: 2000–2009 Likely Warmest Decade on Record,” Associated Press, December 8, 2009. 32. Lulu Liu, “Global Warming: NASA Says It’s the Hottest Year on Record,” McClatchy , July 27, 2010, http://www.mcclatchydc.com/2010/07/27/98203/earth-bakes-worldwide.html . 33. Sid Perkins, “Less, Thinner Arctic Ice,” Science News 175, no. 10 (2009), 14. 34. Michael Reilly, “First Signs of Melting Seen in East Antarctica,” Discovery News , November 23, 2009. 35. Boston Globe , “Jellyfish Flourish as Water Warms,” July 2, 2002. 36. Drew FitzGerald, “The New Ocean Predator: Jellyfish?” Global Post , November 29, 2009, http://www.globalpost.com/dispatch/study-abroad/091022/the-new-ocean-predator-jellyfish . 37. Ibid. 38. University of California, Santa Barbara, Butterflies Move North Due to Global Warming , press release, June 10, 1999, http://www.ia.ucsb.edu/pa/display.aspx?pkey=312 . 39. Associated Press, “Two-Thirds of World’s Polar Bears Will Be Gone by 2050,” Saturday, September 08, 2007. 40. David Adam, “Global Warming: Melting Ice Threatens Arctic Foxes,” Guardian , Tuesday 15, July 2008. 41. Cynthia Rosenzweig and William Solecki, “How Does Climate Change Today Compare with Climate Change in the Past?” Columbia University, 2004–5, http://ccir.ciesin.columbia.edu/nyc/pdf/q1b.pdf . 42. Richard A. Muller, Physics for Future Presidents (New York: W. W. Norton, 2008), 302. 43. Peter Hoffmann and Tom Harkin , Tomorrow’s Energy: Hydrogen, Fuel Cells, and the Prospects for a Cleaner Planet (Cambridge: MIT Press, 2002), 6. 44. Jeff Tester and Ron DiPippo, “The Future of Geothermal Energy: Structure and Outcome of the Analysis,” Presentation at the Doe Geothermal Program Workshop (Cambridge: MIT, 2006). 45. U.S. Department of Energy, http://www.energy.gov/energysources/electricpower.htm . Accessed August 9, 2010.",
        "char_count": 70970
      }
    ]
  },
  "four_pillars": {
    "meta": {
      "key": "four_pillars",
      "title": "The Four Pillars of Investing",
      "creator": "William J. Bernstein",
      "filepath": "G:/My Drive/15_E-BOOKS/file002119.epub",
      "subject": "Economics"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Copyright © 2010, 2002 by The McGraw-Hill Companies, Inc. All rights reserved. Except as permitted under the United States Copyright Act of 1976, no part of this publication may be reproduced or distributed in any form or by any means, or stored in a database or retrieval system, without the prior written permission of the publisher. ISBN: 978-0-07-175917-5 MHID: 0-07-175917-4 The material in this eBook also appears in the print version of this title: ISBN: 978-0-07-174705-9, MHID: 0-07-174705-2. All trademarks are trademarks of their respective owners. Rather than put a trademark symbol after every occurrence of a trademarked name, we use names in an editorial fashion only, and to the benefit of the trademark owner, with no intention of infringement of the trademark. Where such designations appear in this book, they have been printed with initial caps. McGraw-Hill eBooks are available at special quantity discounts to use as premiums and sales promotions, or for use in corporate training programs. To contact a representative please e-mail us at bulksales@mcgraw-hill.com. This publication is designed to provide accurate and authoritative information in regard to the subject matter covered. It is sold with the understanding that the publisher is not engaged in rendering legal, accounting, or other professional service. If legal advice or other expert assistance is required, the services of a competent professional person should be sought. — From a Declaration of Principles Jointly Adopted by a Committee of the American Bar Association and a Committee of Publishers and Associations TERMS OF USE This is a copyrighted work and The McGraw-Hill Companies, Inc. (“McGraw-Hill”) and its licensors reserve all rights in and to the work. Use of this work is subject to these terms. Except as permitted under the Copyright Act of 1976 and the right to store and retrieve one copy of the work, you may not decompile, disassemble, reverse engineer, reproduce, modify, create derivative works based upon, transmit, distribute, disseminate, sell, publish or sublicense the work or any part of it without McGraw-Hill’s prior consent. You may use the work for your own noncommercial and personal use; any other use of the work is strictly prohibited. Your right to use the work may be terminated if you fail to comply with these terms. THE WORK IS PROVIDED “AS IS.” McGRAW-HILL AND ITS LICENSORS MAKE NO GUARANTEES OR WARRANTIES AS TO THE ACCURACY, ADEQUACY OR COMPLETENESS OF OR RESULTS TO BE OBTAINED FROM USING THE WORK, INCLUDING ANY INFORMATION THAT CAN BE ACCESSED THROUGH THE WORK VIA HYPERLINK OR OTHERWISE, AND EXPRESSLY DISCLAIM ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. McGraw-Hill and its licensors do not warrant or guarantee that the functions contained in the work will meet your requirements or that its operation will be uninterrupted or error free. Neither McGraw-Hill nor its licensors shall be liable to you or anyone else for any inaccuracy, error or omission, regardless of cause, in the work or for any damages resulting therefrom. McGraw-Hill has no responsibility for the content of any information accessed through the work. Under no circumstances shall McGraw-Hill and/or its licensors be liable for any indirect, incidental, special, punitive, consequential or similar damages that result from the use of or inability to use the work, even if any of them has been advised of the possibility of such damages. This limitation of liability shall apply to any claim or cause whatsoever whether such claim or cause arises in contract, tort or otherwise.",
        "char_count": 3682
      },
      {
        "heading": "Chapter 2",
        "text": "Contents Preface Introduction Pillar One: The Theory of Investing Chapter 1. No Guts, No Glory Chapter 2. Measuring the Beast Chapter 3. The Market Is Smarter Than You Are Chapter 4. The Perfect Portfolio Pillar Two: The History of Investing Chapter 5. Tops: A History of Manias Chapter 6. Bottoms: The Agony and the Opportunity Pillar Three: The Psychology of Investing Chapter 7. Misbehavior Chapter 8. Behavioral Therapy Pillar Four: The Business of Investing Chapter 9. Your Broker Is Not Your Buddy Chapter 10. Neither Is Your Mutual Fund Chapter 11. Oliver Stone Meets Wall Street Investment Strategy: Assembling the Four Pillars Chapter 12. Will You Have Enough? Chapter 13. Defining Your Mix Chapter 14. Getting Started, Keeping It Going Chapter 15. A Final Word Bibliography Index 2010 Postscript",
        "char_count": 805
      },
      {
        "heading": "Chapter 3",
        "text": "Preface In the mid-1990s, I began writing a small book, The Intelligent Asset Allocator , which ultimately became a “successful failure”: successful because it attracted positive notice and sold enough copies to please my publisher and myself, and a failure because it did not accomplish its ultimate goal. My aim had been to explain modern portfolio theory, a powerful way of understanding investing, to the general public. What I instead produced was a work comprehensible only to those with a considerable level of mathematical training and skill. After initially failing to interest any publishers, the original electronic version of the book was placed on my Web site, , at the end of 1996. Following a slow start, it gradually elicited much positive comment. The only problem was that almost all of its readers were scientists, engineers, or finance professionals. www.efficientfrontier.com Closer to home, my family and friends uniformly gave up on it with alarming dispatch: “Bill, you’ve got to be kidding. I fell asleep after five pages; this stuff is way over my head.” The dividing line seemed to be slightly north of Statistics 101; if you never took it, or did but hated it, the book might as well have been written in Tamil. Eventually, in a show of unalloyed courage, McGraw-Hill did print it as a trade publication—aimed at professionals, not the general public. The book was a methodical mathematical exercise. First, the behavior of multiple asset classes was statistically analyzed. Next, the theoretical basics of portfolio theory were examined. Ultimately, these two foundations, as well as a practical tour of the investment industry, were synthesized into a coherent investment strategy. The small minority of investors who thrive on such fare felt well rewarded. But, as with the electronic versions, most considered it more sedative than informative. Fortunately, The Intelligent Asset Allocator’s limited success allowed me a second chance to write a book about investing for the general audience. My watchwords in producing The Four Pillars of Investing were accessibility and enjoyment; I’ve used engaging historical vignettes wherever possible to illustrate key financial concepts and kept mathematical detail to a minimum. A well-known rule among scientists is that each successive mathematical formula cuts a book’s popular readership in half; I’ve done my best to keep the math simple and the graphs as spare as possible. Now, almost a decade later, this title is in its seventeenth printing; so I suppose I’ve succeeded. Special thanks go to those who have provided encouragement and help along the way, including Cliff Asness, John C. Bogle Sr., Scott Burns, Edward Chancellor, Mark Gochnour, Christian Oelke, John Rekenthaler, Bill Schultheis, Larry Swedroe, Robert Sidelsky, Richard Thaler, Mike Veseth, and Jason Zweig. I’ll never understand what motivated Catherine Dassopoulos and Jeffrey Krames of McGraw-Hill to take an interest in an obscure electronic file by an unknown scribbler floating around in cyberspace, but their editorial and publishing support has been a constant source of delight and satisfaction. Thanks are also given to Stephen Isaacs, who shepherded this work through each step of the production process. There must be no harder job in publishing than getting an author to “kill his darlings” in the cause of producing a tighter and more muscular manuscript; Stephen accomplished this with aplomb and grace. Author and academic Larry Cunningham and my friends Stephen Dunn and Charles Holloway spent many hours of their precious time hammering out the flaws in both finance and wordsmithing. Jonathan Clements brought not only his time but also his years of journalistic experience at Cambridge, Forbes , and The Wall Street Journal to bear in improving the book’s detail and structure. Particular thanks go to my business partner, Susan Sharin, whose unique combination of financial savvy, editorial skills, and command of the investment business landscape proved as essential in this effort as it was in my last book. Finally, to my wife, Jane Gigler, go the fondest thanks of all. Her cheerful and unending transmutation of large heaps of muddled verbiage into readable prose and amused tolerance of an obsessed author and husband are a constant source of pleasure and awe. William Bernstein Portland, Oregon",
        "char_count": 4372
      },
      {
        "heading": "Chapter 4",
        "text": "Introduction I didn’t start out my professional life in finance; my original training was in the sciences, and, later, in medicine. Practicing physicians, among whom I still count myself, have a richly deserved reputation as miserable investors. The conventional explanations for this are that our practices are so demanding that we don’t have the time to do it properly, or that we’re too egotistical to take professional advice. In fact, neither is the case. Learning how to invest properly doesn’t take an inordinate effort, and I don’t find most of my colleagues overly egotistical. Medical practice is a profoundly humbling experience to anyone with a breath of intellectual honesty; the best doctors soon come to the conclusion that the more they see, the less they know. The same, not surprisingly, is true in finance. The real reason that physicians are rotten investors is that it never occurs to them that finance is a science, just like medicine. Day-to-day medical practice is profoundly scientific, informed by a vast amount of underlying research; nowadays almost no drug or surgical treatment is adopted without rigorous trials comparing it to other accepted treatments or placebo. In short, most physicians would not commence a treatment for so much as a cold without a good deal of experimental and statistical evidence in back of it. The most important work is reported in prestigious peer-reviewed periodicals such as The New England Journal of Medicine and Lancet . The key term here is “peer reviewed.” Nothing appears in these high-level periodicals without being vetted first by the top experts in the field—requests for multiple extensive revisions are routine. Your own physician hopefully reads these top-echelon publications on a regular basis for data relevant to his practice. Unfortunately, when doctors put on their investing hats, they completely forget their scientific training. There is, in fact, a rich and informative scientific literature about what works and what doesn’t in finance; it is routinely ignored. Instead of depending on the Journal of Finance (the investing equivalent of The New England Journal of Medicine ), they get their advice from USA Today or worse, from their stockbroker. Of course, I’m only picking on my colleagues for fun—in this regard doctors are no different from lawyers, retail clerks, or anyone else. What’s truly scandalous is that even most finance professionals are unaware of the scientific basis of investing, which consists of four broad areas, the Four Pillars of this book. Pillar One: Theory The most fundamental characteristic of any investment is that its return and risk go hand in hand. As all too many have learned in the past few years, a market that doubles rapidly is just as likely to halve rapidly, and a stock that appreciates 900% is just as likely to fall 90%. Or that when a broker calls suggesting that the price of a particular stock will rocket, what he’s really telling you is that he is not overly impressed with your intelligence. Otherwise, you would realize that if he actually knew that the price was going to increase, he would not tell it to you or even his own mother. Instead, he would quit his job, borrow to the hilt, purchase as much of the stock as he could, and then go to the beach. The first, and most important, part of the book will survey the awesome body of theory and data relevant to everyday investing. Don’t be daunted by this; my primary mission is to present this information in terms that you will find both understandable and entertaining. We’ll learn that: • Whether you invest in stocks, bonds, or for that matter real estate or any other kind of capital asset, you are rewarded mainly for your exposure to one thing—its risk. We’ll learn just how to measure that risk and explore the interplay of risk and investment return. • Over the long haul, it is not that hard to measure the probable return of different kinds of stocks and bonds; yet even well-respected experts usually manage to do a bad job of this. • Almost all the differences in the performances of money managers can be ascribed to luck and not to skill; you are most certainly not rewarded for trying to pick the best-performing stocks, mutual funds, stockbrokers, or hedge funds. • The biggest risk of all is failing to diversify properly. • It’s the behavior of your portfolio as a whole, and not the assets in it, that matters most. We’ll also learn that a portfolio can behave in ways radically different than its component parts, and that this can be used to your advantage. The science of mixing different asset classes into an effective blend is called “portfolio theory” and occupies center court in the grand tournament of investing. Pillar Two: History It is a fact that, from time to time, the markets and investing public go barking mad. Of course, the madness is obvious only in retrospect. But a study of previous manias and crashes will give you at least a fighting chance of recognizing when asset prices have become absurdly expensive and risky and when they have become too depressed and cheap to pass up. The simplest way of separating managers who would be suckered into the dot-com mania (or, more recently, homeowners who took out interest-only liar-loan mortgages) from those who would not would be to administer a brief quiz on the 1929 crash. Finance, unfortunately, is not a “hard” science. It is instead a social science. The difference is this: a bridge, electrical circuit, or aircraft should always respond in exactly the same way to a given set of circumstances. What separates the “hard” sciences of physics, engineering, electronics, or aeronautics from the “social” sciences is that in finance (or sociology, politics, and education) apparently similar systems will behave very differently over time. Put a different way, a physician, physicist, or chemist who is unaware of their discipline’s history does not suffer greatly from the lack thereof; the investor who is unaware of financial history is irretrievably handicapped. For this reason, an understanding of financial history provides an additional dimension of expertise. In this section, we’ll study the history of finance through the widest possible lens by examining: • Just what the centuries of recorded financial history tell us about the short-term and long-term behavior of various financial assets. • How, from time to time, the investing public becomes almost psychotically euphoric, and at other times, toxically depressed. • How modern investment technology has exposed investors to new risks. Pillar Three: Psychology Most of what we fondly call “human nature” becomes a deadly quicksand of maladaptive behavior when allowed to roam free in the investment arena. A small example: people tend to be attracted to financial choices that carry low probabilities of high payoffs. In spite of the fact that the average payoff of a lottery ticket is only 50 cents on the dollar, millions “invest” in it. While this is a relatively minor foible for most, it becomes far more menacing as an investment strategy. One of the quickest ways to the poorhouse is to make finding the next Microsoft your primary investing goal. Only recently have academics and practitioners begun the serious study of how the individual investor’s state of mind affects his or her decision making; we’ll survey the fascinating area of “behavioral finance.” You’ll learn how to avoid the most common behavioral mistakes and to confront your own dysfunctional investment behavior. You will find out, for example, that most investors: • Tend to become grossly overconfident. • Systematically pay too much for certain classes of stocks. • Trade too much, at great cost. • Regularly make irrational buy and sell decisions. Pillar Four: Business Investors tend to be touchingly naïve about stockbrokers and mutual fund companies: brokers are not your friends, and the interests of the fund companies are highly divergent from yours. You are in fact locked in a financial life-and-death struggle with the investment industry; losing that battle puts you at increased risk of running short of assets far sooner than you’d like. The more you know about the industry’s priorities and how it operates, the more likely it is that you will be able to thwart it. The brokerage and mutual fund businesses form a financial colossus that bestrides modern financial, and increasingly, social, and political life. (If you doubt this, just turn on your television and time the interval between advertisements for financial services.) In the book’s penultimate section, then, we’ll examine how the modern financial services industry is designed solely to serve itself, and how it: • Exists almost entirely for one purpose: the extraction of fees and commissions from the investing public, and that in fact, we are all locked in a constant zero-sum battle with this behemoth. • Operates at a level of educational, moral, and ethical imperatives that would be inconceivable in any other profession. A small example: by law, bankers, lawyers, and accountants all have a fiduciary responsibility towards their clients. Not so stockbrokers. Only after you’ve mastered these four areas can you formulate an overall investment strategy. Only after you’ve formulated a program that focuses on asset classes and the behavior of asset-class mixtures will you have any chance for overall success. A deficiency in any of the Four Pillars will torpedo this program with brutal dispatch. Here are a couple of examples of how a failure to master the Four Pillars can bring grief to even the most sophisticated investors: Big time players: The principals of Long-Term Capital Management, the firm that in 1998 almost single handedly crippled the world financial system with their highly leveraged speculation, had no trouble with Pillar One—investment theory—as they were in many cases its Nobel Prize-winning inventors. Their appreciation of Pillars Three and Four—psychology and the investment business—was also top drawer. Unfortunately, despite their corporate name, none of them had a working knowledge of Pillar Two—the long-term history of the capital markets. Focusing narrowly on only several years of financial data, they forgot the fact that occasionally markets come completely off the rails, often in ways never before seen. A working knowledge of Western financial history would have warned them that their investment strategy carried with it the near certainty of self-destruction. Small investors: On the other hand, the average investor most often comes to grief because of deficiencies in Pillars One and Three—theory and psychology. They usually fail to understand the everyday working relationship between risk and reward and routinely fail to stay the course when things get rough. The above two examples are caricatures: the failure modes of individual investors are as varied as their personalities. In this tome, I want to provide you with these invaluable tools—the Four Pillars—to avoid the kinds of failures I’ve listed above. I also want to expose you to the wondrous clockwork and history of the capital markets, which are deserving of attention in their own right. Arguably the most substantive domestic issue facing the republic is the fate of Social Security, with privatization the most frequently mentioned option. For the first time in history, a familiarity with the behavior of the financial markets has become a prerequisite for competent citizenship, apart from its obvious pecuniary value. Using the Four Pillars In the book’s last section, we’ll show how mastery of the Four Pillars can result in a coherent strategy that will enable you to accomplish investing’s primary aims: achieving and maintaining financial independence and sleeping well at night. The essential mechanics of operating an efficient investment portfolio will be covered: • Calculating how much you’ll need to save and when you can retire. • Allocating your assets among various classes of stocks and bonds. • Choosing which mutual funds and securities to employ. • Getting off dead center and building your portfolio. • Maintaining and adjusting your portfolio over the long haul. In Conclusion Although I hope that I’ve conveyed my enthusiasm for financial theory, history, psychology, and strategy, I’ll freely admit that I’ve been dealt the short straw in the subject scintillation department—this book, after all, is not a bodice-ripper or a spy thriller. There is no arguing with the fact that some areas of finance can be damnably opaque, even to cognoscenti. This book, then, should be consumed in small bites, perhaps ten or twenty pages at a time, preferably first thing in the morning. Lastly, while I’ve tried to make this work as comprehensive and readable as possible, no one book can claim to be an all-encompassing source of investment instruction. At best, what is offered here is a study guide—a financial tour d’horizon , if you will. Personal finance, like most important aspects of life, is a never-ending quest. The competent investor never stops learning. As such, the most valuable section is the reading list of the end of Chapter 11 . Remarkably, eight years after this book’s original publication, it survives with only one change, which is to update the latest edition of Jack Bogle’s amazing Common Sense on Mutual Funds . This list should guide you through the subsequent legs of the life-long journey towards financial self-sufficiency.",
        "char_count": 13509
      },
      {
        "heading": "Chapter 5",
        "text": "P ILLAR O NE The Theory of Investing The Nature of the Beast In 1798, a French expedition under the direct command of Napoleon invaded Egypt. His forces possessed only the most rudimentary maps and had almost no knowledge of the climate or terrain. It came as no surprise that the invasion was a disaster from start to finish when, three years later, the last French troops, dispirited, diseased, starving, and abandoned by their leader, were mopped up by Turkish and British forces. Unfortunately, most investors muster the same degree of planning in their investing, unaware of the nature of the investment terrain. Without an understanding of the relationship between risk and reward, how to estimate returns, the interplay between other investors and themselves, and the mechanics of portfolio design, they are doomed to failure, much like Napoleon’s troops. Each of these essential topics can be mastered and will be covered chapter by chapter in this book. The first chapter, dealing with the historical returns and risks in the European and U.S. markets during the past several centuries, is the most critical. We cover a large expanse of historical territory, the premise being that the more history you know, the more prepared you will be for the future.",
        "char_count": 1263
      },
      {
        "heading": "Chapter 6",
        "text": "1 No Guts, No Glory There are certain things that cannot be adequately explained to a virgin either by words or pictures. Nor can any description that I might offer here even approximate what it feels like to lose a real chunk of money that you used to own . Fred Schwed, from Where Are the Customers’ Yachts? I’m often asked whether the markets behave rationally. My answer is that it all depends on your time horizon. Turn on CNBC at 9:31 A.M. any weekday morning and you’re faced with a lunatic asylum described by the Three Stooges. But stand back a bit and you’ll start to see trends and regular occurrences. When the market is viewed over decades, its behavior is as predictable as a Lakers-Clippers basketball game. The one thing that stands out above all else is the relationship between return and risk. Assets with higher returns invariably carry with them stomach-churning risk, while safe assets almost always have lower returns. The best way to illustrate the critical relationship between risk and return is by surveying stock and bond markets through the centuries. The Fairy Tale When I was a child back in the fifties, I treasured my monthly trips to the barbershop. I’d pay my quarter, jump into the huge chair, and for 15 minutes become an honorary member of adult male society. Conversation generally revolved around the emanations from the television set: a small household god dwarfed by its oversized mahogany frame. The fare reflected the innocence of the era: I Love Lucy , game shows, and, if we were especially lucky, afternoon baseball. But I do not ever recall hearing one conversation or program that included finance. The stock market, economy, machinations of the Fed, or even government expenditures did not infiltrate our barbershop world. Today we live in a sea of financial information, with waves of stock information constantly bombarding us. On days when the markets are particularly active, our day-to-day routines are saturated with news stories and personal conversations concerning the whys and wherefores of security prices. Even on quiet days, it is impossible to escape the ubiquitous stock ticker scrolling across the bottom of the television screen or commercials featuring British royalty discoursing knowledgeably about equity ratios. It has become a commonplace that stocks are the best long-term investment for the average citizen. At one time or another, most of us have seen a plot of capital wealth looking something like Figure 1-1 , demonstrating that $1 invested in the U.S. stock market in 1790 would have grown to more than $23 million by the year 2000. Unfortunately, for a number of reasons, no person, family, or organization ever obtained these returns. First, we invest now so that we may spend later. In fact, this is the essence of investing: the forbearance of immediate spending in exchange for future income. Because of the mathematics of compound interest, spending even a tiny fraction on a regular basis devastates final wealth over the long haul. During the last two hundred years, each 1% spent each year reduces the final amount by a factor of eight. For example, a 1% reduction in return would have reduced the final amount from $23 million to about $3 million and a 2% reduction to about $400,000. Few investors have the patience to leave the fruits of their labor untouched. And even if they did, their spendthrift heirs would likely make fast work of their fortune. But even allowing for this, Figure 1-1 is still highly deceptive. For starters, it ignores commissions and taxes, which would have shrunk returns by another percent or two, reducing a potential $23 million fortune to the above $3 million or $400,000. Even more importantly, it ignores “survivorship bias.” This term refers to the fact that only the best outcomes make it into the history books; those financial markets that failed do not. It is no accident that investors focus on the immense wealth generated by the economy and markets of the United States these past two centuries; the champion—our stock market—is the most easily visible, while less successful assets fade quickly from view. And yet the global investor in 1790 would have been hard pressed to pick out the United States as a success story. At its birth, our nation was a financial basket case. And its history over the next century hardly inspired confidence, with an unstable banking structure, rampant speculation, and the Civil War. The nineteenth century culminated in the near bankruptcy of the U.S. Treasury, which was narrowly averted only through the organizational talents of J.P. Morgan. Worse still, for most of the past 200 years, stocks were inaccessible to the average person. Before about 1925, it was virtually impossible for even the wealthiest Americans to purchase shares in an honest and efficient manner. Figure 1-1. Value of $1.00 invested in U.S. stock market. ( Source: Jeremy Siegel/William Schwert.) Worst of all, in the year 2002, the good news about historically high stock returns is out of the bag. For historical reasons, many financial scholars undertake the serious study of U.S. stock returns with data beginning in 1871. But it’s worth remembering that 1871 was only six years after the end of the Civil War, with industrial stocks selling at ridiculously low prices—just three to four times their annual earnings. Stocks today are selling at nearly ten times that valuation, making it unlikely that we will witness a repeat of the returns seen in the past 130 years. Finally, there is the small matter of risk. Figure 1-1 is also deceptive because of the manner in which the data are displayed, with an enormous range of dollar values compressed into its vertical scale. The Great Depression, during which stocks lost more than 80% of their value, is just barely visible. Likewise, the 1973–1974 bear market, during which stocks lost more than one-half of their after-inflation value, is seen only as a slight flattening of the plot. And the October 1987 market crash is not visible at all. All three of these events drove millions of investors permanently out of the stock market. For a generation after the 1929 crash, the overwhelming majority of the investing public shunned stocks altogether. The popular conceit of every bull market is that the public has bought into the value of long-term investing and will never sell their stocks simply because of market fluctuation. And time after time, the investing public loses heart after the inevitable punishing declines that stock markets periodically dish out, and the cycle begins anew. With that in mind, we’ll plumb the history of stock and bond returns around the globe for clues regarding how to capture some of their rewards. Ultimately, this book is about the building of investment portfolios that are both prudent and efficient. The construction of a house is a valuable metaphor for this process. The very first thing the wise homebuilder does, before drawing up blueprints, digging a foundation, or ordering appliances, is learn about the construction materials available. In the case of investing, these materials are stocks and bonds, and it is impossible to spend too much time studying them. We will expend a lot of energy on the several-hundred-year sweep of human investing—a topic that some may initially find tangential to our ultimate goal. Rest assured that our efforts in this area will be well rewarded. For the better we understand the nature, behavior, and history of our building materials, the stronger our house will be. The study of financial history is an essential part of every investor’s education. It is not possible to precisely predict the future, but a knowledge of the past often allows us to identify financial risk in the here and now. Returns are uncertain. But risks, at least, can be controlled. We tend to think of the stock and bond markets as relatively recent historical phenomena, but, in fact, there have been credit markets since human civilization first took root in the Fertile Crescent. And governments have been issuing bonds for several hundred years. More importantly, after they were issued, these bonds then fluctuated in price according to economic, political, and military conditions, just as they do today. Nowhere is historian George Santayana’s famous dictum, “Those who cannot remember the past are condemned to repeat it,” more applicable than in finance. Financial history provides us with invaluable wisdom about the nature of the capital markets and of returns on securities. Intelligent investors ignore this record at their peril. Risk and Return Throughout the Centuries Even before money first appeared in the form of small pellets of silver 5,000 years ago, there have been credit markets. It is likely that for thousands of years of prehistory, loans of grain and cattle were made at interest; a bushel or calf lent in winter would be repaid twice over at harvest time. Such practices are still widespread in primitive societies. (When gold and silver first appeared as money, they were valued according to head of cattle, not the other way around.) But the invention of money magnified the prime question that has echoed down through investment history: How much return should be paid by the borrowers of capital to its lenders? You may be wondering by now about why we’re spending time on the early history of the credit markets. The reason for their relevance is simple. Two Nobel Prize-winning economists, Franco Modigliani and Merton Miller, realized more than four decades ago that the aggregate cost of and return on capital, adjusted for risk, are the same, regardless of whether stocks or bonds are employed. In other words, had the ancients used stock issuance instead of debt to finance their businesses, the rate of return to investors would have been the same. So we are looking at a reasonable portrait of investment return over the millennia. The history of ancient credit markets is fairly extensive. In fact, much of the earliest historical record from the Fertile Crescent—Sumeria, Babylon, and Assyria—concerns itself with the loaning of money. Much of Hammurabi’s famous Babylonian Code—the first comprehensive set of laws—dealt with commercial transactions. A small ancient example will suffice. In Greece, a common business was that of the “bottomry loan,” which was made against a maritime shipment and forfeited if the vessel sank. A fair amount of data is available on such loans, with rates of 22.5% for a round-trip voyage to the Bosphorus in peacetime and 30% in wartime. Since it is likely that fewer than 10% of ships were lost, these were highly profitable in the aggregate, though quite risky on a case-by-case basis. This is one of the first historical demonstrations of the relationship between risk and return: The 22.5% rate of interest was high, even for that period, reflecting the uncertainty of dealing with maritime navigation and trade. Further, the rate increased during wartime to compensate for the higher risk of cargo loss. Another thing we learn from a brief tour of ancient finance is that interest rates responded to the stability of the society; in uncertain times, returns were higher because there was less sense of public trust and of societal permanence. All of the major ancient civilizations demonstrated a “U-shaped” pattern of interest rates, with high rates early in their history that slowly fell as the civilizations matured and stabilized, reaching the lowest point at the height of the civilizations’ development and rising again as they decayed. For example, the apex of the Roman Empire in the first and second century A.D. saw interest rates as low as 4%. As a general rule, the historical record suggests excellent investment returns in the ancient world. But this record reflects only those societies that survived and prospered, since successful societies are much more likely to leave a record . Babylonian, Greek, and Roman investors did much better than those in the nations they vanquished—the citizens of Judea or Carthage had far bigger worries than their failing financial portfolios. This is not a trivial issue. At a very early stage in history we are encountering “survivorship bias”—the fact that only the best results tend to show up in the history books. In the twentieth century, for example, investors in the U.S., Canada, Sweden, and Switzerland did handsomely because they went largely untouched by the military and political disasters that befell most of the rest of the planet. Investors in tumultuous Germany, Japan, Argentina, and India were not so lucky; they obtained far smaller rewards. Thus, it is highly misleading to rely on the investment performance of history’s most successful nations and empires as indicative of your own future returns. At first glance, it might appear that the above list of winners and losers contradicts the relationship between risk and return. This is an excellent example of “hindsight bias”; in 1913 it was by no means obvious that the U.S., Canada, Sweden, and Switzerland would have the highest returns, and that Germany, Japan, Argentina, and India, the lowest. Going back further, in 1650 France and Spain were the mightiest economic and military powers in Europe, and England an impoverished upstart torn by civil war. The interest rate bottom of 4% reached in Rome is particularly relevant to the modern audience. Never before, and perhaps not since, have the citizens of any nation had the sense of cultural and political permanence experienced in Rome at its apex. So the 4% return at Rome’s height may represent a kind of natural lower limit of investment returns, experienced only by the most confident (or perhaps overconfident) nations at the top of their game. The Austrian economist Eugen von Böhm-Bawerk stated that the cultural and political level of a nation could be discerned by its interest rate: The more advanced the nation, the lower the loan rate. Economist Richard Sylla notes that a plot of interest rates can be thought of as a nation’s “fever chart,” with upward spikes almost always representing a military, economic, or political crisis, and long, flat stretches signifying extended periods of stability. As we’ll see, the 4% Roman rate of return is about the same as the aggregate return on capital (when stocks and bonds are considered together) in the U.S. in the twentieth century, and perhaps even a bit more than the aggregate return expected in the next century. (The 4% Roman rate was gold-based, so the return was a real , that is, after-inflation, return.) The same phenomenon was observed in Europe. The primitive and unstable societies of medieval Europe initially had very high interest rates, which gradually fell as the Dark Ages gave way to the Renaissance and Enlightenment. To illustrate this point, Figure 1-2 shows European interest rates from the thirteenth through the eighteenth centuries. One of the most important European financial inventions was the “annuity,” that is, a bond that pays interest forever, without ever repaying the principal amount. This is different from the modern insurance company annuity, in which payments cease with the death of the owner. European annuities were usually issued by a government to pay for war expenses and never expired; instead, they were handed down and traded among succeeding generations of investors. Newcomers tend to recoil at a loan that yields only interest with no return of principal, but the annuity provides a very useful way of thinking about the price of a loan or bond. It’s worth spending some time discussing this topic, because it forms one of the foundations of modern finance. Figure 1-2. European interest rates, 1200–1800. ( Source: Homer and Sylla, A History of Interest Rates .) If you have trouble dealing with the concept of a loan which pays interest forever but never repays its principal, consider the modern U.S. 30-year Treasury bond, which yields 60 semiannual payments of interest before repaying its principal. During the past 30 years, inflation has averaged more than 5% per year; over that period the purchasing power of the original dollar fell to less than 23 cents. (In other words, the purchasing power of the dollar declined by 77%.) So almost all of the value of the bond is garnered from interest, not principal. Extend the term of the loan to 100 years, and the inflation-adjusted value of the ending principal payment is less than one cent on the dollar. The historical European government annuity is worthy of modern consideration for one compelling reason: its value is extremely simple to calculate: divide the annual payment by the current (market) interest rate. For example, consider an annuity that pays $100 each year. At a 5% interest rate, this annuity has a value of $2,000 ($100/0.05 = $2,000). If you purchased an annuity when interest rates were 5%, and rates then increased to 10%, the value of your annuity would have fallen by half, since $100/0.1 = $1,000. So we see that the value of a long-term bond or loan in the marketplace is inversely related to the interest rate. When rates rise, the price falls; when rates fall, the price rises. Modern long-duration bonds are priced in nearly the same way: if the bond yield rises proportionally by 1%—say from 5.00% to 5.05%—it has lost 1% of its value. The best-known early annuity was the Venetian prestiti, used to finance the Republic’s wars. These were forced loans extracted from the Republic’s wealthiest citizens. The money was remitted to a central registry office, which then paid the registered owner periodic interest. They carried a rate of only 5%. Since prevailing interest rates in the nation’s credit markets were much higher, the “purchase” of a prestiti at a 5% rate constituted a kind of tax levied on its owner, who was forced to buy it at face value. But the Venetian treasury did allow owners to sell their prestiti to others—that is, to change the name registered at the central office. Prestiti soon became the favored vehicle for investment and speculation among Venetian noblemen and were even widely held throughout Europe. This “secondary market” in prestiti provides economic historians with a vivid picture of a medieval bond market that was quite active over many centuries. Consider a prestiti forced upon a wealthy citizen for 1,000 ducats, yielding 50 ducats per year, or 5%. If the prevailing interest rate in the secondary market was actually 6.7%, then the owner could sell it in the market at only 75% of its face value, or 750 ducats, since 50/0.067 = 750. Figure 1-3. Venetian prestiti prices, 1300–1500. ( Source: Homer and Sylla, A History of Interest Rates .) I’ve plotted the prices of prestiti during the fourteenth and fifteenth centuries in Figure 1-3 . (The “par,” or face value of the bonds, is arbitrarily set at 100.) For the first time in the history of capital returns, we are now able to examine the element of risk . Defined in its most basic terms, risk is the possibility of losing money. A fast look at Figure 1-3 shows that prestiti owners were certainly exposed to this unhappy prospect. For example, in the tranquil year of 1375, prices reached a high of 92 1/2. But just two years later, after a devastating war with Genoa, interest payments were temporarily suspended and vast amounts of new prestiti were levied, driving prices as low as 19; this constituted a temporary loss of principal value of about 80%. Even though Venice’s fortunes soon reversed, this financial catastrophe shook investor confidence for more than a century, and prices did not recover until the debt was refinanced in 1482. Even taking these stumbles into account, investors in medieval and Renaissance Europe earned healthy returns on their capital. But these rewards were bought by shouldering risk, red in tooth and claw. As we shall soon see, later investors in Europe and America also have experienced similar high inflation-adjusted returns. But even in the modern world, where there is return, there also lurks risk. The point of this whole historical exercise is to establish the most important concept in finance, that risk and return are inextricably connected . If you desire the opportunity to achieve high returns, you have to shoulder high risks. And if you desire safety, you will of necessity have to content yourself with meager rewards. Consider the prices of prestiti in three different years: The Venetian investor who bought prestiti in 1375, when the Republic seemed secure, would have been badly damaged. Conversely, the investor brave enough to purchase at 1381’s depressed price, when all seemed lost, would have earned high returns. High returns are obtained by buying low and selling high; low returns are obtained by buying high and selling low. If you buy a stock or bond with the intention of selling it in, say, twenty years, you cannot predict what price it will fetch at that future date. But you can state with mathematical certainty that as long as the issuing company does not go bankrupt, the lower the price you pay for it now, the higher your future returns will be; the higher the price you pay, the lower your returns will be. This is an essential point that escapes most small investors. Even the world’s most sophisticated financial economists occasionally make this mistake: in financial parlance, they “conflate expected returns with realized returns.” Or, in plain English, they confuse the future with the past. This point cannot be made too forcefully or too often: high previous returns usually indicate low future returns, and low past returns usually mean high future returns. The rub here is that buying when prices are low is always a very scary proposition. The low prices that produce high future returns are not possible without catastrophe and risk . The moral for modern investors is obvious: the recent very high stock returns in the U.S. would not have been possible without the chaos of the nineteenth century and the prolonged fall in prices that occurred in the wake of the Great Depression. Conversely, the placid economic, political, and social environment before the World Trade Center bombing resulted in very high stock prices; the disappearance of this apparent low-risk world produced low returns in its wake. A Closer Look at Bond Pricing and Returns So far, we’ve looked at credit and bond returns through a very wide historical lens. It’s now time to focus on the precise nature of bond and debt risk and its behavior through the ages. Let’s assume that you are a prosperous Venetian merchant, happily sipping bardolino in your palazzo, thinking about the value of the prestiti that your family has had registered at the loan office in the Piazza San Marco for the past few generations. From your own experience and that of your parents and grandparents, you know that the price of these annuities responds to two different factors. The first is that of absolute safety—whether or not the Republic itself will survive. When the barbarians are at the gates, interest rates rise and bond prices fall precipitously. When the danger passes, interest rates fall and bond prices rise. The risk, then, is the possibility that the bond issuer (in this case, the Republic itself) will not survive. In modern times, we worry more about simple bankruptcy than military catastrophe. But you notice something else: Even in the most tranquil times, when credit becomes easy and interest rates fall, prices rise. When credit becomes tight and interest rates rise, prices fall. This is, of course, as it should be—the iron rules of annuity pricing mandate that if interest rates double, their value will halve. You begin to get unnerved at the rises and falls in your family’s fortune with the credit market’s gyrations; you ask yourself if it is possible to reduce, or even eliminate, this risk. The answer, as we’ll shortly see, is a resounding “yes!” But before we proceed, let’s recap. The first risk—that of the Turks overrunning the Republic or your neighbor’s ship sinking—is called “credit risk.” In other words, the possibility of losing some, or all, of your principal because of the debtor’s failure. The second risk—that caused by the rise and fall of interest rates—is called “interest-rate risk.” For the modern investor, interest-rate risk is virtually synonymous with inflation risk. When you buy a 30-year Treasury bond, the biggest risk you are taking is that inflation will render your future interest and principal payment nearly worthless. The solution to interest-rate risk, then, is to lend short term. If your loan or bond is due in only one month, then you have virtually eliminated interest-rate/inflation risk, since in less than 30 days’ time, you’ll be able to reinvest your principal at the new, higher rate. Ever since the Babylonians began secondary trading of debt instruments, investors have sought safety from interest-rate risk in short-term loans/securities. Unfortunately, short-term loans have their own peculiar risks. We need to get one last bit of housekeeping out of the way. For the next few chapters, we shall call short-term obligations (generally less than one year) “bills,” and longer-term obligations “bonds.” Direct comparisons between bill and bond rates did not become possible until the Bank of England began operations in 1694 and immediately began to dominate the English credit markets. In 1749, the Chancellor of the Exchequer (the English equivalent of our Treasury Secretary), Henry Pelham, combined all of the government’s long-term obligations. These consolidated obligations later became known as the famous “consols.” They were annuities, just like the prestiti, never yielding up their principal. They still trade today, more than two-and-a-half centuries later. These consols, like the prestiti, provide historians with an unbroken record of bond pricing and rates through the centuries. Bills, on the other hand, were simply pieces of paper of a certain face value, purchased at a discount. For example, the Bank of England might offer a bill with a face value of ten pounds. It could be purchased at a discounted price of nine pounds and ten shillings (9 1/2 pounds) and redeemed one year later at the ten pound face value. This results in a 5.26% rate of interest (10/9.5 = 1.0526). The rates for bills (and bank deposits) and bonds (consols) in nineteenth century England are shown in Figure 1-4 . The modern investor would predict that the bills would carry a lower interest than the consols, since the bills were not exposed to interest-rate (i.e., inflation) risk. But for most of the century, short-term rates were actually higher than long-term rates. This occurred for two reasons. First, as we’ll discuss later, only in the twentieth century did sustained high inflation become a scourge; gold was money, so investors did not worry about a potential decline in its value. And second, wealthy Englishmen valued the consols’ steady income stream. The return on bills was quite variable, and a nobleman desiring a constant standard of living would find the uncertainty of the bill rate highly inconvenient. As you can see, the interest rate on short-term bills was much more uncertain than for consols. Thus, the investor in bills demanded a higher return for the more uncertain payout. Figure 1-4 also shows something far more important: the gradual decline in interest rates as England’s society stabilized and came to dominate the globe. In 1897 the consol yield hit a low of 2.21%, which has not been seen since. This identifies the high-water mark of the British Empire as well as any political or military event. Figure 1-4. English short- and long-term rates, 1800–1900. ( Source: Homer and Sylla, A History of Interest Rates .) The tradeoff between the variability of bill payouts and the interest-rate risk of consols reverses during the twentieth century. With the abandonment of the gold standard after World War I, and the consequent inflationary explosion, the modern investor now demands a higher return from long-term bonds and annuities than from bills. This is because bonds and annuities risk serious damage from depreciating money (inflation). Thus, in recent years, long-term rates are usually higher than short-term rates, since investors need to be compensated for bearing the risk of inflation-caused damage to long-term bonds. The history of English interest rates reinforces the notion that with high return comes risk. Anarchy and destruction lapped at Britain’s very shores between 1789 and 1814, leading investors to require higher and higher returns on their funds. What they received was a 5.5% perpetual rate (remember, no inflation) with the otherwise ultrasafe consols. On the other hand, the Englishman in the late Victorian era lived in, what seemed at the time, the height of stability and permanence. With such safety came low returns. History played a cruel trick on the English investor after 1900, with low stock and bond returns being the least of his troubles. The lesson here for the modern investor is obvious. Before the tragic events of September 11, 2001, many investors were encouraged by the apparent economic vigor and safety of the post-Cold War world. And, yet, both the logic of the markets and history show us that when the sun shines the brightest, investment returns are the lowest. This is as it should be: stability and prosperity imply high asset prices, which, because of the inverse relation between yields and prices, result in low future returns. Conversely, the highest returns are obtained by shouldering prudent risk when things look the bleakest, a theme we shall return to repeatedly. Bond Returns in the Twentieth Century The history of bonds in the twentieth century is unique—even the most comprehensive grasp of financial history would not have prepared the nineteenth century investor for the hurricane that buffeted the world’s fixed-income markets after 1900. In order to understand what happened, it’s necessary to briefly discuss the transition from the gold standard to the paper currency system that took place in the early 1900s. We’ve already touched on the abandonment of the gold standard after World War I. Before then, except for very brief periods, gold was money. In the U.S., there is still an abundant supply of quarter ($2.50), half ($5), full ($10), and double ($20) eagles sitting in the hands of collectors and dealers; they are still legal tender. Because of that abundance, most of these coins are not worth much more than their metallic value. However, they disappeared from circulation when their gold value exceeded their face value. For example, a quarter eagle, weighing about an eighth of an ounce, contains about $35 worth of gold at present prices; you’d be foolish to exchange it for goods worth its $2.50 face value. Over time, the value of gold relative to other goods and services remains roughly constant: an ounce of gold bought a respectable suit of men’s clothes in Dante’s time, and, until a just a few years ago, you could still buy a decent suit with that amount of gold. Because of the instabilities of international bullion flows resulting from postwar inflation, the gold-standard world, which had existed since the Lydian’s first coinage, disappeared forever in the two decades after World War I. Freed from the obligation of having to exchange paper money for the yellow metal, governments began to print bills, sometimes with abandon. Germany in the 1920s is a prime example. The result was the first great worldwide inflation, which accelerated in fits and starts throughout most of the century, finally climaxing around 1980, when the world’s central banks and treasuries increased interest rates and finally slowed down the presses. But the damage to investor confidence had already been done. Before the twentieth century, bond buyers had long been accustomed to dollars, pounds, and francs that did not depreciate in value over time. At the beginning of the twentieth century, investors still believed that a current dollar, pound, or franc would buy just as much in fifty years. In the decades following the conversion to paper currency, they slowly realized that their bonds, which promised only future paper currency, were worth less than they thought, producing the rise in interest rates seen in Figures 1-5 and 1-6 ; the result was devastating losses for bondholders. In short, bondholders in the twentieth century were blindsided by what financial economists call a “thousand year flood”: in this case, the disappearance of constant-value gold-backed money. Before the twentieth century, nations had temporarily gone off the hard-money standard, usually during wartime, but its permanent global abandonment was never contemplated until shortly before World War I. After World War I, the change was made permanent. The shift in the investment landscape was cataclysmic, and the resulting financial damage to bonds was of the sort previously seen only with revolution and military disaster. Even in the United States, which suffered no challenge to its government or territory in the 1900s, bond losses were severe. Figure 1-5. English consol/long bond rates, 1900–2000. ( Source: Homer and Sylla, Bank of England.) Figure 1-6. U.S. government bond rates, 1900–2000. ( Source: Homer and Sylla, U.S. Treasury.) Consider that in 1913, a U.S. stockholder or bondholder both received a 5% yield. The bondholder could reasonably expect that this 5% yield was a real one—that is, that its fixed value would not decrease over time. The stockholder, on the other hand, balanced the prospect of modest dividend growth versus the much higher risk of stocks. The abandonment of the gold standard turned all that upside down—suddenly, the future value of the bondholder’s income stream was radically devalued by higher inflation, whereas that of the stockholder was enhanced by the ability of corporations to increase their earnings and dividends with inflation. It took investors more than a generation to realize this. In the process, stock prices rose dramatically and bond prices fell. But do not lament today’s paper-based currency, because the gold-based economic system, which Keynes called a “barbarous relic,” was far worse. With hard currency, there is no control of the money supply—the government is committed to exchange bills for gold, or vice versa, at the will of its citizens. So it cannot expand the supply of paper money; otherwise it will risk depleting its gold supply at the hands of individuals who, detecting the increased numbers of dollar bills in circulation, appear at the Treasury’s window bearing dollars. And it cannot shrink the supply of money, lest individuals, detecting the decreased number of bills, appear at the Treasury’s windows bearing gold. The problem is that national economies are subject to boom-and-bust cycles. These can be mitigated by printing more money during the busts and by taking bills out of circulation during the booms. The advantages of being able to do this under a paper-based monetary system far outweigh the inflationary tendencies of a paper money system. Because of the abandonment of hard currency, the history of bonds in the twentieth century was not a happy one. Look again at Figure 1-5 , where I’ve plotted British government bonds interest rates since 1900. As you can see, this is close to a mirror image of Figure 1-4 , with increasing rates for most of the century. What you are looking at is a picture of the financial devastation of British bondholders. Between 1900 and 1974, the average consol yield rose from 2.54% to 14.95%, or a fall in price of 83%. But there was even worse news. Between those two dates, inflation had decreased the value of the pound by approximately 87%, so the real principal value of the consol had fallen 98% during the period, although that loss was partially mitigated by the dividends paid out. The twentieth century history of bonds in the U.S. was almost as unhappy. Figure 1-6 plots U.S. interest rates since 1900. Once again, inflation gutted returns of U.S. bonds. Even after accounting for dividends, the real return of long-term U.S. government bonds in the twentieth century was only 2% per year. Although it is difficult to predict the future, it is unlikely that we will soon see a repeat of the poor bond returns of the twentieth century. For starters, our survey of bond returns suggests that prior to the twentieth century, they were generous. Second, it is now possible to eliminate inflation risk with the purchase of inflation-adjusted bonds. The U.S. Treasury version, the 30-year “Treasury Inflation Protected Security,” or TIPS, currently yields 3.45%. So no matter how badly inflation rages, the interest payments of these bonds will be 3.45% of the face amount in real purchasing power, and the principal will also be repaid in inflation-adjusted dollars. (These are the equivalent of the gold-backed bonds of the last century.) Third, inflation is a painful, searing experience for the bondholder and is not soon forgotten. During the German hyperinflation of the 1920s, bonds lost 100% of their value within a few months. German investors said, “Never again,” and for the past 80 years, German central banks have carefully controlled inflation by reining in their money supply. American investors, too, were traumatized by the Great Inflation of 1965 to 1985 and began demanding an “inflation premium” when purchasing long-term bonds. For example, long-term corporate bonds currently yield more than 6%, nearly 4% above the inflation rate. Lastly, and I’ll admit this is a weak reed, it is possible that the world’s central banks have finally learned how to tame the inflationary beast. But the key point is this: bond returns in the twentieth century should not be used to predict future bond returns. The past few pages have hopefully more than adequately described bond risks. The monetary shocks of the twentieth century are among the most severe in recorded economic history, and it is more likely that inflation-adjusted bond returns going forward will be closer to the 3% to 4% rate of the previous centuries, than to the near-zero rate of the last ninety years. The Long-Term History of Stock Returns The history of stock returns is much more restricted. Although there has been active trading of stocks in England, France, and Holland for more than three hundred years, it is only in the past two centuries that we have information on long-term returns of stocks, beginning in the United States soon after its birth. And only in the past several decades does detailed information become available from around the globe. At this point, it’s important to clarify the difference between bonds and stocks. A bond is simply a loan. Most often, bonds have a sharply limited upside: the best that you can do is collect your interest payments and principal at maturity. A share of stock, on the other hand, represents a claim on all of the future earnings of the company. As such, its upside is potentially unlimited. It is, of course, quite possible to suffer a 100% loss with either. If a company goes bankrupt, both its stocks and bonds may be worth nothing, although bondholders have first claim on the assets of a bankrupt company. The major difference between stocks and bonds occurs during inflation. Because a bond’s payments are fixed, its value suffers during inflationary periods; it may become worthless if inflation is severe enough. Stocks are also damaged by inflation, but since a company can raise the price of the goods and services it produces, its earnings, and, thus, its value, should rise along with inflation. This is not to say that stocks are always superior to bonds. Although stocks often have higher returns because of their unlimited upside potential and inflation protection, there are times when bonds shine. Stocks, Bonds, and Bills in the Twentieth Century Figure 1-7 summarizes the returns of U.S. stocks, long-term Treasury bonds, and Treasury bills since 1900. Its message should not surprise you by this point—stocks have the highest returns (9.89% annualized), followed by bonds (4.85% annualized), with “safe” bills (3.86% annualized), bringing up the rear. All of these returns are “nominal,” that is, they do not take inflation into account, which, during the period, averaged 3.6%. So the “real,” or inflation-adjusted, returns were about 6% for stocks, 1% for bonds, and zero for bills. Figure 1-7. Value of $1.00 invested in stocks, bonds, and bills, 1901–2000. ( Source: Jeremy Siegel.) Note that the representation of wealth on the vertical scale of the graph is “arithmetic”—that is, its scale is even, with each tick mark representing the same amount of money (in this case, $1,000). This graph really doesn’t convey a lot of useful information about stock returns in the first half of the century, and very little about bond or bill returns at all. To get around this problem, finance professionals use a slightly different kind of plot to follow wealth creation over very long periods—the so-called “semilog” display shown in Figure 1-8 . This means that the wealth displayed on the vertical axis is represented “logarithmically,” that is, each tick represents a tenfold increase in value—from $1 to $10 to $100 to $1,000. This kind of plot is one of the most familiar teaching tools in personal finance, used by brokers and investment advisors across the nation to demonstrate the benefits of stocks to small investors. But, as we have already seen with Figure 1-1 , which is also a semilog plot, this graph can be highly deceptive, as it tends to underplay risk. Figure 1-8. Value of $1.00 invested in stocks, bonds, and bills, 1901–2000 (semilogarithmic scale). ( Source: Jeremy Siegel.) Risk—The Second Dimension The study of investment returns is only half of the story. Distilled to its essence, investing is about earning a return in exchange for shouldering risk. Return is by far the easiest half, because it is simple to define and calculate, either as “total returns”—the end values in Figures 1-7 and 1-8 , or as “annualized returns”—the hypothetical gain you’d have to earn each year to reach that value. Risk is a much harder thing to define and measure. It comes in two flavors: short-term and long-term. Short-term risk is somewhat easier to deal with. Let’s start with the annual returns of bills, bonds, and stocks, which I’ve plotted in Figures 1-9 through 1-11 . Notice that the bills are “perfectly safe,” with nary a losing year. Bonds, on the other hand, do occasionally lose money—as much as 13% in 1999, according to the long-bond data from Professor Jeremy Siegel. And finally, stocks lose money in one of every three years. Sometimes, they lose a lot. Figure 1-9. U.S. Treasury bill returns, 1901–2000. ( Source: Jeremy Siegel.) Figure 1-10. U.S. Treasury bond returns, 1901–2000. ( Source: Jeremy Siegel.) Figure 1-11. U.S. stock returns, 1901–2000. ( Source: Jeremy Siegel.) In fact, stocks can behave badly for years at a time. For example, from 1973 to 1974, stocks lost about 40% of their value, while inflation reduced the value of a dollar by nearly 20%, for an after-inflation cumulative loss of about one-half. And from the market peak in September 1929 to the bottom in July 1932, the market lost an astonishing 83% of its value. The loss was mitigated, however, by the approximate 20% fall in consumer prices that occurred during the period. The market recovered strongly after 1932, but in 1937, another drop of about 50% occurred. 1 Figure 1-12. U.S. annual stock returns, 1790–2000. Actual ( bars ) versus predicted random distribution ( curve , see footnote). Figure 1-11 is interesting for another reason. Many investors cling to the belief that by following the right indicator or listening to the right guru, they can reduce risk by avoiding bear markets. Do you see any particular pattern to the annual returns? If you do, then you’re also likely quite adept at seeing the George Washington Bridge or the face of Bruce Willis in the clouds scudding overhead. The pattern of annual stock returns is almost totally random and unpredictable. The return in the last year, or the past five years, gives you no hint of next year’s return—it is a “random walk.” As we’ll see later, no one—not the pundits from the big brokerage firms, not the newsletter writers, not the mutual fund managers, and certainly not your broker—can predict where the market will go tomorrow or next year. So the twentieth century has seen three severe drops in stock prices, one of them catastrophic. The message to the average investor is brutally clear: expect at least one, and perhaps two, very severe bear markets during your investing career. Long-term risk—the probability of running out of money over the decades—is an entirely different matter. Strangely, human beings are not as emotionally disturbed by long-term risk as they are by short-term risk. Clearly, long-term returns are much more important than the magnitude of short-term reversals. Paradoxically, in the long run, bonds are at least as risky as stocks. This is because stock returns are “mean reverting.” That is, a series of bad years is likely to be followed by a series of good ones, repairing some of the damage. Unfortunately, this is a two-edged sword, as a series of very good years is likely to be followed by bad ones, as investors have learned, to their chagrin, in the past few years. In Figure 1-13 , I’ve plotted the annualized 30-year real (inflation-adjusted) returns of stocks. Note how placid this graph looks, with no periods of real or nominal losses. This sort of plot is often used to demonstrate that stocks become “less risky” over time. But as we’ve already seen, it’s easy to make graphs lie. Notice that the difference between the lowest and highest return is about 5%. Compound a 5% return difference over 30 years and you wind up with a more than fourfold difference in value. End-period wealth—the total amount of capital you have after 30 years—is a much better gauge of long-term risk than are annualized returns. Figure 1-13. Thirty-year annualized real U.S. stock returns, 1901–2000. ( Source: Jeremy Siegel.) Figure 1-14. Thirty-year real end wealth of $1.00 invested in U.S. stock, 1901–2000. ( Source: Jeremy Siegel.) In Figure 1-14 , I’ve plotted the real (inflation-adjusted) end wealth for $1.00 invested in each of the 30-year periods in this century. Note the enormous range of values. If these amounts represent your retirement nest egg, it can be easily seen that the gap between the best and worst 30-year periods represents the difference between a comfortable old age and the trailer park. Retirement planning is an enormously complicated topic, which we’ll explore in Chapter 12 in some detail. Obviously, your personal circumstances are critically important, but one thing is clear: an examination of historical stock returns shows that the market can perform miserably for periods as long as 15 to 20 years. For example, during the 17 years from 1966 to 1982, stock returns just barely kept up with inflation, with the brutal 1973–1974 bear market occurring in the middle of the period. Had you begun your retirement in 1966, the combination of poor inflation-adjusted returns and mandatory withdrawals would likely have devastated your assets—there would have been little or no savings left to enjoy the high returns that followed. Bonds are even worse, since their returns do not mean revert—a series of bad years is likely to be followed by even more bad ones, as happened during the 1970s. This is the point made by Jeremy Siegel in his superb treatise, Stocks For The Long Run . Professor Siegel pointed out that stocks outperformed bonds in only 61% of the years after 1802, but that they bested bonds in 80% of ten-year periods and in 99% of 30-year periods. Looked at from another perspective, in the 30 years from 1952 to 1981, stocks returned 9.9% and bonds returned only 2.3%, while inflation annualized out at 4.3%. Thus, during this period, the bond investor lost 2% of real value on an annualized basis, while the stock investor made a 5.6% real annualized return. The last fifteen years of that period were years of high inflation, so this is just another way of saying that stocks withstand inflation better than bonds. Short-term risk, occurring over periods of less than several years, is what we feel in our gut as we follow the market from day to day and month to month. It is what gives investors sleepless nights. More importantly, it is what causes investors to bail out of stocks after a bad run, usually at the bottom. And yet, in the long-term, it is of trivial importance. After all, if you can obtain high long-term returns, what does it matter if you have lost and regained 50% or 80% of your principal along the way? This, of course, is easier said than done. Even the most disciplined investors exited the markets in the 1930s, never to return. Obsession with the short term is ingrained in human nature; the impulse is impossible to ignore. Your short-term investing emotions must be recognized and dealt with on their own terms. It is an easy thing to look at the above data and convince yourself that you will be able to stay the course through the tough times. But actually doing it is an entirely different affair. Examining historical returns and imagining losing 50% or 80% of your capital is like practicing an airplane crash in a simulator. Trust me, there is a big difference between how you’ll behave in the simulator and how you’ll perform during the real thing. During bull markets, everyone believes that he is committed to stocks for the long term. Unfortunately, history also tells us that during bear markets, you can hardly give stocks away. Most investors are simply not capable of withstanding the vicissitudes of an all-stock investment strategy. The data for the U.S. markets displayed in Figures 1-9 to 1-14 are summarized in Table 1-1 . It’s pretty clear that there’s a relationship between return and risk—you enjoy high returns only by taking substantial risk. If you want to earn high returns, be prepared to suffer grievous losses from time to time. And if you want perfect safety, resign yourself to low returns. In fact, the best way to spot investment fraud is the promise of safety and very high returns. If someone offers you this, turn 180 degrees and do not walk—run. This is such an important point that I’m going to repeat it: Table 1-1. Historical Returns and Risks of U.S. Stocks and Bonds in the Twentieth Century High investment returns cannot be earned without taking substantial risk. Safe investments produce low returns . We’ll go into the relationship between risk and return in much more detail later, but it’s worth mentioning one common example here. Almost every one of you owns a money market account from one of the large mutual fund companies. The reason you do is that money-fund yields are higher than you get from a bank passbook or checking account. This is because your money market account carries with it a slight amount of risk. Your money market owns “commercial paper” issued by large corporations, which is not insured and can default, whereas your bank accounts are federally insured. So you are being rewarded for taking this risk with extra return. It’s also true that the mutual fund industry does its best to soft pedal this inconvenient fact. No major fund company’s money market fund has ever “broken the buck,” even though commercial paper does occasionally default. In 1990, paper issued by Mortgage and Realty Trust, held by many large money market accounts, fell into default. Passing these losses onto the shareholders would have resulted in a devastating loss of confidence, and without exception, the fund companies reimbursed their money market funds. One company alone—T. Rowe Price—spent about $40 million repairing the damage. But there is no guarantee that they will always be able to do this. In addition, banks’ yields are hobbled by the necessity of holding reserves—funds that cannot be loaned out. Stock Returns Outside the U.S. The investment stories and data presented in this chapter vividly illustrate the interplay between investment and societal risk factors and return. High-risk societies—or crisis periods in stable societies—result in high investment returns, if those societies survive . As we saw with Venetian prestiti, the highest returns of all were made during the transition from a high-risk to a low-risk environment. And, as we’ve already alluded to, the high returns of U.S. stocks were at least partly the result of the same phenomenon, drawn out over two centuries. In fact, the U.S. stock returns of the past 200 years represent a best-case scenario. To get a more realistic view of stock returns, it’s important to examine stock returns from as many nations, and over as long a period, as possible. Professors Philippe Jorion and William Goetzmann examined stock returns around the world in the twentieth century, and the picture they draw is not nearly as pretty as the American story. With their kind permission, I’ve reproduced their summary findings, shown in Figure 1-15 . This graph is a bit confusing, but it’s worth the effort to understand it. The horizontal (bottom) axis plots the number of years each market has been in existence. Almost all of the nations on the right half of the graph—the ones with the longest market histories—are developed Western nations. Because stock markets accompany development, it is no surprise that some of the most developed countries were the first to create them. Most of these nations—especially the U.S., Canada, Sweden, Switzerland, Norway, Chile, Denmark, and Britain—have had high stock returns. (The returns shown on the vertical axis are a bit misleading to the non-academic reader, as they subtract out the return due to inflation, and further do not include dividends.) Figure 1-15. Real equity returns versus market age. ( Source: Jorion and Goetzmann, Journal of Finance , 1999.) Now look on the left-hand portion of the graph. These are the markets with the shortest histories and are exclusively what we would today call “emerging markets.” Although there is a fair amount of scatter, note how, in general, the countries clustering on the left half of the graph have lower returns than the “developed” nations on the right half of the graph. Some consider Figure 1-15 to be an argument against investing in emerging markets. It is no such thing . Remember that a century ago, the U.S. was an emerging market, and that two centuries ago, England, France, and Holland were also. Rather, it is a demonstration that the markets with the best returns survive, and that those with the worst returns do not—survivorship bias, yet again. The moral here is that because the most successful societies have the highest past stock returns, they become the biggest stock markets and are considered the most “typical.” Looking at the winners, we tend to get a distorted view of stock returns. It helps to recall that, three centuries ago, France had the world’s largest economy and just a century-and-a-half ago, that distinction belonged to England. Yet even the detailed work cited above provides a skewed version of national security returns. You’ll note that many of the names at the top of the graph are of English-speaking nations that were largely spared the destruction of the two world wars. As grievously as Britain and its Commonwealth suffered in these conflicts, they did not suffer the near total destruction of their industrial apparatus, as did Germany, the rest of continental Europe, Russia, Japan, and China. Limiting our analysis to the period following the initial phase of postwar reconstruction may provide a much less biased estimate of non-U.S. investment returns. The Morgan Stanley Capital International Europe, Australasia, and Far East (EAFE) Index is a highly accurate measure of equity returns in the developed world outside the U.S. In Figure 1-16 , I’ve plotted the value of a dollar invested in the S&P 500 Index and the EAFE since its inception in 1969. The returns were virtually the same: 11.89% for the EAFE versus 12.17% for the S&P 500, with end-wealths of $36.44 and $39.43, respectively. In a world in which billions of dollars of capital can be instantaneously moved around the globe with a keystroke, this is as it should be. There is no reason why an investor from one nation should accept, as a matter of course, poor returns in his own country if he can just as easily invest abroad. If investors think that returns will be higher in Australia than in Belgium, then capital will flow from Belgium to Australia. This will depress prices in Belgium, which, in turn, will increase future returns. The opposite will occur in Australia. Prices will adjust to the point where the expected returns, adjusted for risk, in both nations will be the same. Assuming that the risks are the same, there is no reason that the future return in any one nation should be higher than another. And, to the extent that one nation is perceived to be riskier than another, the nation with the highest perceived risk should have the highest future return, in order to compensate for the extra risk. Figure 1-16. U.S. versus foreign equity, 1969 to 2000. ( Source: Principia Pro Plus Morningstar, Inc.) Since World War II, real long-term stock returns in the U.S. have been about 8% (after dividends and inflation are taken into account), dwarfing bond performance. But world financial history cautions us not to expect the generous rewards of U.S. stocks in the future. In fact, historical returns are of only limited use in predicting future returns. The real value of the historical record is as a gauge of risk, not return. Size Matters As we move forward through the twentieth century, detail about stock returns comes into increasingly sharp focus. In recent decades, financial economists have begun to study how company characteristics affect stock return. The first company characteristic to be studied was size. The “size” of a company can be measured in many ways—the number of its employees, or the amount of sales, profits, or physical assets it owns. But the most easily measured and most important number to investors is its “market capitalization” (usually shortened to “market cap”), which is the total market value of its outstanding stock. This is an important number for many reasons, not the least of which is that most market indexes are market cap weighted, meaning that the representation of each stock in the index is proportional to its market cap. For example, as of this writing, the biggest company in the S&P 500 is General Electric, with a market cap of $460 billion. The smallest is American Greetings, with a market cap of $700 million. Thus, the S&P contains 600 times as much GE as it does American Greetings ($460 billion/$700 million = 600). Is there a difference between the returns of small and large companies? Yes. It appears that small stocks have had higher returns than large ones. In Figure 1-17 , I’ve plotted the returns of the stocks of the largest and smallest companies in the U.S. market from July 1926 to June 2000. This data was kindly supplied by Professor Kenneth French of MIT. He divided the markets into three groups—small, medium, and large. (I’ve omitted the medium-sized, however.) A summary of the data appears below: Figure 1-17. Small stocks versus large stocks, 1926–2000. ( Source: Kenneth French.) Small versus Large Stocks, July 1926–June 2000 Note how small stocks have had higher returns than larger stocks, but that they also have higher risks. In both the Great Depression and the 1970s bear market, small-stocks sustained higher losses than large stocks. In addition, the small stock advantage is extremely tenuous—it’s less than a percent-and-a-half per year, and there have been periods of more than 30 years when large stocks have bested small stocks. For these reasons, the small-stock advantage is controversial. But over long time periods, it is present in most foreign countries. For example, during the past 46 years, British small stocks have outperformed large stocks by 2.66% per year. During the past 31 years, the small-stock advantage in Japan has been 1.78%. Abroad, as in the U.S. small stocks were riskier. Once again, the relationship between risk and return holds up. Yes, you can have higher returns, but only by bearing more risk. Company Quality and Stock Return Finally, there is the issue of corporate quality. Simply put, there are “good” companies, and there are “bad” companies. And it’s critical that you grasp how the market treats them and how that, in turn, affects the risk and return of your portfolio. First, I’d like to introduce a bit of investment nomenclature. In common parlance, the shares of good companies are called “growth stocks,” and those of bad companies are called “value stocks.” Let’s consider for a moment, Wal-Mart and Kmart. The former is financially healthy and universally admired, with legendary management, a steadily growing stream of earnings, and a huge pile of cash on hand for emergencies. The latter is a sick puppy, having recently declared bankruptcy due to marginal financial resources and a history of poor management. Even in the best of years, it had very irregular earnings. Wal-Mart is manifestly a good/growth company. Kmart is a bad/value company; without making too fine a point, it is, in fact, a real dog. More importantly, Wal-Mart, aside from being the better company, is also the safer company. Because of its steadily growing earnings and assets, even the hardest of economic times would not put it out of business. On the other hand, Kmart’s finances are marginal even in the best of times, and the recent recessionary economy very well could put it on the wrong side of the daisies with breathtaking speed. Now we arrive at one of the most counterintuitive points in all of finance. It is so counterintuitive, in fact, that even professional investors have trouble understanding it. To wit: Since Kmart is a much riskier company than Wal-Mart, investors expect a higher return from Kmart than they do from Wal-Mart . Think about it. If Kmart had the same expected return as Wal-Mart, no one would buy it! So its price must fall to the point where its expected return exceeds Wal-Mart’s by a wide enough margin so that investors finally are induced to buy its shares. The key word here is expected , as opposed to guaranteed . Kmart has a higher expected return than Wal-Mart, but this is because there is great risk that this may not happen. Kmart’s recent Chapter 11 filing has in fact turned it into a kind of lottery ticket. There may only be a small chance that it will survive, but if it does, its price will skyrocket. Let’s assume that Kmart’s chances of survival are 25%, and that if it does make it, its price will increase by a factor of eight. Thus, its “expected value” is 0.25 × 8, or twice its present value. The risk of owning stock in a single shaky company is very high. But in a portfolio of many such losers, a few might reasonably be expected to pull through, providing the investor with a reasonable return. Thus, the logic of the market suggests that: Good companies are generally bad stocks, and bad companies are generally good stocks . Is this actually true? Resoundingly, yes. There have been a large number of studies of the growth-versus-value question in many nations over long periods of time. They all show the same thing: unglamorous, unsafe value stocks with poor earnings have higher returns than glamorous growth stocks with good earnings. Probably the most exhaustive work in this area has been done by Eugene Fama at the University of Chicago and Kenneth French at MIT, in which they examined the behavior of growth and value stocks. They looked at value versus growth for both small and large companies and found that value stocks clearly had higher returns than growth stocks. Figure 1-18 and the data below summarize their work: Fama and French’s work on the value effect has had a profound influence on the investment community. Like all ground-breaking work, it prompted a great deal of criticism. The most consistent point of contention was that the results of their original study, which covered the period from 1963 to 1990, was a peculiarity of the U.S. market for those years and not a more general phenomenon. Their response to such criticism became their trademark. Rather than engage in lengthy debates on the topic, they extended their study period back to 1926, producing the data you see above. Next, they looked abroad. In Table 1-2 , I’ve summarized their international data, which cover the years from 1975 to 1996. Note that in all but one of the countries, value stocks did, in fact, have higher returns than growth stocks, by an average of more than 5% per year. The same was also true for the emerging-market countries studied, although the data is a bit less clear because of the shorter time period studied (1987–1995): in 12 of the 16 nations, value stocks had higher returns than growth stocks, by an average margin of 10% per year. Figure 1-18. Value versus growth, 1926–2000. ( Source: Kenneth French.) Table 1-2. Value versus Growth Abroad, 1975–96 Campbell Harvey of Duke University has recently extended this work to the level of entire nations. Just as there are good and bad companies, so are there good and bad nations. And, as you’d expect, returns are higher in the bad nations—the ones with the shakiest financial systems—because there the risk is highest. By this point, I hope you’re moving your lips to this familiar mantra: because risk is high, prices are low. And because prices are low, future returns are high. So the shares of poorly run, unglamorous companies must, and do, have higher returns than those of the most glamorous, best-run companies. Part of this has to do with the risks associated with owning them. But there are also compelling behavioral reasons why value stocks have higher returns, which we’ll cover in more detail in later chapters; investors simply cannot bring themselves to buy the shares of “bad” companies. Human beings are profoundly social creatures. Just as people want to own the most popular fashions, so too do they want to own the latest stocks. Owning a portfolio of value stocks is the equivalent of wearing a Nehru jacket over a pair of bell-bottom trousers. The data on the performance of value and growth stocks run counter to the way most people invest. The average investor equates great companies, producing great products, with great stocks. And there is no doubt that some great companies, like Wal-Mart, Microsoft, and GE, produce high returns for long periods of time. But these are the winning lottery tickets in the growth stock sweepstakes. For every growth stock with high returns, there are a dozen that, within a very brief time, disappointed the market with lower-than-expected earnings growth and were consequently taken out and shot. Summing Up: The Historical Record on Risk/Return I’ve previously summarized the returns and risks of the major U.S. stock and bond classes over the twentieth century in Table 1-1 . In Figure 1-19 , I’ve plotted these data. Figure 1-19 shows a clear-cut relationship between risk and return. Some may object to the magnitude of the risks I’ve shown for stocks. But as the recent performance in emerging markets and tech investing show, losses in excess of 50% are not unheard of. If you are not prepared to accept risk in pursuit of high returns, you are doomed to fail. Figure 1-19. Risk and return summary. ( Source: Kenneth French and Jeremy Siegel.) CHAPTER 1 SUMMARY 1. The history of the stock and bond markets shows that risk and reward are inextricably intertwined. Do not expect high returns without high risk. Do not expect safety without correspondingly low returns. Further, when the political and economic outlook is the brightest, returns are the lowest. And it is when things look the darkest that returns are the highest. 2. The longer a risky asset is held, the less the chance of a loss. 3. Be especially wary of data demonstrating the superior long-term performance of U.S. stocks. For most of its history, the U.S. was a very risky place to invest, and its high investment returns reflect that. Now that the U.S. seems to be more of a “sure thing,” prices have risen, and future investment returns will necessarily be lower.",
        "char_count": 68710
      },
      {
        "heading": "Chapter 7",
        "text": "The New World Order, circa 1913 The tragic events in New York, Washington, DC, and Pennsylvania in the fall of 2001 served to underscore the relationship between return and risk. Prior to the bombings, most investors felt that the world had become progressively less risky. This resulted in a dramatic rise in stock prices. When this illusion was shattered, prices reacted equally dramatically. This is not a new story. There is no better illustration of the dangers of living and investing in an apparently stable and prosperous era than this passage from Keynes’s The Economic Consequences of the Peace , which chronicles life in Europe just before the lights went out for almost two generations: The inhabitant of London could order by telephone, sipping his morning tea in bed, the various products of the whole earth, in such quantity as he might see fit, and reasonably expect their early delivery upon his doorstep; he could at the same moment and by the same means adventure his wealth in the natural resources and new enterprises of any quarter of the world, and share, without exertion or even trouble, in their prospective fruits and advantages; or he could decide, to couple the security of his fortunes with the good faith of the townspeople of any substantial municipality in any continent that fancy or information might recommend. He could secure forthwith, if he wished it, cheap and comfortable means of transit to any country or climate without passport or other formality, could dispatch his servant to the neighboring office of a bank for such supply of the precious metals as might seem convenient, and could then proceed abroad to foreign quarters, without knowledge of their religion, language, or customs, bearing coined wealth upon his person, and would consider himself greatly aggrieved and much surprised at the least interference. But, most important of all, he regarded this state of affairs as normal, certain, and permanent, except in the direction of further improvement, and any deviation from it as aberrant, scandalous, and avoidable. The projects and politics of militarism and imperialism, of racial and cultural rivalries, of monopolies, restrictions, and exclusion, which were to play the serpent to this paradise, were little more than the amusements of his daily newspaper, and appeared to exercise almost no influence at all on the ordinary course of social and economic life, the internationalization of which was nearly complete in practice.",
        "char_count": 2487
      },
      {
        "heading": "Chapter 8",
        "text": "2 Measuring the Beast Capital value is income capitalized, and nothing else . Irving Fisher In the history of modern investing, one economist towers above all others in influence on the way we examine stocks and bonds. His name was Irving Fisher: distinguished professor of economics at Yale, advisor to presidents, famous popular financial commentator, and, most importantly, author of the seminal treatise on investment value, The Theory of Interest . And it was Fisher, who, a century ago, first attempted to scientifically answer the question, “What is a thing worth?” His career was dazzling, and his precepts are still widely studied today, more than seven decades after the book was written. Fisher’s story is a caution to all great men, because, in spite of his long list of staggering accomplishments, he will be forever remembered for one notorious gaffe. Just before the October 1929 stock market crash, he declared, “Stock prices have reached what looks like a permanently high plateau.” Weeks before the start of a bear market that would eventually result in a near 90% decline, the world’s most famous economist declared that stocks were a safe investment. The historical returns we studied in the last chapter are invaluable, but these data can, at times, be misleading. The prudent investor requires a more accurate estimate of future returns for stocks and bonds than simply looking at the past. In this chapter, we’re going to explore Fisher’s great gift to finance—the so-called “discounted dividend model” (referred to from now on as the DDM), which allows the investor to easily estimate the expected returns of stocks and bonds with far more accuracy than the study of historical returns. 1 Bluntly stated, an understanding of the DDM is what separates the amateur investor from the professional; most often, small investors haven’t the foggiest notion of how to estimate a reasonable share price for the companies they are buying. You may find this chapter the most difficult in the book; the concepts we will explore are not intuitively obvious, and, in a few spots, you will have to put the book down and think. But if you can understand the chapter’s central point—that the value of a stock or a bond is simply the present value of its future income stream—then you will have a better grasp of the investment process than most professionals. As we’ve seen, the British enjoy a nearly millennial head start on us in the capital markets. This has allowed them to embed some bits of financial wisdom into their culture that we have yet to absorb. Ask an Englishman how wealthy someone is, and you’re likely to hear a response like, “He’s worth 20,000 per year.” This sort of answer usually confuses us less sophisticated Yanks, but it’s an estimable response, because it says something profound about wealth: it does not consist of inert assets but, instead, a stream of income . In other words, if you own an orchard, its value is defined not by its trees and land but, rather, by the income it produces. The worth of an apartment house is not what it will fetch in the market, but the value of its future cash flow. What about your own house? Its value is the shelter and pleasure it provides you over the years. The DDM, by the way, is the ultimate answer to the age-old question of how to separate speculation from investment . The acquisition of a rare coin or fine painting for purely financial purposes is clearly a speculation: these assets produce no income, and your return is dependent on someone else paying yet a higher price for them later. (This is known as the “greater fool” theory of investing. When you purchase a rapidly appreciating asset with little intrinsic value, you are dependent on someone more foolish than you to take it off your hands at a higher price.) There is nothing wrong with purchasing any of these things for the future pleasure they may provide, of course, but this is not the same thing as a financial investment. Only an income-producing possession, such as a stock, bond, or working piece of real estate is a true investment. The skeptic will point out that many stocks do not have current earnings or produce dividends. True enough, but any stock price above zero reflects the fact that at least some investors consider it possible that the stock will regain its earnings and produce dividends in the future, even if only from the sale of its assets. And, as Ben Graham pointed out decades ago, a stock purchased with the hope that its price will soon rise independent of its dividend-producing ability is also a speculation, not an investment. And lest I unnecessarily offend art lovers, it should be pointed out that even an old master, bought from the artist for $100 and sold 350 years later for $10,000,000, has returned only 3.34% per year. Ideally, a fine painting, like a house, is neither a speculation nor an investment; it is a purchase . Its value consists solely of the pleasure and utility it provides now and in the future. The dividend the painting provides is of the non-financial variety. How, then, do we define a stock’s stream of income? Next, how do we determine its actual worth? This is a tricky problem, which we’ll tackle in steps. In the next several pages, we’ll uncover how the stock market is properly valued and how future stock market returns are estimated. These pages may prove difficult. I recommend that you slow your reading down a bit at this juncture, making sure you have carefully read each sentence before proceeding to the next . One of Fisher’s favorite investment paradigms was a gold or lead mine that began with a maximum yield in year one, then dwindled to nothing in 10 years: Now that we’ve defined the income stream in the above table, how do we value it? At first glance, it appears that the mine’s worth is simply the sum of the income for all ten years—in this case, $11,000. But there’s a hitch. Human beings prefer present consumption to future consumption. That is, a dollar of income next year is worth less to us than a dollar today , and a dollar in thirty years, a great deal less than a dollar today. Thus, the value of future income must be reduced to reflect its true present value. The amount of this reduction must take into account four things: • The number of years you have to wait: The further in the future you receive income, the less it is worth to you now. • The rate of inflation: The higher the rate of inflation, the less value in terms of real spending power you can expect to receive in the future. • The “impatience” of society for future consumption: The more society prefers present to future consumption, the higher are interest rates, and the less future income is worth today. (The second and third factors can be combined into the “real rate of interest.”) • Risk itself: The greater the risk that you might not receive the income at all, the less its present value. The simplest way to look at the problem is to imagine waiting in line to board a plane for a week in Paris. You’ve been working hard at your job in downtown Cleveland, and you can almost smell the crêpes on Rue Saint Germain. But wait! Just as you get to the head of the line, the ticket agent swipes your boarding pass and says, “Sorry sir, but Hillary Clinton has just arrived, and she needs your seat.” (You’re flying first class, of course.) “It’s the last one, and the Secret Service agent demands I give it to her. Don’t worry though, because I can offer you another trip in ten years.” What a raw deal! A week in Paris in ten years is not worth nearly as much to you as a trip right now. You balk. Finally, “I’m sorry, but you’ll have to make it five weeks in Paris a decade from now to make it worth my while.” With a sigh of defeat, the agent accepts. What you have just done is what financial economists call “discounting to the present.” That is, you have decided that a week in Paris in ten years is worth a good deal less to you than a week there right now; you have lowered the value of the future weeks in Paris to account for the fact that you will not be enjoying them for another decade. To wit, you have decided that five weeks in ten years is worth as much as just one week today. In the process of doing so, you have determined that your week-in-Paris discount interest rate is 17.5% per year; 17.5% is the rate at which one week grows to five weeks over ten years. Here is where things start to get a bit sticky, because the discount rate (referred to from now on as the DR) and the present value are inversely related: the higher the DR, the lower the present value. This is the same as with consols and prestiti, whose values are inversely related to interest rates. For example, if you decide that a week in Paris now is worth ten weeks a decade from now, that implies a much higher DR of 25.9%. This is the same as saying that the present value of a week in Paris in a decade has cheapened. Again, an increase in the DR means that the present value of a future item has decreased; if the value of one week in Paris now has increased from five to ten weeks in Paris in the future, then the value of those future weeks has just fallen. Fisher’s genius was in describing the factors that affect the DR, or simply, the “interest rate,” as he called it. For example, a starving man would be willing to pay much less for a delayed meal than a well-fed person. In other words, a hungry person’s DR for food is very high since he has a more immediate need for it than someone who is well nourished. Fisher, in fact, uses the words “impatience” and “interest rate” interchangeably; the wastrel has a higher interest rate (DR) than the tightwad. Another of Fisher’s observations was that societies characterized by highly durable goods have lower interest rates than those that are not. Where the houses are made of bricks and stone, interest rates are low. Where the houses are made of mud and straw, rates are high. Fisher found that, by far, the single most important factor affecting the DR is risk . The one week/five week Paris trip relationship discussed above assumed that the airline and travel agent were well-established and likely to still be in business in ten years when you return for your vacation. But what if you weren’t so sure that they would be there for you in a decade? You would, of course, demand a longer vacation in 10 years—say 10 weeks, instead of five. In which case, you’ve arrived at the 25.9% DR we mentioned previously. In other words, the riskier the payoff, the higher the return you would demand. Let’s now return to our mine. We have to decide on a discount factor to apply in each successive year to its income. But before I tell you just how to estimate the DR, let’s see what a given DR means. Say that we decide on an 8% DR. The table below is the same one we saw a few pages ago, but now we’ve added two more columns. The column labeled “Discount Factor” is the amount we must reduce the dividend by in a given future year to compute its value in the present day; the first year’s income must be divided by 1.08, the second year’s by 1.08 × 1.08, and so on. The last column, labeled “Discounted Income,” is the resultant present value: For example, look at year 8. In this year, the mine earns $600 but, just like your delayed trip to Paris, this future payment of $600 is not worth $600 to you right now. To obtain the current value of this future $600, you must divide it by 1.8509 (1.08 multiplied by itself seven times), to yield a value of $324. This is the present value of $600 for which we must wait eight years at an 8% DR. The total present value of the mine—in effect, its “true value”—is the sum of all of the future dividends, discounted to the present . This is the sum at the bottom of the table: $8,225. The next step is to apply this method to stocks. The primary job of the security analyst is to predict the dividend flow of a company so that it may be discounted to obtain the “fair value” of its stock. If the market price is below the calculated fair value, it is bought. If the market price is above the calculated fair value, it is sold. This is no easy task. (In fact, as we’ll find out in Chapter 4 , it is an impossible task.) Not infrequently, promising companies with large expected future dividend streams stumble and fall; nearly as often, companies given up for dead recover and provide shareholders with prodigious amounts of future income. On the other hand, when you examine an entire market, consisting of hundreds or thousands of companies, these unexpected events average out. For this reason, the income stream of the market as a whole is a much more reliable calculation. But at first, even this seems a hopeless task. Because the stock market is expected to produce dividends forever, you have to predict the future income stream for an infinite number of future years, discount the dividends for each year to the present, then add them all up. But with a few mathematical tricks, this nut is easily cracked. A Stream of Future Dividends, Forever and Ever, Amen To paraphrase the famous Chinese proverb, even a journey of a thousand miles must begin with a single step. Here’s our first one. At the end of 2001, the Dow Jones Industrial Average was selling at around 9,000 and yielded 1.55% of that, or about $140 per year in dividends. Further, over the long haul, the Dow’s dividends grow at about 5% per year. So in 2002, there should be about $147 of dividends; in 2031, $605. Now take a look at Table 2-1 . In the second column, under “Nominal Dividends” (“ nominal ” refers to the actual dollar amount, not adjusted for inflation), I’ve tabulated the actual dividend for each future year; I’ve also plotted this rise in dividends in Figure 2-1 . We’ve just taken the first step in valuing the market: we’ve defined its future stream of dividends. Next, we must discount the actual dividend in each future year to the present. To do this, we divide the dividend in each future year by the appropriate discount factor, similar to our calculation for the mine. How do we decide on a DR for the entire stock market? Similar to our hypothetically discounted future meal, the DR of the Dow is simply the rate of return we expect from it, taking its risk into consideration . Table 2-1. Dow Jones Industrial Average Projected and Discounted Dividends Figure 2-1. Dow dividend value. Let’s say that we expect an 8% return from stocks. So just like our mine, the market’s DR, by definition, is thus 8%. As we’ve already determined, the Dow’s dividend 30 years from now should be about $605. Similar to our mine, to get the present value of those dividends we have to divide that amount by 1.08 for each year in the future. To obtain the present value of the Dow dividend 30 years from now, in 2031, you have to divide $605 by 10.06 (1.083 30 , that is, 1.08 multiplied by itself 29 times). Dividing the $605 dividend in 2031 by 10.06 yields a present value of $60. If we perceive that economic, political, or market risk has increased, we may decide that the DR should be higher; if we are really frightened about the state of the economy, the nation, or the world, we will decide that 15% is appropriate. In that case, the present value of the year 2031’s $605 dividend is reduced even further, to just $9. Take another look at Table 2-1 . Again, the second column in this table displays the nominal expected dividends, which rise at a 5% annual rate in each future year. The third column is the discount factor at 8% for each year. The fourth column is the value of the dividend in that year, discounted to the present (this is calculated by dividing the actual dividend in the second column by the discount factor in the third). As with prestiti and consols, when the DR rises, prices fall; when the DR falls, prices rise. I’ve also plotted these numbers in Figure 2-2 . The top curve—the same curve plotted in Figure 2-1 —represents the actual, or “nominal,” dividends received in each future year. To reiterate, the top curve represents the actual dividend stream of the Dow received by shareholders before its value has been adjusted down to its present value. The bottom curves are the present value of the Dow’s income stream, obtained by discounting the nominal dividends at rates of 8% and 15%. Notice how at the higher discount rate, the discounted value of the dividends decays nearly to zero after a few decades; such is the corrosive effect of high DRs, caused by high risk or high inflation, on stock values. Better Living Through Mathematics Now we need only perform one more step. To obtain the “true value” of the Dow, you have to add together all of the discounted dividends for each year (excluding the first, because it has already been paid). For example at a DR of 8%, you would add up all of the numbers (except the first) in the fourth column, the one labeled “8% Discount Value.” Does this seem like a hopelessly difficult task? It is, if you are doing the computation by what mathematicians call the “brute force” method, i.e., trying to add the infinite column of numbers in column four. Figure 2-2. Discounted Dow dividend value. Fortunately, mathematicians can help us out of this pickle with a simple formula that calculates the sum of all of the desired values in column four. Here it is: Market Value = Present Dividend/(DR − Dividend Growth Rate) Using our assumption of a $140 present dividend, an 8% DR, and 5% earnings growth, we get: Market Value = $140/(0.08−0.05) = $140/0.03 = $4,667 (Finance types always do their calculations with decimals; 8% becomes 0.08 in the formula.) Oops. This formulation suggests that the Dow, currently priced at around 10,000, is about 100% overvalued compared to the 4,667 value we just computed using the rosy 8% DR − return scenario. And if things get really rough, investors may decide they require a 15% DR to invest in stocks (as they did in the early 1980s, when Treasury bonds yielded almost 16%). I’ve shown the relevant figures for a 15% DR in the last two columns of Table 2-1 . The simplified calculation looks like this: Figure 2-3. Dow fair value versus discount rate. Market Value = $140/(0.15 − 0.05) = $140/0.10 = $1,400 It is unlikely (but not impossible) that the Dow will drop as far as 1,400 at any point in the future, but recall that at least twice in this century U.S. investors indeed did demand a 15% DR. This kind of calculation is enormously sensitive to the DR and dividend growth rate. For example, raise earnings growth to 6% and lower the DR to 7%, and you come up with a market value of 14,000. Some of you may be aware of the controversy surrounding a book by James Glassman and Kevin Hassett, provocatively titled Dow 36,000 , in which they arrive at the title’s number by fiddling with the above equation in the manner we’ve described. In fact, using entirely reasonable assumptions, you can make the Dow’s discounted market value almost anything you want it to be. To show how the DR affects the “fair value” of the Dow via this technique, I’ve plotted the Dow’s “fair value” from the DDM versus the DR in Figure 2-3 . Rescued by the Gordon Equation Why have we spent so much time and effort on the DDM when it turns out that it cannot be used to accurately price the stock market? For three reasons. First and foremost, because it provides an intuitive way to think about the value of a security. A stock or bond is not an abstract piece of paper that has a randomly fluctuating value; it is a claim on real future income and assets. Second, it enables us to test the growth and return assumptions of a stock or of the entire market. At the height of the tech madness in April 2000, the entire Nasdaq market sold at approximately 100 times earnings. Applying the DDM to it revealed that this implied either a ridiculously high earnings growth rate or a low expected return. The latter seemed far more plausible to serious observers, and unfortunately, this is eventually what happened. Third, and most important, the real beauty of the above formulas is that they can be rearranged to calculate the market’s expected return, producing an equation that is at once stunningly simple and powerful: DR (Market Return) = Dividend Yield + Dividend Growth This formula, which is known as the “Gordon Equation,” provides an accurate way to predict long-term stock market returns. For example, during the twentieth century, the average dividend yield was about 4.5%, and the compounded rate of dividend growth was also about 4.5%. Add the two together and you get 9.0%. The actual return was 9.89%—not too shabby. The approximately 1% difference was due to the fact that stocks had become considerably more expensive (that is, the dividend yield had fallen) during the period. The Gordon Equation also has an elegant intuitive beauty. If the stock market is simply viewed as a source of dividends, then its price should rise in proportion to those dividends. So if its dividends increase at 4.5% per year, then over the very long term its price should also increase by 4.5% per year. In addition to the price increase, you also receive the actual dividend each year: the annualized total return comes from the combination of the annualized price increase (which is roughly the same as the annualized dividend growth) and the average dividend yield. The Gordon Equation is as close to being a physical law, like gravity or planetary motion, as we will ever encounter in finance. There are those who say that dividends are quaint and outmoded; in the modern era, return comes from capital gains. Anyone who really believes that might as well be wearing a sandwich board on which is written in large red letters, “I haven’t the foggiest notion what I’m talking about.” It is, of course, true that a company never has to pay out a dividend in order to provide capital gains. But even if all of the companies in the U.S. stopped paying out dividends (which they have just about done), in the long term their return would be roughly the same as their aggregate earnings growth. Thus, in a world without dividends, company earnings must grow at an average rate of 10% per year in order to provide the historical 10% long-term return of stocks. And, as we’ll soon see, the long-term average rate of corporate earnings and dividend growth is only 5%. Worse, when adjusted for inflation, it has not changed in the past century. Never forget that in the long run, it is corporate earnings growth that produces stock price increases. If, over the very long term, the annualized earnings growth is about 5%, then the annualized stock price increase must be very close to this number. One exception to this is the case of companies that are buying back their shares. A company that has grown its earnings by 5% per year and annually buys back 5% of its outstanding shares will appreciate by 10% per year, in the long term. The opposite is true of companies that issue new stock. Averaged over the whole U.S. market, these two factors tend to cancel each other out. The discounted dividend model is a powerful way of understanding stock and bond behavior. As we’ve seen, it isn’t of much use in accurately predicting the fair value of the market, let alone a stock. Princeton economist Burton Malkiel famously stated that “God Almighty himself does not know the proper price-earnings multiple for a common stock.” In other words, it is impossible to know the intrinsic value of a stock or the market. But the DDM is useful in more subtle, powerful ways. First, it can be used in reverse. That is, instead of entering the estimated dividend growth and DR and getting the price, we can derive these two values from the price of the market or for a given stock. We’ve already seen that in 1999, for example, applying the DDM in this manner would have told you that highly unrealistic growth expectations were embedded in the prices of tech stocks. And, of course, the DDM gives us the Gordon Equation, which allows us to estimate stock returns. This raises an important point. Wall Street and the media are constantly obsessed with the question of whether the market is overvalued or undervalued (and by implication, whether it is headed up or down). As we’ve just seen, this is essentially impossible to determine. But in the process, we’ve just acquired a much more valuable bit of knowledge: the long-term expected return of the market . Think about it, which would you rather know: the market return for the next six months, or for the next 30 years? I don’t know about you, but I’d much rather know the latter. And, within a reasonable margin of error, you can. But you don’t sell newspapers, magazines, and airtime speculating about 30-year returns. And what does the Gordon Equation tell us today about future stock returns? The news, I’m afraid, is not good. Dividend growth still seems to be about 5%, and the yield, as we’ve already mentioned, is only 1.55%. These two numbers add up to just 6.55%. Even making some wildly optimistic assumptions—say a 6% to 7% dividend growth rate—does not get us anywhere near the 10% annualized returns of the past century. What about bonds? The expected return of a long-term bond is simply its “coupon,” that is its interest payments. (For a bond, the second number in the Gordon Equation, dividend growth, is zero. In almost all cases, a bond’s interest does not grow.) High-quality corporate bonds currently yield about 6%. This figure provides a reasonably accurate estimate of their future returns. If interest rates rise, their value will fall, but the rate at which the interest is reinvested will rise, and vice versa. So over a 30-year period, the total bond return cannot be very far from the 6% coupon. What we have now is a very different picture from what transpired in the twentieth century, with its high stock returns and low bond returns. Going forward, it looks like stock and bond returns should both be in the 6% range, not the 10% historical reward. Don’t shoot me, I’m only the messenger. Viewed from an historical perspective, what has happened is that stocks have had an incredible run the past few decades. Their prices have been bid up dramatically, so their future returns will be commensurately lower. The exact opposite has happened to bonds. As we’ve already seen, bondholders were severely traumatized by the unprecedented monetary shift in the twentieth century. Their prices have fallen, so their expected returns have commensurately risen. On an intellectual level, most investors have no trouble understanding the notion that high past returns result in high prices, which, in turn, result in lower future returns. But at the same time, most investors find this almost impossible to accept on an emotional level. By some strange quirk of human nature, financial assets seem to become more attractive after their price has risen greatly. But buying stocks and bonds is no different than buying tomatoes. Most folks are sensible enough to load up when the tomatoes are selling at 40 cents per pound and to forgo them at three dollars. But stocks are different. If prices fall drastically enough, they become the lepers of the financial world. Conversely, if prices rise rapidly, everyone wants in on the fun. Until very recently, there was a great deal of talk about the “new investment paradigm.” Briefly stated, this doctrine asserts that Fisher had gotten it all wrong: earnings, dividends, and price no longer matter. The great companies of the New Economy—Amazon, eToys, and Cisco—were going to dominate the nation’s business scene, and no price was too high to pay for the certain bonanza these firms would provide their shareholders. Of course, we’ve seen this movie before. In 1934, the great investment theorist Benjamin Graham wrote of the pre-1929 stock bubble: Instead of judging the market price by established standards of value, the new era based its standards of value upon the market price. Hence, all upper limits disappeared, not only upon the price at which a stock could sell, but even upon the price at which it would deserve to sell. This fantastic reasoning actually led to the purchase for investment at $100 per share of common stocks earning $2.50 per share. The identical reasoning would support the purchase of these same shares at $200, at $1,000, or at any conceivable price. Even the most casual investor will see the parallels of Graham’s world with the recent tech/Internet bubble. Graham’s $100 stock sold at 40 times its $2.50 earnings. At the height of the 2000 bubble, most of the big-name tech favorites, like Cisco, EMC, and Yahoo! sold at much more than 100 times earnings. And, of course, almost all of the dot-coms went bankrupt without ever having had a cent of earnings. At the end of the day, the Fisher DDM method of discounting interest streams is the only proper way to estimate the value of stocks and bonds. Future long-term returns are quite accurately predicted by the Gordon Equation. As I’ve already said, these are essentially the laws of gravity and planetary motion of the financial markets. But it seems that once every 30 years or so, investors tire of valuing stocks by these old-fashioned techniques and engage in orgies of unthinking speculation. Invariably, Fisher and Graham’s lesson—not to overpay for stocks—is re-learned in excruciating slow motion in the years following the inevitable market crash. The rub is, the Gordon Equation is useful only in the long term—it tells us nothing about day-to-day, or even year-to-year, returns. And even in the very long term, it is not perfect. As we’ve already seen above, over the course of the twentieth century, it was off by about 1% of annualized return. This 1% difference can be attributed to the change in the dividend rate, which decreased from 4.5% to 1.4% between 1900 and 2000. In other words, stocks, which in 1900 sold for 22 times their dividends, now sell for 70 times their dividends. The ratio of price to dividends—22 in 1900, 70 in 2000—is called the “dividend multiple.” (This is simply the inverse of the dividend yield: 1/.045 = 22, and 1/.014 = 70.) This ratio is the number of dollars you must pay to get one dollar of dividends. It is similar to the more familiar “PE multiple”: price divided by earnings. The PE multiple is the most popular measure of how “expensive” the stock market is. The Gordon Equation does not account for changes in the dividend or PE multiple. The tripling of the dividend multiple between 1900 and 2000 accounts for most of the approximately 1% difference between the 9% predicted by the Gordon Equation and the 9.89% actual return. (Compounding 0.89% over a century produces close to a tripling of the stock market’s value.) Stating that there was a “tripling of the dividend multiple” is just another way of saying that an enthusiastic investing public has driven up stock prices relative to earnings and dividends by a factor of three. Over relatively short periods of time—less than a few decades—this change in the dividend or PE multiple accounts for most of the stock market’s return, and over periods of less than a few years, almost 100% of it. John Bogle, founder of the Vanguard Group of mutual funds, provides us with a very useful way of thinking about this. He calls the short-term fluctuations in stock prices due to changes in dividend and PE multiples the “speculative return” of stocks. On the other hand, the long-term increase in stock market value is entirely the result of the sum of long-term dividend growth and dividend yield calculated from the Gordon Equation, what Bogle calls the “fundamental return” of stocks. In engineering terms, Bogle’s fundamental return is the signal—a constant, reliable occurrence. Bogle’s speculative return is the noise—distracting and unpredictable. For example, on October 19, 1987, the stock market fell by 23%. Certainly, on that day—Black Monday—there were no significant changes in the dividend payments or dividend growth of common stocks. The market crash of 1987, and the run up which preceded it, were purely speculative events. The key point, which we’ll return to again and again, is that the fundamental return of the stock market—the sum of dividends and dividend growth—is somewhat predictable, but only in the very long term. The short-term return of the market is purely speculative and cannot be predicted. Not by anyone. Not the panelists on Wall Street Week , not the “market strategists” at the biggest investment houses, not the newsletter writers, and certainly not your stockbroker. Perhaps somewhere in a dark secret corner of Wall Street, there is one person who knows just where the market is going tomorrow. But if she exists, she would of course not tell a soul for fear of tipping off the market and damaging the enormous profits that are to be hers on the morrow. (Or, as financial economist Rex Sinquefield replies with a straight face when asked about the direction of the stock market, “I know where the market’s headed, I just don’t want to share that with anyone.”) A superb metaphor for the long-term/short-term dichotomy in stock returns comes from Ralph Wanger, the witty and incisive principal of the Acorn Funds. He likens the market to an excitable dog on a very long leash in New York City, darting randomly in every direction. The dog’s owner is walking from Columbus Circle, through Central Park, to the Metropolitan Museum. At any one moment, there is no predicting which way the pooch will lurch. But in the long run, you know he’s heading northeast at an average speed of three miles per hour. What is astonishing is that almost all of the market players, big and small, seem to have their eye on the dog, and not the owner. As we’ve already mentioned, the Gordon Equation is not good news for future equity returns. Is there any way out of this gloomy scenario? Yes. There are three possible scenarios in which equity returns could be higher than the predicted 6.4%: • Dividend growth could accelerate. Companies usually only pay part of their dividends out as earnings. At the present time, the market sells at about 25 times its annual earnings. Another way of saying this is that the “earnings yield” of the market is 4% (1/25). So, if these companies are paying out 1.4% as dividends, that leaves 2.6% to pay for growth. The above figures represent an average of the whole market. Many companies earn far more or far less than 4% of their market value, while many, like Microsoft, pay out zero dividends, retaining all their earnings for future growth. It is said that U.S. companies have experienced dramatic increases in productivity in the past few decades, and that this will further accelerate earnings growth beyond the 5% historical figure. This is wishful thinking. In the first place, before 1980, companies kept far more than 2.6% of their capital value in retained earnings. In the second place, there is voluminous evidence that excess corporate cash from “retained earnings” (that is, earnings not paid out to the shareholders, but instead reinvested in the company) tends to be wasted. And finally, it just isn’t happening. In Figure 2-4 , I’ve plotted the dividends and earnings of the stock market since 1900 (courtesy of Robert Shiller at Yale). Figure 2-4 is another one of those confusing “semilog” graphs. Their major advantage is that they allow you to estimate the percent rate of increase of earnings and dividends across a wide range of values. This is not true of standard “arithmetic” plots. With a semilog graph, a constant growth rate produces a plot that moves up at a fairly constant angle, called the slope. This is approximately what is seen in Figure 2-4 . Those of you with an eagle eye will detect that the slope for the first 50 years seems to be ever-so-slightly less than for the last 50. This is because of inflation. In inflation-adjusted terms, dividend growth may actually be slowing. When inflation is factored in, from 1950 to 1975, annualized earnings growth was 2.22%, and from 1975 to 2000 it was 1.90%. Clearly the rapidly accelerating trend of earnings and dividend growth frequently cited by today’s New Era enthusiasts is nowhere to be seen. This analysis also demolishes another one of the supposed props of current stock valuations: stock buybacks, which should also increase per-share stock dividends. This is what is actually plotted in Figure 2-4 . Figure 2-4. Nominal earnings and dividends, S&P 500. ( Source: Robert Shiller, Yale University). • Bogle’s speculative return—the growth of the dividend multiple—could continue to provide future stock price increases with further growth of the dividend multiple. Why, you might ask, can’t the dividend multiple grow at 3% per year from here, yielding 3% of extra return? Unfortunately, this means that the dividend multiple would have to double every 24 years. While it is possible that this could occur for another decade or two, it is not sustainable in the long term. After all, if the dividend multiple increased at 3% per year for the next century, then stocks in 2102 would sell at 1,350 times dividends, for a yield of 0.07%! In fact, thinking about the future of the speculative return is a scary exercise. The best-case scenario has the dividend multiple remaining at its present inflated level and not affecting returns. It is quite possible, however, that we may see a reduction in this value over time. Let’s say, for the sake of argument, that the dividend multiple halves from the current value, raising the dividend from its current 1.4% to 2.8%—still far lower than the 5% historical average—over the next 20 years. In that case, the speculative return will be a negative 3.4% per year, for a total annualized market return of 2.8%. Sound far-fetched? Not at all. If inflation stays at the 2% to 3% level of the past decade, this implies a near zero real return over 20 years. This is not an uncommon occurrence. It’s happened three times in the twentieth century: from 1900 to 1920, from 1929 to 1949, and from 1964 to 1984. • The stock market could crash. You heard me right. The most sustainable way to get high stock returns is to have a dramatic fall in stock prices. Famed money manager Charles Ellis likes to tease his friends with a clever riddle. He asks them which market scenario they would rather see as long-term investors: stocks rising dramatically and then staying permanently at that high level, or falling dramatically and staying permanently at that low level. The correct answer is the latter, since with permanently low prices you will benefit from permanently high dividends. As the old English ditty says, “Milk from the cows, eggs from the hens. A stock, by God, for its dividends!” After several decades, the fact that you are reinvesting income at a much higher dividend rate will more than make up the damage from the original price fall. To benefit from this effect, you have to be investing for long enough—typically more than 30 to 50 years. To demonstrate this phenomenon, in Figure 2-5 , I’ve plotted three different scenarios: (1) no change in the dividend multiple, with its current 1.4% dividend, (2) a 50% fall, resulting in a 2.8% dividend, and (3) an 80% fall, resulting in a 7% dividend. As you can see, the more drastic 80% fall produces a quicker recovery than the 50% fall. The below table shows why: After an 80% fall in prices, the higher long-term return eventually compensates for the initial devastation. Even better than having a long time horizon in this situation is having the wherewithal to periodically invest sums regularly at such low levels—this dramatically shortens the “break-even point.” The implications of the last scenario are profound. What this says is that a young person saving for retirement should get down on his knees and pray for a market crash, so that he can purchase his nest egg at fire sale prices. For the young investor, prolonged high stock prices are manifestly a great misfortune, as he will be buying high for many years to invest for retirement. Alternatively, the best-case scenario for a retiree living off of savings is a bull market early in retirement. Figure 2-5. Effect of stock declines on final wealth. For the retiree, the worst-case scenario is a bear market in the first few years of retirement, which would result in a very rapid depletion of his savings from the combination of capital losses and withdrawals necessary for living expenses. To summarize: How to Think about the Discount Rate and Stock Price The relationship between the DR and stock price is the same as the inverse relationship between interest rates and the value of prestiti and consols in the last chapter: when DR goes up, the stock price goes down, and vice versa. The most useful way of thinking about the DR is that it is the rate of return demanded by investors to compensate for the risk of owning a particular asset. The simplest case is to imagine that you are buying an annuity worth $100 per year, indefinitely, from three different borrowers: The world’s safest borrower is the U.S. Treasury. If Uncle Sam comes my way and wants a long-term loan paying me $100 per year in interest, I’ll charge him just 5%. At that DR, the annuity is worth $2,000 ($100/0.05). In other words, I’d be willing to loan Uncle Sam $2,000 indefinitely in return for $100 in annual interest payments. Next through the door is General Motors. Still pretty safe, but a bit more risky than Uncle Sam. I’ll charge them 7.5%. At that DR, a perpetual $100 annual payment is worth $1,333 ($100/0.075). That is, for a $100 perpetual payment from GM, I’d be willing to loan them $1,333. Finally, in struts Trump Casinos. Phew! For the risk of lending this group my money, I’ll have to charge 12.5%, which means that The Donald’s perpetual $100 payment is worth only an $800 ($100/0.125) loan. So the DR we apply to the stock market’s dividend stream, or that of an individual stock, hinges on just how risky we think the market or the stock is. The riskier the situation, the higher the DR/return we demand, and the less the asset is worth to us. Once more, with feeling: High discount rate = high perceived risk, high returns, depressed stock price Low discount rate = low perceived risk, low returns, elevated stock price The Discount Rate and Individual Stocks In the case of an individual stock, anything that decreases the reliability of its earnings and dividend streams will increase the DR. For example, consider a food company and a car manufacturer, each of which are expected to have the same average earnings and dividends over the next 20 years. The earnings and dividends of the food company, however, will be much more reliable than that of the car manufacturer—people will need to buy food no matter what the condition of the economy or their employment. On the other hand, the earnings and dividends of auto manufacturers are notoriously sensitive to economic conditions. Because the purchase of a new car is a discretionary decision, it can easily be put off when times are tough. During recessions, it is not unusual for the earnings of the large automakers to completely disappear. So investors will apply a higher DR to an auto company than to a food company. That is why “cyclical” companies with earnings that fluctuate with business cycles, such as car manufacturers, sell more cheaply than food or drug companies. Put another way, since the earnings stream of an auto manufacturer is less reliable than that of a food company, you will pay less for its earnings and dividends because of the high DR you apply to them. All other things being equal (which they never are!), you should earn a higher return from the auto manufacturer than from the food company in compensation for the extra risk involved. This is consistent with what we saw in the last chapter: “bad” (value) companies have higher returns than “good” (growth) companies, because the market applies a higher DR to the former than the latter. Remember, the DR is the same as expected return; a high DR produces a low stock value, which drives up future returns. Probably the most vivid example of the good company/bad stock paradigm was provided in the popular 1982 book, In Search of Excellence , by management guru Tom Peters. Mr. Peters identified numerous “excellent” companies using several objective criteria. Several years later, Michelle Clayman, a finance academic from Oklahoma State University, examined the stock market performance of the companies profiled in the book and compared it with a matched group of “unexcellent” companies using the same criteria. For the five-year period following the book’s publication, the unexcellent companies outperformed the excellent companies by an amazing 11% per year. As you might expect, the unexcellent companies were considerably cheaper than the excellent companies. Most small investors naturally assume that good companies are good stocks, when the opposite is usually true. Psychologists refer to this sort of logical error as “representativeness.” The risk of a particular company, or of the whole market, is affected by many things. Risk, like pornography, is difficult to define, but we think we know it when we see it. Quite frequently, the investing public grossly overestimates it, as occurred in the 1930s and 1970s, or underestimates it, as occurred with tech and Internet stocks in the 1960s and 1990s. The Societal Discount Rate and Stock Returns The same risk considerations that operate at the company level are in play market-wide. Let’s consider two separate dates in financial history—September 1929 and June 1932. In the fall of 1929, the mood was ebullient. Commerce and daily living were being revolutionized by the technological marvels of the day: the automobile, telephone, aircraft, and electrical power plant. Standards of living were rapidly rising. And just like today, the stock market was on everyone’s lips. People had learned that stocks had much higher long-run returns than any other investment. In Common Stocks as Long Term Investments , a well-researched and immensely popular book published in 1924, Edgar Lawrence Smith showed that stock returns were far superior to bank deposits and bonds. The previous decade had certainly proved his point. At the height of the enthusiasm in 1929, John J. Raskob, a senior financier at General Motors, granted an interview to Ladies Home Journal . The financial zeitgeist was engagingly reflected in a quote from this piece: Suppose a man marries at the age of twenty-three and begins a regular savings of fifteen dollars a month—and almost anyone who is employed can do that if he tries. If he invests in good common stocks and allows the dividends and rights to accumulate, he will at the end of twenty years have at least eighty thousand dollars and an income from investments of around four hundred dollars a month. He will be rich. And because anyone can do that, I am firm in my belief that anyone not only can be rich but ought to be rich. Raskob’s frugal young man was a genius indeed; compounding $15 per month into $80,000 over 20 years implies a rate of return of over 25%. Clearly, the investing public could be excused for thinking that this was the best time to invest in stocks. Now, fast forward less than three years to mid-1932 and the depths of the Great Depression. One in three workers is jobless, the gross national product has fallen by almost half, protesting veterans have just been dispersed from Washington by Major General MacArthur and a young aide named Eisenhower, and membership in the American Communist Party has reached an all-time high. Even economists have lost faith in the capitalist system. Certainly not a good time to invest, right? Had you bought stock at one of the brightest moments in our economic history, in September 1929, and held on until 1960, you’d have earned an annualized 7.76%, turning each dollar into $9.65. Not a bad rate of return; but for a stock investment, nothing to write home about. But had you the nerve to buy stocks in June of 1932 and hold on until 1960, you’d have earned an annualized 15.86%, turning each dollar into $58.05. Few did. Finally, we come to the World Trade Center bombing. Before it, the world was viewed as a relatively safe place to live and invest. In an instant, this illusion was shattered, and the public’s perception of risk dramatically increased; the DR rose, resulting in a sharp lowering of price. It’s likely that the permanency of this feeling of increased risk will be the primary determinant of stock prices in the coming years. The key point is this: if public confidence remains depressed, prices will remain depressed, which will increase subsequent returns. And if confidence returns, prices will rise and subsequent returns will be lower. These vignettes neatly demonstrate the relationship between societal risk and investment return. The worst possible time to invest is when the skies are the clearest. This is because perceived risks are low, causing investors to discount future stock income at a very low rate. This, in turn, produces high stock prices, which result in low future returns. The saddest part of this story is that “pie-in-the-sky investing” is both infectious and emotionally effortless—everyone else is doing it. Human beings are quintessentially social creatures. In most of our endeavors, this serves us well. But in the investment arena, our social instincts are poison. The best possible time to invest is when the sky is black with clouds, because investors discount future stock income at a high rate. This produces low stock prices, which, in turn, beget high future returns. Here also, our psychological and social instincts are a profound handicap. The purchase of stocks in turbulent economic times invites disapproval from family and peers. Of course, only in retrospect is it possible to identify what legendary investor Sir John Templeton calls “the point of maximum pessimism”; nobody sends you an overdue notice or a bawdy postcard at the market’s bottom. So even when you are courageous and lucky enough to invest at the low point, throwing money into a market that has been falling for years is a profoundly unpleasant activity. And, of course, you are taking the risk that the system may, in fact, not survive. This brings to mind an apocryphal story centering on the Cuban Missile Crisis of 1962, which has a young options trader asking an older colleague whether to make a long (bullish) bet or a short (bearish) one. “Long!” answers the older man, without a moment’s hesitation. “If the crisis resolves, you’ll make a bundle. And if it doesn’t, there’ll be nobody on the other side of the trade to collect.” Finally, at any one moment the societal DR operates differently across the globe. Nations themselves can take on growth and value characteristics. For example, 15 years ago, the Japanese appeared unstoppable. One by one, they seemed to be taking over the manufacture of automobiles, televisions, computer chips, and even machine tools—product lines that had been dominated by American companies for decades. Signature real estate like Rockefeller Center and Pebble Beach were being snatched up like so many towels at a blue light special. The grounds of the Imperial Palace in Tokyo were said to be worth more than the state of California. Such illusions of societal omnipotence carry with them a very low DR. Since the Japanese income stream was discounted to the present at a very low rate, its market value ballooned, producing very low future returns. The peak of apparent Japanese invincibility occurred around 1990. A dollar of Japanese stock bought in January 1990 was worth just 67 cents 11 years later, yielding an annualized return of minus 3.59%. In the early 1990s, the Asian Tigers—Hong Kong, Korea, Taiwan, Singapore, and Malaysia—were the most fashionable places to invest. Their industrious populations and staggering economic growth rates were awesome to behold. Once again, the investment returns from that point forward were poor. The highest return of the five markets was obtained in Hong Kong, where a dollar invested in January 1994 turned into 93 cents by year-end 2000. The worst of the five was Malaysia, where you’d have wound up with just 37 cents. And, finally, in the new millennium, everyone’s favorite market is here at home. Which gets us right back where we started this chapter, with a low discount rate, high prices, and low expected future returns. The most depressing thing about the DR is that it seems to be quite sensitive to prior stock returns. In other words, because of human society’s dysfunctional financial behavior, a rising stock market lowers the perception of risk, decreasing the DR, which drives prices up even further. What you get is a vicious (or virtuous, depending on your point of view) cycle. The same thing happens in reverse. Because of damage done to stocks in the 1930s, the high DR for stocks outlived the Great Depression, resulting in low prices and high returns lasting for more than a quarter of a century. Real Returns: The Outlook It’s now time to translate what we’ve learned into a forecast of the long-term expected returns of the major asset classes. Whenever you can, you should think about returns in “real” (inflation-adjusted) terms. This is because the use of real returns greatly simplifies thinking about the purchasing power of stocks, making financial planning easier. Most people find this a bit difficult to do at first, but after you get used to it, you’ll wonder why most folks use “nominal” (before-inflation) returns. Let’s start with the historical 10% stock reward for the twentieth century. Since the inflation rate in the twentieth century was 3%, the real return was 7%. That’s the easy part. The hard part is trying to use nominal returns for retirement planning. Let’s say that you’re going to be saving for 30 years before retiring. If you’re using the 10% nominal return, you’ll have to deflate that by the cumulative inflation rate over 30 years. And then, for every year after you retire, you’ll have to deflate your nest egg by 3% per year to calculate your real spending power. It is much simpler to think the problem all the way through in real terms—a 10% nominal return with 3% inflation is the same as a 7% return and no inflation 2 ; no adjustments are necessary. A real dollar in 50 years will buy just as much as it will now. (And before World War I, when money really was hard gold and silver, that’s how folks thought. There’s an old economist’s joke: An academic is questioning a stockbroker about investment returns, and asks him, “Are those real returns?” The broker responds, “Of course they are, I got them from The Wall Street Journal yesterday!”) From now on, we’re going to talk about real returns whenever possible. For starters, the DDM tells us to expect cash to yield a zero real return, bonds to have an approximately 3% real return, and stocks in general to have about a 3.5% real return. In the current environment, is it possible to find assets with higher DRs and expected returns? Yes. As this is being written, except perhaps for Japan, foreign stocks are slightly cheaper than U.S. stocks. But even in Japan, dividend multiples are lower than in the U.S., so expected returns abroad may be slightly more than domestic expected returns. Small stocks also sell at a slight discount to large stocks around the globe, and so too have slightly higher expected returns. Next, there’s value stock investing. Value stock returns are impossible to estimate using the traditional methods, because most of the excess return arises from the slow improvement in valuations that occurs as doggy stocks become less doggy over time. This is a difficult process to model, but a general observation or two are in order. As recently as five years ago, if you had sorted the S&P 500 by the earnings multiple (“P/E ratio”: the number of dollars of stock needed to buy a dollar of current earnings), you would have found that the top 20% of stocks typically sold at about twice the multiple of the bottom 80%—at about 20 and 10 times earnings, respectively. As 2002 began, the top 20% and bottom 80% of companies sold at 64 and 20 times earnings, respectively—a more than threefold difference between top and bottom. This is not nearly as bad as the sevenfold difference at the market peak in the spring of 2000, but large nevertheless. So, absent a permanent new paradigm, the historical 2% extra return from value stocks seems a good bet, yielding large-value real expected returns of about 5% and small-value real expected returns of about 7%. Real Estate Investment Trusts (REITs) are the stocks of companies that manage diversified portfolios of commercial buildings. One example is the Washington Real Estate Investment Trust (WRE), which owns a large number of office buildings in the D.C. area. By law, WRE is required to pay out 90% of its earnings as income. Because of this enforced payment of dividends, REITs currently yield an average of about 7% per year. The downside is that because they can reinvest only a small portion of their profits, they usually carry a large amount of debt and, in the aggregate, do not grow well. Since 1972, they have increased their earnings by about 3% per year. This was about 2% less than the inflation rate during the period. Add a 7% dividend to a negative 2% real earnings growth and the expected real return of REITs is about 5% per year. Stocks in many countries have been battered by the “Asian Contagion” of the late nineties, and their markets now yield 3% to 5% dividends. Most of the “Tiger” countries, as well as many South American stock markets, fall into this category. The future long-term dividend growth rate in these nations is anybody’s guess, but it is quite possible that they will resume their earlier economic growth to produce healthy stock returns going forward. The stocks of gold and silver mining companies are an intriguing asset class. They currently yield dividends of about 3%, and the most conservative assumption is that they will have zero real earnings and dividend growth, for a total real expected return of 3%—about the same as bonds and cash. In the long run, they offer excellent inflation protection. But because these stocks are very sensitive to even small changes in gold prices, they are extremely risky. We’ll talk about why you might want a small amount of exposure to these companies in Chapter 4 , when we discuss portfolio theory. From time to time, it makes sense to take credit risk. This is an area we’ve touched on earlier. The bonds of companies with low credit ratings carry high yields—these are the modern equivalent of the Greek bottomry loans discussed in the last chapter. At present, such “high yield,” or “junk,” bonds, carry coupons of approximately 12%, compared to only about 5% for Treasury bonds. Are these a worthwhile investment? Many of these companies will default on their bonds and then go bankrupt. (Default does not necessarily imply bankruptcy and total loss. Many companies—about 30%—will temporarily default, then resume payment of interest and principal. Bondholders frequently recover some of their assets from bankrupt companies.) The default rate on these companies is about 6% per year, on average, and the “loss rate”—the percent loss of capital each year from these bonds—appears to be about 3% to 4% per year. I cannot stress the word “average” enough in this context. In good times, the loss rate is near zero. And in bad times, it can be quite high—approaching 10% per year. So, if you are earning 7% more in interest per year than with a Treasury bond, but you are losing an average of 4% per year on bankruptcies, then in the end you should still be left with 3% more return than Treasuries. Most investors would consider this to be an adequate tradeoff. But it’s important to understand that during a recession, even the market value of the surviving bonds may temporarily decrease. For example, during the 1989–1990 junk bond debacle, price declines approaching 20% were common even in the healthiest issues. If you’re going to invest in junk bonds, you have to keep your eye on the yield spread between Treasuries and junk. In Figure 2-6 , I’ve plotted this junk-Treasury spread (JTS) over the recent past. Note how the JTS is, more often than not, quite low—in fact, lower than even the historical loss rate! This irrational behavior is explained by investors “reaching for yield”: unhappy with low bond and bill rates, they take on more credit risk than they had bargained for in a foolish attempt to get a few bits of extra return. When the JTS is below 5%, don’t even think about buying junk. (You can find the high-yield and Treasury yields in the “Yield Comparisons” table in the back section of The Wall Street Journal . You’ll have to subtract the Treasury yield from the junk yield yourself.) Treasury bills are the ultimate “risk-free investment.” Their expected real return is very difficult to predict, as the yield can change quite quickly and dramatically, ranging from a low of nearly zero in the late 1930s to briefly more than 20% in the early 1980s. Currently, the T-bill yield is less than 2%, or about the same as the inflation rate, for a real zero return. And, as we saw in Chapter 1 , their actual long-term real return is not much greater than zero. Lastly, there are TIPS (Treasury Inflation Protected Securities). For those investors who are risk-averse, it’s tough to beat them, as they provide a 3.4% real yield. You can design the amount of inflation protection you want by balancing maturities; the maximum comes with the 3.375% TIPS of April 2032, the cost of which is 30 years of “real interest rate risk,” the possibility that real interest rates will rise after you have bought them. This is not the same thing as (and certainly much less scary than) the inflation risk experienced by conventional bonds, where the fixed interest payments can be seriously eroded by sustained inflation. After all, with TIPS, inflation is what you’re protecting against. Figure 2-6. Junk-treasury spread, 1988–2000. ( Source: Grant’s Interest Rate Observer .) In Table 2-2 , I’ve summarized reasonable expected real returns, derived from the DDM. Understand that “expected” returns are just that. In finance, as in life, there is often a huge chasm between what is expected and what actually transpires. The estimation of foreign stock returns is particularly perilous. Between the breakdown of the 1944 Bretton Woods agreement, which fixed currency exchange rates among the major developed nations, and the advent of increasingly active foreign-currency-denominated futures and options markets, the currencies have grown increasingly volatile. This means that the gap between expected versus realized returns for foreign stocks is liable to be especially large. The “Realized-Expected Disconnect” In the first chapter we talked about the history of past stock returns—what economists call “realized returns.” These realized returns were quite high. In fact, in the past decade, a small industry has arisen that thrives on the promotion and sale of this optimistic data. The message of this happy band of brothers is that past is prologue: because we have had high returns in the past, we should expect them in the future. Table 2-2. Expected Long-Term Real Returns The ability to estimate future stock and bond returns is perhaps the most critical of investment skills. In this chapter, we’ve reviewed a theoretical model that allows us to compute the “expected returns” of the major asset classes on an objective, mathematical basis. The message from this approach is not nearly as agreeable. Which should we believe: the optimism of historical returns, or the grim arithmetic of the Gordon Equation? It should be obvious by now where my sympathies lie. Warren Buffett famously said that if stock returns came from history books, then the wealthiest people would be librarians. There are numerous examples of how historical returns can be highly misleading. My favorite comes from the return of long Treasury bonds before and after 1981. For the 50 years from 1932 to 1981, Treasury bonds returned just 2.95% per year, almost a full percent less than the inflation rate of 3.80%. Certainly, the historical record of this asset was not encouraging. And yet, the Gordon Equation told us that the bond yield of 15% was more predictive of its future return than the historical data. Over the next 15 years, the return of the long Treasury was in fact 13.42%—slightly lower than the predicted return because the coupons had to be reinvested at an ever-falling rate. The fundamental investment choice faced by any individual is the overall stock/bond mix. It seems more likely that future stock returns will be closer to the 3.5% real return suggested by the Fisher DDM method than the 7% historical real gain. If, as we calculated earlier, stock and bond returns are going to be similar going forward, then even the most aggressive, risk-tolerant individual should have no more than 80% exposure to stocks. Unfortunately, although the DDM informs us well about expected returns, it tells us nothing about future risk. We are dependent on the pattern of past returns to inform us of the potential risks of an asset. And in this regard, I believe that the historical data serve us well. Although anything is possible in finance, it is hard to imagine the stock markets of the next century throwing anything our way that would surpass the 1929–1932 bear market. In the coming chapters, we’ll explore how to use the lessons we’ve learned to construct portfolios that give us the best chance of reaping the most reward with the minimum necessary risk. CHAPTER 2 SUMMARY 1. The ability to estimate the long-term future returns of the major asset classes is perhaps the most important investment skill that an individual can possess. 2. A stock or bond is worth only the future income it produces. This income stream must be reduced in value, or “discounted,” to the present, to reflect the fact that it is worth less than currently received income. 3. The rate at which that income is discounted is inversely related to the asset’s value; a high discount rate (DR) lowers the asset’s value. 4. The DR is the same as the asset’s expected return; it is determined by the asset’s perceived risk. The higher the risk, the higher the DR/expected return. 5. In the long term, the asset’s DR/expected return is approximately the sum of the dividend yield and the growth rate. The current high price and low dividend rate of stocks suggest that they will have much lower returns in the future than they have had in the past. 6. The above considerations pertain only to long-term returns (more than 20 years). Over shorter periods, asset returns are almost exclusively related to speculative factors and cannot be predicted. 7. The methods we discussed in this chapter suggest that the returns of stocks and bonds will be similar over the coming decades. This means that even the most aggressive investors should not have more than 80% of their savings in stocks.",
        "char_count": 67316
      },
      {
        "heading": "Chapter 9",
        "text": "3 The Market Is Smarter Than You Are I know what you’re thinking: “Okay, you’ve convinced me. Future market returns will not be that high. But that doesn’t matter, because I can beat the market. Or, I may not be able to beat the market myself, but I’m sure I can find a mutual fund/stock broker/financial advisor who can.” Pretend, just for a moment, you live in an obscure tropical country called “Randomovia.” It’s really quite a wonderful place—lush, prosperous, with universal high-speed Internet access. But it has one serious problem: a rampant chimpanzee population. In order to keep the chimps happy, the Randomovians periodically round them up, dress them in expensive suits, place them in luxurious offices, and allow them to manage the nation’s investment pools. And since chimps are very jealous creatures, humans are not allowed to manage money. Further, it’s a well-known fact that chimps love playing darts; they pick stocks by hurling these projectiles at the stock page. This means three things about Randomovia: • Over any given period of time, some of the chimpanzees will be lucky and obtain high returns. • The past performance of a chimp at selecting stocks has no bearing on his future performance. Last year’s, or last decade’s, winner will just as likely be a loser as a winner next time. • The average performance of all the chimpanzees will be the same as the market’s, since chimps are the only ones who can buy and sell. The chimps each have about a 50% chance of beating the market. There’s only one problem: The investment pools they manage charge the Randomovians 2% of assets each year in expenses. In any given year, the differences in performance are great enough that the 2% expense doesn’t matter that much. But because of the 2% drag, instead of 50% of the chimps beating the market each year, only about 40% of them do. With the passage of time, however, the law of averages catches up with all but the luckiest chimps. After 20 years, only about one in ten beats the market by more than their 2% annual expenses. So, the odds of your picking that winning chimpanzee are . . . one in ten. Well, dear readers, I have very bad news. For the past several decades, financial economists have been studying the performance of all types of investment professionals, and their message is unambiguously clear: Welcome to Randomovia! Better Living Through Statistics Although the modern scientific revolution started with the mathematical modeling of the physical world by Copernicus, Kepler, Galileo, and Newton, it was not until the nineteenth century that social scientists—sociologists, economists, and psychologists—began the serious mathematical study of social phenomena. In Chapter 1 , we saw that a dramatic improvement in the quality of financial data occurred at the beginning of the twentieth century. This was the result of a massive collaborative effort to collect and analyze stock and bond prices. As researchers began to examine the aggregate performance of stocks and bonds, it was only natural that they began by looking at the behavior of money managers. Until relatively recently, no one questioned the notion that investing was a skill, just like medicine, law, or professional sports. Ability, training, and hard work should result in superior performance. The best practitioners should excel year after year. A skilled broker or money manager should be worth his weight in gold. In this chapter, we’ll examine the utter demolition of that belief system and the emergence of a powerful new theory for understanding stock and bond market behavior—the efficient market hypothesis. Alfred Cowles III Gets Burned Most great financial innovators come from humble circumstances—nothing arouses fascination with financial assets quite like their absence. Or, as someone born to great wealth once explained to me, if you are raised in the desert, all you think about is water. But the average Western citizen, who can get it from the tap at will, hardly considers it at all. Those raised with great wealth think about money the way most of us think about water—if you want some, just turn on the faucet! Which is why Alfred Cowles III was a most unlikely financial pioneer; his family owned a large chunk of the Chicago Tribune company and was extremely wealthy. After duly graduating from Yale in 1913, he started working as a reporter, but developed tuberculosis and was sent to a sanatorium in Colorado Springs to recover. With time on his hands, he began involving himself in the family finances. He subscribed to many financial newsletters and by the mid-1920s was regularly reading about two dozen of them. He was stunned at the abysmal quality of advice. The ferocious bear market of 1929–32 was completely unforeseen by all of them, and Cowles’s family suffered as a consequence. He also found that the newsletters’ recommendations during the 1920s bull market had been nothing to write home about either. Cowles’s signature characteristic was his love of collecting and analyzing data. He began recording the newsletters’ recommendations and analyzing their predictive value. Eventually, he found his way to none other than Irving Fisher, who happened to be the president of a small impoverished academic organization dedicated to the study of financial data—the Econometric Society. With his family wealth, Cowles was a godsend to the struggling group, and in 1932, he endowed the Cowles Foundation, dedicated to the statistical study of financial assets. The importance of his generosity and research cannot be overstated. He was directly responsible for the collection and analysis of most of the nation’s stock and bond data from 1871 to 1930, and, more importantly, he provided the inspiration for most of the security research that followed. Without Cowles, we would still be financial cave dwellers, stumbling around blindly in the dark. Cowles’s first organized research project, predictably enough, studied financial newsletters. His report, published in the first edition of Econometrica, the foundation’s journal, was simply titled, “Can Stock Market Forecasters Forecast?” The article had an introductory abstract consisting of just three words: “It is doubtful.” He evaluated the recommendations of the most prestigious financial newsletters and financial services and analyzed the stock purchases of the largest group of institutional investors at the time—fire insurance companies. His results were stunning. The stock-picking abilities of the financial services and insurance companies were awful—only about one-third equaled or beat the market. And the performance of the market-timing newsletters, as he had suspected for years, was even worse. In almost all cases, investors would have been better off flipping coins than following their advice. Cowles found that the very best newsletter results could easily be obtained by random choice. But what was truly stunning was that the results of the worst newsletters could not be explained purely by chance. In other words, although there was no evidence of skill among the best newsletter writers, the worst seemed possessed of a special ineptitude. This is a pattern that we shall encounter repeatedly: among finance professionals, the best results can easily be explained by chance, but the worst performers seem to maintain an almost uncanny incompetence. It is no coincidence that the explosion of knowledge regarding investment management occurred when it did. The statistical computations involved in Cowles’s study could not have been done by hand. He was the first financial economist to make use of the new punch card machines being produced by the Hollerith Corporation. (Another investment giant, Benjamin Graham, also had a connection with Hollerith. As a young analyst in the 1920s, he almost lost his first job by recommending that his conservative employer purchase stock in the company. A few years later, Hollerith decided that a more modern-sounding name would be appropriate: International Business Machines.) But it was not until the commercial availability of electronic computers that things really got going. In 1964, academic Michael Jensen decided to look at the performance of mutual fund managers, testing for evidence of stock selection skill. Because most of the funds he examined held a significant portion of cash, almost all of them underperformed the market. But, of course, with their lower returns came greater safety. So he used sophisticated computer-based statistical methods to correct for the amount of cash and test the significance of his results. Figure 3-1 is a plot of how the funds did relative to the market, adjusted for risk. It displays the performance of the funds on a gross basis, that is, before the funds’ management fees are subtracted. The thick vertical black line in the middle of the graph represents the market performance. The bars on the left represent the number of funds underperforming the market, and the bars on the right represent funds outperforming it. Only 48 funds out of 115 outperformed the market; 67 underperformed it. As predicted, the average performance was close to that of the market (actually, 0.4% less, annualized). Figure 3-2 demonstrates fund performance on a net basis—that is, after the funds’ management fees have been subtracted. This is the return that the shareholders actually see. Essentially, this shifted fund performance about 1% to the left, so that only 39 outperformed, versus 76 underperforming. Even more interesting, while only one fund outperformed the market by more than 3% per year, 21 underperformed it by more than 3%! Again, we find the pattern seen in Cowles’s original work: no evidence of skill at the top of the heap, but at the bottom of the heap, the strong suggestion that some managers possess a special ineptitude. Figure 3-1. Mutual funds 1946–1964: gross returns relative to market.0 = market return, average fund = −0.4% per year. ( Source: Michael Jensen, Journal of Finance, 1965.) And it goes downhill from there. All of the mutual funds studied carried sales loads (a fee, typically 8.5% of the purchase amount), which Jensen did not take into account. So the funds’ investors actually obtained even lower returns than shown in Figure 3-2 . Except at the bottom end, the distributions found in Figures 3-1 and 3-2 are precisely what you’d expect from a bunch of dart-throwing chimpanzees: • The average fund produces a gross return equal to the market’s. • The average investor receives a net return equal to the market’s minus expenses. • The “best” managers produce returns that are easily explained by the laws of chance. Are we in Randomovia yet? Almost. If we actually were in Randomovia, we would find that above-average performance does not persist, primarily due to the chimpanzees’ random stock picking methodology (throwing darts). In fact, subsequent researchers soon found this to be the case in the real world as well. Figure 3-2. Mutual funds 1946–1964: net returns relative to market .0 = market return, average fund = −1.1% per year. ( Source: Michael Jensen, Journal of Finance, 1965.) Since Jensen’s study, literally dozens of studies have duplicated his findings and verified the last prediction: past superior performance has almost no predictive value. Unfortunately, almost none of the subsequent studies are understandable to the lay reader. The mid-1960s, when Jensen’s study was published in the Journal of Finance, was about the last time that the average college-educated person could get through an academic finance article without falling asleep. Vast improvements in statistical and computational sophistication in financial research meant that, in most cases, the results were impossible to translate into plain English. In Twain’s words, financial research had become “chloroform in print.” Typically, these studies show that there is some brief persistence in performance; last year’s top performers will beat the average fund by perhaps 0.25% to 0.5% the next year. But after that, nothing. And excellent past performance over longer periods is of no benefit at all. Since a 0.25% to 0.50% return boost is much lower than the expenses incurred in fund management, this is not a game worth playing. Of the dozens of studies done on mutual fund performance persistence, the most optimistic found that if you invested in the top 10% of last year’s funds, you would match, but not exceed, the performance of an index fund with low expenses. This “strategy” requires a near-total fund turnover each year. This is the best-case scenario for actively managed mutual funds—turn your portfolio over once a year, and you might—just might—match the index. And that’s before taxes. In a taxable account, this strategy would eat you alive with short-term capital gains, which are penalized at your full marginal federal and state rates. One delightful exception to the tedium of this research is an ongoing study by Dimensional Fund Advisors and S&P/Micropal, which looks at what happens to the investor who picks a mutual fund with excellent past performance. For each five-year period, they select the 30 best-performing domestic mutual funds. They then follow the performance of these best performers forward. I’ve displayed their data in Figure 3-3 . Figure 3-3. Subsequent performance of top-30 funds. ( Source: Standard and Poor’s/Mieropal/Dimensional Fund Advisors.) In order to understand this graph, take a look at the first group of bars on the left. The first (solid) bar represents the subsequent performance of the top 30 domestic stock funds from 1970 to 1974. In other words, the funds were selected for their superior performance from 1970 to 1974; then their performance from 1975 to 1998 was followed and compared to that of the average mutual fund (checkered bar) and the S&P 500 (gray bar). Note that for some of the periods, the previous best-performing funds did slightly better than average, and for some, worse than average. But in each instance, the previous winners underperformed the S&P 500 index going forward, sometimes by a large margin. This is classic Randomovian behavior; we are once again looking at chimps, not skilled operators. Actually, because of “survivorship bias,” these studies understate the case against active management. We’ve already come across survivorship bias in Chapter 1 when we discussed the differences in stock and bond returns among nations. In this case, when you look at the prior performance of all the funds in your daily newspaper, or even a sophisticated mutual fund database like Morningstar’s Principia Pro, you are not looking at the complete sample of funds; you’re looking only at those that have survived. The funds that were recently put out of their misery because of poor performance do not make it into the record unless you go out of your way to find them. It’s estimated that including these defunct funds decreases the actual average active fund performance by about 1.5% per year. So, actively managed funds are even worse than they look. In plain English, an actively managed fund exposes you to the risk that its return may be so bad that the fund company will want to obliterate its record. In other words, you may wind up owning a fund that, like so many of Comrade Stalin’s unlucky colleagues, wound up having its face airbrushed out of official photographs. More Bad News: Market Impact The dominance of the investment market by mutual funds is a relatively recent phenomenon. Before the 1960s, mutual funds were largely ignored by the investing public because of the high sales fees, usually 8.5%, and uninspiring performance. Further, 40 years ago, mutual funds were still associated in the public’s mind with the “investment trusts” of the 1920s. These were the equivalent of today’s closed-end mutual funds, except that they made extensive use of leverage (borrowed funds). Because of this leverage, many declared bankruptcy in the first stages of the 1929 crash. All that changed in the 1960s. In 1957, Fidelity put a young manager named Gerald Tsai in charge of its Capital Fund. Tsai’s specialty was growth-stock investing, and in the mid-1960s, growth companies—Xerox, IBM, LTV, Polaroid—came very much into vogue. The Go-Go Years, as they were called, were almost a carbon copy of today’s tech/Internet binge. Exciting new technologies were being brought to market, and the companies at the cutting edge zoomed, eventually selling at prices approaching those seen in the more recent bubble. Tsai was the prototypical “gunslinger,” as this type of fund manager became known—aggressively buying and selling stocks at a rapid pace and ringing up attention-getting returns in the process. In the aftermath of the 1962 downturn, his Fidelity Capital Fund gained 68%, and in 1965 it gained another 50%, versus only 15% for the market. After being told by Fidelity’s founder, Edward Crosby Johnson II, that he was not in line to succeed him, he left to found the high-octane Manhattan Fund. Unfortunately for Tsai, just at that point, he was struck with a fatal case of chimpanzee syndrome. The years 1966–1967 were mediocre for Manhattan and in 1968, the patient crashed. In the first half of the year, Manhattan lost 6.6% of its value while the market gained 10%, ranking 299th among the 305 funds tracked by mutual fund expert Arthur Lipper. At that point, Tsai cashed in his chips and abandoned his shareholders, selling Manhattan to C.N.A. Financial Corporation for $30 million. Why had things gone so horribly wrong at the Manhatttan Fund? The nation’s senior financial writers spun a tale of speculation and hubris, followed by the inevitable rough justice. (At least for the shareholders. In addition to his golden parachute, Tsai eventually went on to a distinguished business career, ultimately becoming chairman of Primerica.) But the financial press missed something far more important: the Manhattan Fund was the first example of what later became an all-too-common phenomenon in the world of mutual funds—asset bloat, with its corrosive effect on returns. In order to understand asset bloat, we’ll have to step back and examine the relationship between portfolio size and investment results. Let’s say that you think that the stock of XYZ company is a good buy. You call your broker and, without too much fuss, you purchase $1,000 worth. It is unlikely that anyone has noticed your order—millions of dollars worth of company stock are traded every day, and your purchase produces not a ripple in the stock’s activity. But suppose that you have $25 million to invest in the stock. Now you have a very big problem. You will not be able to complete your purchase without dramatically inflating the stock price. Another way of saying this is that at today’s price, there is not nearly enough stock available for sale to meet your needs—in order to bring sufficient shares out of the woodwork, the price must be raised. The amount you pay for your shares will be considerably higher than if you had only a small order, and your overall return will be commensurately smaller. The opposite will happen if you decide to sell a large block of stock: you will seriously depress the price, again lowering your return. This decrease in return experienced by large traders is called “impact cost,” and it goes straight to the bottom line of a fund’s return. Unfortunately, it is almost impossible to measure. Now it becomes clear what happened to Manhattan’s unfortunate shareholders. Tsai was the first person to attain the modern label of “superstar fund manager” and, in short order, suffered its inevitable consequence, asset bloat. In the first three months of 1968, Tsai’s reputation attracted $1.6 billion into the fund—an enormous amount for the time. He was simply unable to invest that amount of cash without incurring substantial impact costs. In effect, Manhattan’s shareholders paid a hefty “Tsai tax” each time he bought or sold, eventually destroying the fund’s performance. This scenario repeated itself innumerable times in the decades following Tsai’s departure from the fund scene. One of the best examples of asset bloat’s ramifications happened to Robert Sanborn, who, until he “retired” at a fairly young age, ran Oakmark Fund. Mr. Sanborn was an undisputed superstar manager. From its inception in 1991 to year-end 1998, Oakmark’s annualized return was 24.91% versus 19.56% for the S&P 500. In 1992, it beat the benchmark by an astonishing 41.28%. Mr. Sanborn’s performance was extremely unusual in that even the most powerful statistical tests showed that this could not have been due to chance. (Unlike Tsai’s record, which could easily be explained by his exposure to growth stocks and random variation.) A different story emerges when we examine the fund’s performance and assets by individual year. The first row tracks the performance of Oakmark Fund relative to the S&P 500 (that is, how much better or worse it did relative to the S&P) and the second row tracks the fund’s assets: What we see is the typical pattern of fund investors chasing performance, resulting in progressive asset bloat, with more and more investors getting lower and lower returns. It can be clearly seen that Mr. Sanborn had significant difficulties once his fund grew beyond a few billion dollars in size. There’s another depressing pattern that emerges from the above story: relatively few of a successful fund’s investors actually get its high early returns. The overwhelming majority hop onto the bandwagon just before it crashes off the side of the road. If we “dollar-weight” the fund’s returns, we find that the average investor in the Oakmark Fund underperformed the S&P by 7.55% annually. Jonathan Clements, of The Wall Street Journal, quips that when an investor says, “I own last year’s best-performing fund,” what he usually forgets to add is, “Unfortunately, I bought it this year.” And finally, one sad, almost comic, note. As we’ve already mentioned, most of the above studies show evidence of performance consistency in one corner of the professional heap—the bottom. Money managers who are in the bottom 20% of their peer group tend to stay there far more often than can be explained by chance. This phenomenon is largely explained by impact costs and high expenses. Those mangers that charge the highest management fees and trade the most frenetically, like Mr. Tsai and his gunslinger colleagues, incur the highest costs, year-in and year-out. Unfortunately, it’s the shareholders who suffer most. How the Really Big Money Invests There is one pool of money that is even bigger and better-run than mutual funds: the nation’s pension accounts. In fact, the nation’s biggest investment pools are the retirement funds of the large corporations and governmental bodies, such as the California Public Employees Retirement System (CALPERS), which manages an astounding $170 billion. These plans receive a level of professional management that even the nation’s wealthiest private investors can only dream of. If you are a truly skilled and capable manager, this is the playground you want to wind up in. For example, a top-tier pension manager is typically paid 0.10% of assets under management—in other words, $10 million per year on a $10 billion pool—more than most “superstar” mutual fund managers. Surely, if there is such a thing as skill in stock picking, it will be found here. Let’s see how these large retirement plans actually do. I’m indebted to Piscataqua Research for providing me with the data in Figure 3-4 , which shows the performance of the nation’s largest pension plans from 1987 to 1999. The average asset allocation for almost all of these plans over the whole period was similar—about 60% stocks and 40% bonds. So the best benchmark is a mix of 60% S&P 500 and 40% Lehman Bond Index. As you can see, more than 90% of these plans underperformed the 60/40 indexed mix. Discouraged by this failure of active management, these plans are slowly abandoning active portfolio management. Currently, about half of all pension stock holdings are passively managed, or “indexed,” including over 80% of the CALPERS stock portfolio. Figure 3-4. Performance of 243 large pension plans, 1987–1999. ( Source: Dimensional Fund Advisors, Piscataqua Research.) Small investors, though, have not “gotten it” yet; hope triumphs over experience and knowledge. If the nation’s largest mutual funds and pension funds, with access to the very best information, analysts, and computational facilities, cannot successfully pick stocks and managers, what do you think your chances are? How likely do you think it is that your broker or financial advisor will be able to beat the market? And if there actually were money managers who could consistently beat the market, how likely do you think it would be that you would have access to them? Comic Relief from Newsletter Writers and Other Market Timers The straw that struggling investors most frequently grasp at is the hope that they can increase their returns and reduce risk by timing the market—holding stocks when they are going up and selling them before they go down. Sadly, this is an illusion—one that is exploited by the investment industry with bald cynicism. It is said that there are only two kinds of investors: those who don’t know where the market is going and those who don’t know that they don’t know. But there is a rather pathetic third kind—the market strategist. These highly visible brokerage house executives are articulate, highly paid, usually attractive, and invariably well-tailored. Their job is to convince the investing public that their firm can divine the market’s moves through a careful analysis of economic, political, and investment data. But at the end of the day, they know only two things: First, like everybody else, they don’t know where the market is headed tomorrow. And second, that their livelihood depends upon appearing to know. We’ve already come across Alfred Cowles’s assessment of the dismal performance of market newsletters. Some decades later, noted author, analyst, and money manager David Dreman, in Contrarian Market Strategy: The Psychology of Stock Market Success, painstakingly tracked opinions of expert market strategists back to 1929 and found that their consensus was mistaken 77% of the time. This is a recurring theme of almost all studies of “consensus” or “expert” opinion; it underperforms the market about three-fourths of the time. The sorriest corner of the investment prediction industry is occupied by market-timing newsletters. John Graham and Campbell Harvey, two finance academicians, recently performed an exhaustive review of 237 market-timing newsletters. They measured the ability of this motley crew to time the market and found that less than 25% of the recommendations were correct, much worse than the chimps’ score of 50%. Even worse, there were no advisors whose calls were consistently correct. Once again, the only consistency was found at the bottom of the pile; there were several newsletters that were wrong with amazing regularity. They cited one very well-known advisor whose strategy produced an astounding 5.4% loss during a 13-year period when the S&P 500 produced an annualized 15.9% gain. More amazing, there is a newsletter that ranks the performance of other newsletters; its publisher believes that he can identify top-performing advisors. The work of Graham and Harvey suggests that, in reality, he is actually the judge at a coin flipping contest. (Although the work of Graham, Harvey, Cowles, and others does suggest one promising strategy: pick the very worst newsletter you can find. Then do the opposite of what it recommends.) When it comes to newsletter writers, remember Malcolm Forbes’s famous dictum: the only money made in that arena is through subscriptions, not from taking the advice. The late John Brooks, dean of the last generation of financial journalists, had an even more cynical interpretation: when a famous investor publishes a newsletter, it’s a sure tip-off that his techniques have stopped working. Eugene Fama Cries “Eureka!” If Irving Fisher towered over financial economics in the first half of the twentieth century, there’s no question about who did so in the second half: Eugene Fama. His story is typical of almost all of the recent great financial economists—he was not born to wealth, and his initial academic plans did not include finance. He majored in French in college and was a gifted athlete. To make ends meet, he worked for a finance professor who published—you guessed it—a stock market newsletter. His job was to analyze market trading rules. In other words, to come up with strategies that would produce market-beating returns. Looking at historical data, he found plenty that worked—in the past. But a funny thing happened. Each time he identified a strategy that had done beautifully in the past, it fell flat on its face in the future. Although he didn’t realize it at the time, he had joined a growing army of talented finance specialists, starting with Cowles, who had found that although it is easy to uncover successful past stock-picking and market-timing strategies, none of them worked going forward. This is a concept that even many professionals seem unable to grasp. How many times have you read or heard a well-known market strategist say that since event X had just occurred, the market would rise or fall, because it had done so eight out of the last ten times event X had previously occurred? The classic, if somewhat hackneyed, example of this is the “Super Bowl Indicator”: when a team from the old NFL wins, the market does well, and when a team from the old AFL wins, it does poorly. In fact, if one analyzes a lot of random data, it is not too difficult to find some things that seem to correlate closely with market returns. For example, on a lark, David Leinweber of First Quadrant sifted through a United Nations database and discovered that movements in the stock market were almost perfectly correlated with butter production in Bangladesh. This is not one I’d want to test going forward with my own money. Fama’s timing, though, was perfect. He came to the University of Chicago for graduate work not long after Merrill Lynch had funded the Center for Research in Security Prices (CRSP) in Chicago. This remarkable organization, with the availability of the electronic computer, made possible the storage and analysis of a mass and quality of stock data that Cowles could only dream of. Any time you hear an investment professional mention the year 1926, he’s telling you that he’s gotten his data from the CRSP. Fama had already begun to suspect that stock prices were random and unpredictable, and his statistically rigorous study of the CRSP data confirmed it. But why should stock prices behave randomly? Because all publicly available information, and most privately available information, is already factored into their prices. Sure, if your company’s treasurer has been recently observed to be acting peculiarly and hurriedly obtaining a Brazilian visa, you may be able to profit greatly (and illegally) from this information. But the odds that you will be able to repeat this feat with a large number of company stocks on a regular basis are zero. And with the increasing sophistication of Securities and Exchange Commission (SEC) surveil-lance apparatus, the chances of pulling this off even once without winding up a guest of the state grow dimmer each year. Put another way, the simple fact that there are so many talented analysts examining stocks guarantees that none of them will have any kind of advantage, since the stock price will nearly instantaneously reflect their collective judgment. In fact, it may be worse than that: there is good data to suggest that the collective judgment of experts in many fields is actually more accurate than their separate individual judgments. A vivid, if nonfinancial, example of extremely accurate collective judgment occurred in 1968 with the sinking of the submarine Scorpion. No one had a precise idea of where the sub was lost, and the best estimates of its position from dozens of experts were scattered over thousands of square miles of seabed. But when their estimates were averaged together, its position was pinpointed to within 220 yards. In other words, the market’s estimate of the proper price of a stock, or of the entire market, is usually much more accurate than that of even the most skilled stock picker. Put yet another way, the best estimate of tomorrow’s price is . . . today’s price. There’s a joke among financial economists about a professor and student strolling across campus. The student stops to pick up a ten-dollar bill he has noticed on the ground but is stopped by the professor. “Don’t bother,” he says, “if that were really a ten-dollar bill, someone would have picked it up already.” The market behaves exactly the same way. Let’s say that XYZ company is selling at a price of 40 and a clever analyst realizes that it is actually worth 50. His company or fund will quickly buy as much of the stock as it can get its hands on, and the price will quickly rise to 50 dollars per share. The whole sequence usually takes only a few days and is accomplished in great secrecy. Further, it is most often not completed by the original analyst. As other analysts notice the stock’s price and volume increase, they take a closer look at the stock and also realize that it is worth 50. In the stock market, one occasionally does encounter ten-dollar bills lying about, but only very rarely. You certainly would not want to try and make a living looking for them. The concept that all useful information has already been factored into a stock’s price, and that analysis is futile, is known as “The Efficient Market Hypothesis” (EMH). Although far from perfect, the EMH has withstood a host of challenges from those who think that actively picking stocks has value. There is, in fact, some evidence that the best securities analysts are able to successfully pick stocks. Unfortunately, the profits from this kind of sophisticated stock analysis are cut short by impact costs, as well as the above-described piggybacking by other analysts. In the aggregate, the benefits of stock research do not pay for its cost. The Value Line ranking system is a perfect example of this. Most academics who have studied the system are impressed with its theoretical results, but, because of the above factors, it is not possible to use its stock picks to earn excess profits. By the time the latest issue has hit your mailbox or the library, it’s too late. In fact, not even Value Line itself can seem to make the system work; its flagship Value Line Fund has trailed the S&P 500 by 2.21% over the past 15 years. Only 0.8% of this gap is accounted for by the fund’s expenses. If Value Line cannot make its system work, what makes you think that you can beat the market by reading the newsletter four days after it has left the presses? There’s yet another dimension to this problem that most small investors are completely unaware of: you only make money trading stocks when you know more than those on the other side of your trades. The problem is that you almost never know who those people are. If you could, you would find out that they have names like Fidelity, PIMCO, or Goldman Sachs. It’s like a game of tennis in which the players on the other side of the net are invisible. The bad news is that most of the time, it’s the Williams sisters. It never ceases to amaze me that small investors think that by paying $225 for a newsletter, logging onto Yahoo!, or following a few simple stock selection rules, they can beat the market. Such behavior is the investment equivalent of going up against the Sixth Fleet in a rowboat, and the results are just as predictable. Buffett and Lynch Any discussion about the failure of professional asset management is not complete until someone from the back of the room triumphantly raises his hand and asks, “What about Warren Buffett and Peter Lynch?” Even the most diehard efficient market proponent cannot fail to be impressed with their track records and bestow on them that rarest of financial adjectives—“skilled.” First, a look at the data. Of the two, Buffett’s record is clearly the most impressive. From the beginning of 1965 to year-end 2000, the book value of his operating company, Berkshire Hathaway, has compounded at 23.6% annually versus 11.8% for the S&P 500. The actual return of Berkshire stock was, in fact, slightly greater. This is truly an astonishing performance. Someone who invested $10,000 with Buffett in 1964 would have more than $2 million today. And, unlike the theoretical graphs which graced the first chapter, there are real investors who have actually received those returns. (Two of whom are named Warren Buffett and Charlie Munger, his Berkshire partner.) But it’s worth noting a few things. In the first place, Berkshire is not exactly a risk-free investment. For the one-year period ending in mid-March of 2000, the stock lost almost half its value, compared to a gain of 12% for the market. Second, with its increasing size, Buffett’s pace has slowed a bit. Over the past four years, he has beaten the market by less than 4% per year. Third, and most important, Mr. Buffett is not, strictly speaking, an investment manager—he is a businessman. The companies he acquires are not passively held in a traditional portfolio; he becomes an active part of their management. And, needless to say, most modern companies would sell their metaphorical mothers to have him in a corner office for a few hours each week. Peter Lynch’s accomplishments, while impressive, do not astound as Buffett’s do. Further, his personal history, while exemplary, gives pause. For starters, Lynch’s public career was much shorter than Buffett’s. Although he had worked at Fidelity since 1965, he was not handed the Magellan fund until 1977. Even then, the fund was not opened to the public until mid-1981—before that it was actually the private investment vehicle for Fidelity’s founding Johnson family. From mid-1981 to mid-1990, the fund returned 22.5% per year, versus 16.53% for the S&P 500. A remarkable accomplishment, to be sure, but not in the same league as Buffett’s. In fact, not at all that unusual. As I’m writing this, more than a dozen domestic mutual funds have beaten the S&P 500 by more than 6%—Lynch’s margin—during the past 10 years. This is about what you would expect from chance alone. The combination of his performance and Fidelity’s marketing muscle resulted in a cash inflow the likes of which had never been seen before. Beginning with assets of under $100 million, Magellan grew to more than $16 billion by the time Lynch quit just nine years later. Lynch’s name and face became household items; even today, more than a decade after his retirement, his white-maned gaunt visage is among the most recognized in finance. The combination of Magellan’s rapidly increasing size and fame’s klieg light took its inevitable toll. With an unlucky draw of the cards, Lynch was out of the country in the days leading up to the market crash of 1987. That year, he underperformed the market by almost 5%. Driven by mild public criticism and a stronger need to prove to himself that he still had the magic, he threw himself into his work, turning in good performances in 1988 and 1989. As the fund’s assets swelled, he had to make two major accommodations. First, he had to focus on increasingly large companies. Magellan originally invested in small- to mid-sized companies: names like La Quinta and Congoleum. But by the end of his tenure, he was buying Fannie Mae and Ford. If there is such a thing as stock selection skill, then the greatest profits should be made with smaller companies that have scant analyst coverage. By being forced to switch to large companies, which are extensively picked over by stock analysts, Lynch found the payoff of his skills greatly diminished. Second, he had to purchase more and more companies in order to avoid excessive impact costs. By the end of his tenure, Magellan held more than 1,700 names. Both of these compromises drastically lowered his performance relative to the S&P 500 Index. Figure 3-5 vividly plots his decreasing margin of victory versus the index. During his last four years, he was only able to outperform the S&P 500 by 2%. Exhausted, he quit in 1990. Now, having considered these two success stories, let’s take a step back and draw some conclusions: • Yes, Lynch and Buffett are skilled. But these two exceptions do not disprove the efficient market hypothesis. The salient observation is that, of the tens of thousands of money managers who have practiced their craft during the past few decades, only two showed indisputable evidence of skill—hardly a ringing endorsement of professional asset management. • Our eyes settle on Buffett and Lynch only in retrospect. The odds of picking these two out of the pullulating crowd of fund managers ahead of time is nil. (It’s important to note that just before Magellan was opened to the public, Fidelity merged two unsuccessful It’s bad enough that mutual-fund manager performance does not persist and that the return of stock picking is zero. This is as it should be, of course. These guys are the market, and there is no way that they can all perform above the mean. Wall Street, unfortunately, is not Lake Wobegon, where all the children are above average. Figure 3-5. Magellan versus S&P 500: The Lynch years. ( Source: Morningstar Principia Pro Plus.) • For the mutual fund investor, even Peter Lynch’s performance was less than stellar. After his talent became publicly known around 1983, this intensely driven individual could continue outperforming the market for just seven more years before he saw the handwriting on the wall and quit at the top of his game. It is not commonly realized that the investing public had access to Peter Lynch for exactly nine years, the last four of which were spent exerting a superhuman effort against transactional expense to maintain a razor thin margin of victory. “incubator funds”—Essex and Salem—into it.) On the other hand, there have been hundreds of stories like Tsai’s and Sanborn’s—managers who excelled for a while, but whose performance flamed out in a hail of assets attracted by their initial success. The Really Bad News The bad news is that the process of mutual fund selection gives essentially random results. The really bad news is that it is expensive. Even if you stick with no-load funds, you will still incur hefty costs. Even the best-informed fund investors are usually unaware as to just how high these costs really are. Most investors think that the fund’s expense ratio (ER) listed in the prospectus and annual reports is the true cost of fund ownership. Wrong. There are actually three more layers of expense beyond the ER, which only comprises the fund’s advisory fees (what the chimps get paid) and administrative expenses. The next layer of fees is the commissions paid on transactions. These are not included in the ER, but since 1996 the SEC has required that they be reported to shareholders. However, they are presented in the funds’ annual reports in such an obscure manner that unless you have an accounting degree, it is impossible to calculate how much return is lost as a percentage of fund assets. The second extra layer of expense is the bid/ask “spread” of stocks bought and sold. A stock is always bought at a slightly higher price than its selling price, to provide the “market maker” with a profit. (Most financial markets require a market maker—someone who brings together buyers and sellers, and who maintains a supply of securities for ready sale to ensure smooth market function. The bid/ask spread induces organizations to provide this vital service.) This spread is about 0.4% for the largest, most liquid companies, and increases with decreasing company size. For the smallest stocks it may be as large as 10%. It is in the range of 1% to 4% for foreign stocks. The last layer of extra expense—market impact costs, which we’ve already discussed—is the most difficult to estimate. Impact costs are not a problem for small investors buying shares of individual companies but are a real headache for mutual funds. Obviously, the magnitude of impact costs depends on the size of the fund, the size of the company, and the total amount transacted. As a first approximation, assume that it is equal to the spread. The four layers of mutual fund costs: • Expense Ratio • Commissions • Bid/Ask Spread • Market Impact Costs Taken together, these four layers of expense are least for large-cap funds, intermediate for small-cap and foreign funds, and greatest for emerging market funds. They are tabulated in Table 3-1 . Table 3-1. The Expense Layers of Actively Managed Mutual Funds Recall that the nominal return of stocks in the twentieth century was 9.89% per year, and that, based on the DDM, the actual real returns that future investors will receive may be very much smaller. It should be painfully obvious that this is not the return that you, the mutual fund investor, will actually receive. You must subtract from that return your share of the fund’s total investment expense. Now the full magnitude of the problem becomes clear. The bottom row of Table 3-1 shows the real costs of owning an actively managed fund. In fairness, this does overstate things a bit. Money spent on research and analysis is not a total loss. As we’ve seen, such research does seem to increase returns, but almost always by an amount less than that spent. How much of the first expense-ratio line is spent on research? Figure about half, if you’re lucky. So, even if we use the more generous historical 9.89% stock return as our guideline, active management will lose you about 1.5% in a large-cap fund, 3.3% in a foreign/small cap fund, and 8% in an emerging markets fund, leaving you with 8.4%, 6.6%, and 1.9%, respectively. Not an appetizing prospect. The mutual fund business has benefited greatly by the high returns of recent years that have served to mask the staggering costs in most areas. One exception to this has been in the emerging markets, where the combination of low asset class returns and high expenses has resulted in a mass exodus of investors. Bill Fouse’s Bright Idea By 1970, professional investors could no longer ignore the avalanche of data documenting the failure of supposed expert money managers. Up until that point, money management was based on the Great Man theory: find the Great Man who could pick stocks and hire him. When he loses his touch, go out looking for the next Great Man. But clearly, that idea was bankrupt: there were no Great Men, only lucky chimpanzees. There is no greater test of character than confrontation with solid evidence that the whole of your professional life has been a lie—that the craft that you have struggled so hard to master is worthless. Most money managers fail this trial and are still in the deepest stages of denial. We’ll examine their rationalizations for active management at the end of this chapter. The cream of the crop—thoughtful and intelligent observers like Peter Bernstein (no relation), Ben Graham, James Vertin, and Charles Ellis—painfully reexamined their beliefs and adjusted their practices. Let’s summarize the bleak landscape they surveyed: • The gross returns obtained by money managers were in the aggregate the market’s, since they were the market. • The average net return to investors was the market return minus the expense of active stock selection. Since this averaged between 1% and 2%, the typical investor received about 1% to 2% less than the market return. • There seemed to be few managers capable of consistently beating the market. Worst of all, there were almost no managers capable of persistently beating it by the 1% to 2% margin necessary to pay for their expenses. One of the professionals surveying the scene in the late 1960s was a young man named William Fouse. Excited by the new techniques of portfolio evaluation, he began evaluating the performance of his colleagues at his employer, Mellon Bank. He was aghast—none of those money managers came even close to beating the market. Today, for a dollar, you can pick up The Wall Street Journal and compare the performance of thousands of mutual funds to the S&P 500. It’s remarkable to remember that 30 years ago, investors and clients never thought to compare their performance to an index, or, in many cases, even to ask what their performance was. Sadly, the average client and his broker still do not calculate and benchmark their returns. The solution was obvious to Mr. Fouse, however. Create a fund that would buy all the stocks in the S&P 500 Index. This could be done with a minimum of expense and was guaranteed to produce very close to the market return. His idea was met with approximately the same enthusiasm as a stink bomb at a debutante ball. Very soon he found himself looking for alternative employment. Fortunately, Fouse wound up at Wells Fargo, which provided a more receptive environment for the ideas of modern finance. In 1971, the old-school head of the trust department, James Vertin, reluctantly gave the go-ahead and Wells Fargo founded the first index fund. It was an unmitigated disaster. Instead of using Fouse’s original S&P 500 idea, they decided to hold an equal dollar amount of all 1,500 stocks on the New York Stock Exchange. Since the stock price of its companies often moved in radically different directions, this required almost constant buying and selling to keep the values of each position equal. This, in turn, resulted in expenses equal to that of an actively managed fund. It was not until 1973 that Fouse’s original idea, a fund that held all of the stocks in the S&P 500 in proportion to their market value (and thus did not need rebalancing), was adopted. At this point, it’s necessary to define what we mean by an “index fund.” This usually refers to a fund that owns all, or nearly all, of the stocks in a given index, with no attempt to pick those with superior performance. Less commonly, it refers to a fund that holds all stocks meeting certain rigid criteria, usually having to do with market size or growth/value characteristics, such as price-to-book ratio. Today, almost all index funds are “cap weighted.” This means that if the value of a stock doubles or falls by half, its proportional contribution in the index does as well, so it is not necessary to buy or sell any to keep things in balance. Thus, as long as the stocks remain in the index, it is not necessary to buy or sell stocks because of changes in market value. Wells Fargo’s index fund was not initially available to the general public, but that was soon to change. A few years later, in September 1976, John Bogle’s young Vanguard Group offered the first publicly available S&P 500 Index fund. Vanguard’s fund was not exactly a roaring success out of the starting gate. After two years, it had collected only $14 million in assets. In fact, it did not cross the billion-dollar mark—the radar threshold of the fund industry—until 1988. But as the advantages of indexing became evident to small investors, it took off. For the past few years, it has been running neck-and-neck for the number one spot in asset size with Lynch’s old fund, Magellan. Truth be told, the Vanguard 500 Index Fund has gotten a little too popular. Of all the major stock indexes, the S&P 500 has done the best in recent years. Much of the new assets that the fund has collected are “hot money,” coming from naïve investors who are simply chasing performance. There’s another facet to this as well: Dunn’s Law, a phenomenon that affects index funds. Dunn’s Law states that when an index does well (that is, it does better than other asset classes), indexing that particular asset class does very well compared to actively managed funds. For example, in each of the years between 1994 and 1998, the Vanguard 500 Index Fund ranked in the top quarter in its peer group of funds—the so-called “large blend” category. But in 2000, it dropped into the lower half of the category. This was largely because the S&P 500 dramatically outperformed all other indexes from 1994 to 1998, but was the worst of the indexes in 2000. How well has indexing worked? The proper way to judge is to compare like with like—that is, to compare a large-growth index fund with all the funds in the large growth category. Morningstar Inc. is the world’s premier purveyor of mutual fund investment tools. I’ve used their Principia Pro software package to rank the performance of the appropriate Vanguard index fund or S&P/Barra index in its Morningstar category for the five years ending March 31, 2001. The rankings are percentile rankings, ranging from a ranking of 1 for the top percentile and 100 for the worst: So, in seven of nine categories, the index approach produces above-average results, and in four of the nine categories, top-quarter performance. A few observations are in order. First, the Morningstar database suffers from survivorship bias—it does not include the deceased funds in each group. Were these to be included, the performance of the indexes would look even better. Second, as the time horizon lengthens, index fund relative performance improves even more. In the words of Jonathan Clements of The Wall Street Journal, “Performance comes and goes. Expenses are forever.” We have data for four categories—large growth, large blend, large value, and small blend—going back 15 years (ending March 31, 2001). The percentile rankings for these indexes and funds are 24, 20, 17, and 23. Clearly, the best way to avoid the expensive chimpanzees is to simply keep your expenses to a minimum and buy the whole market with an index fund. Taxes If the case I’ve presented for indexing is not powerful enough for you, then consider the effect of taxes. While many of us hold funds in our retirement accounts, where taxability of distributions is not an issue, most investors also own funds in taxable, nonsheltered accounts. While it is probably a poor idea to own actively managed funds in general, it is truly a terrible idea to own them in taxable accounts, for two reasons. First, because of their higher turnover, actively managed funds have higher distributions of capital gains, which are taxed at both the federal and state level. The typical actively managed fund distributes several percent of its assets each year in capital gains. If turnover is high enough, a substantial portion of these will be short-term, which are taxed at the higher ordinary rate: this will amount to a 1% to 4% drag on performance each year. Many index funds allow your capital gains to grow largely undisturbed until you sell. There is another factor to consider as well. Most actively managed funds are bought because of their superior performance. But, as we’ve demonstrated above, outperformance does not persist. As a result, most small investors using active-fund managers tend to turn over their mutual funds once every several years in the hopes of achieving better returns elsewhere. What actually happens is that they generate more unnecessary capital gains and resultant taxes. For the taxable investor, indexing means never having to pay the tax and investment consequences of a bad manager. Why Can’t I Just Buy and Hold Stocks on My Own? Some of you may ask, “If the markets are efficient, why can’t I simply buy and hold my own stocks? That way, I’ll never sell them and incur capital gains as I would when an index occasionally changes its composition, forcing capital gains in the index funds that track it. And since I’ll never trade, my expenses will be even lower than an index fund’s.” In fact, until recently, periodic turnover in the stock composition of some indexes has been a problem at tax time. An excellent example is Vanguard’s Small-Cap Index Fund, which in recent years has penalized its taxable shareholders by distributing about 10% of its value each year as capital gains. Fortunately, there are now “tax-efficient” index funds designed for taxable accounts, which are generally able to avoid capital gains. In 1999, Vanguard created its Tax-Managed Small-Cap Index Fund, which minimizes both capital gains and dividend distributions. But there is a much more important reason why you should not attempt to build your own portfolio of stocks, and that is the risk of buying the wrong ones. You may have heard that you can obtain adequate diversification by holding as few as 15 stocks. This is true only in terms of lowering short-term volatility. But the biggest danger facing your portfolio is not short-term volatility—it’s the danger that your portfolio will have low long-term returns. In other words, you can buy a 15-stock portfolio that has low volatility, but it may put you in the poorhouse just the same. In order to demonstrate the risks of not owning enough stocks, Ronald Surz of PPCA Inc., a provider of investment software, kindly supplied me with some data he generated on the returns of random stock portfolios, which I plotted in Figure 3-6 . Mr. Surz examined 1,000 random portfolios of 15, 30, and 60 stocks. What you are looking at is the final wealth of these portfolios relative to the market. For example, look at the cluster of bars on the left—the 15-stock portfolios. First, note the middle black bar and the thick horizontal line through it, which represents the market return at the 50th percentile (the median performance). By definition, this returned $1.00 of wealth after 30 years relative to the market—that is, it got the market return. The bar at the extreme left, representing 5th percentile performance, beating 95% of all of the random portfolios, returned two-and-one-half times the wealth of the market portfolio. At the 25th percentile—the top quarter of performance—you got almost 50% more than the market’s final wealth. Figure 3-6 shows us just how much luck can contribute to portfolio performance. The 60-stock portfolios are about the size of a small mutual fund. Notice that, purely by chance, one out of 20 of the portfolios had a 30-year wealth of $1.77 or more, relative to the market’s $1.00. This means that, by accident, these portfolios beat the market by more than 2% per year over 30 years—enough to put any manager in the Mutual Fund Hall of Fame. (The 95th-percentile-by-accident portfolios would similarly be expected to beat the market by more than 10% in any one-year period.) Now, go back to the 15-stock portfolios on the left. If you were unlucky and got bottom quarter performance (the fourth bar), after 30 years you only received 70 cents on the dollar. And if you were really unlucky and got bottom 5% performance (95th percentile), then you received only 40 cents on the dollar. Note how adding more stocks (the 30-stock and 60-stock portfolios) moderates the differences in returns—the lucky picks don’t do quite as well, and the bad draws don’t do quite as badly. Finally, if you own all the stocks in the market, you will always get the market return, with no risk of failing to obtain it. Figure 3-6 demonstrates the central paradox of portfolio diversification. Obviously, a concentrated portfolio maximizes your chance of a superb result. Unfortunately, at the same time, it also maximizes your chance of a poor result. This issue gets to the heart of why we invest. You can have two possible goals: One is to maximize your chances of getting rich. The other is to minimize your odds of failing to meet your goals or, more bluntly, to make the likelihood of dying poor as low as possible. Figure 3-6. 30-year wealth of nondiversified portfolios relative to the S&P 500. ( Source: Ronald Surz.) It’s important for all investors to realize that these two goals are mutually exclusive. For example, let’s say that you have $1,000 and want to turn it into $1,000,000 within a year. The only legal way that you have a prayer of doing so is to go out and buy 1,000 lottery tickets. Of course, you will almost certainly lose most of your money. On a more mundane level, let’s say that in order to retire in ten years, you need to obtain a 30% annualized return during that period. It is quite possible to do this: 113 of the 2,615 stocks with ten-year histories listed in the Morningstar database have had ten-year annualized returns in excess of 30%. Of course, 496 of those 2,615 stocks had negative returns and that doesn’t count the bankrupted stocks missing from the database. In fact, only 885 of the stocks had returns higher than the S&P 500. In other words, concentrating your portfolio in a few stocks maximizes your chances of getting rich. Unfortunately, it also maximizes your chance of becoming poor. Owning the whole market—indexing—minimizes your chances of both outcomes by guaranteeing you the market return. A recent innovation—stock “folios”—have been touted as an inexpensive and tax-efficient way for small investors to own portfolios of 30 to 150 stocks. As you can see, these new vehicles fail to provide investors with an adequate degree of diversification. Take a long, hard look at Figure 3-6 . Realize that the market return is by no means certain: neither I nor anyone else really knows precisely what it will be. Failing to diversify properly is the equivalent of taking that uncertain return and then going to Las Vegas with it. It’s bad enough that you have to take market risk. Only a fool takes on the additional risk of doing yet more damage by failing to diversify properly with his or her nest egg. Avoid the problem—buy a well-run index fund and own the whole market. Why Indexing “Doesn’t Work,” and Other Transparent Rationalizations It should be painfully apparent by now that most of the investment industry is engaged in nonproductive work. When faced with ironclad data, it takes intellectual honesty in tank-car quantity to admit that you are harming your clients, or that your entire professional life has been for naught. Unfortunately, the investment industry is not known for an abundance of critical self-examination. It is much easier to offer excuses and rationalizations about why you should avoid indexing and continue to use active management. Here are the most common ones you’ll hear: • “Indexing did terribly last year.” It’s true. In some years, “indexing” (by which is usually meant the S&P 500) does sometimes underperform most actively managed funds. For example, in 1977, 1978, and 1979, Vanguard’s S&P 500 index fund ranked in the 85th, 75th, and 72nd percentiles of all stock funds. The reason was Dunn’s Law: in those three years, small stocks did much better than large stocks. Since the S&P 500 consists only of the largest stocks, it could not benefit from holding better-performing small stocks, whereas the active managers were free to own them. In fact, in any given year, you can predict roughly how well an S&P 500 index fund will rank by comparing the returns of small versus large stocks—it will do well when large stocks do better, and worse when small stocks do better. There’s an even more important point to be made here, which is that the “index advantage,” typically 1% to 2% per year, is small enough that, in any given year, a large number of actively managed funds will beat the market. Remember Mr. Clements’ dictum: “Performance comes and goes. Expenses are forever.” As the time horizon lengthens, the odds that an active manager will beat the index by enough to pay for her expenses slowly vanish. • “Indexing works fine for large stocks, but in the less efficient small-cap market, active analysis pays off.” This is really the flip side of Dunn’s Law. It’s true: indexing small stocks has not worked terribly well over the past decade. But it is because small-cap stocks have not done well. Dimensional Fund Advisors runs the oldest small-cap index fund: It ranks in the 23rd percentile of all surviving small cap funds for the past 15 years. In those years when small caps have done well, indexing them has also done well. For example, for the years 1992–1994, this Fund ranked in the 13th percentile of the Morningstar small-cap category, and, for the three years ending August 2001, in the 29th percentile. If survivorship bias were taken into account, it would almost certainly have had even higher rankings. Even if it is possible for active managers to successfully pick small stocks, transactional costs in this arena are much higher than with large stocks, so any gains from stock picking will be more than offset by the costs of trading small stocks. • “Active managers do better than index funds in down markets.” This is flat-out wrong—they certainly do not. For example, from January 1973 to September 1974, according to Lipper Inc., the average domestic stock fund lost 47.9%, versus a loss of 42.6% for the S&P 500. And from September to November 1987, the average stock fund lost 28.7%, only slightly better than the S&P 500’s 29.5% loss. This is particularly amazing in view of the fact that most actively managed funds generally carry about 5% to 10% in cash, whereas, by definition, index funds hold hardly any. • “Index funds expose you to forced capital gains in the event of a market panic.” The argument here is a subtle one: During a market panic, investors will pull their money out of index funds, forcing the funds to sell appreciated shares, saddling the remaining shareholders with unwanted capital gains. Even at first glance, this is a nonstarter. Most index fund investors, like active fund investors, are simply chasing performance and, as such, tend to buy at high prices. As prices fall, the fund can sell those shares at a loss. The fund most vulnerable to this concern is the Vanguard 500 Index Fund, which, because of its age and size, contains some shares bought 25 years ago at a small fraction of their current value. After the events of September 11, its shareholders did not panic and the fund experienced only minuscule net sales. By month’s end, the fund contained less than 10% embedded capital gains. Any further fall in prices, even if it precipitated panic selling of the fund, would thus also have completely wiped out the embedded capital gains problem. At the present time, no other Vanguard stock-index fund has any significant remaining embedded capital gains exposure. Vanguard’s popular Total Stock Market Fund, which tracks the Wilshire 5000, has a significant negative capital gains exposure. • “An index fund dooms you to mediocrity.” Absolutely not: it virtually guarantees you superior performance. Over the typical ten-year period, most money managers would kill for index-matching returns. Money manager and author Bill Schultheis likens the active-versus-indexed fund choice to a shell game in which there are ten boxes, with the following amounts under each box: You can pick a random box, or you can take a guaranteed payment of $8,000. Yes, it’s possible to beat the index, but since we’ve shown that because of expenses, active managers do worse than chimpanzees, the more likely probability is that you’ll also do much worse. Finally, there is one legitimate criticism that can be leveled at an indexing strategy: You will never have exceptional returns; you will never get fabulously rich. As we’ve already discussed, poorly diversified strategies do indeed maximize your chances of winding up with bags of money. Unfortunately, they also maximize your chances of ending your days in a trailer park. Giving up a shot at the brass ring does bother a lot of investors. But that’s your own choice; no one else can make it for you. The market possesses an awesome power that cannot be easily overcome. Were Obi-Wan Kenobi an investment advisor, it’s clear what he’d tell his clients: “Use the force. Index your investments.” Chapter 3 SUMMARY 1. There is almost no evidence of stock-picking skill among professional money managers; from year to year, manager relative performance is nearly random. 2. There is absolutely no evidence that anyone can time the market. 3. The gross (before expenses) return of the average money manager is the market return. 4. The expected net (after expenses) return of a money manager is the market return minus expenses. 5. The most reliable way of obtaining a satisfying return is to index (own the whole market).",
        "char_count": 68565
      },
      {
        "heading": "Chapter 10",
        "text": "4 The Perfect Portfolio Let’s summarize the practical lessons from the first three chapters: • Risk and reward are inextricably intertwined. If you desire high returns, you will have to purchase risky assets—namely, stocks. • You are not capable of beating the market. But do not feel bad, because no one else can, either. • Similarly, no one—not you, not anyone else—can time the market. As Keynes said, it is the duty of shareholders to periodically suffer loss without complaint. • Owning a small number of stocks is dangerous. This is a particularly foolish risk to take, since, on average, you are not compensated for it. We have already come to some conclusions about what this means: the intelligent investor’s stock exposure should be to the entire market. What we haven’t yet discussed is exactly how much of your assets you should expose to the market, or even what we mean by “the market.” These two issues—how much of your overall assets you should place in stocks and how you should allocate your assets between different classes of stocks—form the core of “asset allocation.” In the 1980s, famed investor Gary Brinson and his colleagues published a pair of papers purporting to demonstrate that more than 90% of the variation in investment returns is due to asset allocation and less than 10% to timing and stock selection. These articles have been hotly contested by practitioners and academicians ever since. However, this controversy completely misses the point: it does not matter how much of your return is determined by timing or stock selection—no sane investor denies that these are important determinants of return. It’s just that you can’t control the results of timing and selection—asset allocation is the only factor you can positively impact. In other words, since you cannot successfully time the market or select individual stocks, asset allocation should be the major focus of your investment strategy, because it is the only factor affecting your investment risk and return that you can control. It’s important to make perfectly clear what we can and cannot do. In examining the behavior of different kinds of portfolios, all we have to rely on is the historical record. It is easy to obtain the monthly or annual returns of various classes of stock assets, feed them into a spreadsheet or a device called a “mean variance optimizer” (MVO) and determine precisely which combinations of these assets worked the best. But we can only do this in the past tense; it tells us nearly nothing about future portfolio strategy. If anyone tells you that he knows the future’s best allocation, nod slowly, slide back several steps, turn, and run like hell. Let me give you a simple example. For the 20 years from 1970 to 1989, the best performing stock assets were Japanese stocks, U.S. small stocks, and precious metals (gold) stocks. At the end of that period, MVOs began making their way to the desktops of financial planners. In went the historical data and out came portfolios consisting almost exclusively of, you guessed it, Japanese, U.S. small company, and gold stocks. These turned out to be the worst performing assets over the next decade. In fact, designing stock portfolios based on past performance is usually a prescription for disaster. Is it possible to predict which portfolios will perform best in the future? Of course not. In order to do so, you need to be able to predict future asset class behavior with a high degree of accuracy. This is the same thing as timing the market which, you already know, cannot be done. And if it could, you would not need an MVO or any of its fancier relatives. You would simply go out and buy the best performing assets. (Or, to paraphrase Will Rogers, buy only those stocks that are going to go up.) The Portfolio’s the Thing First and foremost, it’s important that you manage all of your financial assets—retirement accounts, taxable accounts, kids’ college money, emergency money, etc.—as a single portfolio. For example, assume you own an S&P 500 index fund. If it returns, say, 10% in a given year, does it bother you that some of the stocks in it may have lost more than 80% of their value, as will happen to a few each year? Of course not. A globally diversified portfolio behaves the same way, except that the performance of each component is now more visible to you in the form of returns data in the daily paper and your quarterly statements. As an example, I’ve listed the returns for 1998, 1999, and 2000 for some of the most commonly used stock asset classes: This three-year sequence is a pretty typical one. Let’s start with 1998. In the first place, a diversified portfolio did reasonably well in that year. U.S. large stocks did the best, but REITs lost a lot of money. Many investors got discouraged that year and sold their REITs. They were soon sorry because by 2000, stock returns were generally poor and REITs were the only stock asset with superlative returns. Foreign and U.S. large stocks, which delivered excellent returns in the first two years, took a nosedive in 2000. The key is to ignore the year-to-year relative performance of the individual asset classes—their behavior usually averages out over the years—it is the long-term behavior of your whole portfolio that matters, not its day-to-day variation. If you cannot help focusing on the performance of the individual asset classes in your portfolio, at least do so only over as long a period as possible. With training and experience, most investors take these normal asset class ups and downs in stride. (There is even a way to take advantage of them, which we’ll discuss later in the chapter.) But some investors cannot. If you are such an individual and become upset when one of your asset classes does poorly, even when the rest of your portfolio is doing well, then you should not be managing your own money. I can guarantee you that each and every year you will have at least one or two poorly performing assets. And in some years, like 2000, most will behave miserably. If you cannot handle the routine asset class volatility inherent in the capital markets, then you should have a reputable financial advisor making your investment decisions. Your decisions will forever be clouded by your emotional responses to normal market activity. Our exploration of the asset allocation process will proceed in several steps. We’ll start with the most important allocation question of all: the decision of how much of your capital to put at risk. Step One: Risky Assets, Riskless Assets Distilled to its essence, there are only two kinds of financial assets: those with high returns and high risks, and those with low returns and low risks. The behavior of your portfolio is determined mainly by your mix of the two. As we learned in Chapter 1 , all stocks are risky assets, as are long-term bonds. The only truly riskless assets are short-term, high-quality debt instruments: Treasury bills and notes, high-grade short-term corporate bonds, certificates of deposit (CDs), and short-term municipal paper. To be considered riskless, their maturity should be less than five years, so that their value is not unduly affected by inflation and interest rates. Some have recently argued that Treasury Inflation Protected Securities (TIPS) should also be considered riskless, in spite of their long maturities, because they are not negatively affected by inflation. What we’ll be doing for the rest of this chapter is setting up a “laboratory” in which we create portfolios composed of various kinds of assets in order to see what happens to them as the market fluctuates. How we compute the behavior of these portfolios is beyond the scope of this book; for those few of you who are interested, I suggest that you read the first five chapters of my earlier book, The Intelligent Asset Allocator. Suffice it to say that it is possible to simulate with great accuracy the historical behavior of portfolios consisting of many assets. Keep in mind that this is not the same as predicting the future behavior of any asset mix. As we discussed in the first chapter, historical returns are a good predictor of future risk, but not necessarily of future return. Let’s start with the simplest portfolios: mixtures of stocks and T-bills. I’ve plotted the returns of Treasury bills, U.S. stocks, as well as 25/75, 50/50, and 75/25 mixes of the two, in Figures 4-1 through 4-5 . In order to give an accurate idea of the risks of each portfolio, I’ve shown them on the same scale. As you can see, when we increase the ratio of stocks, the amount lost in the worst years increases. This is the face of risk. In Table 4-1 , I’ve tabulated the return, as well as the damage, in the 1973–74 bear markets for a wide range of bill/stock combinations. Finally, in Figure 4-6 , I’ve plotted the long-term returns of each of these portfolios versus their performance in 1973–1974. Figure 4-6 provides the conceptual heart of this chapter, and it’s worth dwelling on for a few minutes. What you are looking at is a map of portfolio return versus risk. The numbers along the left-hand edge of the vertical axis represent the annualized portfolio returns. The higher up on the page a portfolio lies, the higher its return. The numbers on the horizontal axis, at the bottom of the graph, represent risk. The further off to the left a portfolio lies, the more money it lost in 1973–74, and the riskier it is likely to be in the future. Figure 4-1. All Treasury bill annual return, 1901–2000. ( Source: Jeremy Siegel.) Figure 4-2. Mix of 25% stock/75% Treasury bill annual returns, 1901–2000. ( Source: Jeremy Siegel.) Figure 4-3. Mix of 50% stock/50% Treasury bill annual returns, 1901–2000. ( Source: Jeremy Siegel.) Figure 4-4. Mix of 75% Stock/25% Treasury bill annual returns, 1901–2000. ( Source: Jeremy Siegel.) Figure 4-5. All-stock annual returns, 1901–2000. ( Source: Jeremy Siegel.) It’s important to clear up a bit of confusing terminology first. Until this point in the book, we’ve used two designations for fixed-income securities: bonds and bills, referring to long- and short-duration obligations, respectively. Bonds and bills are also different in one other respect: bonds most often yield regular interest, whereas bills do not—they are simply bought at a discount and redeemed at face value. The most common kinds of bills in everyday use are Treasury bills and commercial paper, the latter issued by corporations. Long-duration bonds are generally a sucker’s bet—they are quite volatile, extremely vulnerable to the ravages of inflation, and have low long-term returns. For this reason, they tend to be bad actors in a portfolio. Most experts recommend keeping your bond maturities short—certainly less than ten years, and preferably less than five. From now on, when we talk about “stocks and bonds,” what we mean by the latter is any debt security with a maturity of less than five to ten years—T-bills and notes, money market funds, CDs, and short-term corporate, government agency, and municipal bonds. For the purposes of this book, when we use the term “bonds” we are intentionally excluding long-term treasuries and corporate bonds, as these do not have an acceptable return/risk profile. I’ll admit that this is a bit confusing. A more accurate designation would be “stocks and relatively short-term fixed-income instruments,” but this wording is unwieldy. Table 4-1. 1901–2000, 100-Year Annualized Return versus 1973–1974 Bear Market Return The data in Table 4-1 and the plot in Figure 4-6 vividly portray the tradeoff between risk and return. The key point is this: the choice between stocks and bonds is not an either/or problem. Instead, the vital first step in portfolio strategy is to assess your risk tolerance. This will, in turn, determine your overall balance between risky and riskless assets—that is, between stocks and short-term bonds and bills. Many investors start at the opposite end of the problem—by deciding upon the amount of return they require to meet their retirement, educational, life style, or housing goals. This is a mistake. If your portfolio risk exceeds your tolerance for loss, there is a high likelihood that you will abandon your plan when the going gets rough. That is not to say that your return requirements are immaterial. For example, if you have saved a large amount for retirement and do not plan to leave a large estate for your heirs or to charity, you may require a very low return to meet your ongoing financial needs. In that case, there would be little sense in choosing a high risk/return mix, no matter how great your risk tolerance. Figure 4-6. Portfolio risk versus return of bill/stock mixes, 1901–2000. There’s another factor to consider here as well, and that’s the probability that stock returns may be lower in the future than they have been in the past. The slope of the portfolio curve in Figure 4-6 is steep—in other words, in the twentieth century, there was a generous reward for bearing additional portfolio risk. It is possible, for example, that the future risk/reward plot may look something like Figure 4-7 , with a much lower difference in returns between risky and risk-free investments. In this illustration, I’ve assumed a 7% return for stocks and a 5.5% return for bonds. In such a world, it makes little sense to take the high risk of an all-stock portfolio. Finally, it cannot be stressed enough that between planning and execution lies a yawning chasm. It is one thing to coolly design a portfolio strategy on a sheet of paper or computer monitor, and quite another to actually deploy it. Thinking about the possibility of losing 30% of your capital is like training for an aircraft crash-landing in a simulator; the real thing is a good deal more unpleasant. If you are just starting out on your investment journey, err on the side of conservatism. It is much better to underestimate your risk tolerance at an early age and adjust your risk exposure upwards later than to bite off more than you can chew up front. Figure 4-7. Likely future portfolio risks/returns. Millions of investors in the 1920s and 1960s thought that they could tolerate a high exposure to stocks. In both cases, the crashes that followed drove most of them from the equity markets for almost a generation. Since the risk of your portfolio is directly related to the percentage of stocks held, it is better that you begin your investment career with a relatively small percentage of stocks. This flies directly in the face of one of the prime tenets of financial planning conventional wisdom: that young investors should invest aggressively, since they have decades to make up their losses. The problem with an early aggressive strategy is that you cannot make up your losses if you permanently flee the stock market because of them. This all adds up to one of the central points of asset allocation: Unless you are absolutely certain of your risk tolerance, you should probably err on the low side in your exposure to stocks. Step Two: Defining the Global Stock Mix Why diversify abroad? Because foreign stocks often zig when domestic markets zag, or at least may not zig as much. Let’s look at the most recent data. In the early part of this century, the international capital markets were a good deal more integrated than they are now. It was commonplace for an Englishman to buy American bonds or French stocks, and there were few barriers to cross-border capital flow. The two World Wars changed that; the international flow of capital recovered only slowly afterwards. The modern history of international diversification properly begins in 1969, with the inception of Morgan Stanley’s EAFE (Europe, Australasia, and Far East) Index. As of year-end 2000, there is a 32-year track record of accurate foreign returns. For the period, this index shows an 11.89% annualized return for foreign investing, versus 12.17% for the S&P 500. Why invest in foreign stocks if their returns are the same, or perhaps even less than U.S. stocks? There are two reasons: risk and return. In Figure 4-8 , I’ve plotted the annual returns of the two indexes. Note how there can be a considerable difference in return between the two in any given year. Particularly note that during 1973 and 1974, the EAFE lost less than the S&P: a total 33.16% loss for the EAFE versus a 37.24% loss for the S&P 500. What this means is that foreign investing provided a bit of cushion to the global investor. Figure 4-8. Returns for S&P 500 and foreign stocks, 1962–2000. An even more vivid case for diversifying into foreign stocks is made by looking at returns decade by decade, as shown in Figure 4-9 . Notice how during the 1970s, the return of the S&P 500 was less than inflation—that is, it had a negative real return—whereas the EAFE beat inflation handily. You’ll also see that the EAFE beat the S&P 500 by a similar margin in the 1980s. Thus, for a full two decades you would have been very happy with global diversification. This would have been particularly true if these two decades had been your retirement years, since a U.S.-only portfolio would have very likely run out of money due to its relatively low returns. In the 1990s, the law of averages finally caught up with foreign stocks, souring many on global diversification. Despite the slightly lower rewards of foreign stocks, the most powerful argument, paradoxically enough, can actually be made on the basis of return. Most investors do not simply select an initial allocation and let it run for decades without adjustment. Because of the varying returns of different assets over the years, portfolios must be “rebalanced.” To see what rebalancing means, let’s look at the two-year period from 1985 to 1986. Figure 4-9. S&P 500, EAFE, and inflation, by decade. ( Source: Morningstar Inc.) The overall return of the S&P 500 for those years was quite high—57%—but the return of the EAFE was off the charts—166%! Had you started with a 50/50 portfolio at the beginning of the period, at the end, it would have been 63% foreign and 37% domestic. Rebalancing the portfolio means selling enough of the better performing asset (in this case, the EAFE) and with the proceeds buying the worse performing asset (the S&P 500) to bring the allocation back to the 50/50 policy. Had you rebalanced a 50/50 S&P 500/EAFE portfolio every two years between 1969 and 2000, it would have returned 12.62%. This was almost one-half percent better than the best-performing asset, the S&P 500. Why? Because when you rebalance back to your policy allocation (your original 50/50 plan), you are generally selling high (the best performer) and buying low (the worst performer). So, over the long haul, international diversification not only reduces risk, but it may also increase return. But be warned: as the past decade has clearly taught us, foreign diversification is not a free lunch, especially if your time horizon is less than 15 or 20 years. Until recently, the average U.S. investor did not have to worry about diversifying abroad—it simply wasn’t an option. Although domestic investors have been able to purchase foreign stocks for more than a century, in practice this was expensive, cumbersome, and awkward; it could only be done one stock at a time. Although the first U.S.-based international fund opened its doors almost five decades ago, it wasn’t until the early 1980s that these vehicles became widely available. In 1990, the Vanguard Group made available the first easily accessible, low-cost indexed foreign funds. What is the proper allocation to foreign stocks? Here we run into an enormous problem—one that makes even the most devout believer in efficient markets a bit queasy. The rub is that the total market cap of non-U.S. stocks is about $20 trillion versus only $13 trillion for the U.S. market. If you believe that the global market is efficient, then you should own every stock in the world in cap-weighted fashion, meaning that foreign companies would comprise 60% of your stock exposure. This is more than even the most enthusiastic proponents of international diversification can swallow. So what’s a reasonable foreign allocation? Certainly less than 50% of your stock pool. For starters, foreign stocks are more volatile, in general, than domestic stocks on a year-by-year basis. Second, they are more expensive to own and trade. For example, the Vanguard Group’s foreign index funds, on average, incur about 0.20% more in annual expenses than their domestic index funds. Finally, a small portion of the dividends of foreign stocks are taxed by their national governments. Although these taxes are deductible on your tax returns, this deduction does not apply to retirement accounts. Here, it is lost money. Experts differ on the “optimal” foreign stock exposure, but most agree it should be greater than 15% of your stock holdings and less than 40%. Exactly how much foreign exposure you can tolerate hinges on how much “tracking error” (the difference between the performance of your portfolio and the S&P 500) you can bear. Take a look again at Figure 4-9 . An investor with a high foreign exposure would have suffered accordingly in the nineties. Although their returns would have been satisfying, they would have been much less than those obtained by their neighbors who had not diversified. So although the long-term return of a globally diversified stock portfolio should be slightly higher than a purely domestic one, there will be periods lasting as long as 10 or 15 years when the global portfolio will do worse. If this temporary shortfall relative to the S&P 500—tracking error—bothers you greatly, then perhaps you should keep your foreign exposure relatively low. If it does not bother you at all, then you may be able to stomach as much as 40% in foreign stocks. But whatever allocation you settle on, the key is to stick with it through thick and thin, including rebalancing back to your target percentage on a regular basis. Step Three: Size and Value Steps one and two—the stock/bond and domestic/foreign decisions—constitute asset allocation’s heavy lifting. Once you’ve answered them, you’re 80% of the way home. If you’re lazy or just plain not interested, you can actually get by with only three asset classes, and thus, three mutual funds: the total U.S. stock market, foreign stocks, and short-term bonds. That’s it—done. However, there are a few relatively simple extra portfolio wrinkles that are worth incorporating into your asset allocation repertoire. We’ve already talked about the extra return offered by value stocks and small stocks. The diversification benefits of small stocks and value stocks are less certain. For example, during the 1973–74 bear market, value stocks did much better than growth stocks; the former lost only 23% versus 37% for the latter. But during the 1929–32 bear market, value stocks lost 78% of their worth, versus “only” 64% for growth stocks. The academicians who have most closely examined the value effect—Fama and French—insist that the higher return of value stocks reflects the fact that these companies are riskier than growth stocks because they are weaker and thus more vulnerable in hard times. Fama and French’s theory is consistent with stock performance during the 1929–32 bear market. But there are also times when growth stocks demonstrate their own peculiar risks. As we’ll see in the next chapter, from time to time, the public becomes overly enthusiastic about the prospects for companies at the leading edge of the era’s technology. These growth stocks can appreciate beyond reason—as happened in the late 1990s in the technology and Internet areas. When the bubble deflates, however, large sums can be lost. On the other hand, we usually don’t have to worry about a bubble in bank, auto, or steel stocks. There can be no question that small stocks are riskier than large stocks. Small companies tend to be insubstantial and fragile. More importantly, they are thinly traded—relatively few shares change hands during an average day, and in a general downturn, a few motivated sellers can dramatically lower prices. From 1929 to 1932, small stocks lost 85% of their value, and from 1973 to 1974, a 58% loss was incurred. Why invest in small stocks at all? Because over the very long haul, they do offer higher returns; this is particularly true for small value stocks, as we saw in Figure 1-18 . How much of your portfolio should be held in small and value stocks? Again, it depends on the amount of tracking error you can tolerate. Small stocks and value stocks can underperform the broad market indexes for very long periods of time—in excess of a decade, as occurred in the 1990s. To demonstrate this, I’ve plotted the returns of the market, small stocks, large-value stocks, and small-value stocks for the past three decades in Figure 4-10 . From 1970 to 1999, small-value stocks had the highest return (16.74% annualized), followed by large-value stocks (15.55%), the S&P 500 (13.73%), and small stocks (11.80%). But Figure 4-10 also shows that during the last ten years of the period, this pattern was virtually reversed, with the S&P 500 being the best-performing asset, and small value stocks, the worst. So, again, it comes down to tracking error: how long are you willing to watch your portfolio underperform the market before it (hopefully) turns around and pays off? If you cannot tolerate playing second fiddle to your more conventionally invested neighbors at cocktail parties, then small stocks and value stocks are not for you. What is the maximum you should allot to small stocks and value stocks? This is a tremendously complex subject that we’ll tackle in some detail in Chapter 12 . In general, you should own more large-cap stocks than small-cap stocks. In the large-cap arena, you should have a reasonable balance of value and growth stocks. Small-growth stocks have relatively low returns and high risks, so your allocation to small value should be much larger than to small growth. But realize that the more you stray from the S&P 500, the more often your portfolio will dance to its own drummer. This will distress investors who do not like to temporarily underperform the market. Figure 4-10. S&P 500, small, large value, and small value, by decade. ( Source: Dimensional Fund Advisors, Morningstar Inc.) Step Four: Sectors What about industry sectors: tech, autos, banks, airlines, and the like? They are hardly worth the trouble; once you’re exposed to the whole market via an index fund, you already own them. The only way you can improve on the market return by using sectors is by picking the areas with the future highest returns. And, as we’ve already seen in the preceding chapter, lots of luck. There’s another reason why it’s generally a bad idea to focus on sectors: they can virtually disappear. For example, at the turn of the last century, railroad companies constituted most of the U.S. market’s total value. But by 1950, they had been devastated by the automobile and the aircraft. In 1980, the market was dominated by oil stocks, but within a decade, they had shrunk to one-quarter of their former share of market capitalization. The real risk in the sector game is that you may wind up owning the next generation’s buggy whip and leather industries. But with some trepidation, I think that there are two sectors worth considering: REITs (real estate investment trusts) and precious metals stocks. Of the two, a much stronger case can be made for REITs. Their historical returns, as well as their expected future returns, are probably comparable to the market’s. And, as we saw a few pages ago, they can do quite well when everything else has gone down the tubes. Unfortunately, the same table showed that the opposite is also true: they can do poorly when the rest of the market is going great guns. (Or, as Dan Wheeler of Dimensional Fund Advisors puts it, the problem with diversification is that it works, whether or not we want it to.) Again, it all comes down to tracking error: how much does it bother you when an asset grossly underperforms the rest of the market? Because of the high volatility and tracking error of REITs, the maximum exposure you should allow for this asset class is 15% of your stock component. Precious metals stocks—companies that mine gold, silver, and platinum—historically have had extremely low returns, perhaps a few percent above inflation. Not only that, they tend to have very poor returns for very long periods of time and are extremely volatile. Why expose yourself to this asset class? For three reasons. First, precious metals stock returns are almost perfectly uncorrelated with most of the world’s other financial markets. During a global market meltdown, they are liable to do quite well. For example, from 1973 to 1974, gold stocks gained 28%. We don’t have exact returns for gold stocks from 1929 to 1932, but anecdotally, they seemed to have done quite well at that time as well, when everything else was getting hammered. Second, precious metals stocks will be profitable if inflation ever again rears its ugly head. During such periods, “hard assets” such as precious metals, real estate, and “collectibles” (e.g., art, rare coins, etc.) tend to do very well. And third, this asset’s random volatility will work in your favor via the rebalancing mechanism. If you can hold precious metals stocks in a retirement account and trade them without tax consequences, the natural buy-low/sell-high discipline of the rebalancing process should earn 3% to 5% per year in excess of the low baseline return for this asset. Be forewarned that this process takes discipline, because you will be continually moving against the crowd’s sentiment. While you are selling, you will be reading and hearing some very compelling reasons to buy, and when you are buying, you will find that others consider it an act of lunacy. This brings up a very interesting point about asset classes in general. Some bring a bit more to the portfolio than their historical rates of return would suggest. The benefit occurs when an asset is extremely volatile and does not move in synch with the rest of the market. Gold stocks are the epitome of this behavior. REITs, emerging markets stocks, and small international stocks also do this. In general, this kind of behavior can only be taken advantage of in sheltered accounts or in accounts that have high inflows of funds, as it is dependent on the rebalancing technique discussed above. That said, precious metals are strictly optional. If gold stocks make you queasy, don’t buy them. But if you do buy this asset class, it should be no more than a few percent of your portfolio. Some Working Illustrations It’s time to show you what the overall process looks like with a few examples. First of all, to reiterate: there will be an optimal allocation among different kinds of stocks over the next 10, 20, or 30 years. Unfortunately, there is no way of knowing in advance what it will be. (Over the shorter periods, it will likely consist of a 100% allocation to the best-performing asset, and over longer periods, to a mixture of two or three of them.) The important thing, then, is that your asset allocation be properly diversified and behave tolerably well under most circumstances. Let’s start with a theoretical fellow named Charlie Cringe. Charlie hates investing and wants to keep it as simple as possible. Further, it drives him nuts when his neighbor, Harry Hubris, brags about how well his blue chips are doing. Charlie’s no spring chicken: he’ll be retiring in a few years and has lived through a few bear markets. He knows that he can’t sleep at night owning more than 50% stocks. Here’s a reasonable allocation for Charlie: • 35% U.S. stock market (the “total market,” not just the S&P 500) • 10% Foreign stocks • 5% REITs • 50% Short-term bonds The performance of the equity portion of Charlie’s portfolio will never stray too far from that of the overall market, making cocktail hour with Harry much less stressful. Best of all, he should only have to spend a few hours per year following and rebalancing his portfolio. On the other hand, consider Wendy Wonk, who runs the computer network in the accounting department of a large company. She’s 28 years old, and numbers don’t scare her one bit. Not only that, but she inherited her father’s love of investing and is something of a risk taker. Here’s what Wendy might do: • 10% S&P 500 • 10% U.S. large-value stocks • 5% U.S. small stocks • 7.5% U.S. small-value stocks • 7.5% REITs • 2.5% Precious metals stocks • 10% European stocks • 7.5% Japanese and Pacific Rim stocks • 7.5% Emerging markets stocks • 7.5% International value stocks • 25% Short-term bonds First, note that she’s at 75/25 stocks/bonds. This is about as much equity exposure as anyone should have, given the expected returns of stocks and bonds. Next, notice that nearly half of her stock exposure is foreign, and that only a small corner of it owns the S&P 500. The next cubicle happens to be occupied by an unpleasant creature named Bonnie Bore, who’s forever going on about her Microsoft options. But Wendy knows that Bonnie couldn’t invest her way out of the lady’s room, and on days when the big blue chips soar above all other asset classes (and Wendy’s portfolio), she couldn’t care less. Finally, this is not a simple portfolio: Wendy owns no less than ten different stock asset classes; she tells me that she’s thinking of adding in some junk and international bonds, and I can’t come up with good reasons not to. Wendy will probably do better than Charlie. Not only does she have a higher stock exposure, but she’s also much more exposed to value and small stocks, which should earn higher returns. Of course, we can’t be sure—in finance, nothing’s for certain. But even if we knew positively that she would have better returns than Charlie, he’s still better off sticking with his less efficient portfolio. He’ll be able to manage it without exhausting his limited patience for finance and stay the course when the chips are down. Charlie and Wendy are only two extreme illustrations. For example, a case mid-way between the two might look like this: • 25% U.S. total stock market • 10% U.S. large-value stocks • 10% U.S. small-value stocks • 5% REITS • 10% Foreign stocks • 40% Short-term bonds Your asset allocation may need to be radically different from the above examples based on your own circumstances, the most critical being your tax structure. (That is, how much of your assets are held in ordinary taxable accounts, and how much in sheltered retirement and annuity accounts.) We’ll explore this in much greater detail in Chapter 12 . The comparison between Charlie and Wendy highlights the tradeoff between the benefits of diversification and the pain of tracking error. The superior expected return and risk of a highly diversified portfolio come at the price of tracking error—the risk that your portfolio will significantly lag the S&P 500, and thus the portfolios of your friends and neighbors—for years at a time, as happened during the late 1990s. CHAPTER 4 SUMMARY 1. Past portfolio performance is only weakly predictive of future portfolio behavior. It is a mistake to design your portfolio on the basis of the past decade or two. 2. Your exact asset allocation is a function of your tolerance for risk, complexity, and tracking error. 3. The most important asset allocation decision revolves around the overall split between risky assets (stocks) and riskless assets (short-term bonds, bills, CDs, and money market funds). 4. The primary diversifying stock assets are foreign equity and REITs. The former should be less than 40% of your stock holdings, the latter less than 15%. 5. Exposure to small stocks, value stocks, and precious metals stocks is worthwhile, but not essential.",
        "char_count": 35890
      },
      {
        "heading": "Chapter 11",
        "text": "P ILLAR T WO The History of Investing When Markets Go Berserk About once every generation, the markets go barking mad. When this happens, most investors sustain serious damage, many are totally ruined. Unless you have been living at the bottom of a well these past several years, you are keenly aware that we are in the midst of such a period. Markets can crash, but it is less well known that markets can also become depressed for decades at a time. The following two chapters will deal with the periods of euphoria and depression that occur on a fairly regular basis. The average investor lives through at least a few markets of both types. Even with an appreciation of their behavior, dealing with both buoyant and morose markets is difficult. Sometimes even the best-prepared can fail. But if you are unprepared, you are sure to fail.",
        "char_count": 838
      },
      {
        "heading": "Chapter 12",
        "text": "5 Tops: A History of Manias Progress, far from consisting in change, depends on retentiveness. Those who cannot remember the past are condemned to repeat it. George Santayana There is nothing new—only the history you haven’t read. Larry Swedroe Men of business have keen sensations but short memories. Walter Bagehot To many readers, this section on booms and busts will seem out of place. After all, this book is a humble how-to tome; it has no pretension of being a documentary work. But of the four key areas of investment knowledge—theory, history, psychology, and investment industry practices—the lack of historical knowledge is the one that causes the most damage. Consider, for example, the principals of Long Term Capital Management, whose ignorance of the vagaries of financial history almost single-handedly brought the Western financial system to its knees in 1998. A knowledge of history is not essential in many fields. You can be a superb physician, accountant, or engineer and not know a thing about the origins and development of your craft. There are also professions where it is essential, like diplomacy, law, and military service. But in no field is a grasp of the past as fundamental to success as in finance. Academics love to argue whether the primary historical driving forces over the ages are repetitive and cyclical or non-repetitive and progressive. But in finance, there is no controversy: the same speculative follies play out with almost clock-like regularity about once a generation. The aftermaths of these binges are a bit less uniform, but just as worthy of study. I’m writing this chapter with great trepidation, because as my keyboard clacks, we are likely just past the cusp of one of the greatest speculative bubbles of all time. For this generation, the horses are already out of the barn, and it may be another 30 years—the typical interval between such episodes—until the warning implicit in this story is again fully useful. I do not know if this time we will see the usual sequel that issues from periods of speculation, in which prices plummet as investors flee all except the safest securities, having previously embraced the riskiest. Although this chapter has just lost much of its timeliness, it is still the most important one in the book. For even if you can master the theory, psychology, and business of investing, your efforts will still come to naught if you cannot keep your head when everyone around you has lost his. General Considerations Manifestly, technological progress drives economic progress, which in turn drives stock prices. Should some malign force suddenly stop all scientific and technological innovation, then our standard of living would remain frozen at the present level; corporate profits would remain stationary, and stock prices, although fluctuating as they always have, would not experience any long-term rise. This point cannot be made forcefully enough: the great engine of stock returns is the rate of technological progress, not its absolute level. I recently spoke at an investment conference at which a member of the audience, knowing that I was a physician, asked how the great strides in biotechnology were revolutionizing my medical practice. My reply was that these advances—gene therapy, DNA-based diagnostic testing, the flow of new surgical and angiography tools—had brought only marginal improvements on a day-to-day basis. In fact, the greatest single advance in medicine occurred more than six decades ago, with the invention of sulfa drugs and penicillin. At a stroke, literally millions of lives, which had been previously lost to diseases such as bacterial pneumonia and meningitis, could now be saved. Not only that, those saved were predominantly the young. In contrast, today’s advances disproportionately benefit the elderly. I do not think it likely that we shall again see the kind of medical progress experienced at the dawn of the antibiotic era. We tend to think of technological progress as an ever-accelerating affair, but it just isn’t so. Technological innovation comes in intense spurts. And the most impressive blooms were not at all recent. If you want to see the full force of scientific progress on human affairs, you have to go back almost two centuries. The technological explosion that occurred from 1820 to 1850 was undoubtedly the most deep and far reaching in human history, profoundly affecting the lives of those from the top to the bottom of the social fabric, in ways that can hardly be imagined today. Within a brief period, the speed of transportation increased tenfold, and communications became almost instantaneous. For example, as late as the early 1800s, it took Jefferson ten days to travel from Monticello to Philadelphia, with considerable attendant expense, physical pain, and peril. By 1850, the steam engine made the same journey possible in one day, and at a tiny fraction of its former price, discomfort, and risk. Consider this passage from Stephen Ambrose’s Undaunted Courage: A critical fact in the world of 1801 was that nothing moved faster than the speed of a horse. No human being, no manufactured item, no bushel of wheat, no side of beef, no letter, no information, no idea, order or instruction of any kind moved faster. Nothing had moved any faster, and, as far as Jefferson’s contemporaries were able to tell, nothing ever would. The revolution in communication was even more dramatic. For most of recorded history, information traveled as slowly as physical goods. With the invention of the telegraph by Cooke and Wheatstone in 1837, instantaneous telegraphy abruptly changed the face of economic, military, and political affairs in ways that can scarcely be comprehended by even our modern technologically jaded sensibilities. It is humbling to realize that the news of Grover Cleveland’s election in 1884 traveled from New York to San Francisco and London almost as quickly as it would today. In other words, for the past century and a half, the transmission of essential news has been instantaneous. The advent of modern communication technology has simply facilitated the rapid dissemination of increasingly trivial information. But that does not mean that the economic and financial effects of technological revolutions occur immediately. Not at all. The steam and internal combustion engines did not completely displace horses in the transport of bulk goods for nearly a century, and it took several decades for computers to travel from the laboratory into the office, and, finally, into the home. Immediately after their invention, the telegraph and telephone were the toys and tools of the wealthy. Ordinary people did not begin to routinely make long-distance calls until relatively recently. I find the following analogy useful for understanding the diffusion of technology. Imagine a well hand pumped by a ponderous handle. Once every several seconds, a gush of water issues from the spout. The water is then funneled into a long pipe. From the perspective of the person at the pump handle—the innovator and the wealthy first-adopter—the water is clearly coming in spurts. But to the person at the end of the pipe—the average consumer, and, more importantly, the investor—the water is flowing evenly. To illustrate the point, I’ve plotted the real gross domestic product (GDP) of the United States and Britain since 1820 on a semilog scale in Figure 5-1 . Recall that the slope of a semilog plot at any point shows the true rate of growth. Note how relatively smooth and constant the rates of growth are in the two countries. The American plot slopes upward at 3.6% per year, and the British at about 1.9% per year. (Incidentally, this plot places the eclipse of the British empire in 1871, when its GDP was exceeded by that of the U.S.—about a quarter of a century earlier than suggested by the plot of consol interest rates.) About two-thirds of the difference in GDP growth between the two nations can be accounted for by the higher American population growth, and the other third by our increasing edge in labor efficiency. The United States and Britain have been at the forefront of world technological progress for the past two centuries. What you are looking at is its flesh-and-blood track; it is also the engine of increasing stock prices. On occasion, other nations have had even more rapid growth. For example, in the 50 years following World War II, Japan’s economy grew at an astonishing 6.65% real rate. However, little of this was the result of technological innovation, but rather to “catch up” to the level of the rest of the world. Even today, labor productivity in Japan is far below that of the United States and western Europe. It is not a coincidence that Figures 5-1 and 1-1 have nearly the same appearance, as they are driven by the same factors. Now things start to get interesting. Recall that technological progress comes in spurts, but that the economic and investment rewards driven by economic activity occur relatively evenly. The capitalization of technological ideas is as uneven as the innovative process itself, however. This is because investment in new technologies is driven by the first blush of excitement surrounding their discovery. And it is almost uniformly a bad business. For example, investors in almost all of the early automobile companies did very poorly. Similarly, although RCA pioneered the young radio industry, most of its investors got taken to the cleaners in the wake of the 1929 crash. Generations before academic research proved that investing in young tech companies yielded low returns, J.P. Morgan grasped this fact. Consequently, he almost always avoided unseasoned companies. He made only one exception—Edison’s invention of the electric light bulb in 1879. Both Morgan and Edison realized the transformative nature of this device. Edison lacked the enormous capital required to build the bulb factories and power plants necessary to exploit it, but a consortium led by Morgan provided it. And, as almost always occurs, the lion’s share of the ultimate reward did not fall to the original inventor. Unfortunately, Edison Electric, with its direct current technology, steadily lost ground to Westinghouse’s more efficient alternating current system. When the two companies finally merged, Edison sold out in disgust, depriving himself of a great fortune. And, as he almost always did, Morgan prospered. Figure 5-1. U.S. and U.K. real GDP ($billion, based on 1990 value). (Source: Angus Maddison, The World Economy. ) The key point is this: the funding, or capitalization, of transformative inventions is an intensely seductive activity. After all, who doesn’t want to get in on the ground floor of the next General Motors, IBM, or Microsoft? From time to time, certain technologies capture the public imagination, and huge amounts of capital are hurled at companies promising to exploit them. In other words, the flow of capital to new technologies is driven not so much by demand from the innovators as by supply from an impressionable investing public. This cycle has been occurring in fits and starts for the past three centuries, and an examination of the process demonstrates three things: First and foremost, the capitalization of the nation’s great companies occurs largely during brief periods of public enthusiasm. Second, our society owes its success and prosperity to both the inventors and the financial backers of the technological process. And last, the returns to technology’s investors are low. Let’s get a bit of nomenclature out of the way. When you and I purchase shares of stock or a mutual fund, according to strict economic definition, we are not investing. After all, the money we pay for our shares does not go to the companies, but, instead, to the previous owner of the shares. In economic terms, we are not investing; we are saving. (And, contrary to popular opinion, the overall economic effect of saving is often negative.) Only when we purchase shares at a so-called “initial public offering” (IPO) are we actually providing capital for the acquisition of personnel, plant, and equipment. Only then are we truly investing. Most of the time, we are buying and selling shares in the “secondary market”; the company usually has no interest in the flow of funds, since such activity does not directly impact it. Here’s the punch line: The returns on “real investing”—that is, the purchase of IPOs—are ghastly. In 1991, academician Jay Ritter objectively confirmed what most experienced investors have known for generations—that the shares of new companies are a raw deal for everyone but the underwriters. He found that from 1975 to 1984, IPOs returned 10.37%—just 3% more than inflation—while the market returned 17.41%. He concluded, in a triumph of academic understatement, “Investors become periodically overoptimistic about the earnings potential of young growth companies.” Ritter’s conclusions have since been confirmed by others and are also consistent with the sorry showing by small-growth stocks discussed in Chapter 1 , as most IPOs fall into this category. IPO investors thus deserve an honored place in our economic system—they are capitalism’s unsung, if unwitting, philanthropists, bearing poor returns so that the rest of us may prosper. The spasmodic history of these philanthropic orgies is perhaps the most critical part of any investor’s (excuse me, saver’s ) education. Diving For Dollars Recall that the first stock exchanges were started in Paris, Amsterdam, and London. The English “stock exchange” consisted of a cluster of coffeehouses in the neighborhood of Change Alley. By the late seventeenth century, these coffeehouses became the most active and advanced exchanges in the world. The average “stock jobber,” as brokers were known, would have little trouble understanding the action on the floors of the New York Stock Exchange or Chicago Mercantile, although ordering a proper brew at Starbucks might strike them as overly complex. This revolution in financial engineering quickly found its way into the era’s emerging technologies. In 1687, William Phipps, a New England sea captain, docked in England with 32 tons of silver raised from a Spanish pirate ship, enriching himself, his crew, and his backers beyond their wildest dreams. This captured the imagination of the investing public and before long, numerous patents were granted for various types of “diving engines,” followed soon after by the flotation of even more numerous diving company stock issues. Almost all of these patents were worthless, submitted for the express purpose of creating interest in their company’s stock. The ensuing ascent and collapse of the diving company stocks, culminating about 1689, could be said to be the first tech bubble. Daniel Defoe, of Robinson Crusoe fame, was the treasurer of one of those companies. His insider knowledge of their workings did not prevent his bankruptcy—one of the most spectacular of the age. The diving companies never developed any credible operations, let alone earnings. This quickly became apparent to investors, and the madness was soon over. We don’t have any records of exact prices and returns, but it’s a sure bet that the eventual result of investment in all of these companies was total loss. It was very similar in this regard to the dot-com craze. Aside from Phipps’ enterprise, no diving company had actually ever turned a profit, and it was not immediately clear how any of these companies could ensure access to a steady stream of treasure-laden wrecks. In modern parlance, all they had was a dubious business model. For a few months, the shares of these companies rose dramatically. There was nothing unusual, per se, even three centuries ago, about the raising of capital for enterprises with questionable prospects. There was even nothing untoward about the shares of those enterprises rising temporarily in price. This is, after all, how capital markets work. If you have trouble with the concept that such highly dubious enterprises can command a rational price, consider the following example: Assume that your neighbor Fritz tells you he thinks that sitting under his property is a huge reservoir of oil. He estimates that it is worth $10 million, but in order to produce it, he requires capital to pay for drilling equipment. He’s willing to let you in for half the profits. How much would you be willing to stake him for? Fritz has always been a bit dotty, but he’s also a retired petroleum engineer, so there’s a remote chance he is not blowing smoke. You estimate there is a one-in-a-thousand chance he’s onto something. The expected payoff of your investment is thus $5 million (your half of his $10 million reservoir) divided by 1,000, or $5,000. Add in another factor of ten as a “risk premium,” and you calculate that it might be reasonable to give your neighbor $500 for a piece of the action. This is another way of saying that Fritz’s adventure carries with it a low chance of success coupled with a high discount rate to compensate for its risk. Since you are applying such a high discount rate to the low expected cash flow, the share is worth very little. Further, subsequent reevaluation of your risk tolerance and of Fritz’s chances of success will cause your estimation of the value of your share to fluctuate. So it was not unusual that the shares of companies with dubious chances of success should have some value, or that this value should fluctuate. It’s not unusual now (can you spell “biotech?”), and it was certainly not unusual 300 years ago. But from time to time, for reasons that are poorly understood, investors stop pricing businesses rationally. Rising prices take on a life of their own and a bubble ensues. Monetary theorist Hyman Minsky comes as close to a reasonable explanation of bubbles as any. He postulates that there are at least two necessary preconditions. The first is a “displacement,” which, in modern times, usually means a revolutionary technology or a major shift in financial methods. The second is the availability of easy credit—borrowed funds that can be employed for speculation. To those two, I would add two more ingredients. The first is that investors need to have forgotten the last speculative craze; this is why bubbles occur about once per generation. And second, rational investors, able to calculate expected payoffs and risk premiums, must become supplanted by those whose only requirement for purchase is a plausible story. Sadly, during bubbles, not a few of the former convert into the latter. The last two conditions can be summarized in one word: euphoria. Investors begin purchasing assets for no other reason than the fact that prices are rising. Do not underestimate the power of this contagion. Listen to hedge fund manager Cliff Asness’ observations on online trading in the late 1990s: I do not know if many of you have played video poker in Las Vegas. I have, and it is addicting. It is addicting despite the fact that you lose over any reasonable length period. Now, imagine video poker where the odds were in your favor. That is, all the little bells and buttons and buzzers were still there providing the instant feedback and fun, but instead of losing you got richer. If Vegas was like this, you would have to pry people out of their seats with the jaws of life. People would bring bed-pans so they did not have to give up their seats. This form of video poker would laugh at crack cocaine as the ultimate addiction. Or a somewhat dryer perspective, from economic historian Charles Kindleberger: “There is nothing so disturbing to one’s well-being and judgment as to see a friend get rich.” In the past several years, to lack this sense of exhilaration is to have been asleep. To recap, the necessary conditions for a bubble are: • A major technological revolution or shift in financial practice. • Liquidity—i.e., easy credit. • Amnesia for the last bubble. This usually takes a generation. • Abandonment of time-honored methods of security valuation, usually caused by the takeover of the market by inexperienced investors. But whatever the underlying conditions, bubbles occur whenever investors begin buying stocks simply because they have been going up. This process feeds on itself, like a bonfire, until all the fuel is exhausted, and it finally collapses. The fuel, as Minsky points out, is usually borrowed cash or margin purchases. The South Sea Bubble The diving company bubble was, in fact, simply the warm-up for a far greater speculative orgy. Most bubbles are like Shakespeare’s dramas and comedies: the costumes, dialect, and historical setting may be foreign, but the plot line and evocation of human frailty are intimately familiar to even the most casual observer of human nature. The South Sea Bubble’s origins were complex and require a bit of exposition. For starters, it was not one bubble, but two, both beginning in 1720: the first in France, followed almost immediately by one in England. As we saw in the first chapter, government debt was a relatively late arrival in the investment world, but once the warring nation-states of the late Middle Ages got a taste of the abundant military financing available from the issuance of state obligations, they could not get enough. By the mid-seventeenth century, Spain was hopelessly behind on its interest payments, and France was also rather deep in the hole to its debtors. Into the financial chaos of Paris arrived a most extraordinary Scotsman: John Law. After escaping the hangman for killing a man in a 1694 duel, he studied the banking system in Amsterdam and eventually made his way to France, where he founded the Mississippi Company. He ingratiated himself with the Duke of Orléans, who, in 1719, granted the company two impressive franchises: a monopoly on trade with all of French North America, and the right to buy up rentes (French government annuities, similar to prestiti and consols) in exchange for company shares. The last issue was particularly attractive to the Royal Court, since investors would exchange their government bonds for shares of the Mississippi Company, relieving the government of its crushing war debts. Law’s so-called “system” contained one remarkable feature—the Mississippi Company would issue money as the price of its shares increased. Yes, the company issued its own currency, as did all banks of that time. This practice was one of the central mechanisms of pre-twentieth century finance. If the bank was sound and located nearby, its banknotes would usually be worth their face value. If it was unsound or further away, then its banknotes would trade at a considerable discount. (Of course, modern banks also print money when their loans are made in the form of a bank draft, as they almost always are.) Now, all of the necessary ingredients for a bubble were present: a major shift in the financial system, liquidity from the company’s new banknotes, and a hiatus of three decades from the last speculation. In 1720, as the Mississippi Company’s shares rose, it issued more notes, which purchased more shares, increasing its price still more. Vast paper fortunes were made, and the word millionaire was coined. The frenzy spilled over the entire continent, where new ventures were floated with the vast amounts of capital now available. There was even a fashionable new technology involved: the laws of probability. Fermat and Pascal had recently invented this branch of mathematics, and, in 1693, Astronomer Royal Edmund Halley developed the first mortality tables. Soon the formation of insurance companies became all the rage; these would figure prominently as the speculative action moved to London. The ancien régime was not the only government deep in hock. By 1719, England had incurred immense debts during the War of the Spanish Succession. In fact, a decade before, in 1710, the South Sea Company had actually exchanged government debt held by investors for its shares and had been granted the right to a monopoly on trade with the Spanish Empire in America. The government, in exchange for taking over its debt, also paid the South Sea Company an annuity. But neither the Mississippi Company nor the South Sea Company ever made any money from their trade monopolies. The French company never really tried, and war and Spanish intransigence blocked British trade with South America. (In any event, none of South Sea’s directors had any experience with South American trade.) The Mississippi Company was just a speculative shell. The situation of the South Sea Company was a bit more complex, as it did receive an income stream from the government. Unfortunately, its deal with the government was structured in a most peculiar manner. The South Sea Company was allowed to issue a fixed number of shares that could be exchanged for the government debt it bought up from investors. In other words, investors would exchange their bonds, bills, and annuities for stock in the company. The higher the share price of the company, the fewer the shares it had to pay investors, and the more shares that were left over for the directors to sell on the open market. So it suited the South Sea Company to inflate its price. The liquidity sloshing through the European financial system in 1720 allowed it to do so. At some point, the share price took on a life of its own, and investors were happy to exchange their staid annuities, bonds, and bills for the rapidly rising shares. The directors took advantage of the meteoric price increase to issue several more lots of stock to the public: first for government debt, then for money. The later purchasers were allowed to purchase on margin with a 20% down payment, the remainder being due in subsequent payments. In the case of the South Sea Company, even this was a fiction, as many of the down payments were themselves made with borrowed money. In the summer of 1720, share values peaked on both sides of the channel; the last subscription was priced at £1,000 and was sold out in less than a day. (The stock price was about £130 at the start of the bubble.) The South Sea Company involved itself in a fair amount of skullduggery. The government became alarmed at the rapidly rising share price—there were still some gray heads remaining who had lived through the diving company debacle—and parliament proposed limiting the share price. In the process of blocking this, the company provided under-the-table shares (which in fact were counterfeit) to various notables, including the king’s mistress, and the price limitation was scotched. The most fantastic manifestation of the speculation was the appearance of the “bubble companies.” With the easy availability of capital produced by the boom, all sorts of dubious enterprises issued shares to a gullible public. Most of these enterprises were legitimate but just a bit ahead of their time, such as one company to settle the region around Australia (a half century before the continent was actually discovered by Cook), another to build machine guns, and yet another that proposed building ships to transport live fish to London. A lesser number were patently fraudulent, and still others lived only in later legend, including a famous mythical company chartered “for carrying on an undertaking of great advantage but no one to know what it is.” Interestingly, two of the 190 recorded bubble companies eventually did succeed: the insurance giants Royal Exchange and London Assurance. The South Sea Company grew anxious over competition for capital from the bubble companies, and, in June 1720, had parliament pass the Bubble Act. This legislation required all new companies to obtain parliamentary charters and forbade existing companies from operating beyond their charters. Paradoxically, this was their undoing. Since many of the insurance companies, which helped sustain the frenzy by lending substantial amounts to the South Sea Company and its shareholders, started out in other lines of business, they were forced to cease operation. Prime among them was the Sword Blade Company, which, naturally enough, was chartered only to make swords. When the Bubble Act forced the withdrawal of their credit from the market, the effect was electric: the bubble was pricked. By October, it was all over. The South Sea episode was a true mania, enveloping the populace from King George on down. Jonathan Swift best summarized England’s mood at the time: I have enquired of some that have come from London, what is the religion there? They tell me it is the South Sea stock. What is the policy of England? The answer is the same. What is the trade? South Sea still. And what is the business? Nothing but South Sea. A foreign visitor to Change Alley was more succinct, stating that it looked “as if all the lunatics had escaped out of the madhouse at once.” Neither the Mississippi Company nor the South Sea Company had any real prospects of foreign trade. While the former had no revenues at all, the latter had at least a stream of income from the government. Contemporary observers, eyeballing this cash flow, estimated the fair value of South Sea Company at about £150 per share, precisely where it wound up after the dust had settled. Let’s reflect on the four conditions necessary for the blowing of a bubble. First, Minsky’s “displacement,” which, in this case, was the unprecedented substitution of public debt with private equity. The second was the availability of easy credit, particularly the self-perpetuating output of paper money from the Mississippi Company. Third was the 30-year hiatus following the diving company episode. The last condition was the increasing domination of the market by nonprofessionals clueless about asset valuation. Although Fisher’s discounted dividend method lay two centuries in the future, for centuries, investors had an intuitive working grasp of how to value an income stream, in the same way that ball players are able to catch fly balls without knowing the ballistic equations. Reasonable investors might debate whether the intrinsic value of South Sea Shares was £100 or £200, but no one could make a rational case for £1,000. And the more speculative bubble companies, which in normal times might be valued like your neighbor Fritz’s oil well, saw their prices go through the roof. This, then, is the essence of a bubble: a brief period of rising prices and suspended disbelief, which, in turn, supplies large numbers of investors willing to invest in dubious enterprises at absurdly low discount rates and high prices. Bubbles streak across the investment heavens, leaving behind financial destruction and disillusionment, respecting neither intelligence nor social class. Probably the most famous dupe of the South Sea episode was none other than Sir Isaac Newton, who famously remarked, “I can calculate the motions of the heavenly bodies, but not the madness of people.” The Duke’s Failed Romance The first technological marvel that can be properly said to have transformed modern life was the development of large-scale canal transport. In 1758, the Duke of Bridgewater, heartbroken by an unsuccessful romance, concocted the radical notion of building a canal to bring coal from his mines to a group of textile mills 30 miles away. Completed nine years later and financed to the brink of his estate’s financial ruin, this eventually proved enormously profitable, and within 20 years, more than 1,000 miles of canals laced the English countryside. The initial returns on the first canal companies were highly agreeable, and their shares soared. Naturally, the profits made by early investors aroused a great deal of attention and set into motion the by now familiar process. Large amounts of capital were raised from a gullible public for the construction of increasingly marginal routes. Dividends, which were as high as 50% for the first companies, slowly disappeared as competing routes proliferated. Bubbles are pricked when liquidity dries up. In this particular case, it was the disappearance of easy credit brought on by the French Revolution that produced a generalized price collapse. By the turn of the century, only 20% of the companies paid a dividend. The canal-building bubble was the first of its kind, involving a business that not only provided healthy profits but also transformed and benefited society in profound and long-lasting ways. Although the average speed of canal transport was only a few miles per hour, it was a vast improvement over road conveyance, which was much slower, more dangerous, and less reliable. Until the canals, sea transport was far more efficient. Travel from, say, London to Glasgow, was many times cheaper, faster, and safer by sea than by land, although it was by no means a sure thing, either. For the first time, thousands of inland villages were brought into contact with the outside world, changing England forever. The canal building episode is also an object lesson for those who become enthusiastic over the investment possibilities of new technology. Even if it is initially highly profitable, nothing attracts competition like a cash cow. Rest assured, if you have identified a “sure thing,” you will not keep it a secret for long; you will attract competitors who will rapidly extinguish the initial flow of the easy profits. The canals established a pattern that has held to this day—of transformative inventions that bring long-run progress and prosperity to society as a whole, short-run profits to an early lucky few, and ruin to most later investors. A Very Profitable Clock The canal episode also established another pattern in the finance of innovative technologies: it is the users, not the makers, who benefit. Over the long run, the canal operators did not profit nearly as much as the businesses that used the new method of transport, particularly the building and manufacturing trades that thrived in the newly prosperous inland towns. The best example of this is a device invented about the same time as the blowing of the canal bubble: the marine chronometer. Profitable sea trade requires accurate navigation. This, in turn, demands the precise measurement of latitude (north/south position) and longitude (east/west position). The determination of latitude is a relatively easy task, and by the mid-eighteenth century, had been practiced for hundreds of years—a sea captain simply needs an accurate midday measurement of the sun’s elevation. But longitude is a much tougher nut. By the eighteenth century, seafarers realized that the most likely route to success lay in the development of a highly accurate timepiece. If a navigator could determine the local solar noon—the maximum elevation of the sun—and also know the time in London at the same moment, he then would know just how far east or west of London he was. This required a timepiece that could keep time to within one-quarter of a second per day over a six-week journey—at sea. Master craftsman John Harrison finally accomplished this amazing feat in 1761. His clock—the so-called “H4,” is considered a technological marvel even today; two and a half centuries ago, it was the equivalent of the space shuttle. But the key point is this: neither Harrison, nor his heirs, nor his professional successors ever made very much money from this crucial invention. In fact, the clock industry has no real investment history. Until Swatch and Rolex, no great timekeeping boodles were made. But the users of this technology—the East India Company and the other great trading corporations of England and Holland—made vast fortunes with it. This is another early demonstration of the basic rule of technology investing: it is the users, and not the makers, who profit most. Queen Victoria and Her Subjects Get Taken for a Ride The reason why the invention of the marine chronometer did not produce an investment bubble was that its effects were not immediately visible. But if any technological marvel was both visible and revolutionary at the same time, it was the invention of the railway steam engine. Until the advent of steam power in the nineteenth century, long-distance overland travel was almost exclusively the province of the rich. Only they could afford the exorbitant fares of the coach companies, or if truly wealthy, their own coach-and-six. And even then, the poor quality of the roads and public safety made travel a dangerous, slow, and extremely uncomfortable endeavor. At a stroke, the railroads made overland travel cheap, safe, rapid, and relatively comfortable. Even more importantly, the steam engine was undoubtedly the most dramatic, romantic, and artistically appealing technological invention of any age (aside from, perhaps, the clipper ship). Fanny Kemble, a famous actress of the period, captured the mood precisely after her first trip at the footplate of George Stephenson’s Rocket. She found it: .... a snorting little animal which I felt inclined to pat. It set out at the utmost speed, 35 miles per hour, swifter than the bird flies. You cannot conceive what that sensation of cutting the air was; the motion as smooth as possible. I could either have read or written; and as it was I stood up and with my bonnet off drank the air before me. When I closed my eyes this sensation of flying was quite delightful and strange beyond description. Yet strange as it was, I had a perfect sense of security and not the slightest fear. The public sensation surrounding rail travel was unimaginable to the modern reader—it was the jet airliner, personal computer, Internet, and fresh-brewed espresso all rolled into one. The first steam line was established between Darlington and Stockton in 1825, and in 1831, the Liverpool and Manchester Line began producing healthy dividends and soaring stock prices. This euphoria carried with it a bull market in railroad stocks, followed by a sharp drop in prices in the bust of 1837. However, a second stock mania, the likes of which had not been seen in Britain before or since, ensued when Queen Victoria made her first railway trip in 1842. Her ride ignited a popular enthusiasm for rail travel that even modern technology enthusiasts might find difficult to fathom. Just as people today speak of “Internet time,” in the 1840s “railway time” was the operative phrase. For the first time, people began to talk of distances in hours and minutes, instead of days and miles. Men were said to “get up a head of steam.” By late 1844, the three largest railway companies were paying a 10% dividend, and by the beginning of 1845, 16 new lines were planned and 50 new companies chartered. These offerings usually guaranteed dividends of 10% and featured MPs and aristocrats on their boards, who were generally paid handsomely with under-the-table shares. Dozens of magazines and newspapers were devoted to railway travel, supported by hundreds of thousands of pounds in advertising for the new companies’ stock subscriptions. Nearly 8,000 miles of new railways were planned—four times the existing trackage. By late summer 1845, with existing shares up 500%, at least 450 new companies were registered. Foreign lines were being projected around the globe, from the Bengal to Guyana. More than 100 new lines were planned for Ireland alone. In the latter part of the bubble, lines were planned literally from nowhere to nowhere, with no towns along the way. The Minsky “displacement” here was obvious. Credit was equally abundant: In the 1840s, it took the form of the subscription mechanism of purchase, in which an investor “subscribed” to the issue for a small fraction of the purchase price and was subject to “calls” for the remaining price as construction capital was needed. And, as in all bubbles, the sudden contraction of credit punctured it. By 1845, with building underway, investors sold existing shares to meet the calls for the capital necessary. By mid-October 1845, it was all over. Reporting the fiasco, the Times of London introduced the word “bubble” into popular financial lexicon when it proclaimed: “A mighty bubble of wealth is blown away before our eyes.” The rapid contraction of liquidity cascaded through the British financial world in the following years, almost taking the Bank of England with it. Even consols fell; only gold provided a safe haven. Until last year, it was commonly remarked that since so many thought the tech stock scene a bubble, it must not, in fact, be one. And yet, in the summer of 1845, it was apparent to anyone with an IQ above room temperature that railway shares would end badly. Much was also written in the press as to just how it would all end. No less than Prime Minister Robert Peel warned, “Direct interference on our part with the mania of railway speculation seems impracticable. The only question is whether public attention might not be called to the impending danger, through the public press.” In short, Britain’s most brilliant prime minister did everything but shout “irrational exuberance!” at the top of his lungs in Parliament. The United States underwent its own railway mania in the post-Civil War period. But even taking into account the clocklike regularity of railroad bankruptcy and the Credit Mobilier scandal (in which this construction arm of Union Pacific plundered the parent company, not unlike the recent Enron scandal), things were a bit tamer here than in England. This was because U.S. companies were mainly financed with bonds, which are not as prone to bubbles as equity. Nonetheless, the experience of the U.S. railway companies is instructive. Because of murderous competition from the scourge of railways and canals—competing parallel routes—these companies frequently went bankrupt, and returns to investors were low. On the other hand, the societal benefit of the railroads was immeasurable, allowing the settling and growth of the breadth of the continent. The financial rewards from the railroads went to the businessmen, builders, and particularly real estate brokers in places like Omaha, Sacramento, and a small junction town called Chicago. “Wall Street Lays an Egg” So quipped the headline of the entertainment newspaper Variety on the morning of Tuesday, October 30, 1929. Worse, the most famous of all market crashes was just the opening act of the longest and most painful episode in American financial history. Actually, the market rebounded nicely soon after the crash, erasing much of the pain. By early 1930, it was at a higher level than at the beginning of 1929. But for the next two years, the market relentlessly fell, reducing stock prices to a fraction of their former value and taking the rest of the economy with it. The bubble in stock prices which preceded it was equally legendary, and, of necessity, inseparable from it. Once again, the “displacement” was technological. The early twentieth century saw a rate of innovation second only to that of the post-Napoleonic period. The aircraft, automobile, radio, electrical generator, and the devices it powered—most importantly Edison’s light bulb—all burst upon the scene within a few decades. And once again, an expansion of credit loosened the investment floodgates. Ironically, if blame can be assigned anywhere, it probably belongs to Winston Churchill, who, as Chancellor of the Exchequer, reinstated the gold standard and fixed the pound sterling at its prewar value of $4.86. Because of Britain’s wartime inflation, this was a gross overvaluation, making British goods overly expensive abroad and foreign goods correspondingly cheap. The result was a gross trade imbalance that rapidly depleted the British Treasury of gold. The traditional solution for trade imbalance is to get your trading partners to reduce their interest rates; because low rates make investing in your partners unattractive, money flows out of those countries back to yours, solving the problem. Unfortunately, low interest rates in the U.S. also made it easier to borrow money. In 1927, the U.S. was in the middle of an economic boom, and the last thing it needed was easier credit brought about by the lowered American interest rates sought by the British. Most American financial authorities realized that this was an awful idea. Unfortunately, Benjamin Strong, the chairman of the Federal Reserve Bank, and Montagu Norman, the Governor of the Bank of England, were close personal friends. Strong, who dominated the Fed, got his way and interest rates were lowered. This was the equivalent of throwing gasoline onto a fire. Also in place was the third bubble ingredient. It had been more than a generation since the last great railroad enthusiasm, and there were not enough gray heads left to warn that the path led straight over a cliff. At about the same time, the final component of the mix was added as millions of ordinary citizens, completely ignorant of the principles of asset valuation, were sucked into the market by the irresistible temptation of watching their friends and neighbors earning effortless profits. They were joined by tens of thousands of professionals who should have known better. Over the subsequent two and a half years, stock prices rose more than 150%. Of all history’s great bubbles, the 1920s bull market was the most “rational.” Between 1920 and 1929, real GDP rose almost 50%, seemingly confirming the optimists’ predictions of a “new era” born of scientific progress. Further, by today’s standards, stocks were positively cheap. Until 1928, they sold at approximately ten times earnings and yielded about 5% in dividends. Even at the peak, in the summer of 1929, stocks fetched just 20 times earnings, and dividends fell only to 3%. Again, tame by today’s standards. The great bull market of the Roaring Twenties was recognized as a bubble only in retrospect. How else do you explain a price drop of 90%? Of course, there were plenty of individual stocks that were ridiculously overpriced, some the result of rampant speculation and others of outright fraud. But the history of the 1920s bubble is better told with descriptive history than with numbers. The signature characteristic of the era was the stock pool, which consisted of a group of wealthy speculators who would get together with the exchange’s specialist (the floor trader charged with providing a market for the chosen stock) to drive up a stock’s price. They would begin by slowly accumulating a sizeable block of a particular stock at low prices, then commence trading with each other in carefully choreographed fashion, driving the price up and down on gradually increasing volume. As this artificial activity flashed across the ticker tape, the investing public would become aware that something was afoot, or, in the parlance of the day, that the stock was “being taken in hand.” If executed properly, the stock price would be lifted on a frenzy of speculative buying by the public, at which point the pool operators would “pull the plug” and sell. The execution of a proper pool was a high art form, its most accomplished impresario being none other than Joseph P. Kennedy, Sr. Naturally enough, a few years later, he was appointed first commissioner of the Securities and Exchange Commission (SEC). Roosevelt famously justified his appointment of the old rogue by saying, “It takes a thief to catch a thief.” In fact, until the passage of the Securities Act of 1934, which established the SEC, the pools were perfectly legal. The most famous pools of all involved Radio Corporation of America, fondly known back then simply as “Radio.” The names of Radio pool participants still astound the modern reader: Walter Chrysler; Charles Schwab, the distinguished head of U.S. Steel; Mrs. David Sarnoff, wife of Radio’s president and founder; Percy Rockefeller; Joseph Tumulty, former aide to President Wilson; and last but not least, John J. Raskob, who we’ve already encountered, and, by the time of the pool, was head of the Democratic National Committee. The second unique institution of the 1920s was the “investment trust.” Like the modern mutual fund, it had professional managers operating large portfolios of both stocks and bonds. The key difference was that the investment trusts were themselves traded as stocks and touted to small investors as a way of obtaining diversified portfolios managed by experts. In most regards, they were identical to today’s closed-end funds, and a few still survive (General American Investors, Tri-Continental, Adams Express, and Central Securities are examples). In fact, investment trusts had been a feature of the English and Scottish financial landscape for several decades, allowing small investors to diversify across a wide range of investments with just a few dozen pounds. At first these trusts were conservatively run, but as the Roaring Twenties progressed, they began to pyramid themselves using borrowed capital similar to the “margin purchases” used by individual plungers. These “leveraged trusts” would magnify small changes in the levels of individual stocks into wild swings in the trust’s price. The Götterdämmerung was supplied by Goldman Sachs, which did not get into the trust business until late 1928. The Goldman Sachs Corporation sponsored the Goldman Sachs Trading Corporation to the tune of $100 million. Two months later, in February 1929, it merged with another trust sponsored by its parent company, the Financial and Industrial Securities Corporation. By a few days later, the merged trust was selling for twice its assets under management. Most securities firms would have been happy with this agreeable showing, but Goldman was just getting warmed up. The merged trust began buying shares of itself, boosting its value still more. It then unloaded these inflated shares on the public. William Crapo Durant, a well-known former official of General Motors like Mr. Raskob, played a highly visible role in this fraud. More, the Trading Corporation itself sponsored another huge trust, the Shenandoah Corporation. Then, just 25 days later, the Shenandoah Corporation sponsored the Blue Ridge Corporation. Both of the new companies had on their boards a young lawyer named John Foster Dulles. (John Kenneth Galbraith, in his 1954 history of the crash, was barely able to conceal his glee over the past indiscretions of Dulles, who was by then the arch-conservative Secretary of State.) Finally, in August, the Trading Corporation acquired an enormous structure of nested West Coast trusts. Goldman Sach’s timing, of course, could not have been worse. Black Thursday was just several weeks away. The trusts collapsed pretty much in the reverse order of their creation, consistent with their increasing leverage: first Blue Ridge, then Shenandoah, and finally, the Trading Corporation. Shenandoah, which had been trading at 36 soon after its formation, fell to 3 by the end of October and touched 50 cents in 1932. The crash of 1929 and its aftermath scarred the psyche of a generation of American investors, providing them with a particularly expensive lesson in Fisher’s rules of capital value. It would take the passage of that generation before the ground would again become fertile for the seeds of financial speculation. The Go-Go Market and the Nifty Fifty The speculative binge spanning the years 1960 to 1972 was unlike any other in the history of finance, encompassing not one, but three different bubbles. No sooner would one burst than the next was inflated. As the stock market gradually went sour in the early 1970s, more and more investors crowded into the supposed shelter of the “safe” large-cap growth stocks, until finally they, too, collapsed of their own weight, beginning the descent into the awful bear market of 1973–74. It should not surprise any of you by now that the first stirrings of speculative fever began in the late 1950s, almost exactly 30 years from 1929. For almost three decades, prudent investors bought only bonds and avoided common stocks at all costs. Then the generational Wall Street waltz finally took yet another pass in front of the band, and things began to pick up again. Minsky’s “displacement” this time around was the space race, and the magic words were “sonics” and “tronics.” The company names seem dated, almost laughable today: Videotronics, Hydro-Space Technology, Circuitronics, and even Powertron Ultrasonics. (Although not nearly as ridiculous as the names of today’s dot-coms will sound a few decades hence.) The initial public offerings of these companies were spectacular affairs, with typical first-day price rises of 50% to 100% followed by a rapid ascent, culminating in the inevitable price collapse as investors realized that earnings would not be forthcoming in the foreseeable future. The Tronics boom was a relatively small footnote in market history, significant mainly for its entertainment value (unless you happened to be one of the pigeons holding stock in those companies). More serious was the acquisition frenzy that followed, which swallowed up large swaths of the nation’s productive assets into increasingly inefficient, unwieldy conglomerates. For the better part of a century after the passage of the Sherman Antitrust Act in 1890, corporate America had looked for a way to achieve economies of scale without bringing down the government’s wrath. Frustrated by the legal restrictions forbidding the acquisition of companies in the same industry, companies hit upon the notion of conglomeration—the building of huge multi-industry companies. What happened next was completely unexpected. The conglomerates began to rise in value as the investing world perceived that their acquisitions would dramatically increase overall profitability. These companies could then use their overvalued stock to buy yet more companies. As more and more companies were gobbled up, the earnings of the consumed companies were added to the balance sheets of the conglomerates. Naïve investors were then presented with apparently rapidly increasing corporate earnings, mistaking this for increased efficiency. Prices ballooned even further, allowing the conglomerate to purchase even more companies. The banal nature of the industries under their wings was dressed up with impressive jargon: a zinc mine became a “space minerals division,” shipbuilding became “marine systems,” and meatpacking became “nutritional services.” At its height, the four biggest conglomerates—A-T-O, Litton, Teledyne, and Textron—sold for 25 to 56 times earnings. Pretty heady stuff for what were essentially collections of smokestack companies. Finally, in 1968, the music stopped when Litton announced an earnings disappointment, and the whole house of cards collapsed, with the Four Horsemen falling over 60% each. Worse was to come. There comes a point when the efficiencies of scale bought by increasing size are outweighed by the more subtle disadvantages of sheer bureaucratic weight. Even companies in industries that benefit most from economies of scale—aircraft and automobiles, for example—eventually suffer when they grow too large, as happened recently with DaimlerChrysler. (And in some industries, such as medical care, the optimal company size is quite small—perhaps as few as a hundred employees—a fact belatedly recognized by the recent executives and shareholders of most HMO corporations.) So by the mid-1960s, corporate America found itself blessed not by efficient multi-industry juggernauts, but rather cursed by stumbling behemoths with rapidly falling profitability. 1 And by 1970, investors had had it. They were fed up with flaky tech companies and corporate investors who could wheel and deal with the best but who couldn’t operate a profitable company if their lives depended on it. They wanted safety, stability, and excellence—established companies that dominated their industry and had the proven ability to generate genuine growth. Thus was born the “one decision stock”: buy it, forget about it, and hold on to it forever. So investors loaded up on the bluest of the blue chips—IBM, Xerox, Avon, Texas Instruments, Polaroid—great companies all, at least in the early 1970s. Even in normal times, these companies were not cheap, selling at 20 to 25 times earnings with minuscule dividends. But these were not normal times. By 1972, McDonald’s and Disney had risen to over 70 times earnings, and Polaroid to nearly 100. The whole group of 50 stocks sold at 42 times earnings. What does a ratio of price-to-earnings (P/E) of 42 mean? Doing the same sort of calculation we did in Table 2-1 , we discover that in order for a stock to increase in price by 11% per year (i.e., obtain the market return), it must increase its earnings by about 20% per year for a period of ten years. Now, it is not usual for individual companies to do this. But it is impossible for the biggest of the nation’s companies to all do so at the same time. As you saw in Figure 2-4 , the long-term growth rate of corporate earnings and dividends is only 5% per year. Almost all of these companies eventually disappointed, some more than others. The results for the stockholder were highly disagreeable. Professor Jeremy Siegel makes the point that the Nifty Fifty were not bad long-term investments, with subsequent long-term returns nearly identical to the market. This is true, as far as it goes. The only trouble was that along the way most of these stocks lost between 70% and 95% of their value, and many never came back. A portfolio of stocks with market return and greater-than-market risk is not a blessing. Very few of the original shareholders calmly held on for the long run. The Nifty Fifty provided another moral as well. The seven most recognizable tech names on the list—IBM, Texas Instruments, AMP, Xerox, Burroughs, Digital Equipment, and Polaroid—had truly awful returns—just 6.4% per year for the 25 years following 1972. But the cheapest 25 of the group by P/E had a return of 14.4% versus a return of 12.9% for the S&P 500. These “cheap” stocks, generally selling at P/Es of 25 to 40, were consumer companies—Phillip Morris, Gillette, and Coke. They did not produce the era’s technology, but they certainly used it to advantage. So history once again demonstrated that the spoils went not to technology’s makers, but to its users. Yahoo! A small confession. I could never decide which part of speech this corporate moniker was supposed to represent. Was it an interjection, reflecting the technological and economic ebullience of the time, or was it simply a noun, meant to describe the company’s shareholders? Since the definitive history of this sorry era in investing has yet to be written, you will be stuck with my fragmentary impressions. But there are a few things that can already be said about the Great Internet Bubble. First, in the past few years, we have all had bestowed upon us a morbid historical privilege, not unlike being present at the 1906 San Francisco earthquake. I can remember the sheer wonder of my first reading of Mackay’s Extraordinary Popular Delusions and the Madness of Crowds, which described the Dutch Tulip, South Sea, and Mississippi Company episodes. What must it have been like to live in such a time, I wondered? Now you and I know. Not since the diving and bubble companies of the seventeenth and eighteenth centuries have entities with so little substance commanded such high prices. If we were not personally touched by these shooting stars, we all knew people who were. The April 2000 edition of the Morningstar Principia Pro stock module occupies an honored spot on my hard drive, and from time to time I sift through the names with awe: Terra Networks, selling at 1,200 times sales; Akamai Technologies, 3,700 times sales; Telocity, 5,200 times sales. Not a one with earnings. What were we thinking? My all-time favorite is Internet Capital Group. On August 5, 1999, it went public at $6 per share, rose to $212, then fell back to under a buck. Nothing unusual, really. What made it such an enchanted soul was that it was the direct descendant of the 1920s leveraged investment trusts—its holdings were small, private companies operating in the most wild and wooly part of the Internet scene—business-to-business (B2B). It actually issued bonds, which were of the same quality as those issued by my butcher at Safeway, if only the SEC would allow him to do so. The frosting on the cake was that it sold at an estimated ten times the value of the companies it held. So it not only owned just fluff, but was valued at ten times the fluff it held. Again, all the ingredients were in place: First, Minsky’s “displacement,” this time in the guise of yet another revolutionary invention. Second, liquidity in the form of a Federal Reserve as accommodating as any red-light district house of pleasure. Third, yet another generation under the bridge since the last smashup. And, finally, one more joyous abandonment of Fisher’s iron laws. These stories of financial excess, from the diving company bubble to the dot-com mania, are not just entertaining yarns, they are also a mortal warning to all investors. There will always be speculative markets in which the old rules seem to go out the window. Learn to recognize the signs: technological or financial “displacement,” excessive use of credit, amnesia for the last bubble, and the flood of new investors who swallow plausible stories in place of doing the hard math. When this happens, keep a close hold on your wallet and remember John Templeton’s famous warning: The four most expensive words in the English language are, “This time, it’s different.”",
        "char_count": 61605
      }
    ]
  },
  "little_econ": {
    "meta": {
      "key": "little_econ",
      "title": "The Little Book of Economics",
      "creator": "G. Ip",
      "filepath": "G:/My Drive/15_E-BOOKS/file002141.epub",
      "subject": "Economics"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Table of Contents Praise Little Book Big Profits Series Title Page Copyright Page Dedication Foreword Introduction Chapter One - The Secrets of Success How People, Capital, and Ideas Make Countries Rich Chapter Two - Economic Bungee Jumping Business Cycles, Recessions, and Depressions . . . Oh My! Chapter Three - In-Flight Monitor Tracking and Forecasting the Business Cycle from Takeoff to Landing Chapter Four - Labor Pains Employment, Unemployment, and Wages Chapter Five - Fire and Ice Warning: Inflation and Deflation Are Toxic to Your Economic Health Chapter Six - Drop the Puck! The Globalization Game Is Here Whether We’re Ready or Not Chapter Seven - All the World’ s an ATM Knitting Global Markets Together Chapter Eight - All the President’ s Men They Don’t Control the Economy But They Sure Do Try Chapter Nine - The Buck Starts Here The Federal Reserve’s Amazing Power to Print and Destroy Money Chapter Ten - White Smoke over the Washington Mall The Making of Monetary Policy and the Fine Art of Fed Watching Chapter Eleven - When the World Needs a Fireman America’s Lender of Last Resort and the World’s Crisis Manager Chapter Twelve - The Elephant in the Economy What the Government Giveth and Taketh Away Chapter Thirteen - Good Debt, Bad Debt How Government Borrowing Can Save or Destroy an Economy Chapter Fourteen - Love-Hate Relationship The Bipolar Financial System—Essential for Economic Growth But Sometimes It ... Chapter Fifteen - A Species of Neuralgia The Multiple, Recurring Causes of Financial Crises Acknowledgments About the Author Index",
        "char_count": 1571
      },
      {
        "heading": "Chapter 2",
        "text": "Additional Praise for The Little Book of Economics “Greg Ip has the rare talent of making even the toughest topics easy to understand. In The Little of Book of Economics, he tells you what you need to know with superb clarity and memorable examples. I recommend this book to anyone who wants a clear explanation of how the forces of economics shape the world.” —Michael J. Mauboussin, Chief Investment Strategist, Legg Mason Capital Management; Author of Think Twice “The book is an excellent introduction to basic economic concepts and ideas explained in clear and thoughtful ways. A must read in economic literacy.” —Nouriel Roubini, Professor of Economics, New York University; Co-founder and Chairman of Roubini Global Economics",
        "char_count": 732
      },
      {
        "heading": "Chapter 3",
        "text": "Little Book Big Profits Series In the Little Book Big Profits series, the brightest icons in the financial world write on topics that range from tried-and-true investment strategies to tomorrow’s new trends. Each book offers a unique perspective on investing, allowing the reader to pick and choose from the very best in investment advice today. Books in the Little Book Big Profits series include: The Little Book That Beats the Market by Joel Greenblatt The Little Book of Value Investing by Christopher Browne The Little Book of Common Sense Investing by John C. Bogle The Little Book That Makes You Rich by Louis Navellier The Little Book That Builds Wealth by Pat Dorsey The Little Book That Saves Your Assets by David M. Darst The Little Book of Bull Moves in Bear Markets by Peter D. Schiff The Little Book of Main Street Money by Jonathan Clements The Little Book of Safe Money by Jason Zweig The Little Book of Behavioral Investing by James Montier The Little Book of Big Dividends by Charles B. Carlson The Little Book of Investing Do’s and Don’ts by Ben Stein and Phil DeMuth The Little Book of Bull Moves, Updated and Expanded by Peter D. Schiff The Little Book of Commodity Investing by John R. Stephenson The Little Book That Still Beats the Market by Joel Greenblatt The Little Book of Economics by Greg Ip",
        "char_count": 1321
      },
      {
        "heading": "Chapter 4",
        "text": "Copyright © 2010 by Greg Ip. All rights reserved. Published by John Wiley & Sons, Inc., Hoboken, New Jersey. Published simultaneously in Canada. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600, or on the web at www.copyright.com . Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at www.wiley.com/go/permissions . Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Neither the publisher nor author shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages. For general information on our other products and services or for technical support, please contact our Customer Care Department within the United States at (800) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic books. For more information about Wiley products, visit our web site at www.wiley.com . ISBN 978-0-470-62166-0 (cloth); 978-0-470-92940-7 (ebk); 978-0-470-92939-1 (ebk)",
        "char_count": 2254
      },
      {
        "heading": "Chapter 5",
        "text": "Foreword IT WAS AS A 15-year-old at school in England that I was formally introduced to the subject of economics. And I immediately fell in love with it. Here was a subject that provided me with valuable tools to think about a range of topics, to formulate answers from first principles, and to pose additional interesting questions whose answers I was also eager to know. My love affair with economics has blossomed and continues today. And I feel privileged as economics seems to be even more relevant and topical as time passes. It facilitates our understanding of the well-being of societies; it explains many of the daily interactions between individuals, companies, and governments; and it offers a guide to understanding the political and social trends that are shaping our world. Simply put, economics is the key to understanding and analyzing both what is likely to happen and what should happen. Yet, as a topic, it is also horribly misunderstood and often overlooked. Many believe that economics is too complex, too mathematical, and too arcane for them. Others question the benefits of investing their time and effort to get to know a subject that is the source of endless jokes, including presidential ones. (For example, President Harry S. Truman is said to have famously asked for a one handed economist, noting that “all my economists say, on the one hand and on the other.”) Why am I telling you all this? Because I have come across a book that makes economics brilliantly accessible and, also, lots of fun (yes, economics can be fun!). Forget about those heavy textbooks. Instead, read Greg Ip’s book. It is well written and highly engaging. Moreover, this book could not have been written by a more qualified person; and it could not come at a better time. Greg first came to my attention, and that of my professional colleagues, through his reporting and analyses at the Wall Street Journal. We would all eagerly look forward to his columns for insights into economic developments and the outlook for policy. Greg’s work at the Wall Street Journal, and now The Economist, is based on careful, in-depth research. It uses a robust set of analytical frameworks and reflects access to top policymakers and thinkers. And it is always relevant and timely. His columns have been the catalyst for interesting discussions at PIMCO’s Investment Committee as we all tried to better understand developments and detail our shared outlook for the economy and markets. In his elegant book, Greg takes us on an informative and stimulating economic journey. We make multiple stops as we get exposed to basic topics (such as the drivers of economic growth and welfare) and delicate balances (such as the tug of war between inflation and deflation). We learn about how government actions impact the economy—be it through the familiar channel of public finances and interest rates, or the more complex web of regulations and prudential supervision. The book offers us a wonderful mix of perspectives. We are treated to broad overview analyses that are reminiscent of looking at the landscape from a plane flying at 30,000 feet in a cloudless sky. We are also exposed to careful micro discussions, finding ourselves, as Greg puts it, “inside the sausage factory.” As you would expect, Greg’s book also includes delightful discussions of one of his favorite topics—namely, the design and operation of monetary policy. We get a rare view into the mysterious world of the U.S. Federal Reserve where technocratic competence has to be combined with political savvy and judgment calls about the inherently uncertain balance of future risks and opportunities. The book also provides us with numerous examples of how all this analysis applies to companies and people that are familiar to most of us. Indeed, the frequent real world snippets and text boxes are a great reminder of how economics plays out every day in the world around us. Greg did more that produce an elegant book. He did so at a great time. The global economy today is in a multiyear process of resetting after the 2008-2009 global financial crisis. This historical phenomenon is full of unfamiliar dynamics. It constantly questions “conventional wisdom” and it proceeds in a highly uneven and bumpy fashion. No wonder economics features so prominently on the front pages of daily newspapers around the world. In industrial countries, there are frequent reports on the unusual level and composition of unemployment, the explosion in public debt and deficits, the volatility of exchange rates, the prospect for higher taxation, and the still fragile state of the banking system. In major emerging economies, you will find numerous articles on the sustainability of their development breakout phases, on controlling inflation and asset bubbles, and on resisting protectionist pressures from abroad. Greg assembles and analyzes these pressing themes in a work that is as much a guidebook for our times as an explainer of economics. His brilliant book will help you identify and understand the economic forces that are dramatically reshaping the globe today, and having a major impact on our social and political outlook. It will expose you to the key issues in an engaging and enjoyable fashion. Even seemingly old hands like me will end up learning and re-learning critical aspects of this fascinating and relevant topic. I hope that you enjoy this book as much as I did. It’s a must-read for all those wishing to understand what today’s world holds in store for them, for their children, and for their grandchildren. —Mohamed El-Erian",
        "char_count": 5592
      },
      {
        "heading": "Chapter 6",
        "text": "Introduction IN THE SUMMER of 2009 the cover of The Economist portrayed an economics textbook melting into a puddle. “Of all the economic bubbles that have been pricked, few have burst more spectacularly than the reputation of economics itself,” it said. That same summer, Paul Krugman, the Nobel prize—winning economist, surveyed the wreckage of the global economy and declared that most macroeconomics—the study of the broad economy—of the last 30 years was “spectacularly useless at best, and positively harmful at worst.” For those of us whose job is to watch the economy, the last few years have been a trial by fire. Just a few years ago, we supposedly had it all figured out. Steady growth and low inflation were here to stay and nasty recessions were a thing of the past. Like the bathroom plumbing, the broad economy was something people didn’t think about because it worked fine. Who could blame the folks who watch over our economy, like central bankers, for being a bit smug? We’ve now seen the worst crisis and the deepest recession since the 1930s, and unprecedented government firepower unleashed in response. It’s been a Galapagos Islands of economic exotica: central banks out of interest-rate bullets reaching for their monetary bayonets, debt crises stalking rich and poor countries, fear of inflation side by side with fear of deflation. The smiles have been wiped off the experts’ faces. The public’s indifference to the economy has been replaced by rapt attention and, let’s face it, a lot of fear. With such a turbulent and uneasy global economy, clear explanations of what’s going on are vital. Yet, most people find economics shrouded in jargon and dry numbers. The Little Book of Economics provides the solution. Telling the story of our economy has been my stock in trade for 20 years now. At newspapers in Canada, then at the Wall Street Journal, and now The Economist, I’ve followed markets, talked to workers, visited businesses, and got to know central bankers. Then I’ve explained to readers and listeners in plain, simple terms, what’s going on in the economy, why, and how it affects them. I was introduced to economics as a child. My mother, a practicing economist, now retired, delighted in trying to apply what she knew about the dismal science to her four children’s upbringing. We must have been the only kids in town whose weekly allowance was indexed to inflation. I took economics in college, though not intending to write about it; I just wanted a fallback in case journalism didn’t work out. Right out of college, I joined a metropolitan daily newspaper that put me on the night shift covering local politics, crime, and the like, a lot of which never made it into the paper. The business section, however, had lots of space in it and regular hours, so I got a transfer. Soon, I was writing about the economy and the markets, and loving it. In the process, I discovered a chasm between the economics taught in college and the real world. Textbooks go on about the money supply but it turns out central banks ignore it. Simple questions like “how big is the national debt?” have complicated answers. I learned about fiscal policy but not about debt crises. So I wrote this book with those lessons in mind. This is not a book for PhD economists, but for the citizen and investor on Main Street. I’ve explained the essential concepts with real life examples and analogies, and shown the forces behind the news and events of the last two years. I’ve left out the dense and unappealing jargon. If only the world would do the same! But of course, in the world of economics you will run into jargon, so I’ve prepared you by putting a section called “Into the Weeds” in most chapters. By the phrase “into the weeds,” I mean the internal guts of the economy: the data, the people, the lingo. Don’t be frightened by these sections; they are perfect primers for anyone who wants to follow the markets and the economy in detail. Finally, I’ve boiled down everything in each chapter into “The Bottom Line.” If you read nothing else in the chapter, read this: it will tell you the essentials in a few short sentences. There’s much more to economics than what I could put into The Little Book of Economics so please visit my web site, www.gregip.com , where you’ll find a more complete list of sources used in this book, suggestions for further reading, more of my own articles, and answers to questions about things this book discusses. We’ve been through a lot of economic trauma in the last few years, but economics still offers essential tools for understanding it. This book will put those tools in your hands.",
        "char_count": 4644
      },
      {
        "heading": "Chapter 7",
        "text": "How People, Capital, and Ideas Make Countries Rich POP QUIZ: The year is 1990. Which of the following countries has the brighter future? The first country leads all major economies in growth. Its companies have taken commanding market shares in electronics, cars, and steel, and are set to dominate banking. Its government and business leaders are paragons of long-term strategic thinking. Budget and trade surpluses have left the country rich with cash. The second country is on the brink of recession, its companies are deeply in debt or being acquired. Its managers are obsessed with short-term profits while its politicians seem incapable of mustering a coherent industrial strategy. You’ve probably figured out that the first country is Japan and the second is the United States. And if the evidence before you persuaded you to put your money on Japan, you would have been in great company. “Japan has created a kind of automatic wealth machine, perhaps the first since King Midas,” Clyde Prestowitz, a prominent pundit, wrote in 1989, while the United States was a “colony-in-the-making.” Kenneth Courtis, one of the foremost experts on Japan’s economy, predicted that in a decade’s time it would approach the U.S. economy’s size in dollar terms. Investors were just as bullish; at the start of the decade Japan’s stock market was worth 50 percent more than that of the United States. Persuasive though it was, the bullish case for Japan, as fate would have it, turned out completely wrong. The next decade turned expectations upside down. Japan’s economic growth screeched to a halt, averaging just 1 percent from 1991 to 2000. Meanwhile, the United States shook off its early 1990s lethargy and its economy was booming by the decade’s end. In 2000, Japan’s economy was only half as big as the U.S. economy. The Nikkei finished down 50 percent, while U.S. stocks rose more than 300 percent. What explains Japan’s reversal of fortune and its decade-long economic malaise? Simply put, economic growth needs both healthy demand and supply . As is well known, Japan’s deman d for goods and services suffered when overinflated stocks and real estate collapsed, saddling companies and banks with bad debts that they had to work off. At the same time, though less well known, deep-seated forces chipped away at Japan’s ability to supply goods and services. The supply problem is critical because in the long run economic growth hinges on a country’s productive potential, which in turn rests on three things: 1. Population 2. Capital (i.e., investment) 3. Ideas Population is the source of future workers. Because of a low birth rate, an aging population and virtually nonexistent immigration, Japan’s working-age population began shrinking in the 1990s. A smaller workforce limits how much an economy can produce. Capital and ideas are essential for making those workers productive. In the decades after World War II, Japan invested heavily in its human and economic capital. It educated its people and equipped them with cutting-edge technology adapted from the most advanced Western economies in an effort to catch up. By the 1990s, though, it had largely caught up. Once it had reached the frontier of technology, pushing that frontier outwards would mean letting old industries die so that capital and workers could move to new ones. Japan’s leaders resisted the bankruptcies and layoffs necessary for that to happen. As a result, the next wave of technological progress, based on the Internet, took root in the United States, whose economic lead over Japan grew sharply over the course of the 1990s.",
        "char_count": 3605
      },
      {
        "heading": "Chapter 8",
        "text": "A Recipe for Economic Growth Numerous factors determine a country’s success and whether its companies are good investments. Inflation and interest rates, consumer spending, and business confidence are important in the short run. In the long run, though, a country becomes rich or stagnates depending on whether it has the right mix of people, capital, and ideas. Get these fundamentals right, and the short-run gyrations seldom matter. Until the eighteenth century, economic growth was so slight it was almost impossible to distin- guish the average Englishman’s standard of living from his parents’. Between 1945 and 2007 the United States economy went through 10 recessions yet still grew enough to end up six times larger with the average American three times richer. We’ve taken growth for granted for so long that we’ve forgotten that stagnation could ever be the norm. Yet, it once was. Until the eighteenth century, economic growth was so slight it was almost impossible to distinguish the average Englishman’s standard of living from his parents’. Starting in the eighteenth century, this changed. The Industrial Revolution brought about a massive reorganization of production in England in the mid-1700s and later in Western Europe and North America. Since then, steady growth—the kind that the average person notices—has been the norm. According to economic historian Angus Maddison, the average European was four times richer in 1952 than in 1820 and the average American was eight times richer. In the pre-industrial era, China was the world’s largest economy. Its modest standard of living was on a par with that of Europe and the United States. But China then stagnated under the pressure of rebellion, invasion, and a hidebound bureaucracy that was hostile to private enterprise. The average Chinese was poorer in 1952 than in 1820. So why do some countries grow and some stagnate? In a nutshell, growth rests on two building blocks: population and productivity. 1. Population determines how many workers a country will have. 2. Productivity, or output per worker, determines how much each worker earns. The total output a country can produce given its labor force and its productivity is called potential output, and the rate at which that capacity grows over time is potential growth. So if the labor force grows 1 percent a year and its productivity by 1.5 percent, then potential growth is 2.5 percent. Thus, an economy grows.",
        "char_count": 2445
      },
      {
        "heading": "Chapter 9",
        "text": "Take a Growing Population Let’s recap. An economy needs workers in order to grow. And, usually, the higher the population, the higher the number of potential workers. Population growth depends on a number of factors including the number of women of child-bearing age, the number of babies each woman has (the fertility rate), how long people live, and migration. In poor countries, many children die young so mothers have more babies. As countries get richer and fewer children die, fertility rates drop and, eventually, so does population growth. As women have fewer children, more of them go to work. This demographic dividend delivers a one-time kick to economic growth. For example, it was a major contributor to East Asia’s growth from the 1960s onward and to China’s growth after the introduction of its one-child policy. But a country only gets to cash in its demographic dividend once. Eventually, as population growth slows, it ages and each worker must support a growing number of retirees. If fertility drops much below 2.1 babies per woman, the population will shrink unless it is offset by higher immigration. For this reason, a demographic cloud hangs over China. It may be “the first country to grow old before it grows rich,” say population experts Richard Jackson and Neil Howe. Its fertility rate is below two and its working-age population will start to decline around 2015.",
        "char_count": 1393
      },
      {
        "heading": "Chapter 10",
        "text": "Add Capital A country is not rich, though, just because it has a lot of people—just look at Nigeria, which has 32 times as many people as Ireland but an economy of roughly equal size. The reason for this population/economic size disparity is that the average Nigerian is much less productive than the average Irishman. For a country to be rich—that is, for its average citizen to enjoy a high standard of living—it must depend on productivity, which is the ability to make more, better stuff out of the capital, labor, and land it already has. Productivity itself depends on two factors: capital and ideas. You can raise productivity by equipping workers with more capital, which means investing in land, buildings, or equipment. Give a farmer more land and a bigger tractor or pave a highway to get his crops to market, and he’ll grow more food at a lower cost. Capital is not free, though. A dollar invested for tomorrow is a dollar not available to spend on the pleasures of life today. Thus, investment requires saving. The more a society saves, whether it’s corporations or households (governments could save but are more likely to do the opposite), the more capital it accumulates. Capital, though, will only take a country so far. Just as your second cup of coffee will do less to wake you up than your first, each additional dollar invested provides a smaller boost to production. A farmer’s second tractor will help his productivity far less than his first. This is the law of diminishing returns.",
        "char_count": 1506
      },
      {
        "heading": "Chapter 11",
        "text": "Season with Ideas How do you overturn the law of diminishing returns? With ideas. In 1989, Greg LeMond put bars on the front of his bicycle that enabled him to ride in a more aerodynamic position. This simple idea sliced seconds off his time, allowing him to beat Laurent Fignon and win the Tour de France. New ideas transform economic production the same way. By combining the capital and labor we already have in a different way, we can produce different or better products at a lower cost. “Economic growth springs from better recipes, not just from more cooking,” says Paul Romer, a Stanford University economist. For example, DuPont’s discovery of nylon in the 1930s transformed textile production. These man-made fibers could be spun at far higher speeds and required far fewer steps than cotton or wool. Combined with faster looms, textile productivity has soared, and clothes have gotten cheaper and better. The productive power of ideas is nothing short of miraculous. Investing in more buildings and machines costs money. But a new idea, if it’s not protected by patent or copyright, can be repro- duced endlessly for free. The productive power of ideas is nothing short of miraculous. Investing in more buildings and machines costs money. But a new idea, if it’s not protected by patent or copyright, can be reproduced endlessly for free. Just as other cyclists quickly copied Greg LeMond’s aerobars, companies catch up to their competitors by copying their ideas. Although this can be frustrating for the person who came up with the idea, it’s great for the rest of us as we benefit from the improvements made with the existing idea. Here are a few examples: • New Business Processes. Some of the most powerful ideas involve rearranging how a company runs itself. In 1776, in the first chapter of The Wealth of Nations, Adam Smith marveled how an English factory divides pin making into 18 different tasks. Smith calculated that one worker, who could by himself make one pin a day, could now make 4,000. “The division of labor occasions, in every art, a proportionable increase in the productive powers of labor,” he wrote. Two centuries later Wal-Mart revolutionized retailing by using big box stores, bar codes, wireless scanning guns, and exchanging electronic information with its suppliers to track and move goods more efficiently while scheduling cashiers better to reduce slack time. As competitors like Target and Sears copied Wal-Mart, customers of all three benefited from lower prices and more selection, a McKinsey study found. • New Products. Netscape’s Navigator was the first commercially successful browser but was soon supplanted by Microsoft’s Internet Explorer, which is now under siege by Mozilla Firefox, Apple Safari, and Google Chrome. Browsers keep getting better but consumers still pay the same price, zero. Drugs provide another example. According to Robin Arnold of IMS Health, Eli Lilly’s introduction of the antidepressant Prozac in 1986 inspired competitors to develop similar drugs like Zoloft and Celexa, providing alternatives for patients who didn’t respond well to Prozac. It’s not just companies that thrive by imitating their competitors. Entire countries can turbo-charge their development by strategically copying the ideas and technologies that other countries already use. For example, Japanese steelmakers didn’t invent the basic oxygen furnace; they adapted it from a Swiss professor who had devised it in the 1940s. They thus leapfrogged U.S. steelmakers who were using less efficient open hearth furnaces. Their mainframe computer makers benefited from a government edict that IBM make its patents available as a condition of doing business there. More recently, China’s adaptation of existing ideas from other countries has resulted in significant economic growth. Since 1978, it has moved workers from unproductive farms and state-owned companies to more productive privately owned factories that used machinery bought or copied from foreign companies, expertise acquired from foreign universities or joint venture partners, and intellectual property adapted and occasionally stolen from foreign creators. Still, once a country has copied all the ideas it can, future growth depends on waiting for new ideas or developing its own. Inevitably, a country at the technological frontier grows more slowly than one catching up to the frontier. As we learned earlier in this chapter, that’s just what happened to Japan.",
        "char_count": 4473
      },
      {
        "heading": "Chapter 12",
        "text": "Nurturing Growth Getting the ingredients right is essential to economic growth, but so is the environment that the government creates in order to foster its development. Like the temperature on the oven, the wrong setting can ruin the recipe. So, what do governments do that matters most? • Human Capital. It’s no use equipping workers with the most advanced equipment in the world if they can’t read the instructions. Education and training, both forms of human capital, are essential to productivity. Korea went from third world status to the ranks of the industrialized nations in a generation in part by rigorously educating all its children. Its high school graduation rates now exceed those of the United States. • Rule of Law. Economic growth needs investors to know that if they invest today, they get to keep the rewards years later. That requires transparent laws, impartial courts, and the right to property. The United States’ army of lawyers sue at the drop of a hat and wrap every transaction in legalese, but in a maddening way that signifies its respect for laws. Small government is better than big government, but size is less important than quality. For example, Sweden’s government spends more than half of gross domestic product (GDP) while Mexico’s spends only a quarter of its GDP. But Swedish government is efficient and honest while Mexico’s is inefficient and rife with corruption. That’s one reason Sweden is rich and Mexico is poor. Does government have to be democratic for growth? There’s no firm rule. The authoritarian governments of China, Korea, and Chile ran smart policies that produced strong growth early in their development. Conversely, sometimes democratic governments are pressured by voters to expropriate private property, run up unsupportable debts, or shelter politically favored groups at everyone else’s expense. But dictators have done all those things and worse, bringing on social unrest that ruins the investment climate. Democracy provides essential feedback to government just as free markets do to companies, and elections are generally less disruptive than civil wars. • Letting Markets Work. Entrepreneurs and workers get rich coming up with new, cheaper ways to make things. In the process, they drive someone else out of business. Joseph Schumpeter, the Austrian-born Harvard economist, called this “creative destruction.” Governments squelch creative destruction by forbidding new companies from entering a market, granting monopolies, restricting imports or foreign investment, or making it hard for companies to lay off workers. A financial system that would rather lend to government-owned companies than small entrepreneurs also holds back growth.",
        "char_count": 2711
      }
    ]
  },
  "numbers_rule": {
    "meta": {
      "key": "numbers_rule",
      "title": "Numbers Rule Your World",
      "creator": "Kaiser Fung",
      "filepath": "G:/My Drive/15_E-BOOKS/file008489.epub",
      "subject": "Economics"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Copyright © 2010 by Kaiser Fung. All rights reserved. Except as permitted under the United States Copyright Act of 1976, no part of this publication may be reproduced or distributed in any form or by any means, or stored in a database or retrieval system, without the prior written permission of the publisher. ISBN: 978-0-07-174541-3 MHID: 0-07-174541-6 The material in this eBook also appears in the print version of this title: ISBN: 978-0-07-162653-8, MHID: 0-07-162653-0. All trademarks are trademarks of their respective owners. Rather than put a trademark symbol after every occurrence of a trademarked name, we use names in an editorial fashion only, and to the benefit of the trademark owner, with no intention of infringement of the trademark. Where such designations appear in this book, they have been printed with initial caps. McGraw-Hill eBooks are available at special quantity discounts to use as premiums and sales promotions, or for use in corporate training programs. To contact a representative please e-mail us at bulksales@mcgraw-hill.com. TERMS OF USE This is a copyrighted work and The McGraw-Hill Companies, Inc. (“McGraw-Hill”) and its licensors reserve all rights in and to the work. Use of this work is subject to these terms. Except as permitted under the Copyright Act of 1976 and the right to store and retrieve one copy of the work, you may not decompile, disassemble, reverse engineer, reproduce, modify, create derivative works based upon, transmit, distribute, disseminate, sell, publish or sublicense the work or any part of it without McGraw-Hill’s prior consent. You may use the work for your own noncommercial and personal use; any other use of the work is strictly prohibited. Your right to use the work may be terminated if you fail to comply with these terms. THE WORK IS PROVIDED “AS IS.” McGRAW-HILL AND ITS LICENSORS MAKE NO GUARANTEES OR WARRANTIES AS TO THE ACCURACY, ADEQUACY OR COMPLETENESS OF OR RESULTS TO BE OBTAINED FROM USING THE WORK, INCLUDING ANY INFORMATION THAT CAN BE ACCESSED THROUGH THE WORK VIA HYPERLINK OR OTHERWISE, AND EXPRESSLY DISCLAIM ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. McGraw-Hill and its licensors do not warrant or guarantee that the functions contained in the work will meet your requirements or that its operation will be uninterrupted or error free. Neither McGraw-Hill nor its licensors shall be liable to you or anyone else for any inaccuracy, error or omission, regardless of cause, in the work or for any damages resulting therefrom. McGraw-Hill has no responsibility for the content of any information accessed through the work. Under no circumstances shall McGraw-Hill and/or its licensors be liable for any indirect, incidental, special, punitive, consequential or similar damages that result from the use of or inability to use the work, even if any of them has been advised of the possibility of such damages. This limitation of liability shall apply to any claim or cause whatsoever whether such claim or cause arises in contract, tort or otherwise.",
        "char_count": 3139
      },
      {
        "heading": "Chapter 2",
        "text": "Acknowledgments I would like to acknowledge the guidance and assistance of Grace Freedson, Michele Paige, Micah Burch, Kate Johnson, Steven Tuntono, Beth McFadden, Talbot Katz, and my editors, John Aherne and Joseph Berkowitz. My two sisters and brother made invaluable contributions as my most plain-spoken critics. In addition, throughout this project, I was inspired by fans of my Junk Charts blog, www.junkcharts.typepad.com .",
        "char_count": 430
      },
      {
        "heading": "Chapter 3",
        "text": "Introduction This is not another book about “damned lies and statistics.” That evergreen topic has inspired masterworks from Darrell Huff, John Allen Paulos, Ed Tufte, and Howard Wainer, among others. From the manipulative politician to the blundering analyst, from the amateur economist to the hard-selling advertiser, we have endless examples of what can go wrong when numbers are misused. Cherry-picking, oversimplifying, obfuscating—we have seen them all. This book takes a different direction, a positive position: I am interested in what happens when things go right, which is to say, what happens when numbers don’t lie. The More We Know We Don’t Know What will we learn from Bernie Madoff, the New York–based fund manager–swindler who impoverished an exclusive club of well-to-do patrons over three decades until he confessed in 2008? Or from the Enron executives whose make-believe accounting wiped out the retirement savings of thousands of employees? Perhaps we ought to know why the reams of financial data, printed statements, and official filings yielded few clues to the investors, auditors, and regulators who fell for the deception. What will we learn from the Vioxx debacle in which the Food and Drug Administration conceded, five years after blessing its initial release, that the drug had caused ten thousand heart attacks? Perhaps we ought to know why widely available health and medical information and greater scale and sophistication of clinical trials did not spare Vioxx inventor Merck, doctors, or patients from overlooking the deadly side effects. We ought also to ask why, despite having access to torrents of stock data and company reports, most of us have not made a killing in the stock market. Despite tallying up the nutritional information of every can and every packet of food, most of us have not achieved the hoped-for bodily downsizing. Despite heavy investment in information technology, flight delays and traffic jams continue to get worse. Despite detailed records of our shopping behavior, many companies have but the slightest clue when we call their service centers. Despite failing to arrest cancer in patients during large-scale clinical trials, beta-carotene and vitamin pills keep flying off the pharmacy shelves. These examples reveal the unpleasant surprise that the modern obsession with measurement has made us none the wiser. We collect, store, process, and analyze more information than ever before—but to what end? Aristotle’s wisdom has never been more relevant than it is today: the more we know, the more we know we don’t know. Stories of a Positive Nature We begin to overcome these failures by examining positive examples of how enterprising people are making sensible use of the new information to better our world. In the next five chapters, you will meet engineers who keep the traffic flowing on Minnesota highways, disease detectives who warn us about unsafe foods, actuaries who calculate how much Floridians must pay to insure homes against hurricanes, educators who strive to make standardized tests like the SAT fair, lab technicians who scrutinize blood samples from elite athletes, data miners who think they can detect our lies, lottery operators who face evidence of fraud, Walt Disney scientists who devise ever-clever ways to shorten queues, mathematicians whose ideas have set off the explosion of consumer credit, and researchers who offer the best tips for air travel. These ten portraits feature some special men and women whose work is rarely celebrated openly. The reason for this neglect is that their achievement is not of invention, for which we shower awards and accolades, but of adaptation, of refinement, of salesmanship, and of perseverance. Their expertise is applied science. The Statistical Way of Thinking For me, these ten stories ultimately merge into one: all of these exemplary scientists rely on the statistical way of thinking, as distinct from everyday thinking. I organize the stories into five pairs, each dealing with an essential statistical principle. What is so unconventional about the statistical way of thinking? First, statisticians do not care much for the popular concept of the statistical average; instead, they fixate on any deviation from the average. They worry about how large these variations are, how frequently they occur, and why they exist. In Chapter 1 , the experts studying waiting lines explain why we should worry more about the variability of waiting time than about its average. Highway engineers in Minnesota tell us why their favorite tactic to reduce congestion is a technology that forces commuters to wait more, while Disney engineers make the case that the most effective tool to reduce wait times does not actually reduce average wait times. Second, variability does not need to be explained by reasonable causes, despite our natural desire for a rational explanation of everything; statisticians are frequently just as happy to pore over patterns of correlation. In Chapter 2 , we compare and contrast these two modes of statistical modeling by trailing disease detectives on the hunt for tainted spinach (causal models) and by prying open the black box that produces credit scores (correlational models). Surprisingly, these practitioners freely admit that their models are “wrong” in the sense that they do not perfectly describe the world around us; we explore how they justify what they do. Third, statisticians are constantly looking out for missed nuances: a statistical average for all groups may well hide vital differences that exist between these groups. Ignoring group differences when they are present frequently portends inequitable treatment. The typical way of defining groups, such as by race, gender, or income, is often found wanting. In Chapter 3 , we evaluate the mixed consequences that occur when the insurance industry adjusts prices to reflect the difference in the amount of exposure to hurricanes between coastal and inland properties, as well as what happens when designers of standardized tests attempt to eliminate the gap in performance between black and white students. Fourth, decisions based on statistics can be calibrated to strike a balance between two types of errors. Predictably, decision makers have an incentive to focus exclusively on minimizing any mistake that could bring about public humiliation, but statisticians point out that because of this bias, their decisions will aggravate other errors, which are unnoticed but serious. We use this framework in Chapter 4 to explain why automated data-mining technologies cannot identify terrorist plots without inflicting unacceptable collateral damage, and why the steroid-testing laboratories are ineffective at catching most of the cheating athletes. Finally, statisticians follow a specific protocol known as statistical testing when deciding whether the evidence fits the crime, so to speak. Unlike some of us, they don’t believe in miracles. In other words, if the most unusual coincidence must be contrived to explain the inexplicable, they prefer leaving the crime unsolved. In Chapter 5 , we see how this powerful tool was used to uncover extensive fraud in a Canadian state lottery and to dispel myths behind the fear of flying. These five principles are central to statistical thinking. After reading this book, you too can use them to make better decisions. The Applied Scientist at Work These stories take a shape that reflects my own experience as a practitioner of business statistics. They bring out aspects of the applied scientist’s work that differ substantively from that of the pure or theoretical scientist. All the examples involve decisions that affect our lives in one way or another, whether through public policies, business strategies, or personal choices. Whereas the pure scientist is chiefly concerned with “what’s new,” applied work must deal with “how high,” as in “how high would profits go?” or “how high would the polls go?” In addition to purely technical yardsticks, applied scientists have goals that are societal, as with the Minnesota highway engineers; or psychological, as with the Disney queue managers; or financial, as with hurricane insurers and loan officers. The pursuit of pure science is rarely limited by time; as an extreme example, mathematician Andrew Wiles meticulously constructed his proof of Fermat’s last theorem over seven years. Such luxury is not afforded the applied scientist, who must deliver a best effort within a finite time limit, typically in the order of weeks or months. External factors, even the life cycle of green produce or the pipeline of drug innovations, may dictate the constraint on time. What use would it be to discover the cause of an E. coli outbreak the day after the outbreak dies down? What is the point of developing a test for a designer steroid after dozens of athletes have already gained unfair advantage from using it? Some of the most elegant achievements in pure science result from judiciously choosing a set of simplifying assumptions; the applied scientist adapts these results to the real world by noticing and then coping with inconvenient details. If you have read the writings of Nassim Taleb, you will recognize the bell curve as one such simplification that demands refinement in certain situations. Another example, considered in Chapter 3 , is lumping together distinct groups of people when they should be treated differently. Successful applied scientists develop a feel for the decision-making process: they know the key influencers, they grasp their individual ways of thinking, they comprehend their motivations, and they anticipate sources of conflict. Crucially, they repackage their logic-laced messages to impress their ideas upon those who are more comfortable with intuition or emotion than with evidence. Because understanding the context is so valuable to the applied scientist’s work, I have included a wealth of details in all of the stories. To sum up, applied science has measures of success distinct from those used in theoretical science. For instance, Google recognized this distinction by rolling out its famous “20 percent” time policy, which allows its engineers to split their week between pure science projects of their choosing and applied projects (with an 80 percent emphasis on the latter!). More And there is something extra for those who want more. The Conclusion of this book serves a dual purpose of consolidation and extension. While summarizing the statistical way of thinking, I introduce the relevant technical language in case you should want to cross-reference a more conventional book. To illustrate how universal these statistical principles are, I revisit each concept in a new light, harnessing a different story from the one originally selected. Finally, the Notes section contains further remarks as well as my main sources. A complete bibliography is available at the book’s link on my website, www.junkcharts.typepad.com . Numbers already rule your world. And you must not be in the dark about this fact. See how some applied scientists use statistical thinking to make our lives better. You will be amazed how you can use numbers to make everyday decisions in your own life.",
        "char_count": 11260
      },
      {
        "heading": "Chapter 4",
        "text": "1 Fast Passes / Slow Merges The Discontent of Being Averaged Meter mystery If no one likes, why obey? One car per green, please —H AIKU ABOUT THE M INNEAPOLIS –S T. P AUL COMMUTE BY READER OF THE R OADGUY BLOG Heimlich’s Chew Chew Train Good film, big buildup, nice queue Twenty-second ride —H AIKU ABOUT D ISNEY BY A NONYMOUS In early 2008, James Fallows, longtime correspondent at The Atlantic , published an eye-popping piece about America’s runaway trade deficit with China. Fallows explained how the Chinese people were propping up Americans’ standard of living. The highbrow journal has rarely created buzz on the Internet, but this article beat the odds, thanks to Netizens who scrapped Fallows’s original title (“The $1.4 Trillion Question”) and renamed the article “Average American Owes Average Chinese $4,000.” In three months, Internet readers rewarded the piece with more than 1,600 “diggs,” or positive responses, which is the high-tech way of singing praise. Evidently, the new headline caught fire. Our brains cannot comfortably process astronomical numbers such as $1.4 trillion, but we can handle $4,000 per person with ease. Simply put, we like large numbers averaged . The statistical average is the greatest invention to have eluded popular acclaim. Everything has been averaged by someone, somewhere. We average people (“average Joe”) and animals (“the average bear”). Inanimate things are averaged: to wit, after the terrorist attacks of September 11, 2001, a security dispatch demonstrated how to “weaponize the average water cooler.” Economic processes are averaged, as when a market observer in early 2008 proclaimed “the new hope: an average recession,” presumably predicting a shallow one that would depart with haste. Even actions cannot escape: when Barack Obama’s lawyer interjected on a Clinton conference call during the heated Democratic primary elections of 2008, the media labeled the occasion “not your average conference call.” Can rare items be averaged? You bet. Forbes magazine told us, “The average billionaire [in 2007] is 62 years old.” Surely no one averages uncountable things, you think. Not so quick; the U.S. Census Bureau has devised a methodology for averaging time: on an “average day” in 2006, U.S. residents slept 8.6 hours, worked 3.8 hours, and spent 5.1 hours doing leisure and sporting activities. It is a near impossibility to find something that has not been averaged. So pervasive is the idea that we assume it to be inborn and not learned, nor in need of inventing. Now picture a world without averages. Imagine having the average child, the average bear, and the average such-and-so-forth punched out of our lexicon. We are dumbfounded to learn that such a world did exist once, before a Belgian statistician, Adolphe Quetelet, invented the “average man” ( l’homme moyen ) in 1831. Who would have thought: such a commonplace idea is younger than the U.S. Constitution! Before Quetelet, no one had entertained the import of statistical thinking to the social sciences. Up until that time, statistics and probability fascinated only the astronomers who decoded celestial phenomena and the mathematicians who analyzed gambling games. Quetelet himself was first a distinguished astronomer, the founding director of the Brussels Observatory. It was in midlife that he set the ambitious agenda to appropriate scientific techniques to examine the social milieu. He placed the average man at the center of the subject he named “social physics.” While the actual methods of analysis used by Quetelet would strike modern eyes as hardly impressive, historians have, at long last, recognized his impact on the instruments of social science research as nothing short of revolutionary. In particular, his inquiry into what made an able army conscript earned the admiration of Florence Nightingale (it is little known that the famous nurse was a superb statistician who became an honorary member of the American Statistical Association in 1874). In this body of work also lay the origin of the body mass index (BMI), sometimes called the Quetelet index, still used by doctors today to diagnose overweight and underweight conditions. Since the concept of the average man has been so firmly ingrained into our consciousness, we sometimes fail to appreciate how revolutionary Quetelet really was. The average man was literally an invention, for the average anything did not, and does not, physically exist. We can describe it, but we cannot place it. We know it but have never met it. Where does one find the “average Joe”? Which “average bear” can Yogi Bear outsmart? Which call is the “average” conference call? Which day is the “average” day? Yet this monumental invention constantly tempts us to confuse the imaginary with the real. Thus, when Fallows calculated an average of $4,000 debt to China per American, he implicitly placed all Americans on equal footing, spreading $1.4 trillion evenly among the population, replacing 300 million individuals with 300 million clones of the imaginary average Joe. (Incidentally, the Netizens mistakenly fabricated only 300 million Chinese clones, rhetorically wiping out three-quarters of China’s 1.3 billion people. The correct math should have found the average Chinese lending $1,000 to America.) Averaging stamps out diversity, reducing anything to its simplest terms. In so doing, we run the risk of oversimplifying, of forgetting the variations around the average. Hitching one’s attention to these variations rather than the average is a sure sign of maturity in statistical thinking. One can, in fact, define statistics as the study of the nature of variability. How much do things change? How large are these variations? What causes them? Quetelet was one of the first to pursue such themes. His average man was not one individual but many; his goal, to contrast different types of average individuals. For him, computing averages was a means of measuring diversity; averaging was never intended to be the end itself. The BMI (Quetelet index), for good measure, serves to identify individuals who are not average, and for that, one must first decide what the average is. To this day, statisticians have followed Quetelet’s lead, and in this chapter, we shall explore how some of them use statistical thinking to battle two great inconveniences in modern living: the hour-long commute to and from work and the hour-long wait to get on a theme park ride. A reasonable person, when trapped in traffic or stuck in a long queue, will suspect that whoever was in charge of planning must have fallen asleep on the job. To see why this reaction misplaces the blame, we need to know a little about the statistics of averages. Working with engineers and psychologists, statisticians are applying this knowledge to save us waiting time. ~###~ To label Dr. Edward Waller and Dr. Yvette Bendeck Disney World die-hards would be an understatement. On October 20, 2007, they toured every last open attraction in the Magic Kingdom in just under thirteen hours. That meant fifty rides, shows, parades, and live performances. Buzz Lightyear’s Space Ranger Spin, Barnstormer at Goofy’s Wiseacre Farm, Beauty and the Beast—Live on Stage, Splash Mountain, Mad Tea Party, Many Adventures of Winnie the Pooh, you name it—everything in the park! Nice work if you can manage it, no? Disney buffs know this to be a mission impossible; they feel lucky to visit four major rides on a busy day, not to mention the nonstop walking required within the hundred acres of park area. Waller and Bendeck had help from Len Testa, who devised the Ultimate Magic Kingdom Touring Plan. Testa’s plan lays out precise directions for reaching every attraction in the shortest time possible. He warns unsuspecting novices that it “sacrifices virtually all of your personal comfort.” Len Testa is a thirty-something computer programmer from Greensboro, North Carolina. As the patron saint of disgruntled Disney theme park–goers worldwide, he brought the gift of touring plans, which prescribe routes that guide patrons through a sequence of attractions in the shortest time possible. While the Ultimate Plan grabs attention, Testa creates touring plans for just about every need: for small kids, families, tweens, active seniors, grandparents with small children, and so on. He is mainly looking after rabid Disney fans, ones who are the most loyal—and easily the most demanding—customers. Sampling their typically breathless trip reports, posted on fan websites or relayed to journalists, one frequently comes across affectionate gripes like these: “Going to Disneyland in the summer months is kind of like cruising to the Bahamas during hurricane season. You’re just asking for it.” “You haven’t lived until you’ve stampeded to Space Mountain as the opening rope drops, alongside thousands of stroller-wielding soccer moms at a full run.” “When those gates spring open at 8 A.M ., the weak and the semi-comatose will be left in the dust.” “We felt we spent more time in lines than on rides—the fact is, we did! When a wait in the line is ninety minutes and the ride is only five minutes, you have to question your sanity!!” “I’ve never really forgiven my brother for that one time he slowed us down with an untimely bathroom break at Disney’s Epcot Center five years ago.” These park-goers have plenty of company. Disney’s own exit polls reveal long lines as the top source of customer unhappiness. Industry veterans say the average guest dawdles away three to four hours in queues during a visit lasting eight to nine hours; that’s one minute of standing around out of every two to three minutes inside the park! Amusement Business estimated that the national average for wait time at major attractions in a theme park during the summer was sixty minutes—after which patrons get to spend two minutes on the ride. Since a family of four can spend $1,000 or more in a single trip, it is no wonder why some guests are irritated by seemingly interminable lines. These trip reports leave vivid images of heroic maneuvers to avoid lines. A suitable attitude is required: “When I’m in the parks, I’m a Daddy on a mission. . . . In the course of the afternoon, I’ll go from one end of the park to the other and ride more rides, wait less in lines, and see more shows and parades than many other park patrons, with or without kids.” So are small sacrifices . . . “We manage to avoid long lines with an occasional early morning, and hitting popular attractions during parades, mealtimes, and late evenings.” . . . and knowing how to play the system . . . “The mother behind me told me that they had waited three hours to ride Dumbo during their last visit. [This time,] she took advantage of early admission to let her kid ride three times in a row with no waiting.” . . . and sweet-talking teachers into granting special permission . . . “Taking your kids out of school [to go to Disney]. Is it worth it? Yes!” . . . and spotting opportunities that others give . . . “It does rain in Florida, especially during summer afternoons. The good news is that this tends to scare off some people. My advice: Buy bright-yellow ponchos for $5 each from any of the gift shops. Then keep those kids walking.” . . . while always adapting tactics: “We are starting to think that reverse-reverse psychology might work: Disney opens one park earlier for all their guests so all the guests go to that park. . . . [Everyone else avoids that park, and] therefore we can go to that park because people think it is going to be packed and they avoid it.” Queues happen when demand exceeds capacity. Most large rides can accommodate 1,000 to 2,000 guests per hour; lines form if patrons arrive at a higher rate. If Disney accurately anticipated demand, could it not build sufficient capacity? Did the appearance of long lines reflect negligent design? Surprisingly, the answer to both questions is no. The real culprit is not bad design but variability . Disney constructs each theme park to satisfy the “design day,” typically up to the ninetieth-percentile level of demand, which means, in theory, on nine out of ten days, the park should have leftover capacity. In reality, patrons report long lines pretty much any day of the year. Worse, statisticians are certain that queues would persist even if Disney had designed for the busiest day of the year. To understand this piece of anti-intuition, we must realize that the busiest-day demand merely conveys the average park attendance, and this number ignores the uneven distribution of patrons, say, from one attraction to another or from one hour to the next. Even if Disney correctly predicted the total number of patrons riding Dumbo on the peak day (which itself would have been a tough assignment), a line would materialize unavoidably because the patrons would appear irregularly during the day, while Dumbo’s capacity does not change. Statisticians tell us that it is the variable pattern of when guests arrive, not the average number of arrivals, that produces queues on all but the peak days. Capacity planning can cope with large and static demand, not fluctuating demand. (A theme park that guarantees no lines would require capacity wildly disproportionate to demand, ensuring substantial idle time and unviable economics.) The engineers who figured out these secrets are hailed as heroes by the Disney die-hards, and they work for the Imagineering division, based in several nondescript buildings in Glendale, California, near Los Angeles. They also design new rides, handling not only the thrill factor but also operations management. In the realm of waiting lines, scientists rely heavily on computer simulations as the mathematics of queuing are super complex and frequently irreducible to neat formulas. Think of simulations as turbocharged what-if analyses, run by farms of computers. Thousands, perhaps millions, of scenarios are investigated, covering possible patterns of arrival and subsequent movement of guests around the park. The summary of these scenarios yields reams of statistics, such as the likelihood that the Dumbo ride will reach 95 percent of its capacity on any given day. This creative approach to working around intractable mathematical problems was invented by the Manhattan Project team while building the atomic bomb and also forms the basis of Moneyball statistics featured in Michael Lewis’s account of how the Oakland Athletics outwitted powerhouse baseball teams with much bigger budgets. ~###~ Wouldn’t you know it? The same script plays itself out on our highways: the bane of commuters is not so much long average trip time as it is variable trip time. The statistics paint a harsh reality indeed: the average American worker spent 25.5 minutes traveling to work in 2006, and in addition, more than ten million people endured commutes of over an hour. In total, traffic delays cost $63 billion a year while wasting 2.3 billion gallons of fuel. But these scary numbers miss the mark. Just ask the pileup of readers who sent grievances to Minneapolis Star Tribune . Those truly put off by a long trip to work every day either practice avoidance . . . “I chose to live in Minneapolis for transportation-related reasons: great access to transit and reverse commutes. . . . If people chose to live in Eden Prairie [an edge city southwest of Minneapolis], then I don’t have much sympathy for their complaints about traffic problems.” . . . or have made peace with the inevitable: “Every day, no matter how much traffic there is, it slows down right by McKnight [Road near Maplewood on I-94]. . . . There have been times when we have stopped and had a Coke somewhere because it gets so miserable sitting on the highway.” Commuters know what they are in for, and they take charge of the situation. If average trip time is not the source of bother, what is? Julie Cross, another Star Tribune reader, articulated this well: “Picking the fastest route for my morning commute from Apple Valley is a daily gamble. Should I chance Cedar Avenue, hoping to hit free-flowing traffic for a 5-minute trip to work in Eagan? Or would Cedar be stop-and-go, making the reliable 10-minute trip on Interstate Hwy. 35E the better bet?” Pay attention when Cross used the word reliable . She knew well the average length of her trip to work; what troubled her was the larger variability, and thus unreliability, of the Cedar Avenue option. The highway route required ten minutes, with hardly any day-today variation. Now, if the Cedar Avenue option took five minutes without fail, Julie would never consider taking I-35E. Conversely, if the Cedar Avenue stretch took fifteen minutes without fail, Julie would always take I-35E. The only reason Julie Cross anted up each morning was that the Cedar Avenue route might take less time, even though she knew on average it would take longer. In general, if but one of two routes has variable trip times, then the bet is on. (See Figure 1-1 .) It is tempting to think proper trip planning will beat back any variability in travel time. But just like Disney’s problem of fluctuating demand, this beast proves hard to slay. Jim Foti, who pens the Roadguy column at the Star Tribune , learned the lesson firsthand: Figure 1-1 Julie Cross’s Morning Commute Problem: Impact of Variable Trip Times “Last week, when Roadguy had his radio gig, he had to head out to Eden Prairie during the evening rush hour. Scarred by memories of backups at the Hwy. 212 exit, he allowed himself plenty of extra time. But the drive, right around 5 P.M ., turned out to be as easy and graceful as a computerized animation, and Roadguy reached his destination nearly 20 minutes early.” Drivers find themselves in a no-win situation: arriving twenty minutes early leads to wasted time and even unanswered doorbells, while arriving twenty minutes late spoils other people’s moods, wastes their time, and sometimes causes missed connections. This double whammy is on top of any extra time set aside in anticipation of traffic. And once again, variability is the culprit. Jim’s strategy would have produced fruit if every trip were like the average trip. In reality, a trip that takes fifteen minutes on average may take only ten minutes on good days but eat up thirty minutes on rubbernecking days. If Jim allows fifteen minutes, he will arrive too early most of the time, and too late some of the time. On few days will he finish the trip in exactly fifteen minutes. In short, variable traffic conditions mess up our well-laid schedules, and that ought to upset us more than the average journey time. ~###~ After spending decades fighting average congestion levels, traffic engineers at state departments of transportation have come around to the paramount issue of variable trip times. What is the source of such variability? Cambridge Systematics, an influential transportation consultancy, has estimated that bottlenecks, such as three lanes dropping to two and poorly designed interchanges, account for only 40 percent of congestion delay in the United States. Another 40 percent is due to accidents and bad weather. Choke points on highways restrict capacity and cause predictable average delay, while road accidents and weather-related incidents induce variability around the average. They can create extraordinary gridlocks, like this one . . . A truck carrying 45,000 pounds of sunflower seeds tipped over around 5:45 A.M . and blocked the left two lanes of the freeway for more than 2½ hours. Motorists encountered delays of 30 to 45 minutes as they tried to navigate past the scene. . . . and this one: A dusting of snow Monday was enough to snarl traffic on the freeways. . . . From 5 A.M . to just after 5 P.M ., 110 crashes and 20 rollovers were reported on Minnesota roads. . . . A state transportation official had just two words for drivers: Slow down! The unpredictability of such events makes freeway congestion unavoidable, and delay on some days considerably worse than the average. Not surprisingly, building more roads is the wrong medicine: supplemental capacity can eliminate bottlenecks, at least in the short term, but it does not directly affect reliability. Worse, many transportation experts, including economist Anthony Downs, warn that we cannot build our way out of congestion. In his book Still Stuck in Traffic , Downs elegantly espouses his principle of triple convergence, which postulates that as soon as new capacity gets built, commuters shift their behavior in three notable ways to crowd out any planned benefits: those who previously used local roads decide to switch back to freeways, those who previously altered travel times reverse that decision, and those who previously elected to take public transit return to driving. Thus, new thinking is needed. The Minnesota Department of Transportation (Mn/DOT) has championed an advanced technique called “ramp metering.” Ramp meters are stop-go lights installed on highway entrances to regulate the inflow of traffic. “One car per green” is the familiar mantra. Detectors measure the flow of traffic on the freeway; when the flow exceeds 3,900 vehicles per hour, the freeway is deemed “full,” and the meters are turned on to hold back cars at the on-ramp. Another detector counts the backup on the ramp; when the backup threatens to spill over to the local area, the metering speed increases to dump traffic onto the freeway faster. According to an operations specialist with Mn/DOT, these controls temporarily delay the onset of congestion on the freeway. Ramp metering has compiled an impressive record of success in several metropolitan areas. For example, Seattle saw traffic volume swell by 74 percent even as average journey time was halved during peak hours. Not only were more trips completed, but also less time was spent per trip! So incredible was this double bonus that researchers at the University of California, Berkeley, called it “the freeway congestion paradox.” Typically, as more vehicles pile onto the same stretch of highway, inducing congestion, we expect travel times to suffer; conversely, with traffic moving more slowly, the volume of vehicles should decline. Such laws of physics seem immutable. How does ramp metering make its magic? To unravel the paradox, we must first understand why the emergence of congestion is so feared. Statistical evidence has revealed that once traffic starts to pile up, the average speed of vehicles plunges, and oddly, the carrying capacity of the road degrades below its planned level. In one study, as average speed dropped from 60 to 15 miles per hour during peak hours, traffic flow dropped from 2,000 to 1,200 vehicles per hour. This disturbing situation seemed as illogical as if a restaurateur decided to lay off 40 percent of her staff during busy Friday nights, when one would have thought it crucial to run the kitchen at maximum efficiency. In response to the unsettling discovery, the Berkeley researchers recommended a policy of operating freeways at their optimal speeds, typically 50 to 70 miles per hour, for as much time as possible. In ramp metering, they found an ideal way to throttle the influx of vehicles, a means to maintain the condition of the highway just below congestion level. Its purpose is stamping out variability of traffic speed. The gain in terms of reduced travel time and increased traffic flow “far exceeds any improvements that could be achieved by constructing more freeway lanes.” And there is more to ramp meters. They also mitigate the variability of travel time. Two effects are at play here. First, metering ramps regulate speed, which leads directly to more reliable journey times. Second, the rule stipulating one car per green light spaces out vehicles as they enter the highway, and this dramatically brings down accident rates. Fewer accidents mean less congestion and fewer unexpected slowdowns. This is nowhere more widely felt than in the North Star State, birthplace of the notorious “Minnesota Merge.” Jim Foti’s readers again provided the color commentary: “This is a personal peeve of mine, witnessing people slowly, gradually accelerate on to the freeway so that they just barely make it to the speed limit right at the moment they merge on to the freeway; this causes a conga line of people behind that first merger who end up arriving on to the freeway at 50-45-40-35-30 mph. Slow accelerating mergers can be almost as bad as people who stop at the bottom of the ramps waiting for an opening.” “[Where ramps are not metered,] groups of two, three, or more cars [are] TAILGATING EACH OTHER ON THE RAMPS, try to merge as a group. What the heck is wrong with their heads? Unless there are four or five car lengths between cars on the expressway already, how do they expect to keep cars in the right lane from braking?” “The reason folks don’t use their turn signal on the highway is that most of the time there is a jerk in the other lane who closes the gap so you can’t get in. . . . [The person above] is 100 percent right. I no longer use my turn signal on the highway because of the gapclosers.” One reason why volume declines in concert with reducing speed is that vehicles get too close together for comfort when roads become congested. Some drivers are then prone to braking frequently, and in so doing, they release “shock waves” of reactive deceleration upstream, further disrupting the flow of traffic. Thus, the leaching of capacity during rush hours results from incompetence, impatience, aggression, and self-preservation. Mn/DOT was one of the pioneers in ramp metering, installing its first meters in 1969. During a “war on congestion” in the 1990s, the network grew sixfold to become the densest in the nation, encompassing two-thirds, or 210 miles, of the freeway system in the Twin Cities metropolitan area. Mn/DOT is also the most aggressive among its peers at holding back ramp traffic during peak hours in order to deliver a reliable flow on the freeway. Industry experts regard Minnesota’s system of 430 ramp meters as a national model. ~###~ At their core, both Disney and Mn/DOT face the scourge of congestion, and they have both come to realize that no amount of capacity expansion can banish the problem of variability due to fluctuating patron arrivals or unpredictable on-road incidents. Besides, expansion projects take time, money, and frequently political will as well as sacrifice from current users for a future, common good. Growing capacity is a necessary but insufficient solution. Statisticians believe that a sound transportation policy should emphasize optimally utilizing available capacity. Finding new ways to do so costs significantly less than constructing new highways and yields quicker returns. Ramp metering is one such solution. Disney managers have concluded that measures to optimize operations, while effective, also are not sufficient; they have gone one step further than freeway engineers. The crown jewel in Disney’s operating manual is perception management. A body of scholarly research supports the view that crowd control is much more than a mathematical problem or an engineering puzzle; it has a human, psychological, touchy-feely dimension. A key tenet of this research—that perceived waiting time does not equal actual waiting time—has been demonstrated in multiple studies. Mirrors in elevator lobbies, for example, distort people’s sense of the amount of waiting time; we tend not to count time spent looking at our reflection as waiting time. Accordingly, Disney engineers, or “Imagineers,” devote a lot of effort to shaping patrons’ perception of waiting times. By contrast, engineering solutions, including ramp metering, tend to target reductions in actual waiting times; these efforts may fail because people misjudge how much time they have stood in lines or stalled their cars. Over the years, Disney has perfected the magic of managing perceptions. Take a walk around the park, and you cannot fail to see their handiwork. The waiting area of Expedition Everest, for instance, is decorated as a Nepalese village, with artifacts and flora brought back from the Himalayas; before getting on the roller-coaster, patrons weave through a yeti museum and encounter cryptic messages that generate excitement. At other sites, when lines get terribly long, “Streetmosphere” performers playing Hollywood characters mill around to entertain guests. Signs show estimated waiting times that “intentionally turn out to be longer than the actual time waited,” according to Bruce Laval, a former Disney executive. The next time you telephone customer service and hear that computer voice announcing, “Your expected wait time is five minutes,” contrast how you feel if a customer service rep picks up the call after two minutes with your mental state if you are still on hold after eight minutes. Such is the power of this classic strategy of underpromising and overdelivering. These and other designs suggest a briskly moving line or divert attention away from the queue. The superstar of the Disney queue management effort is Fast-Pass, the proprietary “virtual” reservation system launched in 2000. Arriving at any of the major attractions, guests can either join the “standby” line and wait then and there, or opt to pick up FastPasses, which entitle them to return at a designated later time and join an express lane. Since the FastPass lane always clears at a much higher rate than the standby line, the typical wait will be five minutes or less when FastPass holders resurface during the preassigned time. To aid guests in their decision, Disney posts the estimated wait time for those choosing the standby line, juxtaposed with the FastPass return time. Testimony from satisfied patrons points to the unmistakable success of this concept. One analytically minded fan, Allan Jayne Jr., demonstrated why: “How effective is FastPass? Very. . . . Let’s say that FastPass forced the regular (‘standby line’) riders to wait on average 1½ hours each instead of 1 hour while FastPass riders don’t wait at all. So we have 9,000 people who did not spend any time waiting and 3,000 riders who waited an average of 1½ hours each for a total wait of 4,500 hours. That is about six months of waiting compared with 16 months without FastPass [all 12,000 riders waiting 1 hour each]. Thus FastPass saved ten months of standing in line!” Satisfied guests are eager to pass along their wisdom, as Julie Neal did on her blog: How to Get the Most from FastPass 1. Designate someone as your FastPass supervisor. This person will hold all your park tickets, go off to get FastPasses for your entire party throughout the day, and watch the time. Hello, Dad? 2. Always hold at least one FastPass, so you’re always “on the clock” for at least one attraction. Get one when you get in the park, then others as often as possible throughout the day. 3. Don’t sweat it if you miss the return time. Disney rarely enforces it, as long as you use your ticket the same day it was issued. 4. Use the service for every FastPass attraction except those you’ll be riding before 10 A.M. or very late at night. Clearly, FastPass users love the product—but how much waiting time can they save? Amazingly, the answer is none ; they spend the same amount of time waiting for popular rides with or without FastPass! It is mistaken to think that FastPass eliminates waiting, as the above quotation suggested; it is just that instead of standing in line and in the elements, patrons are set free to indulge in other activities, whether on less popular rides or in restaurants, bathrooms, hotel beds, spas, or shops. The time in queue, which is the lag between arriving at the ride to pick up a FastPass ticket and actually getting on the ride, may in fact be even longer than before. Given that the attractions have the same capacities with or without FastPasses, it is just not possible to accommodate more guests by merely introducing a reservation system. So Disney confirms yet again that perception trumps reality. The FastPass concept is an absolute stroke of genius; it utterly changes perceived waiting times and has made many, many park-goers very, very giddy. Behind the scenes, statisticians run the FastPass system through a network of computers that count visitors and record wait times. When a new guest arrives, they figure out how long the ride would take to serve all the patrons in front of him or her, including the “virtual” ones now scattered around the park holding dearly to their FastPass tickets. The guest is then advised a return time later in the day. The line looks short but only because many people in line are not physically present. The new guest does not get to skip ahead. In effect, Disney presents park-goers the Julie Cross gamble: should they accept the reliable FastPass option, or should they get in the standby line and roll the die? Those in the standby line can get in with minimal waits if they happen to catch a lull in guest arrivals or FastPass returns, but more often than not, they will suffer hour-plus waits, as the following frustrated patron could attest: “After standing in line for Peter Pan last summer for over an hour watching the FastPass line moving through constantly, it appeared that the Cast Members were more inclined to let the FastPass holders have far too much precedence over those of us who were sweating profusely (not to mention not smelling too great after a day at the park). It was aggravating.” Compare that experience with this view from the other line: “A lot of people were trying to figure out who we were. You could feel their stares.” Like ramp metering, FastPass also works by stamping out variability, in that guests are being spaced out as they arrive. When the rate of arrival exceeds the ride’s capacity, those picking up FastPasses agree to return later in the day. At other times, when demand lapses temporarily, standby guests are admitted readily to prevent idle time. In this way, the rides run at full capacity whenever possible. As Professor Dick Larson, tellingly known as “Dr. Queue,” remarked, “Even though Disney’s theme park lines get longer each year, customer satisfaction, as measured by exit polls, continues to rise.” ~###~ Back in Minnesota, perception trumped reality once more: much to the chagrin of Mn/DOT, the transportation department’s prized ramp-metering strategy was under siege in the fall of 2000. State senator Dick Day led a charge to abolish the nationally recognized program, portraying it as part of the problem, not the solution. In his view, decades of ramp metering had come to naught as the Twin Cities continued to be among the most congested in America. The state came dead last, with 71 percent of its urban freeways declared congested in a report by the American Society of Civil Engineers. Leave it to Senator Day to speak the minds of “average Joes”—the people he meets at coffee shops, county fairs, summer parades, and the stock car races he loves. He saw ramp metering as a symbol of Big Government strangling our liberty: “It’s always bothered me—who stops? Who is the first person to stop at a ramp meter in the morning? Why does he stop? He should just go right through it. The first guy is jamming it up, and it ripples back to fifteen to twenty cars.” How the senator managed to tap into a deep well of discontent! The Star Tribune readers offered their firsthand accounts: “The operation of the meters makes no sense. Far too often the meters are on when the traffic is actually very light on the freeway, and in addition, the meters are cycling at a very slow rate.” “Why do traffic managers allow the meters to create long lines at 6 P.M . when there are about thirty cars on the freeway and they are moving at 75 miles per hour? What’s up with that? Is no one minding the store?” Recall that Disney guests perceived their waiting times to have shortened drastically even though in reality they may have increased. In the Twin Cities, drivers perceived their trip times to have lengthened even though in reality they have probably decreased. Thus, when in September 2000, the state legislature passed a mandate requiring Mn/DOT to conduct a “meters shutoff” experiment, the engineers were stunned and disillusioned. They were certain that under their watch, the freeway system was carrying more vehicles per hour than ever before, and it was performing close to capacity even during peak hours because of ramp metering. They also knew most drivers were experiencing shorter total trip times despite having stopped at on-ramps. All the engineers got for doing their job well was a slap in the face. The state extinguished all 430 ramp lights for six weeks. Traffic conditions were measured before and during the shutoff experiment to determine the effect of ramp metering. Cambridge Systematics, which conducted the study, collected objective data from detectors and cameras as well as subjective data from focus groups and a phone survey. On the eve of the metering holiday, the two sides issued dueling predictions of doom. Rich Lau, one of the foremost experts on ramp metering at Mn/DOT, predicted that driving without meters would be a lot like “driving in a snowstorm.” He warned, “Any legislator who voted for [the meters shutoff] would have to answer to folks within a couple of weeks. The telephones would not quit ringing.” Meanwhile, Senator Day also had a forecast: “I’ll tell you when the disaster is going to be—a month from now, when they put them back on.” Soon, all of the Twin Cities’ 1.4 million commuters took sides. As then House Majority Leader Tim Pawlenty remarked, “When we talk to people, they want to talk mostly about [Governor Jesse] Ventura and ramp meters.” With few exceptions, they voiced their views, blissfully projecting their experience onto others: “It was a dream. My travel time was a bit quicker than usual. I knew those meters were a hoax!” “My commute [time] more than doubled today [after the meters were turned off]. I eventually had to get off 169 and take back streets to get to work twenty minutes late. Already I was going to have to move up the time I depart my house in the morning about twenty-five minutes.” “After experiencing life without meters, it seems ludicrous to me to consider going back to the same system.” “I think the meters should be fully returned to service after the monitoring period is up—no ifs, ands, or buts.” “When I’m leaving town at night, I wish the meter was there because it’s too much congestion. They [other drivers] don’t want to let you merge in. But at the other end in the morning, I save ten minutes [without meters].” In the final analysis, the engineering vision triumphed. Freeway conditions indeed worsened after the ramp meters went off. The key findings, based on actual measurements, were as follows: • Peak freeway volume dropped by 9 percent. • Travel times rose by 22 percent, and reliability deteriorated. • Travel speeds declined by 7 percent. • The number of crashes during merges jumped by 26 percent. The consultants further estimated that the benefits of ramp metering outweighed costs by five to one. More important, the engineers did get that slap in the face, hard. The subjective portion of the study, reflecting public opinion, substantively replicated the rants by Star Tribune readers over the years. It was only now that the engineers acknowledged their blind spot. As Marc Cutler of Cambridge Systematics concluded, “In general, people don’t like to wait for anything. They don’t like to wait for a bus; they don’t like to be on hold on the telephone. They tend to feel trapped and experience a lack of choice and control.” In other words, despite the reality that commuters shortened their journeys if they waited their turns at the ramps, the drivers did not perceive the trade-off to be beneficial; they insisted that they would rather be moving slowly on the freeway than coming to a standstill at the ramp. At long last, the engineers listened. When they turned the lights back on, they limited waiting time on the ramps to four minutes, retired some unnecessary meters, and also shortened the operating hours. That was not the optimal engineering solution, obviously, but what the people wanted was what they got. Cutler continued, “There’s a tolerance limit people have for waiting at ramp meters. That public perception has to be taken into account by government. You can’t make decisions simply on engineering and planning principles.” In this respect, the freeway engineers could take a cue from Disney’s exemplary effort in perception management. Dr. Queue, the professor who studies Disney lines, has a theory about this apparently irrational behavior. He has long advocated that traditional scientific studies of queues include the psychological perspective. What bothers people most turns out to be “slips and skips”: being held up by a ramp meter while other cars zoom past suggests to them a grave social injustice. As one Twin Cities commuter lamented: “Every day, I queue up and wait. . . . In my attempt to be a good responsible citizen, I just accept my fate. Meanwhile, I watch one [single driver] after another zip up the HOV [High-Occupancy-Vehicle] lane.” Of course, we have heard similar sentiments in the Disney standby lines. ~###~ The average man is one of the few inventions by statisticians that have found a permanent place in our popular lexicon. Statisticians use the concept in an altogether different way from the rest of us: they focus on the variations around the average, rather than the average value itself. For example, theme park–goers who worry about hour-long queues and workers who grumble about hour-long commutes are describing their experiences in terms of average waiting times. Statisticians tell us that large variability around these averages, due to fluctuating guest arrivals or happenstance, is the primary source of irritation. Such variations disrupt our well-laid schedules. Thus, the most effective measures for managing lines and freeway traffic, including Disney’s FastPass virtual reservation system and Mn/DOT’s ramp metering, aim to take variability out of the system. One may think that queues at theme parks can be obviated by expanding capacity, and that congestion at rush hours can be contained by building more roads. Such tactics are hardly sufficient in the face of variability. That, in short, is the discontent of being averaged.",
        "char_count": 42500
      },
      {
        "heading": "Chapter 5",
        "text": "2 Bagged Spinach / Bad Score The Virtue of Being Wrong You can tell a little thing from a big thing. What’s very hard to do is to tell a little thing from nothing at all. —M ICHAEL T HUN, EPIDEMIOLOGIST Does God only send hail to damage the roofs of people who are bad credit risks? —S TEVEN W OLENS, FORMER T EXAS STATE REPRESENTATIVE There is a particular breed of statisticians called modelers . Think of modelers as reconnoiterers sent into foreign lands full of danger; they take snapshots of random places and then make general—critics might say wild—statements about the world at large. They play a high-stakes game, ever wary of the tyranny of the unknown, ever worried about the consequence of miscalculation. Their special talent is the educated guess , with emphasis on the adjective. The leaders of the pack are practical-minded people who rely on detailed observation, directed research, and data analysis. Their Achilles heel is the big I , when they let intuition lead them astray. This chapter celebrates two groups of statistical modelers who have made lasting, positive impacts on our lives. First, we meet the epidemiologists whose investigations explain the causes of disease. Later, we meet credit modelers who mark our fiscal reputation for banks, insurers, landlords, employers, and so on. By observing these scientists in action, we will learn how they have advanced the technical frontier and to what extent we can trust their handiwork. ~###~ In November 2006, the U.S. Senate Committee on Health, Education, Labor, and Pensions held a public hearing to second-guess the response of the Food and Drug Administration (FDA) to the just-abated E. coli outbreak. The atmosphere was surprisingly cordial, as all seven expert witnesses shared one uplifting narrative. They all commended the public-health agencies for pinpointing spinach as the cause of the outbreak in record time and for organizing a bold and broad product recall that prevented many more citizens from falling ill. Only two months earlier, on September 8, officials from Wisconsin had first set the clock ticking by disclosing a suspicious cluster of five cases of E. coli –related illnesses. A week later, the FDA persuaded key producers to recall all fresh spinach produce. Within eighteen days, on the strength of incessant sleuthing, investigators retraced the convoluted path from contamination to disease—linking case after case to spinach processed at a three-acre farm in California during a specific shift on a specific day, spinach that would later reach homes as bagged, prewashed Dole baby spinach. The speed and precision of discovery announced another triumph of the modern science of disease detection, also known as epidemiology . Consumer groups praised the collaborative effort by scientists and public officials; even the produce industry promptly accepted responsibility. Against this feel-good backdrop, the Senate hearing centered on ways to support the agencies through funds or technology. But there is more than one way to tell a good story. Let’s rewind and start over. On August 15, a batch of spinach got contaminated at a producer in California. Ten days later, Marion Graff of Manitowoc, Wisconsin, fell ill after eating spinach from a salad bar. Soon after, she checked into a hospital. She would go on to become Victim Number 1 of the emergent outbreak. In the next few weeks, the tainted spinach found its way to twenty-six states, afflicting at least two hundred people. By September 1, the outbreak reached a peak and started to ebb. Two more weeks passed before the FDA initiated the spinach recall on September 14. By then, new infections had slowed to a trickle. So in all likelihood, the outbreak died a natural death. Indeed, given the short shelf life of spinach, all of the infected batch would have degraded before the recall took shape. In the meantime, mass hysteria summarily crippled nationwide spinach consumption for months, dealing the industry a direct hit of over $100 million in revenues. In the end, three unlucky people perished out of roughly fifty million who eat spinach in any given week. If you are discomforted by the retold story, you are not alone. While both narratives are factual, the official story is simple comfort food. With scant scrutiny, consumer groups and the media gobbled it up. The retelling is like spicy Buffalo wings, the juicy bits caught inside the hard bones. Was it blind trust we gave to the FDA? How did the new science ascertain cause–effect? How did five sick people turn a nation into panicked consumers? Was there a fine line between protection and overreaction? The alternative narrative exposes these hard, practical facts of life. And it is the kind of story made for this book. ~###~ Some legislative hearings are less cordial than others; those involving the credit-scoring industry can be downright acrimonious. Since the 1990s, bills restricting the usage of credit scores have become de rigueur on the legislative agendas of at least forty states. The credit score is a three-digit number computed from credit reports, designed to estimate the chance of someone defaulting on a loan. The technology works by analyzing characteristics purported to be positive or negative indicators of such behavior. Every year, consumer groups introduce us to another handful of wronged consumers who express outrage over rejected loans or soaring interest rates, blamed on incorrect or incomprehensible credit scores. The rhetoric is vicious. Texas state representative Steven Wolens voiced a common sentiment most colorfully: “I am opposed to the notion that people who don’t pay their bills on time are more likely to have hail damage to their roofs.” By this, he challenged the industry to produce evidence of a direct cause–effect relationship between the indicators used in credit scoring and home insurance claims. Other critics deride the technology as “garbage in, credit score out,” charging the credit-reporting agencies with gross incompetence in compiling data that form the basis of credit scores. Still others accuse insurers of co-opting credit scoring as “the 21st century tool for redlining,” referencing the outlawed commercial practice of denying mortgages to inner-city neighborhoods. The supporters of credit scoring are equally fervent. At the Federal Reserve, then-chairman Alan Greenspan averred, “Lenders have taken advantage of credit scoring models and other techniques for efficiently extending credit to a broader spectrum of consumers. The widespread adoption of these models has reduced the costs of evaluating the creditworthiness of borrowers, and in competitive markets, cost reductions tend to be passed through to borrowers.” First marketed in the United States in the 1960s, credit-scoring technology has commanded powerful validation in the marketplace; by 2000, more than ten billion scores were said to be used annually. Today, it plays an integral role in the approval for credit cards, auto and home loans, small-business loans, insurance policies, apartment rentals, and even employment. The senior vice president of one regional bank raved, “As you analyze the portfolio [of loans], you can see that the scorecards absolutely work,” explaining that the bank made thirty-three times as many loans while losses held steady. It is astonishing that this track record hinges entirely on computers identifying repetitive patterns of behavior, often called correlations , without recourse to cause–effect. No wonder Tim Muris, former chairman of the Federal Trade Commission (FTC), remarked, “The average American today enjoys access to credit and financial services, shopping choices, and educational resources that earlier Americans could never have imagined.” Each side, bearing its own script, clashes year after year. The populist narrative assails the practice of credit scoring as harmful to consumers, while the alternative extols the far-reaching benefits of the science. How can we determine whether credit scores are helping people or hurting them? What is the logic behind the science? Where is the fine line between protection and overreaction? It turns out statistics is at the heart of epidemiology as well as credit scoring. These two fields attract the particular breed of statisticians called modelers. Their special talent is the educated guess; their handiwork informs vital decisions in business and public policy. Just as epidemiologists pinpoint the causes of diseases, credit modelers uncover the indicators of undesirable consumer behavior. For their achievements, these statisticians have garnered paltry attention. In this chapter, we shine a light on their craft, beginning with one suburban family in Middle America. ~###~ On September 7, 2006, doctors at Elmbrook Memorial Hospital in Manitowoc County, Wisconsin, readmitted Lisa Brott after her stool tested positive for E. coli , a type of bacteria that can cause discomfort, kidney failure, and even death. Subsequent examination revealed that her blood and kidneys were infected by a virulent class of the bacteria referred to as O157:H7; in the ensuing eight days, Lisa received head-to-toe blood replacement through a slit in her neck. Another resident of Manitowoc, Marion Graff, age seventy-seven, fell ill while taking a bus trip for seniors and later died of E. coli –induced kidney failure in a hospital in Green Bay. Every year, a handful or a dozen Manitowoc residents contract E. coli ; the infections frequently occur in clusters, especially in the summertime, due to the popularity of water sports and barbecue parties. Most of these illnesses are “sporadic,” not linked to an outbreak, and thus cause no special alarm. The presence of incidental cases, however, makes daunting the detection of the beginnings of a true outbreak. As each new case shows up, one must decide if it is part of an upward trend or not. How long does one wait before declaring an outbreak? Between prescience and prevarication is a tight space! The Manitowoc health office believed they had detected a localized cluster, as four of the five patients attended the county fair in late August and presumably came into contact with livestock, a familiar source of E. coli . The five cases were reported to Dr. Jeffrey Davis, the state’s chief medical officer for communicable diseases, who had also learned about another E. coli cluster in Dane County. Since Wisconsin sees hundreds of E. coli cases each year, Dr. Davis’s staff was unsure whether this summertime spurt was anything out of the ordinary. Then, on September 8, the office received word about five patients in five hospitals who had been treated for severe kidney failure in the preceding few days. The educated guess pointed to an outbreak. Later that day, the state laboratory discovered that eight patients had identical strains of O157:H7. Because more than 3,520 such strains have been documented, each with a distinctive “DNA fingerprint,” this finding strongly suggested a common source. Dr. Davis determined that a statewide outbreak was under way, and he alerted the Centers for Disease Control and Prevention (CDC) in Atlanta, Georgia. Meanwhile, disease detectives in Oregon also were hot on the trail after microbiologists confirmed a cluster of three O157:H7 cases on September 8 and a further three cases on September 13. Dr. Bill Keene, the head epidemiologist, recognized a statewide outbreak, and he also notified the CDC. At the CDC, Molly Joyner managed the database of PulseNet, suggestively described by Dr. Davis as “a dating service for bacteria.” Each year, public-health labs around the country contribute over five thousand E. coli fingerprints to this national database. Joyner prescreened the entrants, looking for close matches. On September 11, she noticed Wisconsin’s submission of eight related E. coli cases. This strain resembled one previously found in hamburger patties in Texas, and its DNA was indistinguishable from earlier submissions by nine other states. The now-familiar story replayed itself at the federal level. Joyner was used to seeing two or three uploads of O157:H7 in any given week, reaching a seasonal high during the summer. The specific strain had never been linked to any U.S. outbreaks before, but since 1998, it was appearing more and more often. She wondered if all these cases could be connected. When another new case arrived from Minnesota, she pulled the trigger. ( Figure 2-1 illustrates the decision facing Joyner every year as cases are reported to the CDC.) First individual states and then the federal agencies mobilized. A deadly bacterium on the loose was like a ticking time bomb: there was precious little time to locate it and then defuse it. In Wisconsin and Oregon, the disease detectives sprang into action, calling patients and their families to ask about their eating habits. However, the first round of interviews failed to uncover a “smoking gun,” that is, the tainted food item eaten by the patients before they fell ill. In Manitowoc, John Brott, Lisa’s husband of twenty-seven years, told investigators Lisa did not eat red meat, did not drink, and loved green salads, especially in the summer. This report threw them off guard. As the county health officer explained, “Let’s say someone went out and had a hamburger and a salad. Almost automatically, you would think the hamburger is the link to E. coli because that has been the past history.” About 40 percent of past food-borne outbreaks were caused by contaminated beef—not surprising, since cow intestines harbor E. coli bacteria. Figure 2-1 Between Prescience and Prevarication: The CDC Pulled the Trigger To be fair, all epidemiological evidence collected during these early stages is conflicting and patchy, half facts and half speculation without an obvious dividing line. Try as they might, patients cannot pinpoint each food injested and every restaurant visited in the recent past, so their answers are bound to be incomplete, inaccurate, or even misleading. In Oregon, Dr. Keene ordered a much more intrusive questionnaire, nicknamed the “shotgun.” To say this survey casts a wide net would be an understatement. Melissa Plantenga, an analyst, spent the night and the next morning peppering five patients with 450 questions each, detailing everything and anything that could have entered their stomachs, including commonplace items like romaine lettuce, eggs, and bottled water, as well as the unusual—such as dried seaweed, cheese from a mail-order source, and homegrown fresh tomatoes from a garden. It was like trying to find the needle in a haystack, but the reward could prove gratifying: Plantenga would be the first person to propose that “bagged spinach” caused this E. coli outbreak, and she would later be proven right. She reasoned, “A lot of the time, with [only a few] people, we won’t be able to figure the source out. But this time, it seemed odd that I was hearing, ‘bagged spinach,’ ‘bagged spinach.’” Four of her five interviewees mentioned those leafy greens. Back in Wisconsin, Dr. Davis also ordered more extensive interviews done. The first eight that came back all implicated spinach. In New Mexico, detectives independently suspected leafy greens and collected bags of spinach for lab testing. So it came hardly as a surprise when Dr. Keene called the CDC about the Oregon outbreak, he found Dr. Davis on the other line. Everything came together: those present recalled, “There was an electrical moment when in the space of one hour, two epidemiological hypotheses matched and the two [DNA] patterns matched.” The doctors concluded—thanks to savvy statisticians on the team—that bagged spinach was the cause of an epidemic developing in multiple states. In only eight days following the first report in Manitowoc, epidemiologists succeeded in detecting the outbreak and determining its scope. It was a marvel how much happened in such a short time. They also deduced its most likely cause. But each passing day brought forth more cases: in Wisconsin, they totaled twenty, with one fatality; in Utah, eleven; in Oregon, five; in Indiana, four; in Michigan, three; in Idaho, three; in New Mexico, two; and in Connecticut, one. The fast-rising case count severely tested the scientists’ conviction: if tainted spinach was indeed the cause, then consumers should stop eating the vegetable till the outbreak abated; if it was not the cause, then such an action would devastate an industry while the outbreak would ravage on. The consequence of miscalculation was grave, the stakes high and getting higher. ~###~ A century and a half ago, a young English doctor found himself in a worse predicament when a string of cholera outbreaks killed tens of thousands between 1830 and 1850. In 1854, around London’s Broad Street (now Broadwick Street), 127 people succumbed to the disease in three days, and 500 died in the first ten days. At the time, the cause of cholera was popularly believed to be “miasma,” also known as foul air. In a series of inspired studies, Dr. John Snow demonstrated that cholera is spread by foul water, not foul air. By mapping sites of water pumps and homes of the deceased, he guessed correctly that the Broad Street pump was infected. Folklore had it that the outbreak halted as soon as the handle was taken off the pump. (Epidemiologists now believe that other factors such as the flight of residents from the sullied area also contributed to ending the crisis.) Dr. Snow’s epic field investigations marked the beginning of epidemiology of infectious diseases. It was Dr. Alexander Langmuir who brought this discipline to the United States. As CDC’s chief epidemiologist, Langmuir in 1951 inaugurated the Epidemic Intelligence Service (EIS), a training program for disease detectives. He conceived and sold the program as a form of “civil defense” against the threat of biological weapons during the Cold War. EIS officers have played leading roles in preventing and controlling diseases, including polio, lead poisoning, Legionnaires’ disease, and toxic shock syndrome. They proudly wear lapel pins of a shoe with a hole, symbolizing the sweat and toil involved in their surveillance activities. In Langmuir’s office hung the portraits of his three heroes: John Snow (of course), Sir Edwin Chadwick, and Charles Chapin. Chadwick, like Snow, was instrumental in jump-starting sanitation reform in England in the nineteenth century; he advocated the then-novel concept of using pipes to carry water into residences. Chapin, who served as the health officer of Providence, Rhode Island, for forty-eight years, earning the nickname “the dean of city health officers,” ignited the public-health movement in the United States in the 1880s, and he also championed the use of scientific principles. Langmuir preached the value of collaboration and encouraged people from psychology, anthropology, sociology, and other disciplines to attend EIS training. To date, the program has graduated over three thousand officers, and about 30 percent of those in recent classes are not doctors. EIS officers are celebrated for their balance of analytical rigor and practical outlook. ~###~ On September 14, the FDA went all-in: announcing the multistate outbreak, it urged consumers not to eat bagged spinach, soon expanded to all fresh spinach. The breadth of the advisory was unprecedented for a vegetable or fruit. But the industry absorbed the shock surprisingly well, and several key players agreed to a sweeping product recall. Restaurants including McDonald’s and Subway quickly dropped spinach from their menus. Grocers including Wal-Mart and Safeway yanked spinach off their shelves and salad bars. The media exploded with front-page stories. People dumped what spinach they had at home. For the next five days, U.S. spinach sales evaporated. Robert Rolfs, the Utah state epidemiologist and an EIS graduate, summarized the rationale well: “Until we get to the bottom of this [outbreak] and find out how widespread it is, what brand it is, where the contamination is, for the short term, I’d suggest people not eat raw spinach.” Tacitly, he acknowledged the scientists knew less than what they did not know. Let’s review the evidence up to September 14. Eight states had reported fifty cases. Most of these infections were related because they shared the same strain of O157:H7, the same one out of at least 3,520 known strains in nature. The scientists assumed same strain, same source. Epidemiologists suspected the common source to be tainted spinach on the strength of circumstantial evidence collected through field interviews. No smoking gun had yet been found. The Dole brand was deemed the most likely suspect, but other brands had not been ruled out. In the meantime, the detectives and scientists were scrambling to beat the clock. The detectives rummaged through kitchens for any leftover bags of spinach, from which the lab technicians attempted to culture E. coli bacteria. Unrelentingly, the case count continued to rise, day after day for six days: September 15: 95 cases, 19 states September 16: 102 cases, 19 states September 17: 109 cases, 19 states September 18: 114 cases, 21 states September 19: 131 cases, 23 states September 20: 146 cases, 23 states On the seventh day, the big gamble paid off. The New Mexico lab successfully coaxed E. coli from leftover spinach to grow, and its fingerprint matched the outbreak strain. Eventually, thirteen of forty-four bags collected from households, all marketed as Dole baby spinach, were found to contain O157:H7, and all thirteen matched the outbreak strain. Thus, the circle was complete. This auspicious news gave a boost to agricultural inspectors, who had been scouring spinach fields since September 14, looking for clues. From the start, they had suspected California because the Golden State supplies three-quarters of U.S. spinach, and its leafy-greens farms had caused multiple outbreaks in the past; based on interviews, they narrowed their focus to nine ranches. These early efforts were frustrated, as the environmental samples all tested negative for O157:H7. Perhaps the inspectors arrived too late, after the source of contamination had already dissipated. But now the New Mexico lab handed them a bonus gift, in the form of the lot code P227A, retrieved from the packaging of leftover spinach: “P” for the South facility, “227” for the production date of August 15, and “A” for shift A. (Eventually, twelve other bags of spinach were found to have been tainted, and all carried the inauspicious code, except two with missing packaging.) P227A led inspectors to four specific fields. On one of these fields—a three-acre plot leased by Mission Organics in San Benito Valley—and not on the others, inspectors matched the outbreak strain in samples of river water and animal feces. As the bagged-spinach theory gained traction and new cases ceased to appear, the hardy investigators were finally able to declare victory in what turned out to be a thirty-nine-day war, well fought with unyielding determination and tight teamwork. Indeed, consumer groups became the investigators’ greatest cheerleaders, and the media their obedient messengers. The Senate committee affirmed its goodwill. Seen in this light, the investigation was an utter triumph of the modern science of epidemiology. In the opinion of Caroline Smith DeWaal at the Center for Science in the Public Interest, “Early [action] is good,” because the spinach recall prevented “hundreds more cases.” But the lack of scrutiny by consumer groups, particularly in the early stages, appeared misguided after the FDA issued its final report of March 2007. Contrary to DeWaal’s assertion, we do not know how many lives— if any —were saved by the recall. As always, the true onset of disease preceded the time when patients checked into hospitals or when cases were reported; the earliest known infection occurred on August 19, with 80 percent of the cases reported by September 4, which was ten days before the FDA went all-in. Since the contamination evidently affected a single production run, and since spinach is highly perishable, this outbreak would clearly have wilted on its own. More significantly, to measure the real impact of the recall would require knowing what would have happened had the recall not been instituted. That alternative world of no recall, unfortunately, could only exist in our imagination. So it was impossible, in practice, to prove DeWaal’s claim of many lives saved. The same kind of conundrum was recognized over a century ago by John Snow, who considered the possibility that “the [cholera] attacks had so far diminished before the use of the water was stopped that it was impossible to decide whether the well still contained the cholera poison in an active state or whether, from some cause, the water had become free from it.” Such inability to gauge the effect of public policy served to raise the stakes further, especially when it has costly side effects. If few lives could have been saved, then the final toll for this outbreak amounted to three deaths and about a hundred hospitalizations. While the perceived benefit of the recall could not be ascertained, its destruction overnight of an industry with sales of $300 million a year was broadly felt. It took six months for spinach sales to recover by half. The recall also caused collateral damage as sales of bagged salads without spinach slipped by 5 to 10 percent. Innocents, like smaller farms on the East Coast, especially suffered. The initial FDA advisory covered the whole country; subsequent restriction to California provided scarce relief because shoppers simply could not tell where spinach was grown. Consumer groups say it is better to be safe than sorry. Before you agree, take a look at the following list of foods: Basil Cabbage Green onions Lettuce Parsley Snow peas Squashes Tomatoes Cantaloupes Green grapes Mangoes Melons Orange juice Raspberries Chicken Ground beef Shellfish Eggs Milk Ice cream Almonds Peanut butter Mayonnaise Water Every one of these items has been linked to outbreaks (we are not even talking about sporadic cases). Over 73,000 Americans contract O157:H7 each year. If the FDA went all-in every time, there would not be much food left on the dining table! Expressing his concern about overzealous regulators, John Baillie, a Salinas farmer not implicated in this epidemic, sighed, “You can’t just say, ‘Well, let’s throw a dart and see what we hit’; that’s just unfair.” Furthermore, it was later determined that simultaneous outbreaks were occurring in Manitowoc. Of the initial cluster of five cases, tainted spinach caused but one, and the other four, not matching the outbreak strain, were linked to exposure at the county fair. A skeptic would argue that the spinach recall turned five sick patients in Wisconsin into a nation of panicked consumers, that it reflected more overreaction than consumer protection. Did we give blind trust to the FDA and the CDC? Is there a scientific foundation upon which the agencies ascertain cause–effect? Epidemiology is a fast-moving field that employs statistical modelers who solve real-life puzzles. These modelers specialize in linking causes and effects: they know something happened; they want to know why and how. This task is much more difficult than it seems. People got sick. They ate spinach. Therefore, spinach made them sick. Read that again. There is no reason why the last statement need follow from the first two. What if they also ate lettuce? Could lettuce rather than spinach have made them sick? Worse, could lettuce and spinach have combined to make them sick? (Even worse, could they have eaten spinach after they got sick for whatever reason?) The fact that those first two statements could simultaneously be true and unrelated makes cause-finding a treacherous enterprise. There are few true paths, perhaps only one, but countless wrong turns. Such is the confusing landscape these disease detectives have to negotiate. They do not get to choose. Finding causes of diseases is the be-all and end-all in their line of work. Nothing less can be accepted, because the consequence of miscalculation is devastating to the economy and consumer confidence. As we saw, the case count mounted each day the smoking gun was not found. If the investigators were unlucky and were chasing after bad leads, then the delays in identifying the source could be lethal. In this case, it wasn’t until spinach was confirmed as the cause of the outbreak that they could utter a sigh of relief. As statisticians, epidemiologists have evolved a keen sense of the limits of statistics. This is not to say they doubt its power, only that they are smart enough to look for corroborative evidence from microbiologists, agriculture inspectors, patients, and many other sources beyond statistics. “Not invented here” is not a barrier to progress. Since the 1990s, the discovery of lab techniques for matching DNA fingerprints has buttressed field evidence linking tainted foodstuff to infected stool. The labs uncovered a convoluted audit trail stretching from the Mission Organics field in California to households littered across the nation by tracing the E. coli strain from water and feces to spinach leaves to stool samples. When Melissa Plantenga picked spinach out of 450 candidates after conducting hours of in-depth interviews with patients, it was only a hunch based on statistics, even if a strong one. The accumulation of evidence from multiple sources clinched her case. Similarly, investigators confirmed the onset date of August 19 in two ways: from epidemiological finding, they realized that no patients who fell sick before this date remembered consuming fresh bagged spinach, and from the lab results, they noted that no E. coli DNA from clinical samples collected before this date matched the outbreak strain. Epidemiology generates educated guesses; lab work tests their plausibility. The core role of statistical thinking should not be underestimated. Consider the indispensable role played by the CDC’s information-sharing networks in the spinach outbreak investigation. PulseNet links together public-health laboratories and maintains a national database of DNA fingerprints of food-borne pathogens. OutbreakNet connects epidemiologists who share local tidbits and learning. FoodNet, comprising the state health departments, compiles statistics on general trends, such as food exposure rates. This infrastructure, created in the 1990s, has enabled disease detectives to gain strength in numbers by combining observations from multiple local sites. The modern science of networks elegantly overcomes the extremely daunting challenge of scarce information, particularly at the onset of an outbreak, when there may be as few as one patient, and when local news has yet to spread. As John Besser, a lab manager from Minnesota, explained, “PulseNet has been the biggest breakthrough by increasing the specificity of the case definitions. We can now see the connections you would not have seen before, which has revolutionized the world of food safety.” Recall the electrifying moment when officials from Oregon and Wisconsin matched their hypotheses during a conference call with the CDC. The most striking innovation is the case–control study . The “controls” draw a baseline against which the “cases” can be judged. In our example, the cases were the E. coli patients; the controls were a sampling of people who were not infected but were otherwise comparable in every conceivable way, such as having similar age, income, and ethnicity. Through interviews, Oregon found that four out of five cases ate bagged spinach. This 80 percent figure must be judged in the proper context. If 20 percent of the controls also ate spinach, it would be highly suggestive, but if 80 percent of the controls also ate spinach, it would appear unremarkable. A statistic like that is the difference between a little thing and nothing at all. For this reason, problems with less popular foods, like raw oysters, are easier to catch than those with common foods. More sophisticated researchers use matched controls: the control group is recruited from the uninfected to match the characteristics of the infected. Since 70 percent of the spinach E. coli cases afflicted women, investigators would replicate this gender imbalance when recruiting controls for interviews. Interestingly, our spinach detectives took a shortcut. Instead of interviewing any controls, they used the entire Oregon population. (This was all right because the point of controls was to establish a reference level.) For this trick, they were indebted to the foresight of FoodNet, which had conducted large-scale surveys measuring the proportions of Americans eating different foods on a regular basis. According to the FoodNet atlas of exposures, one in five Oregonians eat spinach in any given week. Put next to this number, the 80 percent rate of exposure to spinach among the infected cases looked extraordinary. With a bit of statistics, Dr. Keene made sense of the scale of this difference. If his staff had interviewed five people chosen at random, one of them would be expected to mention bagged spinach to Plantenga. The probability of getting four out of five was below 1 percent. And there they had the origin of the spinach hypothesis. The case–control study was invented in the 1950s by Sir Bradford Hill and his associates to prove that cigarette smoking causes lung cancer. Hill was also famous for nine “viewpoints” on cause and effect, which continue to affect epidemiological thinking today. By my count, the spinach investigation satisfied six of the nine points: Hill’s Nine Viewpoints Used 1. Strong association 2. Consistent across people, geography, time 3. Specific: one cause, one effect 4. Cause precedes effect 6. Biologically plausible 7. Coherent with past knowledge Not Used 5. Higher dose, stronger response 8. Experimental evidence 9. Analogy Following Hill, generations of epidemiologists acknowledge that without a monstrous and meticulous effort, any assertion of cause–effect is tenuous. Because no statistical model can capture the truth in nature, these statisticians strive toward a more modest goal: to create useful models for understanding and controlling diseases. In this regard, they have triumphed. The New England Journal of Medicine celebrated “application of statistics” as one of the most important developments in medicine in the twentieth century, amidst obligatory selections involving anatomy, cells, anesthesia, genetics, and so on. Indeed, the invention of the case–control study, the aggregation of scarce information via networks, and the integration of statistical, laboratory, and field findings have contributed mightily to the success of outbreak investigations. Even though these statisticians admit that models are always “wrong” insofar as they represent only educated guesses, they are certain that what they do benefits society. They are able to see the virtue of being wrong. ~###~ The vital achievements of statisticians working in epidemiology impress us more if we recognize the challenges they face every day: • Minimal data (Judgments hinge on fewer than ten cases.) • Urgency (People are dying.) • Incomplete information (Some say, “I don’t recall.”) • Unreliable information (People could imagine things.) • Necessity to find cause (This pursuit opens up many ways to err.) • Consequence of mistakes (This one is self-explanatory.) Their world is not the norm. Other statisticians enjoy more forgiving circumstances: • Massive data (They analyze millions of cases, literally.) • Sufficient time (Conclusions are repeatedly tested and refined.) • Interest in patterns only (They hardly care about cause.) • Lower stakes (No one dies.) Blessed with these favors, credit modelers feel confident that they stand on firmer ground than the disease detectives. Consequently, they experience a rude awakening when they find their work vigorously scorned and their profession endlessly attacked by the same consumer groups that embrace epidemiology. Their story is next. ~###~ On a day like any other day, Barbara Ritchie drove her three sons to soccer practice in her dependable Toyota minivan. While the kids dashed around the field, she rang up GEICO to ask about the multicar discount on their automotive insurance, as her husband, George, was in the market for a new sedan. After practice, with the boys screaming at each other in the back seats, Barbara stopped next at Blockbuster to pick up some Disney videos. She put the tab on her Visa, making a mental note to pay the credit card bill on time. Then, they joined the crowd at Costco to stock up for the new school year. She used her brand-new American Express card, quietly content that the 4.99 percent introductory APR would cut their interest payments in half. Late in the afternoon, she arrived back at their split-level house. Logging on to the soccer team’s website, she ordered kits for the upcoming season. Nearly all the other kids had switched to the new style, so she could not hold out anymore, even if they cost a small fortune. Why not spread the burden over six months with the new credit card? The Ritchies represent one slice of Americans, imaginatively named “Kids and Cul-de-Sacs” by Claritas, a marketing research company. This demographic segment rose to national prominence in the late 1990s via the political catchphrase “soccer moms,” the awe-inspiring stay-at-home mothers who run their households with precision and raise the kids with undivided dedication. Only a few decades ago, Barbara’s lifestyle was unheard of. Do you know why the Toyota dealer let her drive the $30,000 minivan off the lot without leaving any of her cash? (Surely, he worried that she could cross state lines and disappear.) How about why GEICO would conduct business strictly over the phone? (Surely, they at least wanted to meet Barbara and George to make sure they are sane drivers.) Their mortgage company had approved their online request for a thirty-year, $400,000 loan in mere minutes. Wonder why? (Without the mortgage, the Ritchies would almost certainly have moved into a more modest home.) Costco “preapproved” Barbara for a credit card without her expressing interest. Can you guess how that happened? (Without the store card, her kids would surely have had to wear their old soccer kits for one more season.) These conveniences are products of what Tim Muris, former FTC chairman, has dubbed “the miracle of instant credit”: in America today, a lot of us can borrow money in an instant, without intrusive interviews or character references, without money down, without collateral. Consumer credit has evolved from a privilege to a right. It seems as if some eager lender is around the corner just in case we want to spend money. It has not always been this way, and it still is not in most other countries, even highly industrialized ones. As Muris elaborated, “This ‘miracle’ [of instant credit] is only possible because of our credit reporting system.” It is not exaggerating much to say that our financial well-being hinges on a number between 300 and 850. This numeral, popularly called the “credit score,” is a summary of the credit report, which contains details of our borrowing and payment history, such as how much money we have borrowed, how much we have paid back, whether our loans have been in arrears, what types of loans we possess, and so on. These three digits pack a powerful punch. Mortgage companies, credit card companies, auto and home insurers, other lenders, and even landlords, employers, and cell-phone providers rely on credit scores to handpick customers, set prices, or both. FICO, the firm that invented credit scoring in the 1960s, has grown from humble beginnings into an $825 million company. Lenders were the first to jump on board. Even in the best of times, some portion of their customers will default for any number of reasons, such as negligence, financial difficulty, and fraud. Too many people stop sending in payments, and the lender goes bust. If every customer has an equal chance of default, lending is just gambling; what makes it a different business is that some borrowers pose better “risks” than others. The successful lender exploits this market structure by demanding higher interest from bad risks or by avoiding them altogether. This sounds too easy, so what is the catch? It is too late to recognize the bad risks after one has already forked over the cash, so lenders must stop less “creditworthy” customers at the door. Like disease detectives, lenders must master the educated guess. Before FICO changed the game, the decision to grant credit was a craft, passed from master to apprentice: get to know the applicant’s character , assess his capacity to repay the debt, determine collateral to secure the loan. The secrets of this business were heavily guarded rules of thumb. Each rule concerned a characteristic known to reflect creditworthiness or lack thereof. Having held a job for many years was regarded as a favorable trait, while renters were considered less desirable than homeowners. Examining an applicant’s file, credit officers judged whether the borrower was a good risk on the balance of positive and negative characteristics. These guidelines are best visualized as if–then statements: IF the applicant is a painter, plumber, or paperhanger THEN reject IF the applicant has ever been bankrupt THEN reject IF the applicant’s total debt payment exceeds 36 percent of income THEN reject Over time, each lender carefully conceived and refined a set of rules. They required that the past foretell the future. The lender who had suffered losses from several painter-borrowers in the past assumed that other painters would behave likewise. While imperfect, such guidelines survived the passage of time and benefited from accumulated wisdom. Like vintage wine, they improved with age. Perfection was out of bounds insofar as human behavior is complicated. No two people were completely synched, and worse, the same person could act differently on two occasions. Therefore, some accepted loans inevitably went unpaid, while some rejected applicants turned up at competitors and became their prized customers. At year’s end, credit officers were evaluated by the proportion of accepted loans that had gone bad. This policy encouraged them to accept only clear winners, turning down any borderline cases. By extending less credit only to the most worthy, they ensured that consumer credit remained tight before the advent of scoring. In 1960, only 7 percent of U.S. households held a credit card, and over 70 percent of bank loans were secured by collateral. Then, in the 1960s, one of the most exciting practical applications of statistical modeling debuted. As conceived by Bill Fair and Earl Isaac, the FICO credit score predicts the chance of a borrower to default on his loan during the subsequent two years. A higher FICO indicates a smaller chance of missing a payment. Although complex, the FICO formulas were well suited for modern computers, so the adoption of credit scores also heralded the era of automated underwriting. Easy online applications and near-instant approval of unsecured consumer loans were both fruits of these developments. Eventually, credit-scoring technology swept the lending industry by storm. How did it work, and what made it so successful? Statistical scoring algorithms are nothing more than computer programs that harvest enormous collections of complicated rules. (They could not be anything more, because they are conceived by human beings. As of today, “artificial intelligence,” the dream of superhuman thinking machines, has yet to honor the hype.) Compared with traditional underwriting, credit scoring is faster, broader, better, and cheaper. A “complicated” rule might look like this: IF Years on Job = 2.5 to 5.5 AND Occupation = Retired AND Rent or Own = Rent AND Years at Address = 0 to 0.5 AND Have Major Credit Card = Yes AND Banking Relationship = No Information AND Number of Recent Credit Inquiries = 1 AND Account Balances = 16 to 30 percent of Credit Lines AND Past Delinquency = None THEN Score = 720 This one rule contains nine characteristics. For each applicant, the computer calculates the nine values from information found in his application form and credit report; any applicant fitting this rule receives a score of 720. Say a second applicant resembles him, except that she has a savings account and five recent credit inquiries. She gets scored 660 according to a different but related rule: IF Years on Job = 2.5 to 5.5 AND Occupation = Retired AND Rent or Own = Rent AND Years at Address = 0 to 0.5 AND Have Major Credit Card = Yes AND Banking Relationship = Savings AND Number of Recent Credit Inquiries = 5 AND Account Balances = 16 to 30 percent of Credit Lines AND Past Delinquency = None THEN Score = 660 Now imagine thousands upon thousands of such rules, each matching a borrower to a three-digit number. More precisely, this number is a rating of applicants in the past who share similar characteristics as the present borrower. The FICO score is one such system. FICO modelers use 100 characteristics, grouped into five broad categories, listed here in order of importance: 1. Has the applicant dealt responsibly with past and current loans? 2. How much debt is currently held? 3. How long is the credit history? 4. How eagerly is the applicant seeking new loans? 5. Does the applicant have credit cards, mortgages, department store cards, or other types of debt? In general, whether a score exceeds some cutoff level is far more telling than any individual score. Given a cutoff of 700, Mr. 720 is accepted, while Ms. 660 is rejected. Lenders set cutoff scores so that some desired proportion of applicants will be approved. They believe this proportion represents a healthy mix of good and bad risks needed to keep the business afloat. The computer-harvested rules outperform the handcrafted ones: covering more details, they facilitate more nuanced comparisons, leading to more accurate predictions. For instance, rather than banning all painters, credit-scoring models selectively grant credit to painters based on other favorable traits. There is a low limit to how many characteristics the human mind can juggle, but the computer has the charming habit of digesting everything it is fed. Moreover, under each characteristic, the computer typically places applicants into five to ten groups, while traditional rules use only two. So instead of using debt ratio above or below 36 percent, a computer rule might split borrowers into groups of High (more than 50 percent), Medium (15 to 35 percent), Low (1 to 14 percent), and Zero debt ratio. This extra complexity achieves the same effect as gerrymandering does in creating voter districts. In the United States, the major political parties realize that simple rules based on things like county lines do not round up as many like-minded voters as do meandering boundaries. The new guidelines can appear illogical, but their impact is undeniable. Automated scoring also has the advantage of being consistent. In the past, different companies, or analysts within the same company, frequently applied different rules of thumb to the same type of applicants, so credit decisions appeared confused and at times contradictory. By contrast, credit-scoring modelers predetermine a set of characteristics upon which all borrowers are evaluated so that no one characteristic dominates the equation. The computer then gives each applicant a rating, taking into account the importance of each characteristic. In the past, analysts weighed relative importance on the fly at their discretion; these days, FICO computers scan large databases to determine the most accurate weights. In these respects, credit scoring is fair. It used to take generations to calibrate a simple rule such as “Don’t lend to painters”; computers can do the job in less than a second because they excel at repetitive tasks like trial and error. This extreme efficiency lends itself to discovering, monitoring, and refining thousands, even millions, of rules. Moreover, computers allow lenders to track the result of each loan decision, rather than knowing only the overall performance of an entire portfolio, thereby facilitating a more surgical diagnosis of why some decisions turned sour. The feedback loop is much shorter, so weaker rules get eliminated fast. Early adopters reaped immediate and dramatic gains from statistical scoring systems. An experienced loan officer took about twelve and half hours to process an application for a small-business loan; in the same amount of time, a computer scored fifty applications. In this world, it is hardly surprising that Barbara Ritchie took out an auto loan with so little hassle—over 80 percent of auto loan approvals occur within an hour, and almost a quarter are approved within ten minutes. In this world, it is no wonder Barbara Ritchie was handed a Costco credit card—store clerks can open new accounts in less than two minutes. Thanks to credit scoring, the cost to process card applications has dropped by 90 percent, and the cost to originate a mortgage has been halved. Lenders have reacted by ratcheting throughput up 25 percent, approving a great many more loans. As a result, the arrival of credit-scoring technology coincided with an explosion of consumer credit. In 2005, American households borrowed $2.1 trillion, excluding mortgages, a sixfold jump in twenty-five years. In turn, this spurred consumer consumption as credit empowered Americans to spend future income on current wants. Today, household expenditures account for two-thirds of the American economy; it is widely believed that heady consumers pulled the United States out of the 2001 recession. Amazingly, higher throughput did not erode quality: the loss rate of new loans turned out to be lower than or equal to the existing portfolio, just as the modelers prescribed. Further, all socioeconomic strata shared the bonanza: among households with income in the bottom 10 percent, the use of credit cards leaped almost twentyfold, from 2 percent in 1970 to 38 percent in 2001; among African-American households, it more than doubled from 24 percent in 1983 to 56 percent in 2001. Before credit card companies fully embraced credit scores in the 1980s, they targeted only the well-to-dos; by 2002, each household had on average ten credit cards, supporting $1.6 trillion of purchases and $750 million of borrowing. During the 1990s, insurers jumped on board, followed by mortgage lenders. As of 2002, providers of substantially all credit cards, 90 percent of auto loans, 90 percent of personal loans, and 70 percent of mortgages utilized credit scores in the approval process. In industry after industry, it appears that, once let in the door, credit scoring is here to stay. What makes it so sticky? Credit-scoring models rate the creditworthiness of applicants, allowing users to separate good risks from bad. This ability to select customers, balancing good and bad risks, is crucial to many industries. The insurance industry is no exception. People who tend to file more claims—say, reckless drivers—are more likely to want to buy insurance because they know those who do not file claims in effect subsidize those who do. If an insurer takes in too many bad risks, then the good customers will flee, and the business will falter. In the 1990s, insurance companies realized that credit scores could help them manage risk. To understand how this technology got to dominate industries, let’s divide the players into Haves (those who use scoring) and Have-Nots. Thanks to scoring, the first Have cherry-picks the good risks with efficiency. The riskier borrowers are turned away, and they line up behind the Have-Nots. Before long, the Have-Nots notice deterioration in their loss performance. The most discerning Have-Not figures out why; it implements scoring to even the playing field, thus becoming a Have. As more and more firms turn into Haves, the Have-Nots see ever-worsening results, and eventually everyone converts. Acknowledging this domino effect, Alan Greenspan once remarked: “Credit-scoring technologies have served as the foundation for the development of our national markets for consumer and mortgage credit, allowing lenders to build highly diversified loan portfolios that substantially mitigate credit risk. Their use also has expanded well beyond their original purpose of assessing credit risk. Today they are used for assessing the risk-adjusted profitability of account relationships, for establishing the initial and ongoing credit limits available to borrowers, and for assisting in a range of activities in loan servicing, including fraud detection, delinquency intervention, and loss mitigation. These diverse applications have played a major role in promoting the efficiency and expanding the scope of our credit-delivery systems and allowing lenders to broaden the populations they are willing and able to serve profitably.” But this story can also be told in an alternative version. To hear it from consumer advocacy groups, credit scoring is a wolf in sheep’s clothing: its diffusion is a national tragedy, the science behind it fatally flawed. Birny Birnbaum, at the Center for Economic Justice, has warned that credit scoring will bring about the “end of insurance.” Chi Chi Wu of the National Consumer Law Center has charged that credit scoring is “costing consumers billions and perpetuating the economic racial divide.” Norma Garcia, speaking for the Consumers Union, has declared, “Consumers [are] caught in the crossfire.” Such was the torrent of disapproval that Contingencies , an actuarial trade publication, gave advice on adjusting to “living without credit scoring.” Owing to the unrelenting pressure by consumer groups, at least forty states as of 2004 have passed laws constraining the use of credit scoring. Some states, including California, Maryland, and Hawaii, have barred home and auto insurers from applying the technology. The FTC amended the Fair Credit Reporting Act in 1996 and again in 2003. Not a year passes without some legislature holding hearings on the subject. These meetings are like a traveling circus with four acts; the same four basic themes are repeated over and over and over again: 1. Ban or heavily censor credit scoring because the statistical models are flawed. The models fail to link cause and effect. Worse, they unfairly slap minorities and low-income households with lower scores. 2. Ban or heavily censor credit scoring until credit reports contain accurate and complete information on every consumer. Data problems are causing many consumers to pay higher rates for loans and insurance. 3. Require credit-scoring companies to open the “black boxes” that hold the proprietary scoring rules. Consumers have a right to inspect, challenge, and repair their credit scores. 4. Conduct more studies or hearings to seek the perfect model of consumer behavior. This research should focus on establishing cause–effect or on measuring disparate impact on the underprivileged. Many a critique of credit scoring begins and ends with the horror story of a wronged consumer. James White became one in 2004 after his insurer hiked his rate by 60 percent. He learned that his credit score had been marked down substantially because of twelve recent credit inquiries (this was five times the national average of 2.4). Each inquiry occurred when someone requested his credit report, and White was shopping for a mortgage, an auto loan, and a credit card at the time. Critics complained that lenders inspecting his credit report could not have caused a change in White’s creditworthiness, so it was nonsensical for modelers to relate the two. Extending this line of thought, they contended that scoring models should employ only characteristics that have a proven causal relationship with failure to repay loans. To them, predicting the behavior of people is analogous to explaining the origin of diseases. In response, credit modelers maintain that they have never sought to find cause; their models find personal traits that are strongly correlated with the behavior of defaulting on loans. Correlation describes the tendency of two things moving together, in the same or opposite directions. In James White’s case, the model observed that, historically, borrowers who experienced a spurt of credit inquiries were much more likely to miss payments compared with those who did not. Most probably, neither thing directly affected the other. Indeed, acting on correlation is vital to our everyday experience. Imagine that John, who is trudging through snow five steps ahead of you, slips while turning the corner. Then David, Mary, and Peter slip, too. Slickly veering left, you stay upright. You could have tried to find the black ice, linking effect to cause, but you do not. You presume that walking straight would mean slipping. You act on this correlation. It saves you from the fall. Similarly, when it feels murky outside, you bring an umbrella. You don’t study meteorology. Before you move your family to a “good school district,” you ask to see standardized test scores. You don’t examine whether good schools hire better teachers or just admit smarter students. How does one live without correlational models? If you think about it, the computer acts like credit officers from yesteryear. If they had noticed the correlation between credit inquiries and failure to pay, they would have used it to disqualify loan applicants, too. Not only is causation unnecessary for this type of decision, but it is also unattainable. No physical or biological laws govern human behavior exactly. Humans by nature are moody, petulant, haphazard, and adaptive. Statisticians build models to get close to the truth but admit that no system can be perfect, not even causal models. Sometimes, they see things that are not there, and, to borrow language from mutual-fund prospectuses, past performance may not be repeated. To the relief of their creators, credit-scoring models have withstood decades of real-world testing. The correlations that define these models persist, and our confidence in them grows by the day. Another common grievance concerns the credit reports, which are known to be inaccurate and often incomplete. Common errors include typing mistakes, mistaken identities, identity fraud, duplicated entries, outdated records, and missing information. Critics say because garbage in must equal garbage out, when “dirty” data are fed to computers, the necessary outcome must be unreliable credit scores. Nobody disputes the messy state of data hygiene; it is fantasy, however, to assume that any credit-reporting system can be free of error. Between them, the three dominant U.S. credit bureaus process 13 billion data per month; on that base, an error rate as low as 0.01 percent still means one mistake appears every two minutes! Welcome to the real world of massive data. Modelers have developed some powerful strategies to cope. We already observed that each computer rule contains multiple characteristics, and these are often partially redundant. For example, many scoring systems evaluate “years at current residence” together with “years at current job” and “length of credit history.” For most people, these three traits are correlated. If one of the triad is omitted or inaccurate, the presence of the other two attenuates the impact. (Sure, a different rule applies, but the score shifts only slightly.) By contrast, credit officers cannot correct course, because their handcrafted rules take one characteristic at a time. Does inaccurate or incomplete information always harm consumers? Not necessarily: when mistakes happen, some people will receive artificially lower scores, while others will get undeservedly higher scores. For example, the credit bureau could have confused James White’s neighbor, a certain Joe Brown, with a namesake New York corporate lawyer, and so attached the latter’s stellar debt repayment record to the former’s credit report, bumping up his credit score and qualifying him for lower interest rates. For good reason, we never hear about these cases. Yet another line of attack by the critics of credit-scoring technology asserts the right of consumers to verify and repair their credit scores. This legislative push engendered the Fair and Accurate Credit Transactions Act of 2003. Innocuous as it sounds, this misguided initiative threatens to destroy the miracle of instant credit. In this era of openness, people disgruntled with bad scores have started knocking on the doors of credit repair agencies, hoping for a quick fix. Dozens of shady online brokers have cropped up to help customers piggyback on the good credit records of strangers by becoming “authorized users” on their credit cards. The customers inherit these desirable credit histories, which elevate their credit scores. This is identity theft turned upside down: cardholders with high FICO scores willingly rent out their identities for $125 a pop. The online brokers, who charge $800 per repaired account, act as the eBay-style marketplace for buying and selling creditworthiness! This dubious tactic distorts credit scores, blurring the separation between good and bad risks. Faced with more losses, lenders would eventually have to turn away more applicants or raise rates. In 2007, FICO moved to close the loophole, eliminating the “authorized user” characteristic from its scoring formulas. However, this solution harms legitimate types of authorized users such as young adults leveraging their parents’ history or one spouse rehabilitating the other’s credit. Piggybacking is but one example of credit repair scams, which will multiply as more knowledge about credit-scoring algorithms becomes available. In the extreme, unscrupulous credit repair ser-vices promise to remove negative but accurate items, and some bombard credit bureaus with frivolous disputes in the hope that creditors will fail to respond within thirty days, after which time such disputed items must be temporarily removed as per the law. The trouble with disclosure, with opening up the “black boxes,” is that people with bad scores are more likely to be actively looking for errors, and that only negative items on reports will be challenged or corrected. Over time, the good risks will get lower scores than they deserve because they have not bothered to verify their credit reports, while the bad risks will get higher scores than they deserve because only beneficial errors remain on theirs. Consequently, the difference between bad risks and good risks may vanish along with other positives associated with credit scoring. Such an outcome would harm the majority of law-abiding, creditworthy Americans. There is a real danger that overly aggressive consumer protection efforts will backfire and kill the goose that lays the golden egg. Much alarming rhetoric has also been spewed over discriminatory practices allegedly hidden in credit-scoring technology. Both sides acknowledge that the underprivileged have a lower average credit score than the general population. But income disparity is the economic reality which no amount of research will erase. Credit-scoring models, which typically do not use race, gender, or income characteristics, merely reflect the correlation that poorer people are less likely to have the means to pay back loans. Simple rules of old would have turned down the entire class; that was why credit cards were originally toys for the rich. Credit-scoring models, by virtue of complexity, actually approve some portion of underprivileged applicants. Recall that in the past, certain lenders rejected all painters and plumbers, but computers today accept some of them on account of other positive traits. The statistics bear out this point: from 1989 to 2004, households earning $30,000 or less were able to boost borrowing by 247 percent. Many studies have shown that access to credit has expanded in all socioeconomic strata since credit scoring began. Going backward would only reverse this favorable trend. In their dogged campaign against credit scoring, consumer groups have achieved mixed results to date. For example, Representative Wolens’s bid to ban credit scoring by insurers in Texas was defeated. Similar legislative drives failed in Missouri, Nevada, New York, Oregon, and West Virginia. The strategy to go after the statistical foundation directly has proven unwise, given the solid foundation of the science. Credit-scoring technology is inarguably superior to the old way of underwriting by handcrafted rules of thumb. Having been deployed at scale, it gains affirmation with each passing day. ~###~ In this chapter, we have seen two innovations of statistics that have made tremendous, positive impact on our lives: epidemiology and credit scoring. The breed of statisticians known as the modelers has taken center stage. A model is an attempt to describe the unknowable by using that which is known: In disease detection, the model describes the path of infection (for all cases, including the unreported), based on interview responses, historical patterns, and biological evidence. In credit scoring, the model describes the chance of loan default based on personal traits and historical performance. These two examples represent two modes of statistical modeling; both can work magic, if done carefully. Epidemiology is an application in which finding cause is the only meaningful objective. We can all agree that some biological or chemical mechanism probably exists to cause disease. Taking brash action based on correlations alone might result in entire industries being wiped out while the disease continues to spread. Credit scoring, by contrast, relies on correlations and nothing more. It is implausible that something as variable as human behavior can be attributed to simple causes; modelers specializing in stock market investment and consumer behavior have also learned similar lessons. Statisticians in these fields have instead relied on accumulated learning from the past. The standard statistics book grinds to a halt when it comes to the topic of correlation versus causation. As readers, we may feel as if the authors have taken us along for the ride! After having plodded through the mathematics of regression modeling, we reach a section that screams, “Correlation is not causation!” and, “Beware of spurious correlations!” over and over. The bottom line, the writers tell us, is that almost nothing we have studied can prove causation; their motley techniques measure only correlation. The greatest statistician of his generation, Sir Ronald Fisher, famously scoffed at Hill’s technique to link cigarette smoking and lung cancer; he offered that the discovery of a gene that predisposes people to both smoking and cancer would discredit such a link. (This gene has never been found.) In this book, I leave philosophy to the academics (they have been debating the issue for decades). I do not deny that this is a fundamental question. But this is not the way statistics is practiced. Causation is not the only worthwhile goal, and models based on correlations can be very successful. The performance of credit-scoring models has been so uniformly spectacular that one industry after another has fallen in love with them. George Box, one of our most preeminent industrial statisticians, has observed, “All models are wrong but some are useful.” Put bluntly, this means even the best statistical model cannot perfectly represent the real world. Unlike theoretical physicists, who seek universal truths, applied statisticians want to be judged by their impact on society. Box’s statement has become a motto to aspiring modelers. They do not care to beat some imaginary perfect system; all they want is to create something better than the status quo. They understand the virtue of being (less) wrong. FICO’s scoring technology has no doubt improved upon handcrafted rules of thumb. The assortment of modern techniques like case–control studies and DNA fingerprint matching advanced the field of epidemiology. Despite being cut from the same cloth, modelers in these two fields face divergent reception from consumer advocacy groups. Generally speaking, these groups support the work of disease detectives but deeply distrust credit-scoring models. However, epidemiologists face the more daunting task of establishing causation with less data and time, and in that sense, their models are more prone to error. It is clear that a better grasp of the cost and benefit of product recalls will further consumer interest more than yet another study on causality in credit scoring. In the meantime, take heart that modelers are looking out for our health and wealth.",
        "char_count": 69127
      },
      {
        "heading": "Chapter 6",
        "text": "3 Item Bank / Risk Pool The Dilemma of Being Together I can define it, but I can’t recognize it when I see it. —L LOYD B OND, EDUCATION SCHOLAR Millionaires living in mansions on the water are being subsidized by grandmothers on fixed incomes in trailer parks. —B OB H ARTWIG, INSURANCE INDUSTRY ECONOMIST The late CEO of Golden Rule Insurance, J. Patrick Rooney, made his name in the 1990s as the father of the health savings account. For this political cause, he spent $2.2 million of his own fortune and partnered with conservative icon Newt Gingrich. For years, he was a generous donor to the Republican Party and a prominent voice within. In 1996, he ran for governor of Indiana. In business, he was equally astute, turning Indianapolis-based Golden Rule into one of the largest marketers of individual health insurance. When Rooney sold his company in 2003 to the industry giant UnitedHealth Group for half a billion dollars, he delivered a windfall of about $100,000 to every Golden Rule employee. Even more than his commercial success, it was Rooney’s extracurricular activities that kept him in the news. He was a maverick before mavericks became fashionable in the Republican set. Given his politics, Rooney was an unlikely defender of civil rights. In the mid-1970s, he noticed that all his insurance agents in Chicago were white—no wonder the firm had struggled to make inroads into the city’s key black neighborhoods. He argued persuasively that the licensing examination unfairly disqualified blacks. He sued the developer of the disputed test, Educational Testing Service (ETS), which is better recognized as the company that administers the SAT to millions of high school students in the United States. At the time, test developers adhered to a “don’t ask, don’t tell” policy when it came to fair testing. The subsequent “Golden Rule settlement” between ETS and Rooney pioneered scientific techniques for screening out unfair test questions, defined as those for which white examinees outperformed black examinees by a sizable margin. But statisticians were none too happy about this apparently sensible rule, and the president of ETS publicly regretted his settlement. Let’s examine why. ~###~ Even those who did not share Rooney’s politics found him endearing. He possessed a flair for effortlessly linking his social causes, his profiteering self-interest, and his Christian duty. He made his name as the father of health savings accounts (HSAs), which provide tax benefits to encourage participants to set aside money for medical expenses. Right before Congress authorized HSAs in 2003, a watershed event that owed much to his political savvy and expensive lobbying, Rooney sold his family insurance business to industry giant UnitedHealth Group for $500 million and then created a new business called Medical Savings Insurance (MSI), becoming one of the first in the nation to sell HSAs. Rooney proclaimed, “I am doing the right thing, and I think the Lord will be pleased about it,” satisfied that “when I die, I would like God to welcome me.” When asked why MSI made it a habit to underpay hospitals that served his customers, he contended, “We’re trying to help the people that are not able to help themselves.” In his mind, he was leading the good fight against “shameful” practices of “sinful” executives. The same motives, as much selfless as self-serving, drove him to file the lawsuit against the Illinois Department of Insurance and the Educational Testing Service. In October 1975, Illinois had launched a new licensing examination for insurance agents, developed by ETS. In short order, it emerged that the passing rate of the new test was merely 31 percent, less than half that of the previous version. In Chicago, one of Rooney’s regional managers worried about the supply of black insurance agents needed to reach the 1.2 million blacks in the Windy City. Rooney knew Chicago was a key market for Golden Rule Insurance, so when he got wind of this information, he once again seized the role of a social-justice champion: he charged that “the new test was for all practical purposes excluding blacks entirely from the occupation of insurance agent.” The Illinois Department of Insurance tried to ward off the lawsuit by twice revamping the licensing examination, bringing the passing rate up above 70 percent. But Rooney was a tenacious opponent, and he had an alluring argument. The overall passing rate obscured an unsightly gap between black and white examinees. In the revamped exam, the passing rate of blacks rose in tandem with that of whites, leaving the gap intact. Finally, in 1984, the two sides acceded to the so-called Golden Rule settlement, which required ETS to conduct scientific analysis on tests to ensure fairness. However one felt about the commercial motivation behind Rooney’s lawsuit, it was clear that his confrontational advocacy stimulated some serious rethinking about fair testing. The implications extended well beyond the insurance industry. ETS spearheaded the bulk of this new research, which was to make its strongest impact on college and graduate school admissions tests, as these, after all, supplied the nonprofit test developer and administrator its biggest source of revenue. ~###~ As admissions to U.S. colleges grow ever more competitive, parents become ever more invested in how their kids perform on admissions tests like the SAT. In Tia O’Brien’s neighborhood in Marin County, the lush region just north of San Francisco Bay, boomer parents with college-age children exercise plain old good manners: “Less-than-near-perfect test scores should not be discussed in polite company.” Bound for college in 2008, O’Brien’s daughter was a member of the biggest class ever to finish high school in California, which has the largest population as well as the most extensive and prestigious public-university system in America. Everywhere she looked, O’Brien saw insanity: anxious parents hired “SWAT teams of test-prep experts,” who promised to boost test scores; they paid “stagers” to make over their kids’ images; their counselors established “grade-point targets” for various colleges; and “summer-experience advisors” planned activities “every week of the summer,” such as community service projects, trips abroad to study languages, and Advanced Placement classes. These type A parents inadvertently have been nudging the United States out of isolation from the rest of the world. In some European countries and especially in Asia, the shortage of university spots coupled with a long-standing reliance on standardized tests have produced generations of obsessed parents who strive as hard at micromanaging their kids’ lives as they do at fulfilling unrealistic expectations. Previously, the United States was an island of serenity in the wild, wide world of university entrance derbies. These days, that is no longer the case. In Marin, discussing test scores in public is taboo, though we know most students there take the SAT (as do other students in California, where only one in ten college applicants submit scores from the ACT, the other recognized college admissions examination). First administered by ETS in 1926, the SAT was taken by 1.5 million college-bound seniors in 2007; many of them took the test more than once. The SAT measures a nebulous quantity known as “academic potential”—let’s just call it ability—and its advocates point to the strong, proven correlation between SAT scores and eventual college GPA as the technical justification for the exam. Since 2005, each SAT test contains ten sections, three each of reading, mathematics, and writing, plus one “experimental” section. The first section of every test involves essay writing, while the other nine appear in random order. Students are permitted about four hours in which to complete the exam. The sixty-seven items in the reading sections (formerly called verbal) are split between sentence completion (nineteen items) and reading passages (forty-eight). All reading items use the multiple-choice format, requiring students to select the correct answer from five choices. Antonyms and analogies were discontinued in 1994 and 2005, respectively. The three mathematics sections (formerly called quantitative) together contain forty-four multiple-choice items plus ten “grid-in” items requiring direct response, which replaced quantitative comparison items in 2005. Besides the essay, the remaining writing sections consist of multiple-choice items focused on grammar. Even though the format of each SAT section is fixed, any two students can see different sets of questions, even if they are seated next to each other in the same test center at the same time. This unusual feature acts as a safeguard against cheating but also strikes some of us as an unfair arrangement. What if one version of the test contains more difficult items? Would not one of the two students be disadvantaged? Here is where the “experimental” section comes to the rescue. This special section can measure reading, mathematics, or writing ability and is indistinguishable from the other corresponding sections of the test, but none of its questions count toward the student’s total score. This experimental section should properly be considered the playground for psychometricians— statisticians specializing in education. In creating tests, they lift specific items from the scored sections of one version and place them into the experimental section of another. These shared items form a common basis upon which to judge the relative difficulty of the two versions and then to adjust scores as needed. Statisticians have many other tricks up their sleeves, including how to make tests fair, a topic we shall examine in detail. ~###~ Asking whether a test item is fair is asking whether it presents the same level of difficulty to comparable groups of examinees. An item is deemed more difficult if a lesser proportion of test takers answers it correctly. Conversely, an easier item has a higher rate of correct answers. Statisticians make tests fair by identifying and removing questions that favor one group over others—say, whites over minorities or males over females. The cure is as simple as it gets. So why did it take almost ten years for Golden Rule and ETS to agree on an operating procedure to address Rooney’s complaint about unfair testing? How can something that sounds so simple be so difficult to put into practice? To explore this issue, let’s inspect a set of sample test items, all of which were long-ago candidates for inclusion in SAT verbal sections. The first four are analogy items, and the other two are sentence completion items. See if you can figure out which items proved more difficult for the college-bound students. 1. PLAIT:HAIR A. knead:bread B. weave:yarn C. cut:cloth D. fold:paper E. frame:picture 2. TROUPE:DANCERS A. flock:birds B. ferry:passengers C. barn:horses D. dealership:cars E. highway:trucks 3. MONEY:WALLET A. rifle:trigger B. dart:spear C. arrow:quiver D. golf:course E. football:goalpost 4. DYE:FABRIC A thinner:stain B. oil:skin C. paint:wood D. fuel:engine E. ink:pen 5. In the past the general had been________________for his emphasis on defensive strategies, but he was________________when doctrines emphasizing aggression were discredited. A. criticized . . . discharged B. parodied . . . ostracized C. supported . . . disappointed D. spurned . . . vindicated E. praised . . . disregarded 6. In order to________________the health hazard caused by an increased pigeon population, officials have added to the area’s number of peregrine falcons, natural________________of pigeons. A. reduce . . . allies B. promote . . . rivals C. starve . . . prey D. counter . . . protectors E. lessen . . . predators Since there were five choices for each question, if all examinees guessed randomly, we would still expect 20 percent to be lucky. Actual test results ranked the items from the hardest to the easiest as follows: Item 5 17 percent correct (hardest) Item 1 47 percent correct Item 3 59 percent correct Items 2, 6 73 percent correct Item 4 80 percent correct (easiest) Notice that the sentence completion item about war strategy (item 5) tripped up so many that the overall correct rate of 17 percent barely departed from the guessing rate. At the other extreme, 80 percent of test takers answered the DYE:FABRIC analogy (item 4) correctly. Comparatively, the MONEY:WALLET analogy (item 3) turned out to be markedly more difficult. How well did this ranking match your intuition? If there were a few surprises, you would not be alone. Even seasoned analysts have learned that predicting the difficulty level of a test item is easier said than done. No longer teenagers, they are unable to think like teenagers. Moreover, what we just estimated was the overall difficulty for the average test taker; what about which questions put minorities at a disadvantage? In the six sample items, three items were unfair. Can you spot them? (The offending items will be disclosed later.) It should be obvious by now how hopeless it is to ask human minds to ferret out unfair test questions. At least most of us get to be teenagers once, but alas, a white man would never experience the world of a black female. This was what the eminent scholar of education Lloyd Bond meant when he parodied Justice Potter Stewart’s celebrated anti-definition of the obscene: “I could not define it, but I know it when I see it.” Bond experiences unfairness as something he can define (mathematically), but when he sees it, he cannot recognize it. When statisticians try their hand at spot-the-odd-item exercises as you just did, they too concede defeat. Their solution is to pretest new items in an experimental section before including them in real exams; they forgo subjective judgment, allowing actual test scores to reveal unfair items. So even though performance in the experimental SAT section does not affect anyone’s test score directly, it has a profound effect on what items will appear in future versions of the test. Because test takers do not know which section is experimental, test developers can assume they exert the same effort on the experimental section as on other sections. ~###~ Constructing SAT test forms, assembling the test items, is a massive undertaking well concealed from the casual test taker. Dozens of statisticians at ETS fuss over minute details of a test form, because decades of experience have taught them that the design of the test itself may undesirably affect scores. They know that changing the order of questions can alter scores, all else being equal, and so can replacing a single word in an item, shuffling the answer choices, or using specialist language. Therefore, much care goes into selecting and arranging test items. In any year, hundreds of new questions enter the item bank. It takes at least eighteen months for a new item to find its way onto a real test. Each item must pass six to eight reviews, with about 30 percent failing to survive. There are people whose full-time job is to write new SAT questions. The typical item writer is middle-aged, a former teacher or school administrator, and from the middle class. If anything, the writers are extremely dedicated to their work. Chancey Jones, the retired executive director of test development at ETS, fondly recalled one of his earliest experiences with the company: “[My mentor] told me to keep a pad right by the shower. Sure enough, I came up with items when taking a shower, and I wrote them down right away. I still keep Post-Its everywhere. You never know.” One of Jones’s key responsibilities was to ensure that all SAT questions were fair; in particular, no one should be disadvantaged merely by the way a test item was written or presented. Before the 1980s, the statisticians steadfastly abided by a “don’t ask, don’t tell” brand of ethic. Test developers believed that, because they wore race blinders, their handiwork was unaffected by the racial dimension and, ipso facto, was fair to all racial groups. Transmitting a total trust in their own creation, they viewed the SAT score as a pure measure of ability, so a differential between two scores was interpreted as a difference in ability between two examinees and nothing more. It did not occur to them to ask whether a score differential could result from unfair test items. The statisticians presumed they did no harm; they certainly meant no harm. Our set of sample questions had already passed several preliminary filters for validity before it got screened for fairness. The items were neither too easy nor too difficult; if everyone—or no one—knew the right answer, that question had nothing to say about the difference in ability between students. Also pruned were motley items offensive to ETS, such as elitist words ( regatta, polo ), legal terms ( subpoena, tort ), religion-specific words, regionalisms ( hoagie, submarine ), and words about farms, machinery, and vehicles ( thresher, torque, strut ), plus any mention of abortion, contraception, hunting, witchcraft, and the like, all deemed “controversial, inflammatory, offensive or upsetting” to students. ~###~ Rooney did to standardized testing what he would later do to hospital bills. He rounded up an elephant of a problem and dropped it in the center of the room. The gap between blacks and whites in test scores had been evident for as long as score statistics have been published. It was not something new that emerged after Rooney filed his lawsuit. Harvard professor Daniel Koretz, in his book Measuring Up , acknowledges, “The difference has been large in every credible study of representative groups of school-age students.” Koretz further estimated that, in the best case, the score of the average black student fell below 75 percent of whites. According to ETS, the average SAT scores for blacks and whites, respectively, in 2006 were 434 and 527 in reading, and 429 and 536 in mathematics. How the racial gap in scores should be interpreted is an extremely challenging and contentious matter for all concerned. Conceptually, group differences in test scores may arise from unequal ability, unfair test construction, or some combination of both. Prior to the Golden Rule settlement, the psychometrics profession was convinced that its “don’t ask, don’t tell” policy produced fair tests, so score differentials could largely equate to unequal ability. Educators generally agreed that African-Americans had inferior access to high-caliber educational resources, such as well-funded schools, top-ranked teachers, small classes, effective curricula, and state-ofthe-art facilities, a condition that guaranteed a handicap in ability, which in turn begat the racial gap in test scores. Rooney and his supporters rejected this line of logic, arguing that score differentials were artifacts of unfair tests, which systematically underestimated the true ability of black examinees. In all likelihood, both extreme views had it wrong, and both factors contributed in part to the racial gap. This debate would not be settled until someone figured out how to untangle the two competing factors. ~###~ At the time Patrick Rooney sued ETS in 1976, the vetting of test questions for fairness was practiced as a craft, informally and without standards or documentation. The Golden Rule settlement became the first attempt to formalize the fairness review process. Further, it mandated explicit consideration of race in the development of tests. In a break from the past, ETS agreed to collect demographic data on test takers and to issue regular reports on the comparative scores of different groups. There followed a period of spectacular advance in scientific techniques to measure fairness. By 1989, test developers at ETS had broadly adopted the technical approach known as differential item functioning (DIF) analysis to augment the traditional judgmental process. Brokered in 1984 between Rooney and Greg Anrig, the former president of ETS, the Golden Rule settlement imposed two chief conditions for validity on every test item: the overall correct rate must exceed 40 percent, and the correct rate for blacks must fall within 15 percent of that for whites. Thus, if 60 percent of whites answered a question correctly, then at least 45 percent of blacks must also have scored in order to qualify this particular item. These new rules were originally developed for the Illinois insurance licensing exam, but several states began to explore applications in educational and other testing. Within three years, however, Anrig was to concede publicly that the Golden Rule settlement had been a “mistake.” Why did this about-face occur? Researchers reported that the new scientific review would have cast doubt on 70 percent of the verbal items on past SAT tests they reexamined. While inspecting many of the offending items that appeared to favor whites, test developers were baffled to identify what about them could have disadvantaged blacks. In practice, the Golden Rule procedure produced many false alarms: statisticians feared that hosts of perfectly fair questions would be arbitrarily rejected. The settlement significantly expanded the ability to identify potentially unfair test items, but it offered no help in explaining why they were unfair. Consider sample item 3. Suppose substantially fewer boys than girls got the right answer (denoted by the asterisk). What might account for this difference in correct rates? 3. MONEY:WALLET A. rifle:trigger B. dart:spear C. arrow:quiver (*) D. golf:course E. football:goalpost Perhaps boys, being generally more active, gravitated to choices that mentioned popular sports like golf and football. Perhaps more girls fell for Robin Hood–style folklore, where they encountered a word like quiver . Ten people would likely come up with ten narratives. Lloyd Bond, the education scholar, frowned upon this type of judgmental review. He once relayed an enlightening story in which he and his graduate student developed elaborate reasons why certain test items favored one group of examinees, only to later discover that they had accidentally flipped the direction of the preference, and were further embarrassed when they had to reverse the previous points to support the now-reversed position. What if item 3 actually favored boys rather than girls? What might account for this difference in correct rates? Perhaps boys, being more active, grasped the relationship between golf and course and between football and goalpost , so they were less affected by those distracters. Perhaps fewer girls were familiar with military words like quiver and rifle . The trouble is that our fertile imagination frequently leads us astray. (By the way, girls underperformed boys by 20 percent on item 3 in real tests.) If reasonable people could not ascertain the source of unfairness even after a test item showed a difference between groups, there was no reasonable basis on which to accuse test developers of malpractice. The problem of false alarms demonstrated that some group differences were not caused by test developers but by differential ability, elevating the need to untangle the two factors. Henceforth, the mere existence of a racial gap should not automatically implicate item writers in the creation of unfair tests. While the initial foray into the scientific method turned out bad science, it nevertheless produced some good data, paving the way to rampant technical progress. By 1987, Anrig could turn his back on the Golden Rule procedure because the team at ETS had achieved the breakthrough needed to unravel the two factors. Simply put, the key insight was to compare like with like. The statisticians learned not to carelessly lump together examinees with varying levels of ability. Before computing correct rates, they now match students with similar ability. High-ability whites should be compared with high-ability blacks, and low-ability whites with low-ability blacks. A test item is said to favor whites only if black examinees tend to have greater difficulty with it than whites of comparable ability. The blame can be safely assigned to test developers when two groups with like ability perform differently on the same test item, since the matching process has made moot any gap in ability. In this way, a light touch of statistical analysis unbundled the two intertwined factors. In hindsight, statisticians added just three extra words (“of comparable ability”) to the Golden Rule settlement and made a world of difference. Anrig realized belatedly that the flawed Golden Rule procedure incorporated the hidden and untenable assumption that white and black examinees were identical, and thus comparable, except for the color of their skin. In reality, the two groups should not be compared directly, because blacks were overrepresented among lower-ability students, and whites overrepresented among higher-ability students. As a result, the correct rate of white examinees leaned toward that of high-ability students, while the correct rate of black examinees leaned toward that of low-ability students. The differential mix of ability levels effected a group difference in correct rates—it would not have mattered if high-ability blacks performed just as well as high-ability whites, and likewise, low-ability blacks and low-ability whites. It was this important breakthrough, known as DIF analysis, that finally made the scientific review of test fairness practical. Today, statisticians use it to flag a reasonable number of suspicious items for further review. A question that “shows DIF” is one in which a certain group of examinees—say, boys—performs worse than another group of like ability. Of course, explicating the source of unfairness remains as slippery as ever. In addressing this task, two test developers at ETS, Edward Curley and Alicia Schmitt, took advantage of the “experimental” SAT sections to test variations of verbal questions previously shown to be unfair. How good were their theories for why certain groups performed worse than others? Could they neutralize a bad item by removing the source of unfairness? Our list of sample test items provided a few clues. They were, in fact, extracted from Curley and Schmitt’s research. Results from real SAT tests indicated that items 1, 3, and 5 showed DIF, while the three even-numbered items did not. (Did these match your intuition?) First, consider the DYE:FABRIC analogy (item 4). Eighty percent of all students answered this question correctly, every racial group performed just as well as whites, and girls did just as well as boys. 4. DYE:FABRIC A. thinner:stain B. oil:skin C. paint:wood (*) D. fuel:engine E. ink:pen A variant of this item (4-b), with the words paint and stain inter-changed, also presented minimal difficulty, with an overall correct rate of 86 percent. 4-b. DYE:FABRIC A. thinner:paint B. oil:skin C. stain:wood (*) D. fuel:engine E. ink:pen However, this variant was found to favor whites over every other racial group with comparable ability by 11 to 15 percent, an alarming differential. This result confirmed the hypothesis that the secondary meaning of the word stain could flummox nonwhite test takers. If the goal of the question was to assess recognition of word relationships rather than knowledge of vocabulary, then item 4 would be vastly preferred to item 4-b. Next, look at item 5, which all examinees found to be very hard (17 percent correct): 5. In the past the general had been__________________for his emphasis on defensive strategies, but he was__________________when doctrines emphasizing aggression were discredited. A. criticized . . . discharged B. parodied . . . ostracized C. supported . . . disappointed D. spurned . . . vindicated (*) E. praised . . . disregarded Remarkably, all racial groups performed as well as whites of comparable ability, but girls appeared disadvantaged against boys of like ability by 11 percent. Researchers believed that unfairness arose from the association with conflict and tried switching the context to economics (item 5-b): 5-b. Heretofore___________________for her emphasis on conservation, the economist was_________________when doctrines emphasizing consumption were discredited. A. criticized . . . discharged B. parodied . . . ostracized C. supported . . . disappointed D. spurned . . . vindicated (*) E. praised . . . disregarded With this change, the group difference shrank to 5 percent. Recall that this 5 percent was calculated after matching ability: in practice, this meant Curley and Schmitt rebalanced the mix of ability levels of boys to mimic those of girls. Item 1 showed an unusual racial DIF: the proportion of blacks answering correctly exceeded that of like-ability whites by an eye-popping 21 percent. 1. PLAIT:HAIR A. knead:bread B. weave:yarn (*) C. cut:cloth D. fold:paper E. frame:picture In hindsight, it appeared that the word plait might be more common in the African-American community. Researchers tried using braid instead (item 1-b): 1-b. BRAID:HAIR A. knead:bread B. weave:yarn (*) C. cut:cloth D. fold:paper E. frame:picture The group difference disappeared, and not surprising, the overall difficulty plunged from 47 percent to 80 percent correct. The item writers took pains to point out that the question passed judgmental reviews before DIF analysis, once again showing how hard it was to identify questions that might favor certain groups without real test data. That the advantage, in this case, accrued to the minority group raised yet another practical challenge: should this type of item be removed from the test? Because test developers at ETS regard DIF in either direction as “invalid,” their standard procedure calls for its removal. Through iterations of testing and learning, Curley and Schmitt validated some but not all of the theories used to explain why items showed DIF; they also demonstrated that, indeed, items could be edited in a manner that disadvantaged one group against another. While the United States is home to world-class test developers, American parents have only recently begun to express world-class angst over test scores. What might the future bring? We can do no worse than observing the Asians. In Hong Kong, some test prep tutors have achieved pop star status, their headshots plastered on gigantic billboards in the city center. Lecturers quit their university jobs, opting to “teach to the test” for better pay and, dare one say, greater respect. In Tokyo, ky iku mamas (education-obsessed mothers) prepare care packages for their kids to carry to the university entrance examinations. Every January, Nestlé makes a killing because Kit Kat, its chocolate wafer bar, sounds like kitto katsu , which means “sure win” in Japanese. It might not be long until Dr. Octopus, the comic character, emerges as a brand of study aid, since it sounds like okuto pasu , or “if you put this on your desk, you will pass.” ~###~ To figure out whether an SAT question favors whites over blacks, it would seem natural to compare the correct rate of whites with that of blacks. If the gap in performance is too wide, one would flag the item as unfair. In the Golden Rule settlement, instigated by Rooney, the acceptable gap was capped at 15 percent. Remarkably, the statisticians at ETS disowned such an approach to the problem. In fact, they saw the Golden Rule procedure as a false start, merely a discredited precursor to a new science for screening out unfair test items. When it comes to group differences, statisticians always start with the question of whether or not to aggregate groups. The ETS staff noticed that the Golden Rule mandate required lumping together examinees into racial groups regardless of ability, which stamped out the diversity of ability levels among test takers, a key factor that could give rise to score differentials. They achieved a breakthrough by treating high-ability students and low-ability students as distinct groups. The procedure of matching ability between black and white examinees served to create groups with like ability, so any difference in correct rates signaled unfairness in the design of the test question. This so-called DIF analysis addressed the unwelcome reality that black students were already disadvantaged by inferior educational opportunities, which meant they were already suffering lower test scores, even without injustice traced to test construction. In the course of creating the new techniques, test developers realized how hopeless it was to use their intuition to pick out unfair questions, and they smartly let actual test results guide their decisions. By placing new items in experimental test sections, they observe directly how students perform in real-life situations, eliminating any guessing. Pinpointing the source of unfair treatment is sometimes still elusive, but items that show positive or negative DIF are typically dropped whether or not an explanation can be proffered. The issue of group differences is fundamental to statistical thinking. The heart of this matter concerns which groups should be aggregated and which shouldn’t. In analyzing standardized test scores, the statisticians strayed from what might be regarded as the natural course of comparing racial groups in aggregate. They stressed that all black examinees should not be considered as one—and neither should white examinees—because of the wide range in ability levels. (However, if the mix of ability was similar across races, the statisticians would have chosen to lump them together.) In general, the dilemma of being together or not awaits those investigating group differences. We will next encounter it in Florida, where the hurricane insurance industry finally woke up to this problem after repeatedly losing tens of billions in single years. ~###~ Like J. Patrick Rooney, Bill Poe Sr. was also an accomplished entrepreneur who built and ran an insurance business that was eventually worth many millions of dollars. Like Rooney, he also spent his personal wealth pursuing public causes. Poe enlivened the airwaves in 1996 when he poured $1 million of his own money into opposing public funding of a new stadium for the Tampa Bay Buccaneers football team. He filed a lawsuit against all involved parties that went up to the Florida Supreme Court, where he lost the decision. A native of Tampa, Poe was heavily involved in local politics, including a stint as mayor. In his professional life, he made a career of selling and underwriting property insurance. His first business venture was a runaway success, rapidly becoming the largest insurance brokerage in Florida. When he retired, he sold his ownership stake for around $40 million. By 2005, he made the news yet again, but in a less illustrious manner. His newest insurance venture, Poe Financial, buckled after a string of eight hurricanes battered the Florida coast in the course of two years. While Poe’s customers vilified him, many of his peers sympathized, convinced that it was the breakdown of the disaster insurance market that had precipitated Poe’s downfall. Indeed, as Poe had prospered in the prior decade, other insurers, particularly the national giants such as State Farm, were plotting their exits from the Sunshine State. These developments made it increasingly certain that the average Florida resident would, willingly or not, subsidize those who choose to live near the vulnerable coast. We will now examine why. ~###~ In his native Tampa, Bill Poe was well known as a former mayor and a gifted insurance man. He founded Poe & Associates in 1956, and under his leadership, it became the largest insurance brokerage in Florida. In 1993, he negotiated a merger with Brown & Brown, the next largest competitor. Three years later, Poe retired, selling his shares for $40 million. But not for long did he stand on the sidelines. Partnering with his son, Bill Jr., he next created Southern Family Insurance Company, jumping from selling to underwriting insurance. As underwriters, the Poes took on the tasks of evaluating risks, setting premium amounts, and reserving surplus in order to cover claims. At the time, national insurance giants like State Farm and Allstate were ruminating openly about quitting the Florida market after taking knee-bending losses from Hurricane Andrew in 1992. Having inherited hundreds of thousands of policies from failed property insurers, the state government realized it lacked sufficient capital to cover potential losses and was offering to pay start-up companies to “take out” and assume these policies. Poe was one of the early takers; on day one, Southern Family burst out with seventy thousand customers, who forked over $32 million of annual premiums to insure $6 billion worth of property, primarily in coastal areas, where the chance of a hurricane landing was the highest. For his trouble, the Florida state paid Poe over $7 million, or about $100 per policy transferred. In a startling move, Poe slashed rates by 30 percent for these customers, even as other take-out companies generally hiked prices, believing that the government had artificially capped rates before, due to political pressure. By positioning itself as a price leader and expanding through acquisitions, Poe Financial Group, operating under Southern Family and two other brands, emerged as Florida’s biggest privately held property insurer by 2004, when it serviced 330,000 policies, collected premiums on the order of $300 million per year, and took on $70 billion of exposure. These results represented a phenomenal growth of 40 percent per year for eight straight years. What’s more, the business produced over $100 million of profits since inception. Then an ill wind named Wilma cleared the deck. Hurricane Wilma arrived at the tail end of two consecutive devastating seasons in which eight hurricanes battered the Florida coast. Poe Financial barely survived 2004: after paying out $800 million in claims, the company showed less than $50 million of capital on its balance sheet. In 2005, it frantically searched for fresh funds while also winning new customers to amass premiums. Neither Bill Poe nor others predicted that one horror would segue to another so that in twenty-four months, his customers suffered losses topping $2.6 billion. It was just a matter of time before Poe became insolvent. In 2005, the upstart lost more money than it had ever made in its ten-year history. ~###~ Pondering his misfortune, Bill Poe said, “This was the most unusual wind pattern in the world. The underwriter on that issue is God.” Before 2004, few would have bet against Poe. With over forty years of experience, he knew the Florida market as well as anyone. Having served as Tampa’s mayor, he had reliable connections and understood the regulatory environment. Almost all his customers were sourced from the state under its generous takeout policy. He then transferred most of his exposure to foreigners via reinsurance contracts. (Reinsurers insure the insurers.) As required by law, he used quantitative models to demonstrate that the firm held sufficient surplus to cope with a 100-year storm. Poe evidently followed the rules, yet the company crashed. What went wrong? By any measure, the 2004 and 2005 seasons were extraordinary. Charley, Frances, Ivan, Jeanne, Dennis, Katrina, Rita, and Wilma: these were ill winds that showed no mercy. The Atlantic basin endured the most storms, the most hurricanes, and the most destructive hurricanes, including the single most expensive (Katrina) and the strongest (Wilma) since records began in 1850. The losses suffered in 2004–2005 erased all the profits earned by insurers in Florida since 1993. In response, the national insurance giants began to rewrite the terms of business with their customers. Property owners with existing contracts were socked with harsh price increases of as much as 200 percent, dramatic reductions in coverage, sharp hikes in deductibles, or all of these. For example, Allstate bumped rates by 8.6 percent in 2005 and 24 percent in 2006. In addition to cherry-picking the lower-risk customers, the insurers terminated outright at least half a million policies, while no other private insurer stepped forward to fill the void. When Florida prevented State Farm from charging an extra 47 percent in late 2008, the company announced its intention to abandon every one of its 700,000 customers. A sure symptom of dysfunction was when the market said no at any price. Industry leaders were acting as if hurricane risk in Florida was uninsurable. In an editorial titled “A Failed Insurance Market,” the St. Petersburg Times concluded, “Hope and prayer for another hurricane-free season are the only things standing between Florida and financial disaster.” The market was in a crisis—an existential crisis, to be exact. At this very moment, having witnessed the ravages of deadly storms, eager customers of hurricane insurance were easy to come by. Curiously, private enterprises no longer desired to play a role, and they called on the government to pick up the slack. The problem went far beyond the collapse of Poe Financial. If hurricane risk was insurable before, why did it suddenly become uninsurable? ~###~ To get a satisfactory answer, we must first ask why anyone buys insurance and what keeps someone buying. Insurance is a thoroughly human response to the challenge of hazards: random events like hailstorms and rockfalls deplete wealth arbitrarily. People who believe in insurance contribute to a pool of funds in advance, to be drawn upon by the unfortunate afflicted. Insurance sidesteps the hopeless problem of predicting victims; instead, we let the lucky majority subsidize the unlucky few. This form of subsidy works because no member of a risk pool is immune to misfortune, and anyone can be either a donor or a beneficiary. In this sense, the arrangement is fair. By contrast, a progressive tax system or a bailout of Wall Street stipulates a subsidy scheme under which winners and losers are predetermined. Who would voluntarily participate in such an arrangement, knowing one is almost sure to lose? Automotive insurance is an example of a well-functioning market. In shifting their risks to insurers, drivers agree to pay premiums, most of which accumulate in a surplus account. Professionally qualified actuaries set the rates of payment at levels that should cover potential claims on average, as well as in any year. Beating the average is not good enough (witness Bill Poe); if and when payouts empty the cash vault, it is game over. Thus, a lot of care goes into designing risk pools. All members should face similar degrees of risk, or else some will tap the surplus more extensively than others. Small gaps in risk exposure are bridged by having less-safe drivers pay higher rates. Large gaps chase away safe drivers, who may feel they are paying more than their fair share, and also attract more risky drivers hoping to receive more than they put in. Since actual automotive claims have held steady over time, the actuaries are reasonably confident in their projections of future losses. In particular, they know that only a small portion of their policyholders will file claims in any given year; if everyone needed a payout immediately, the insurers would surely go bust. Shell-shocked by the staggering losses in Florida, the hurricane insurers argued that they must have mispriced their product for years. The modeling firms that supplied them with estimates of expected losses were quick to second this view. Ernst Rauch from Munich Re, one of the two largest reinsurers in the world, reported, “Commercial modeling software of the 2005 generation put the annual loss expectancy for the USA Hurricane risk at $6 to $8 billion,” which, in hindsight, ought to be described as catastrophically wrong. Based on this assumption, the insurance community requested annual payments of $10 billion from policyholders in Florida, only to suffer an actual loss of $36 billion in a mere two seasons. Warren Buffett, who knows a thing or two about the insurance business, cautioned against unfounded optimism: “Too often, insurers behave like the fellow in a switch-blade fight who, after his opponent has taken a mighty swipe at his throat, exclaimed, ‘You never touched me.’ His adversary’s reply: ‘Just wait until you try to shake your head.’” Writer Michael Lewis, in a feature article in New York Times Magazine , vividly charted how quantitative storm models rose to prominence in the mid-1990s after they had correctly predicted the unprecedented losses due to Hurricane Andrew. Their track record since then has been rather unglamorous. After admitting that it significantly underestimated the impact of the 2004–2005 hurricanes, Risk Management Solutions, the leading modeling firm, made fundamental changes to its methodology, incorporating the judgment of a panel of experts. Many of these scientists opined that climate change has rendered Atlantic hurricanes more ferocious and more frequent. With each refinement, the modelers lifted their estimates of future losses, which justified higher and higher premiums. By the late 2000s, the insurance industry asserted that to have a chance of covering projected losses, companies would have to set annual payments above what customers could reasonably afford. Another reason why the industry grossly misjudged the level of risk was its fixation with the “100-year” storm, commonly defined as a storm of such power that it will appear only once every 100 years. In Florida, all underwriters must prove that their capital structure can withstand a 100-year storm. This rule appeared watertight as even Hurricane Andrew, which cost insurers $17 billion in 1992, was a 60-year storm. (A 100-year storm, while producing more damage than a 60-year storm, is less likely to occur.) It was unimaginable for two once-in-a-century disasters to happen in adjacent years. Statisticians tell us that the concept of a 100-year storm concerns probability, not frequency; the yardstick is economic losses, not calendar years. They say the 100-year hurricane is one that wreaks more economic destruction than 99 percent of hurricanes in history. In any given year, the chance is 1 percent that a hurricane making landfall will produce greater losses than 99 percent of past hurricanes. This last statement is often equated to “once in a century.” But consider this: if, for each year, the probability of a 100-year hurricane is 1 percent, then over ten years, the chance of seeing one or more 100-year hurricanes must cumulate to more than 1 percent (a simplified calculation puts the risk at about 10 percent). Thus, we should be less than surprised when powerful hurricanes strike Florida in succession. The “100-year” hurricane is a misnomer, granting us a false sense of security. From the industry’s perspective, the 2004–2005 disasters exposed the inadequacy of the prevailing insurance rates, which relied on wayward projections of the frequency of storms and the intensity of losses. The insurers also discovered that their customers could not bear the full cost of the insurance, so they could see no profit motive, and thus the insurance market failed. ~###~ Statisticians have something else to add to this story: Natural-disaster insurers, unlike automotive insurers, have no choice but to accept risks that are concentrated in vulnerable geographies. This agglomeration of risk became more and more severe as the existing risk pools disintegrated after the 2004–2005 seasons. That Poe Financial shuttered in Wilma’s wake had much to do with its ill-advised concentration of risks in South Florida. The two infamous seasons yielded 120,000 claims. This is to say, almost two out of five Poe customers dipped into the surplus at the same time . Such a massive coincidental draw on liquidity would have sunk any insurer. For this, Poe had only its flawed vision to blame. The take-out deals with the state government bloated its accounts with customers from previously failed insurers, chiefly coastal properties with the greatest chance of damage. Worse still, by competing on price, Poe violated Warren Buffett’s first principle of underwriting. He once advised that if “winning” is equated with market share rather than profits, trouble awaits; “no” must be an important part of any underwriter’s vocabulary. Even the last-ditch expansion effort after the 2004 hurricanes hastened Poe’s demise: with new customers came more revenues but also more exposure and further accumulation of risk, compounding the original problem. Because natural disasters strike locally, these risk pools are much less spatially diversified than those assembled by automotive insurers. Nonetheless, the principle of insurance still applies: these pools must contain some customers who would not require payment during hurricane seasons, or else simultaneous claims would bury the insurers. Traditionally, such customers included policyholders in inland Florida, other states, and foreign countries. To hear it from Bob Hartwig, the industry economist, because all Floridians belonged to the same risk pool, trailer-park grandmas were subsidizing wealthy owners of estates by the sea. Meanwhile, large national insurers borrowed surplus from other lines of business and income from other states to pay claims in Florida. When primary insurers transferred risk to reinsurers, they in effect bought the right to utilize pools of funds contributed by policyholders in other countries such as those insuring against windstorms in Europe or earthquakes in Japan. This means whenever a hurricane strikes Florida, the Europeans and Japanese effectively subsidize U.S. reconstruction projects. Signs after 2005 indicated that none of the three groups would stick around, and for good reason. The skewed statistics of past mega-catastrophes revealed the inconvenient truth about the winners and losers of the existing insurance arrangements. Of the ten most costly disasters between 1970 and 2005, the top eight occurred in the United States, producing over 90 percent of the $176 million total insured losses; the other two included a typhoon in Japan and a windstorm in Europe. Six of those eight American disasters were Atlantic hurricanes, all of which passed through Florida. Towers Perrin, the global management and actuarial consultancy, estimated that the United States accounted for half of the premiums but three-quarters of the losses in the London reinsurance market. If this level of imbalance persists, other participants will perceive the arrangement to be unfair. Already the market has adjusted to the new reality in various ways. The national insurance giants created Florida-only subsidiaries known as “pup companies” to protect their corporate parents, signaling their reluctance to share surplus across state lines. Reinsurers doubled rates they charge hurricane insurers based on the view that hurricane intensity and frequency have grown irreversibly. Unless the recent trend of foreigners subsidizing American disaster claims is reversed, it is hard to see how foreigners will stay in the reinsurance schemes without demanding eye-popping rate hikes, if at all. Florida’s inland residents are also likely to bail out of the risk pool, now that its inherent inequity has been laid bare. In the case of Poe Financial, 40 percent of the customer base cleaned up ten years’ worth of surplus within two seasons. When coastal and inland properties are treated similarly, every policyholder pitches in the same premium, based on the average exposure to risk. In reality, inland properties have a much lower exposure than coastal buildings, so the low-risk residents are subsidizing the high-risk coast dwellers. As participants have widely varying exposure, the winners and losers in this risk pool are predetermined, and not surprisingly, the low-risk group of customers rejects this subsidy structure as inequitable and illegitimate. Undifferentiated risk pools could not hold together because of large group differences; as unhappy customers decamped, the remaining risk became more and more concentrated. ~###~ Just as the Golden Rule lawsuit prompted developers of standardized tests to start treating high-ability and low-ability students as distinct groups, in the aftermath of the jaw-dropping losses from 2004–2005, the insurance industry reacted by splitting the risk pool into two, a strategy statisticians refer to as stratification. After all, one can forcibly mix oil and water temporarily, but they eventually separate into layers. The insurers now fight for low-risk customers while ceding the high-risk coastal properties. How are the two groups faring under this new arrangement? Recall that Poe Financial Group was the poster child for the take-out program initiated by the Florida government after 1992 to divest high-risk policies. The government’s buildup of 1.5 million accounts was reduced to 815,000 by February 2005. Almost all of Bill Poe’s customers came from this incentive program. With Poe’s insolvency, it was a case of return to sender: in one swoop, Citizens Property Insurance Corporation, the state-run caretaker, added 330,000 customers to its roster. Citizens was ill placed to handle this influx: it was about half a billion dollars in the red after the 2004 hurricane season, and the fiscal deficit ballooned to $1.7 billion by the end of 2005, even before absorbing Poe. Having announced its conviction to bail out the Poe customers, the government was forced to raise the payout amount year after year as closed cases were reopened and new claims materialized. By late 2008, Citizens was collecting $4 billion of annual premiums but covered exposure worth $440 billion. The entity would have folded if it were a private concern. Instead, Florida legislators plugged the hole by levying a series of “assessment fees.” After appropriating $920 million from the 2006 state budget, they still had to charge every buyer of homeowner or automotive insurance in the state a fee equal to 6.8 percent of premiums. For those with property insurance, this came on top of a 2 percent levy. Further, a charge of 2.5 percent would then kick in for ten years. In 2007, another 1.4 percent had to be assessed. In addition, having raised nearly $2 billion by selling bonds in 2006 and 2008, the state covered interest payments by taking another 1 percent of premiums for the next eight years. A reporter reminded her fellow Floridians in 2008, “That sucking sound you hear is a 3-year-old hurricane pulling money out of your wallet.” In a time-honored game of passing the buck, the unwanted risks were shoved from owners of seaside properties to private insurers to state-run Citizens to Bill Poe back to Citizens and finally to Floridians. For those living on the coast, nothing has changed: every year, they wish for a quiet hurricane season. When the insurers raise rates, they put up with it; when one insurer takes off, they scramble to another. As for the inland residents, they subsidized the coastal customers when private insurers used to place both groups in the same risk pool; now the state government takes their money via assessments and sends it to the coast. Same difference. ~###~ In an ominous development, the state government rightly got scared of the possible insolvency of Citizens should another mega-hurricane strike Florida but then promptly repeated its mistake of enticing start-up companies to take out policies from the caretaker agency. From 2006 to 2008, 800,000 policies were taken out and taken up by bit players who received “D” (weak) or “E” (very weak) grades from rating agencies, due to inadequate capital and inexperience. The state regulator took a farcical position: “Could there be another monster like Katrina or worse? God forbid if there were. All bets would be off at that point.” We’ve seen this script before, and it did not have a happy ending. And the troubles do not end there. One might expect the devastation wrought by Hurricane Wilma to have deterred Floridians from moving to the coast, but the trend has showed no sign of easing. Economists blame “moral hazard”: coastal dwellers are less worried about hurricanes because they expect the state to continue the unending bailouts and offer an implicit backstop. New residents believe that if their homes should fall, someone else will pay for the reconstruction, so why not enjoy living along the coast? This alarming trend further aggravates the economics of hurricane insurance. The already heavy concentration of simultaneous risks has gained even more heft. The increased population density inflates real estate prices so that the number of risks multiplied by the value of each exposure has expanded by leaps and bounds. Many scientists consider the “lemming-like march to the sea” as a much more serious threat than the recent rise in intensity and frequency of hurricanes. By 2006, Florida owned $2.5 trillion of insured properties, the largest value of any state, eclipsing even New York. Storm models predicted that a hurricane of Katrina’s strength would produce upwards of $100 billion in losses if it traversed the Miami area, repeating the disaster of 1926. While this threat looms, the insurance market in Florida stands paralyzed. ~###~ The harrowing hurricane seasons of 2004–2005 awakened the disaster insurance industry to an essential reality: under existing risk pools, customers with low-risk inland properties were sure losers, and those with high-risk coastal properties sure winners. This group difference threatened the viability of the insurance arrangements because the cross-subsidies no longer appeared fair. The big insurers reacted by imposing stunning rate hikes, especially on the high-risk group, in effect shutting them out. When the state regulator objected, they relinquished the entire market. Inevitably, the state of Florida assumed the role of insurer of last resort, which did nothing to relieve the low-risk group from subsidizing the coastal property owners. If the state must play such a role, then it must provide incentives to slow the migration of people and wealth to the vulnerable coastline. If the state cannot or will not stop the unfair cross-subsidies, it must at least respect the low-risk residents by working to ease their burden. When past lessons are not learned, the next disaster is only a matter of time. On the surface, the insurer and the test developer have nothing in common: one assembles a profitable roster of customers, while the other constructs a fair set of test questions. From a statistical point of view, they both have to grapple with the issue of group differences. In both cases, variability across groups was seen as undesirable. Test developers made a breakthrough when they understood that they could not directly compare black students with white students; by contrast, an insurance market verged on disintegrating once insurers realized that they could not treat every customer as the average customer. The crucial decision in these situations is whether or not one should aggregate groups. That is the dilemma of being lumped together.",
        "char_count": 59316
      },
      {
        "heading": "Chapter 7",
        "text": "4 Timid Testers / Magic Lassos The Sway of Being Asymmetric I want to talk about the positive, not the negative, about this issue. —M ARK M C G WIRE, PROFESSIONAL BASEBALL PLAYER You don’t even have to know what it is you’re searching for. But you’ll know it once you find it. —C RAIG N ORRIS, CEO OF A TTENSITY Awatershed occurred in the early 2000s, when the baseball players’ union finally acquiesced to a steroid-testing program. Baseball fans were losing faith in the integrity of the national pastime, and the scandal was fueled by a pair of sensational books: Juiced , in which All-Star slugger Jose Canseco exposed himself as the “Godfather of Steroids” and outed several well-loved ballplayers as dopers, and Game of Shadows , in which two San Francisco Chronicle reporters laid bare the federal investigation of BALCO, a California supplier of steroids to many elite athletes, including baseball players. It was no longer possible to deny that performance-enhancing drugs had infiltrated the sport, just as they had cycling and track. Drug use is harmful to the athlete and makes a mockery of the sporting spirit. Most sports have adopted an anti-doping code written by the World Anti-Doping Agency (WADA), requiring athletes to submit urine or blood samples for testing. Baseball’s steroid-testing program, however, does not meet the more stringent international standard, as grudging players opt to take one small step at a time. For example, Major League Baseball (MLB) does not test for human growth hormone (HGH), a powerful drug that burst on the scene in the late 1990s. Boston Red Sox star Mike Lowell explained why: “[HGH testing] has to be 100 percent accurate, because if it’s 99 percent accurate, there are going to be seven false positives in big league baseball, and what if any of those names is one of the major names?” Baseball salary statistics fanned Lowell’s uneasiness: the average MLB player earned almost $2.5 million in 2005, and Lowell’s team, the Red Sox, was one of the league’s wealthiest, paying more than $4 million per athlete. With so much money at stake, it is no wonder that ballplayers are worried sick about false-positive errors in steroid testing—about drug-free athletes who get falsely accused. However, with the focus squarely on this one aspect of testing, the anti-doping community has unintentionally abetted the drug cheats. In this chapter, we will learn how. A variation of the steroid detection problem disquieted American troops stationed in Iraq and Afghanistan: how to screen large numbers of local job applicants for past, present, or future association with insurgency. At Camp Cropper in Iraq, David Thompson led a team of interrogators who relied on their training, real-world experience, and gut instinct to “filter truth from fiction.” This lie detection process proved imperfect as insurgents continued to target Thompson’s soldiers. With each phase of the war, he noticed that the recruits arrived younger, less experienced, and thus less prepared for immediate success in the counterintelligence work. Imagine the thrill when he received a shipment of portable lie detectors in 2007. The portable lie detector is a handheld computer with fingertip electrodes for measuring skin conductivity and pulse rate. An operator asks the subject a list of yes/no questions and taps in the answers; within minutes, the computer processes the data from the electrodes and renders a verdict: green for truthful, red for deceptive, and yellow for inconclusive. Like the conventional polygraph, this miniature version actually detects anxiety, which can be induced by either the act of lying or the fear of getting caught lying, depending on which expert we believe. Unlike users of the conventional polygraph, Thompson’s interrogators no longer require expertise or real-life experience; the computer program, optimized by physicists at Johns Hopkins University, removes the human element from counterintelligence screening. Each portable lie detector costs $7,250 plus an annual maintenance fee of $600. With many American lives at stake, it is no wonder that army leaders worry about false-negative errors in interrogations—about insurgents who evade detection during screening. They instructed the Johns Hopkins researchers to calibrate the gadget so that those who receive green lights have virtually zero chance of having lied. However, statisticians tell us that by focusing exclusively on this one aspect of accuracy, the technologists have unintentionally impaired the ability of this gadget to pick out potential suspects, its primary function. In this chapter, we will learn how. Steroid testing and lie detection are both technologies that classify people into types: dopers versus clean athletes, liars versus truth tellers. Critics fault drug tests for destroying careers (false positives) and polygraphs for missing potential criminals (false negatives). Statisticians point out that such technologies face an undesirable but also unavoidable trade-off between the two types of errors. Any detection system can be calibrated, but different settings merely redistribute errors between false positives and false negatives; it is impossible to simultaneously reduce both. As an analogy, consider a baseball hitter of average skill level: he can swing the bats more aggressively, in which case he will register more strikeouts, or less aggressively, in which case he will hit fewer home runs. More importantly, some errors are more visible and more costly than others. Such asymmetry provides strong incentives for drug testers and law enforcement officers to focus their energies on one type of error while the other aspect is neglected and unnoticed. The sway of being asymmetric is the subject of this chapter. ~###~ Mike Lowell, the professional third baseman, was considered toast in Florida before he became the toast of Boston. When the Florida Marlins traded Lowell to the Red Sox in 2005 after two consecutive under-par seasons, they felt the veteran player had seen his best years, and eagerly unloaded his $9 million annual salary to the Boston club. They could scarcely have imagined that Lowell would be named Most Valuable Player in the 2007 World Series, capping off a banner year in which he broke personal records in hits, runs batted in, batting average, and OPS (on-base plus slugging percentage) at the somewhat-old age of thirty-three. Thanks to the one scintillating season, the Red Sox rewarded Lowell with a hefty pay hike to $12 million a year. Mike Lowell’s climb from the humble son of a Cuban exile and a cancer survivor to the top flight of baseball was the substance of American dreams. For Major League Baseball, 2007 was a year in which dreams threatened to turn into mirages. While Lowell’s performance on the field exhilarated Boston fans, baseball was sagging under the weight of a steroid scandal that could expose some of the game’s biggest stars as frauds. The seeds were sown in 1998, when Mark McGwire and Sammy Sosa captivated crowds with a superhuman, down-to-the-wire home run chase, both of them surpassing Roger Maris’s record, previously regarded as sacrosanct. The cynics whispered about rampant abuse of steroids by ballplayers inflating their statistics artificially. Then tantalizing clues started to emerge. A bottle of androstenedione, a stimulant banned in the Olympics, was spotted inside McGwire’s locker. When Barry Bonds shattered McGwire’s record three years later, skeptics noted that the thirty-seven-year-old appeared bigger, stronger, and better than his younger self. Old-school baseball watchers wanted to embellish Bonds’s record with a big black mark even before any proof came to light. Then, in 2003, federal investigators found physical evidence that a California lab, BALCO, had supplied performance-enhancing drugs to elite athletes. The used syringes, doping schedules, and client records entangled numerous ballplayers, among them super-star Bonds. Bonds later admitted to using two substances from BALCO, known as the “clear” and the “cream,” but maintained he thought they were flaxseed oil and antiarthritis balm. Top track coach Trevor Graham anonymously sent a syringe of the “clear” to anti-doping authorities in a sacrificial act to knock out a rival team of athletes he knew to be fellow BALCO clients, leading to its identification as THG (tetrahydrogestrinone), a designer steroid engineered by chemists to be undetectable by testing labs. Next, 3,000-hit man Jose Canseco blew the lid off when he alleged in his sensational 2005 book, Juiced , that four out of every five ballplayers, including McGwire and Jason Giambi, used steroids. Later that year, prompted by President George W. Bush’s State of the Union address, legislators conducted congressional hearings, which were most notable for McGwire’s refrain, “I am not here to talk about the past. I want to talk about the positive, not the negative, about this issue.” Another star slugger, Rafael Palmeiro, declared to Congress, “I have never used steroids, period. I don’t know how to say it any more clearly than that. Never.” Six months later, he tested positive for stanozolol, the same steroid found in sprinter Ben Johnson’s urine at the 1988 Seoul Olympics. In 2007, young Rick Ankiel provided baseball fans with an unlikely feel-good story: the pitcher for the St. Louis Cardinals, who in his rookie season had inexplicably lost his ability to throw strikes during the World Series, resurrected his career by winning a starting job as a major-league hitter. The excitement faded, however, when an investigation linked Ankiel to a Florida clinic suspected of distributing HGH to professional athletes (the league did not discipline him). All of these threads were expected to converge in December 2007, when Senator George Mitchell issued his report on the steroid scandal. The nature of the evidence was as yet unknown, and speculation was running rife that scores of players would be named and vilified. Such was the backdrop when Mike Lowell spoke to the Boston chapter of the Baseball Writers Association. As befitted a college graduate in finance, he gave a succinct, analytical rationale for why the players, led by union chief Donald Fehr, have long vacillated on the issue of steroid testing: “[HGH testing] has to be 100 percent accurate, because if it’s 99 percent accurate, there are going to be seven false positives in big league baseball, and what if any of those names is one of the major names? You’ve scarred that person’s career for life. You can’t come back and say ‘Sorry, we’ve made a mistake,’ because you just destroyed that person’s career. “There’s got to be 100 percent accuracy, and that’s why Donald Fehr puts himself in a position where he’s responsible for the seven false positives, not the 693 that test OK. Because, God forbid, what if it was [Hall of Fame shortstop] Cal Ripken, you know what I mean? Doesn’t that put a big black mark on his career? That’s where I think the union has to make sure the test is 100 percent, no chance of a false positive. Some people have said 90 percent [accuracy]. That’s 70 [false positives]. That’s three full rosters.” A false positive occurs when an athlete who did not cheat is falsely found to have cheated. “Being called a cheater, knowing I didn’t cheat, it’s the worst feeling in the world,” opined Tyler Hamilton, the American cyclist who famously and valiantly endured a painful collarbone injury to finish fourth in the 2003 Tour de France. Adored by cycling fans as a straitlaced “Boy Scout” and respected by colleagues as an all-around nice guy, Hamilton was poised to emerge from the shadow of Lance Armstrong, his mentor, in 2004. His income topped $1 million, including salary and endorsement deals with Nike, Oakley, and other brands. In Athens that year, he became the first American to win an Olympic road race in twenty years. Suddenly and cruelly, his world came crashing down as the drug testers at the Tour of Spain found foreign blood mixed with Hamilton’s. The outlawed practice of transfusing another person’s blood cells into one’s blood, called blood doping, raises the amount of oxygen carried in one’s bloodstream, a key driver of cycling ability. Subsequently, it was disclosed that the “A” sample collected from Hamilton in Athens had also raised a red flag, but the rules barred further action when the lab technician inadvertently froze the “B” sample. (To increase accuracy, testing labs divide blood or urine samples into “A” and “B” halves and declare a positive only when both parts test positive.) Defiant, Hamilton demurred, “We don’t have an answer to why there was a positive test at the moment. If I knew the answer, I’d have it tattooed on my arm. The bottom line, I didn’t blood dope.” His lawyers advanced the possibility that the foreign blood belonged to a “vanishing twin,” an abortive twin brother who might have shared a womb with Hamilton. Hamilton’s defense was as standard as it came for accused athletes: he never cheated, so the positive finding must have been a false positive, which could be explained by alternative causes, such as vanished twins. The arbitrator eventually rejected Hamilton’s appeal, and he served a two-year ban from cycling. If he were indeed a clean athlete, his plight would justify Mike Lowell’s worry about false positives ruining the supernova careers of elite athletes. Accused athletes have had trouble shaking off the stigma of testing positive—and for good reason. Travis Tygart, CEO of the U.S. Anti-Doping Agency (USADA) once observed, “Denial is the common currency of the guilty as well as the innocent.” Such behavior is consistent with their incentives. The truly innocent athlete, upon failing a drug test, should immediately hire a lawyer, find character witnesses, seek alternative explanations, challenge the lab procedures, and fight tooth and nail. The guilty athlete frequently pursues the same course of action while voluntarily withdrawing from competition. At worst, he loses the argument and gets suspended for two years, backdated to when he ceases competing, disregarding when his final appeal falls apart. If lucky, he may find exoneration via a botched procedure, a spoiled sample, or a sympathetic arbitrating judge. By a strategy of denial, the guilty athlete spends most of the suspension clearing his name with a remote chance of redemption; if he instead chooses not to contest the positive finding, humiliation arrives instantly, but reinstatement no sooner. Consequently, the true positive and the false positive, once commingled, are difficult to set apart. That is why millionaire athletes like Mike Lowell demand nothing less than a test that is “100 percent accurate, [with] no chance of a false positive.” If only real life were so perfect. Statisticians say even if a test committed zero false positives, it would be far from “100 percent accurate” because of false-negative errors. Athletes only complain about false positives; the media wax on about false positives. We are missing the big story of steroid testing: false negatives . ~###~ In an impassioned letter written in his own defense, cyclist Tyler Hamilton asserted, “I have been tested over 50 times throughout my career and this is the first time I have ever even been questioned.” Actually, entire pelotons have been pedaling under a stubborn fog of suspicion ever since a string of sensational drug busts hit the sport’s marquee event, the Tour de France, in the 1990s and 2000s. Second-guessing hard-to-believe performances has become a spectator sport. Protesting and proving their innocence has become a second job for many cyclists. Hamilton’s heroics at the Tour de France happened under the watch of Bjarne Riis, the owner of the CSC-sponsored team and a former champion from Denmark. Accusations also trailed Riis for a decade after his memorable and devastating victory in 1996. One observer recalled the occasion: “Through a series of a dozen or so brutally calculated accelerations and decelerations, he ripped the legs off his competition, knocking a few loose with each surge, until he ended up alone and very far ahead.” This feat Riis accomplished at the age of thirty-three as the leader of a then-unheralded Telekom team, the first time he had commandeered any team in ten years of racing. As owner of the CSC team, he raised many eyebrows by assembling a front-ranked club within two years. As a rider, Riis always met his doubters with one answer: I have never tested positive. He attributed his success to bee pollen, training methods, and “Thinking to Win,” and he incorporated these elements into the CSC program. In 2004, Riis denounced cheaters in a public letter: “It is—to put it mildly—extremely frustrating to experience how some within the sport do not live up to the wish that most of us have for a healthy, sound, professional sport.” Marion Jones, the superstar sprinter and Vogue cover girl, was certified clean in every one of about 160 samples she provided in her illustrious career. She reached dizzying heights at the 2000 Sydney Olympics, earning five medals, three of them gold. Her annual earnings, which included race bonuses and endorsement deals, exceeded $1 million. But rumors hounded her, not least because of the company she kept, particularly ex-husband C. J. Hunter, ex-boyfriend Tim Montgomery, and coach Trevor Graham. Hunter, a shot put champion, was busted when he tested positive for the steroid nandrolone at a thousand times the normal level. Montgomery, one-time 100-meter world record holder, and Graham, celebrated coach of numerous tainted athletes, were key figures in the BALCO scandal. Notwithstanding, Jones adamantly denied ever using drugs. In her autobiography, she shouted in large, red, capital letters: “I HAVE ALWAYS BEEN UNEQUIVOCAL IN MY OPINION: I AM AGAINST PERFORMANCE-ENHANCING DRUGS. I HAVE NEVER TAKEN THEM AND I NEVER WILL TAKE THEM.” In case we missed the message, she splattered the words all over page 173. When the owner of BALCO, Victor Conte, alleged that she doped “before, during and after the 2000 Olympics,” Jones served up a $25 million defamation lawsuit. In an interview with “20/20,” the public-affairs program, Conte described how Jones “did the injection with me sitting right there next to her. . . . [She] didn’t like to inject in the stomach area. . . . She would do it in her quad.” Her lawyers dismissed Conte as “simply not credible.” When ex-husband Hunter also implicated her, she called him a vindictive liar. At a time when droves of elite track athletes were being exposed, such as double world sprint champion Kelli White, 200-meter world champion Michelle Collins, 1,500-meter world record holder Regina Jacobs, British sprinter and European record holder Dwain Chambers, and Olympic gold medalist twins Calvin and Alvin Harrison, Marion Jones stood tall, never testing positive once. She decried unjust treatment by the media, complaining, “The athletes who have not tested positive have been dragged through the mud.” Then in August 2006, Jones got a scare: an “A” sample she had provided at the U.S. championships tested positive for EPO (erythropoietin), a high-tech replica of blood doping that obviates nasty blood transfusions. Her detractors pounced while she continued to deny. Her then coach, Steve Riddick, declared, “I would stake my life on it she did not take EPO.” Within a month, the “B” sample was ruled inconclusive, so for the moment, Jones’s integrity remained intact. Now her supporters had their turn to gloat. They attacked the validity of the EPO test as the positive finding of the “A” sample was overturned by the inconclusive “B” sample. Her lawyer lamented, “Marion was wrongfully accused of a doping violation and her reputation was unfairly questioned.” For her part, Jones reiterated, “I have always maintained that I have never ever taken performance-enhancing drugs, and I am pleased that a scientific process has now demonstrated that fact.” What was the common link between Marion Jones and Bjarne Riis? They both scaled the summit of their sport, they both passed every drug test along the way, they both reaped the riches afforded superstars, and they both swept aside accusations with strident public declarations of honesty. Last but not least, they were disgraceful drug cheats both. Ten years after his stirring victory, long after he had quit competitive cycling, Riis publicly confessed to extensive doping, including EPO, HGH, and cortisone. Jones eventually confessed in 2007, but only after federal prosecutors had hauled her into court on perjury charges stemming from the many lies she sprang at BALCO investigators. She spent six months in jail. (By contrast, Tyler Hamilton, the clean-cut Olympic champion, never admitted to cheating; on returning to competitive cycling after the 2005 suspension, he repeatedly failed drug tests, and the eight-year ban he was served in 2009 effectively ended his career.) Supporters of Marion Jones pointed to her ordeal at the 2006 U.S. Championships as a real example of a false-positive error. In reality, Jones tested negative at the meet owing to the inconclusive “B” sample, which acted as an automatic protector against false positives. Given subsequent events, one must turn this around and ask if, rather than a false positive, the finding was a false negative! That scenario was more likely, even though Jones had only owned up to unintentional doping between September 2000 and July 2001 (that is, not in 2006). Like Barry Bonds, she claimed to have believed the “clear” was flaxseed oil until the BALCO scandal broke. Her many accusers, however, insisted that she had had full knowledge. Only Jones and her staff would know the whole truth. London’s Daily Telegraph , in assessing Jones’s extravagant demise, offered this perspective: “The inconvenient truth that testing negative means nothing is really the key finding of the Marion Jones episode.” The reporter was pitch perfect in her evaluation, and one wonders why few others picked up on the story. Statistical analysis shows that in steroid testing, a negative finding has far less value than a positive. As shown in Figure 4-1 , for each doper caught red-handed (true positive), one should expect about ten others to have escaped scot-free (false negatives). False negatives, not false positives, are the true story of steroid testing. In particular, pay attention to these two numbers: the proportion of samples declared positive by drug-testing laboratories and the proportion of athletes believed to be using steroids. Of thousands of tests conducted each year, typically 1 percent of samples are declared positive. Therefore, if 10 percent of athletes are drug cheats, then the vast majority—at least 9 percent of them—would have tested negative, and they would have been false negatives. (If the athletes were right that some of the positive findings were errors, then even more dopers would have been missed.) ~###~ The issue of false negatives has largely been ignored by the media and is virtually untouched by athletes. Tyler Hamilton, Marion Jones, and others contend that every negative result helped prove their innocence but no positive finding could corroborate their guilt. Channeling Mark McGwire, they might well have chanted, “We are here to talk about the false positive, not the false negative, about steroid testing.” Mike Lowell expressed the same belief in numerical terms. Since three full rosters equaled 70 guys, and there were thirty teams in Major League Baseball, he assumed a total of 700 players, each tested once annually. Of the 700 players, 693 “tested OK,” meaning they were clean; the other 7 were false positives, meaning that they too were clean. In other words, all 700 were clean, but 7 hard-luck players tested positive erroneously. With no dopers, of course, every positive result must be a false positive. In Lowell’s world, the only acceptable test was the one that gave only negatives. Figure 4-1 How Steroid Tests Miss Ten Dopers for Each One Caught Some dismiss false negatives as victimless errors. Not true. As Michael Johnson, the superlative sprinter with the golden Nike spikes, wrote, “the athletes who finished behind [the winner who cheated] will never experience the glory or recoup the financial benefit they deserved for their hard work.” To his credit, Johnson saw the problem of false negatives. A count of the victims of Marion Jones had to start with her relay teammates (who were required to return their medals), and then there were all the silver medalists who should have won gold, all the bronze medalists silver, and all the fourth-place finishers bronze. All waited seven years to learn they had been cheated. (In a sardonic twist, some “victims” turned out to be cheats, too. For example, four of the other seven finalists who raced with Ben Johnson have since been exposed as dopers.) Many athletes get away with cheating. In the anti-doping community, this statement is not controversial. In a review of drug testing for the New York Times , Professor Charles Yesalis disclosed, “It is virtually impossible to mistakenly identify a substance if a person tests positive for it. [However,] it has been proven that testing cannot catch all substance abusers.” Dr. Rasmus Damsgaard, who ran anti-doping programs for professional skiing and cycling teams, estimated that “maybe hundreds, maybe even thousands of EPO positive samples are lying around in WADA-accredited labs,” that is, after having passed testing. Poring over past doping cases, perhaps David Letterman would feel inspired to make one of his famous Top Ten lists for easy tips to produce a false negative. If so, he might consult the following methods that were actually used, as presented by the athletes with firsthand experience: 10. When the tester is looking away, stir in a little whiskey, and shake it. (Irish swimmer Michelle Smith) 9. Misdirect the testers to the wrong place, and then stage a motorcycle accident to avoid the out-of-competition test. (Sprinter Konstantinos Kederis, also known as “the greatest living Greek”) 8. Hold a friend’s pee inside your body, release quickly when the tester shows up. I get extra credit for being cooperative. (Russian track star Yelena Soboleva and six teammates) 7. Believe in human frailty. If a clueless lab technician freezes one of the samples, the lab cannot run a test on it. (Tyler Hamilton) 6. It’s all about timing! Know how long it takes for the stuff to clear. (American sprinter Kelli White) 5. Easy does it for guys. Wear a prosthetic and give them fake pee. (Customers of the Whizzinator and similar products) 4. Be ahead of the curve; use only the newest designer stuff. They don’t know what it is, so they don’t test for it, wink wink. (BALCO athletes) 3. It’s a natural high. The testosterone is all yours. You’re just more manly than the competition. (American cyclist Floyd Landis) 2. It’s so easy to walk right through the front door. Apply for the pass to cheat; it’s called the therapeutic-use exemption. You have asthma, you can dope. (Many athletes) And the number one easy tip to produce a false negative is . . . to sit back and relax, as timid testers will let cheaters ride off into the sunset for fear of wrongly besmirching honest athletes. Could this really be true? Conventional wisdom says testers and cheaters engage in a high-tech cat-and-mouse game, in which self-righteous testers, eager—perhaps overly eager—to catch the cheaters, tend to cast a wide net, trapping many innocents. However, once we understand the incentives causing testers to look the other way, the game appears to play out differently. The testers are timid because they are swayed by asymmetric costs from the two types of error. A false positive—in fact, any positive, as Tygart observed—will be rigorously litigated by the accused. An overturned positive publicly humiliates the anti-doping authorities and diminishes the credibility of the testing program. By contrast, negative findings can only be proven false if athletes, like Riis, step forward to confess, so most false negatives never see the light of day. Athletes and testers alike can hide behind the anonymity of the false negative. The testers are timid because the false-negative error imparts negligible cost while the false positive can be highly public and highly toxic. Since anti-doping agencies pursue only the strongest cases, no wonder they have won almost all of them. Our criminal-justice system makes the same judgment call: a few murderers escape punishment so that very few innocent people are sent to the chair. ~###~ Timid testers are eager to minimize false positives. This objective doesn’t conflict with the desire to avoid false-negative mistakes, or does it? Statisticians tell us it definitely does. Testers face an unsavory trade-off: fewer false positives mean more false negatives; fewer false negatives mean more false positives. We next consider how this trade-off manifests itself in steroid tests, using the hematocrit test for catching blood dopers as an illustration. While no fewer than nine Tour de France champions have been exposed as frauds since 1975, Bjarne Riis had the distinction of carrying the nickname Mr. Sixty Percent, a sarcastic reference to his alleged hematocrit level. The hematocrit level measures the density of red blood cells as a proportion of blood volume. Normal males register a level of about 46 percent. A level of 50 percent or higher is considered abnormal, and 60 percent is insane, because blood becomes too viscous, putting enormous pressure on the heart. The effect is like sucking thick milk shake up a narrow straw. Before more advanced tests became available, the International Cycling Union (known by its French initials, UCI) used the hematocrit test to identify suspected EPO abusers. EPO is a hormone, naturally secreted by the kidney, which stimulates the growth of red blood cells. By injecting synthetic EPO, endurance athletes boost their red cell counts (and hematocrit levels), raising the oxygen-carrying capacity of their blood. Training at altitude provides similar benefits but is inconvenient and reportedly less effective. EPO is basically the modern form of blood doping. It is also a potent killer: doctors suspect that the reason why, in recent years, a number of young cyclists—fit men in their prime—have suffered fatal heart attacks in their sleep is EPO abuse. There is a saying that “Cyclists live to ride during the day and then ride to stay alive at night.” Allegedly, some EPO users wake up multiple times a night and jump on the exercise machines to get their heart rates up! UCI used to disqualify everyone with a hematocrit level above 50 percent. This policy sidelined the dopers but also those with a “natural high”; for example, about 20 percent of people living in highlands have natural red cell densities above 50 percent, and they fell victim to the false positive. Anticipating this, UCI did not regard the positives as doping violations but instead considered the disqualification a measure to protect the health of cyclists. Statisticians tell us it was the threshold of 50 percent used to separate natural from unnatural that fixed the unavoidable tradeoff between the two types of errors. If the testers had used 60 percent, they could have reduced false positives, but without a doubt, more dopers would have evaded detection. Similarly, lowering the disqualifying hematocrit level would decrease false negatives at the expense of allowing more false positives. Nowadays, WADA relies on a more sophisticated, more accurate urine test for EPO. Whether steroid tests measure hematocrit level or another indicator, the principle of all the tests is the same. By setting the threshold of separation, anti-doping authorities explicitly calibrate the tests according to their tolerance for each type of error. Because false positives make for lousy publicity, containing these errors is a top priority. However, this policy inevitably means some drug cheats are let loose, especially since testers can hide behind the false negatives, which are invisible. Due to the sway of asymmetric costs, testers are timid. ~###~ Even though anti-doping agencies are inclined to minimize false positives, many athletes echo Mike Lowell’s fear. Rafael Palmeiro believed an injection of vitamin B 12 caused a false positive. Tyler Hamilton said his vanished twin caused a false positive. Floyd Landis, the American cyclist, claimed a few beers caused his testosterone level to spike. Petr Korda, the Czech tennis player, believed eating veal from calves fed with nandrolone caused his positive. David Martinez, the Spanish discus thrower, citing pigs, even raised one on nandrolone to prove his point. Ben Johnson has long claimed that Carl Lewis spiked his energy drinks, causing the positive. Justin Gatlin, another American sprinter, said his masseuse rubbed steroid-laced cream on his legs. Zach Lund, the American skeleton rider, knew it was a baldness cure that put finasteride in his body. The list goes on. We may choose to believe all, or some, of these claims. It does not matter, because from a scientific point of view, none of these results actually constituted a false positive! To see why, we must separate the test of chemistry from the test of integrity. In the test of chemistry, a false positive occurs when the testers report finding an illegal substance that, in fact, does not exist in the sample. In each of the cases just described, the athlete tacitly admitted the presence of the banned drug, so each case was a true positive, not-withstanding the colorful explanations for how steroids entered their bodies. How then do we assess the claims about nutritional supplements, spiked drinks, and so on? Can we take the athletes’ words for it? This is no longer a question of the science; it falls into the realm of lie detection, which is where we now head. ~###~ The modern-day polygraph machine is a fear-inducing briefcase filled with medical diagnostic tools, including a chest cord for measuring breathing, an arm cuff for gauging blood pressure and pulse rate, and fingertip electrodes for sensing skin conductivity. Forensic psychologists believe that the act of lying or the fear of getting caught lying raises anxiety, and scientifically speaking, the polygraph detects anxiety, not actual deception. William Marston, a Harvard-trained psychologist who was the first to relate truth telling and blood pressure variations, failed to popularize the concept in the early twentieth century, but he ultimately achieved immortality by creating the comic book heroine Wonder Woman, who not coincidentally wielded a Magic Lasso that “makes all who are encircled in it tell the truth.” Rather than a “lie detector,” the polygraph is simply an instrument of data collection: the data can suggest signs of anxiety, but deception is just one of various causes of elevated blood pressure, hastened breaths, and so on. Therefore, the role of the polygraph examiner is paramount in judging which apprehensive subject is a liar and which is not. A polygraph machine without a competent examiner is like a stock chart without a seasoned analyst: reams of numbers without any significance. The typical examiner is a retired employee of a law enforcement or intelligence agency that utilizes polygraphs in conducting investigations. He or she has undertaken professional training, such as the thirteen-week course at the Polygraph Institute of the Department of Defense, followed by a six-month internship. This person has developed confidence in his or her ability to interpret fluctuations of various bodily metrics, such as pulse rate and blood pressure. To establish a baseline level of anxiety, the examiner usually engages the subject in extensive pretest conversation, including previewing the test questions. The actual test begins when the examiner feels that the subject is completely at ease. Whenever the examiner senses signs of deception, he or she suspends the test to elicit the subject’s state of mind. Throughout the test, the examiner looks out for countermeasures—tactics that the subject may use to derail the examiner, such as biting one’s tongue, controlling breathing, contracting certain muscles, deliberately stepping on a hidden tack inside one’s shoe, counting backward, and any number of other tactics directors have popularized on film. ~###~ In 2005, the simmering steroid scandal in Major League Baseball boiled over as six-time All-Star slugger and self-appointed Godfather of Steroids Jose Canseco ignited the blowtorch known as Juiced , his finger-pointing exposé of the steroid subculture in baseball locker rooms. Canseco dropped bombshells such as “If I had to guess, I’d say eight out of every ten players had kits in their lockers filled with growth hormones, steroids, supplements.” Of greatest interest to the media, though, he named names, starting with fan favorites, including Mark McGwire, Juan Gonzalez, Ivan Rodriguez, Rafael Palmeiro, and Jason Giambi. Regarding McGwire, Canseco recounted, “Mark and I would duck into a stall in the men’s room, load up our syringes and inject ourselves. I would often inject Mark.” The author of Juiced was promptly branded as vindictive, despicable, and delusional. Hell hath no fury like a Godfather scorned. Three years after Juiced , Canesco reloaded his blowtorch, delivering a sequel called Vindicated . Far from repenting, he reiterated his earlier claims and even advanced some new ones, including an educated guess that Alex Rodriguez, one of the most bankable stars of baseball, was a doper. To clear any doubts, Canseco released verbatim transcripts of two lie detector tests conducted by recognized experts. One of these, John Grogan, administered the most popular interview format, known as the Control Question Test, which mashes up three types of questions: relevant, irrelevant, and control. The following snippet came from the start of his examination of Canseco: Grogan : Is today Thursday? [irrelevant] Canseco : Yes. Grogan : Is your name Jose? [irrelevant] Canseco : Yes. Grogan : Did you and Mark McGwire ever have conversations about the use of steroids or human growth hormones? [relevant] Canseco : Yes. Grogan : Is your last name Canseco? [irrelevant] Canseco : Yes. Grogan : Did you ever inject Mark McGwire with steroids or human growth hormones? [relevant] Canseco : Yes. Grogan : In the last ten years, have you lied to benefit yourself financially? [control] Canseco : No. Grogan : Is your shirt black? [irrelevant] Canseco : Yes. And on it went. Grogan looked for any difference in emotions when Canseco answered relevant versus control questions. “Control” questions concern vague and broad categories of wrongdoing, such as office theft and white lies, designed to make even truthful subjects experience discomfort. Liars are supposed to feel greater anxiety toward the relevant questions, while truth tellers are expected to be bothered more by control questions. Grogan did not equivocate regarding Canseco’s performance: “He’s one hundred percent telling the truth on all questions regarding human growth hormones and steroids. And the computer misses nothing, not the most smallest, insignificant tracings. . . . It gave him a .01 score on every chart, which, if this was in school, would be an A-plus on every chart collected.” Take that, baseball! ~###~ Many other athletes also tried to clear their names via polygraph tests. The lawyers of superstar sprinter Marion Jones, in a bid to fend off persistent rumors of her steroid use, declared that she had passed a polygraph test. Immediately, they challenged Jones’s accuser-in-chief, BALCO founder Victor Conte, to submit to a polygraph himself (he never did). They taunted, “It is easy to go on national television and . . . make ‘false, malicious and misleading’ statements designed to do harm to Ms. Jones’ character and reputation. However, it is quite another matter to take a polygraph examination that will test whether one is truthful or untruthful.” When evergreen, superstar pitcher Roger Clemens found his name featured in Senator Mitchell’s report, he angrily denied the implication, and he told Mike Wallace, host of “60 Minutes,” he might take a polygraph test to prove his innocence (but later recanted). Polygraph evidence has a following not only among sports icons but also among politicians, celebrities, and business leaders. Disgraced Enron CEO Jeff Skilling publicized a favorable polygraph test to buttress his assertion that he had played no role in the shady dealings that led to the apocalyptic collapse of the energy giant and wiped out the retirement savings of thousands of employees. A cousin of J. K. Rowling took a lie detector test, broadcast on American television, to prove (in vain) that he had inspired the Potter character in her Harry Potter novels. Larry Sinclair, a Minnesota man who claimed to have shared a bed with then presidential candidate Barack Obama, infamously failed a polygraph challenge sponsored by Whitehouse.com. Larry Flynt introduced polygraph evidence to show that a New Orleans prostitute was telling the truth when she revealed having an extramarital affair with Senator David Vitter. It may therefore be a surprise to find out that U.S. courts of law have long considered polygraphs inadmissible as evidence, ever since Marston attempted to set the precedent and failed in the 1920s. The standard has been loosened slightly in recent years in selected jurisdictions. Yet lawyers continue to seize headlines with lie detection results. One reason is that the public appears to trust polygraphs. The popular sentiment was underscored by the unpredicted success of the game show “The Moment of Truth,” in which contestants chained to polygraph machines were dealt embarrassing questions about personal relationships, petty crimes, and sundry private matters. In a notable episode, the audience applauded as the wife of a New York police officer publicly admitted to infidelity, a statement confirmed as true by the polygraph. After debuting on Fox in January 2008, the show ended the season as the most watched new show on network television, averaging 14.6 million viewers. Jose Canseco reportedly threw his cap in the ring to face the examiner on the popular show in his unyielding quest for credibility (though such a show was never aired). ~###~ The enthusiastic, widespread usage of lie detectors runs counter to their unaccredited status in the American legal system. In the 1920s, the courts introduced a litmus test of “general acceptance,” which excluded evidence from polygraphs unless and until the science attained sufficient validation. Almost a century came and went with anemic progress: the scientific community has periodically reviewed available research and repeatedly warned the public that polygraphs make too many errors to be reliable, particularly when used to screen people. Comprehensive reports in 2002 and 1983 were barely distinguishable in their executive findings. Meanwhile, legislators sent mixed messages on the issue: Congress passed the Employee Polygraph Protection Act of 1988, prohibiting American companies from conducting polygraph screening tests on potential or current employees, but it has not restrained government agencies or the police. And in 2008, Congress took a pass on scrutinizing the PCASS (Preliminary Credibility Assessment Screening System) after learning the portable lie detector was to be deployed in Iraq and Afghanistan. Despite the lack of judicial or scientific standing, the FBI, the CIA, and the vast majority of local police forces routinely use polygraphs in criminal investigations. They utilize lie detectors indirectly, as a means to coerce suspects into making confessions. T. V. O’Malley, president of the American Polygraph Association, has compared a polygraph examination to “confessing to a priest: you feel a little better by getting rid of your baggage.” Confession evidence holds awesome power in the courtroom; a noted legal scholar believes it “makes the other aspects of a trial superfluous.” For this reason, federal and local law enforcement officers regard the polygraph as “the most effective collection tool in their arsenal of security tools.” In the United States, it is legal to obtain confessions via the reporting of false evidence, which means the police are free to tell a suspect he or she failed a lie detector test no matter what happened. When the U.S. Army approved PCASS in 2007, the portable gadget was intended for security screening (of non-U.S. citizens), rather than targeted investigations. This use is not new; at least ten government entities, including the FBI, the CIA, the National Security Agency, the Secret Service, the Department of Energy, the Drug Enforcement Agency, and the Defense Intelligence Agency, as well as most police forces use lie detectors to screen new or current employees. At its peak, the Department of Energy’s screening program covered all twenty thousand employees; bowing to pressure from scientists and Congress, the department later cut the list to twenty-three hundred targets who have access to certain “high-risk” programs. The polygraph’s practitioners and supporters argue that the machine is accurate enough, and certainly more accurate than any alternative. They are convinced that the mere presence of the lie detector intimidates some subjects into telling the truth. Since the real deal is the confession evidence, they don’t think accuracy matters as much as the academics say it does. Furthermore, polygraph results have broken open some very difficult cases. ~###~ A case in point was the Angela Correa murder in Peekskill, New York. On November 15, 1989, Angela strolled into the woods of Hillcrest Park to snap photographs for school. She never walked out of the park. Two days later, her partially naked body was found, covered in leaves, raped, beaten, strangled, and murdered. She was fifteen years old. We reserve the word evil for people who commit such heinous crimes. The police detectives, working quickly, obtained an offender profile from the New York Police Department: they were told to look for a white or Hispanic man, younger than twenty-five and probably under nineteen, shorter than five feet ten inches; someone with a physical handicap or mental slowness; a loner unsure around women but who knew Angela; someone not involved in school activities and with a history of assault, drugs, and alcohol. From the first week, the detectives did not doubt that a classmate of Angela’s had killed her. They had their eyes on sixteen-year-old Jeffrey Deskovic, who fit the NYPD profile of an introverted, young murderer, and they never looked back. Deskovic was said to have been absent from school at the time of Angela’s death. Later, he showed unusual curiosity in the case, even volunteering to be interviewed by detectives without the presence of family, a friend, or a lawyer. However, the investigation was stalling, not least because the scientific evidence proved wanting—completely negative. None of the three hair samples collected from Angela’s body came from Deskovic (the police surmised they came from the medical examiner and his assistant). No fingerprint of Deskovic’s was detected on a cassette player and tape, bottles, twigs, and other items retrieved near her body. Most exasperating to the police, the DNA in the live sperm swabbed from inside her body did not match Deskovic’s and instead specifically excluded him. Nor did the detectives have direct-witness testimony. Deskovic was interviewed no fewer than seven times during the two-month investigation. He started to act as if he were part of the investigation team, sharing notes with the detectives and drawing maps of the crime scene. The police knew they had the right guy but were frustrated they had scant evidence against him. So it was the polygraph that saved the day. On January 25, 1990, Deskovic agreed to take a polygraph exam to prove he was telling the truth. Before this day, he had steadfastly maintained his innocence. Early in the morning, he was driven to Brewster, New York, where he was cooped up for eight hours in a ten-foot by ten-foot room, facing in turns Detective McIntyre and Investigator Stephens, who played good cop, bad cop. Eventually, Stephens told Deskovic he had failed the polygraph exam, whereupon a final confrontation ensued in which Deskovic made a confession to McIntyre. On December 7, 1990, a jury convicted Jeffrey Deskovic of murder in the second degree, rape in the first degree, and criminal possession of a weapon in the fourth degree. On January 18, 1991, he was sent to jail with a sentence of fifteen years to life. The court described it as a “classical tragedy.” Deskovic ultimately served sixteen years in prison; he was released in September 2006. Investigator Stephens, like many police officers, regarded the polygraph as a prop to “get the confession.” Whereas most courts do not admit polygraph evidence, introducing a suspect’s admission of guilt greatly aids a prosecutor’s case; researchers have found a conviction rate of about 80 percent among U.S. criminal cases with confession evidence. In the Angela Correa case, Deskovic’s confession helped the prosecutors overcome the absence of scientific evidence and witness testimony. Without the polygraph exam, there would have been no confession and thus no conviction. ~###~ In Pittsburgh, Carnegie Mellon University statistician Stephen Fienberg listened in disbelief as an MSNBC journalist spoke to him about the newly revealed PCASS, the portable lie detector. The army had already poured over $2.5 million into its development and purchased about a hundred units for troops in Iraq and Afghanistan. Professor Fienberg saw this as utter disdain for the considered opinion of American scientists on the unreliability of lie detection technologies, and of polygraphs in particular. In 2002, he had served as the technical director of the report in which the National Academy of Sciences (NAS) resoundingly rejected the polygraph as an inadequate science, especially for use in national-security screening. The key sentence of the entire report was this one: Given [the polygraph’s] level of accuracy, achieving a high probability of identifying individuals who pose major security risks in a population with a very low proportion of such individuals would require setting the test to be so sensitive that hundreds, or even thousands, of innocent individuals would be implicated for every major security violator correctly identified. This ratio of false positives to true positives (hundreds or thousands to one) elegantly captures what the scientists have dubbed the “unacceptable trade-off,” which is a variant of the conundrum faced by anti-doping scientists hoping to pick out drug cheats from squads of clean athletes. Here, polygraph examiners must set the sensitivity of their machines so as to balance the benefits of possibly identifying suspicious individuals with the costs of falsely implicating law-abiding citizens. However, different settings merely redistribute errors between false positives and false negatives, not unlike using different thresholds in the hematocrit test. Addressing the flip side of this trade-off, the NAS opined, “The only way to be certain to limit the frequency of false positives is to administer the test in a manner that would almost certainly severely limit the proportion of serious transgressors identified.” This science is dismal: as false positives ebb, so false negatives flow. The 2002 NAS report specifically recommended that the government reduce or rescind the use of polygraphs for employee screening. Yet the investigative reporter from MSNBC unearthed declassified documents disclosing how the army had been aggressively pursuing a new portable polygraph gadget destined for screening use. As a knockoff of the traditional polygraph, PCASS records fewer measurements and is surely less accurate than its model. The crucial role of the examiner is abrogated, replaced by an “objective” computer program that is easily fooled by countermeasures it cannot see, such as breath control and tongue biting. What’s more, NAS criticized the Johns Hopkins University lab hired to supply the computer program for being “unresponsive” to repeated requests for technical details, so that the research committee could not complete an independent evaluation of the lab’s methodology. Among the uninspiring body of research on the accuracy of PCASS, most studies were conducted by the same people who developed the device itself (conflict of interest, anyone?), and none attempted to replicate the battlefield conditions under which it would be deployed. Despite the lack of serious science to back up the claims of efficacy, Congress has failed to call any hearing on PCASS. In an act of self-regulation, the army acknowledged the weaknesses of the portable lie detector and proactively restricted its use to screening job applicants at military bases and screening potential insurgents at bomb scenes. As counterintelligence team leader David Thompson explained, the “Reds” (subjects determined to be deceptive) would face follow-on interrogations, most likely via the traditional polygraph examination, rather than immediate consequences. Implicit in this change of policy is the idea that the polygraph will be more acceptable if we set lower expectations—if we let PCASS do half the job. Such a compromise seemed as though it should please the skeptical scientific community: while the decision didn’t completely shelve deployment of the flawed technology, the army at least curtailed its role. Far from being satisfied, Fienberg’s panel concluded that while polygraphs are marginally useful for targeted investigations, they are essentially worthless for screening. Alas, against lowered expectations, lie detectors perform even worse! A sports commentator would say the team is playing down to the standard of the opponent. To understand why this must be so, compare the following two situations in which the polygraph attains the 90 percent accuracy level claimed by its supporters: Situation A: Screening The agency believes 10 spies lurk among its 10,000 employees (1 in 1,000). Of the 10 spies, the polygraph correctly identifies 90 percent (9) and passes 1 erroneously. Of the remaining 9,990 good employees, the polygraph erroneously fails 10 percent, or 999. For every spy caught, 111 good employees are falsely accused. Situation B: Police Lineup The police seek 20 murderers out of 100 suspects (1 in 5). Of the 20 murderers, the polygraph correctly identifies 90 percent (18) and passes 2 erroneously. Of the remaining 80 innocent suspects, the polygraph erroneously fails 10 percent, or 8. For every 9 murderers caught, 4 innocent citizens are falsely accused. Notice that Situation B offers a dramatically more favorable cost-to-benefit ratio than Situation A: when the lie detector is used in a specific investigation, such as a police lineup, the price of catching each criminal is less than 1 false accusation, but when it is used for screening, the comparable cost is 111 innocents sacrificed. Given identical accuracy levels in both situations, the real reason for this difference is the divergent ratio of criminals to innocents subject to the tests. Situation A (screening) is more trying because the presence of so many innocents (999 out of 1,000) turns even a small error rate into a bounty of false positives and a roster of ruined careers. The baseball players’ union would not be pleased as Mike Lowell’s worst-case scenario materialized. For security screening, one expects that almost everyone examined is neither a spy nor an insurgent, so the situation is like A, not B. To overcome the challenge of Situation A, we must have a wholly accurate technology, one that yields an exceedingly small quarry of false positives. Scientists warn against PCASS precisely because the military intends to use the gadget for screening masses of mostly innocent people; in this arena, sometimes known as “prediction of rare events,” the polygraph and its variants are decidedly not Magic Lassos. ~###~ When Jeffrey Deskovic walked out of jail on September 20, 2006, he walked out a free man. He also walked out an innocent man. Not a typo. Deskovic became a poster boy for the Innocence Project, a pro bono legal aid consultancy dedicated to overturning wrongful convictions through the latest DNA technology. Earlier that year, the project leaders had convinced Janet DiFiore, the new Westchester County district attorney, to reexamine Deskovic’s DNA. The result confirmed the original forensic finding that the quiet classmate of Angela Correa had nothing whatsoever to do with her murder. More significantly, the murderer’s DNA matched Steven Cunningham, whose profile was inserted into a data bank of criminals due to a separate murder conviction for which he was serving a twenty-year sentence. Cunningham later admitted to Angela’s murder and rape, closing the loop for DiFiore’s office. It took Deskovic sixteen long years to win back his freedom and innocence. At the time of his release in 2006, he was thirty-three years old but just beginning his adult life. A reporter from the New York Times found him struggling with the basics of modern living, such as job hunting, balancing a checkbook, driving a car, and making friends. He said, “I lost all my friends. My family has become strangers to me. There was a woman who I wanted to marry at the time I was convicted, and I lost that too.” “He had been incarcerated half his life for a crime he did not commit.” DiFiore’s office did not mince words in a candid review of the Angela Correa murder case. Her report continued, “Desk-ovic’s January 25th statement was far and away the most important evidence at the trial. Without it, the State had no case against him. He would never have been prosecuted for killing Correa. He would never have been convicted. He would never have spent a day—let alone sixteen years—in prison.” Recall what transpired on that fateful day: Deskovic consented to a polygraph interrogation, during which he confessed to a crime he did not commit. The detectives concluded that Deskovic lied when he claimed innocence, and this error of judgment caused the grave miscarriage of justice. In hindsight, Deskovic was incarcerated half his life due to a false-positive error in a polygraph exam. In a surprising twist, DiFiore acknowledged that the tactics used by the police were in fact lawful. They are allowed to seek polygraph exams (suspects may refuse) and to elicit confessions, even by citing false evidence, such as a fictitious failed polygraph result. According to Saul Kassin, a leading forensic psychologist, such investigative methods frequently produce false confessions. Up to a quarter of the convicts exonerated by the Innocence Project had admitted to crimes they did not commit, and like Jeffrey Deskovic, many had done so during polygraphs. One might think normal people do not make false confessions. But important research by Kassin and other psychologists has refuted this sensible assumption. Kassin has said pointedly that it is innocence itself that puts innocent people at risk. The statistics show that innocent people are more likely to waive the rights designed to protect them, such as the right to silence and to counsel, and they are more likely to agree to polygraphs, house searches, and other discretionary actions. Their desire to cooperate is fueled by another “confession myth” identified by Kassin, the incorrect belief that prosecutors, judges, or jurors will know a false confession in light of other evidence (or lack thereof). Sadly, confession evidence can be overpowering. Kassin reported that in his experiments with mock juries, even when the jurors stated that they fully discounted the confession as unreliable, the conviction rates of these cases were still significantly above those of the same cases presented without the confession evidence. Furthermore, this result held even when the jurors were specifically instructed to disregard the confession. Kassin’s number one confession myth is the misconception that trained interviewers can detect truth and deception, a direct challenge to polygraph supporters. He cited studies from around the world that have consistently found that the self-anointed experts, such as police interrogators, judges, psychiatrists, customs inspectors, and the like, do no better at discerning lies than untrained eyes. More alarmingly, there is emerging evidence that professional training in interrogation techniques does not affect accuracy but merely bolsters self-confidence—a misguided conviction, if not a delusion. The Deskovic tragedy was a case in point. Everything other than his confession was either exculpatory or erroneous. The original scientific and forensic evidence, not just the DNA test, exonerated Deskovic but was explained away by speculative theories and then ignored by the jury. For instance, the prosecution claimed that the hair samples, which were not linked to Deskovic, could have come from the medical examiner and his assistant, and the jury accepted that explanation without proof. When Deskovic maintained his innocence through the sentencing phase and beyond, asserting that he “didn’t do anything,” the jury chose to believe his earlier, unrecorded confession. The NYPD profile, which purportedly fit Deskovic almost perfectly, missed the mark on all fronts: the real perpetrator, Cunningham, was black, not white or Hispanic; his age was almost thirty, not under nineteen or twenty-five; and he was a complete stranger to the victim, not somebody she knew. The psychologists worry that we are only seeing the tip of the iceberg of wrongful convictions. Statisticians elaborate: when we deploy polygraphs for screening, like those in the PCASS project, there will be hundreds, or even thousands, of false positives for every major security threat correctly identified . Some, perhaps most, of these will lead to false confessions and wrongful convictions. ~###~ In calibrating the computer algorithm of PCASS, the army requested that Greens (those judged to be truthful) be minimized and Reds (deceptive) be favored against Yellows (inconclusive). Accordingly, the Johns Hopkins researchers set the passing rate—that is, the percentage of Greens—at less than 50 percent. This situation is as if the anti-doping agency set the hematocrit threshold at 46 percent, thus disqualifying half of the clean athletes while ensuring that all dopers are caught. The way PCASS is calibrated tells us that army leaders are worried sick about the false negative. They are reluctant to pass any job applicant unless they can be sure the person has not lied. This policy is entirely consistent with the prevalent belief that even one undetected insurgent could prove devastating. After all, some terrorist strikes, like the anthrax attacks of 2001, can be perpetrated by a criminal acting alone, as far as we know. By focusing its energy on making sure no potential insurgent goes unnoticed, the army is certain to have made loads of false-positive errors. Stemming from the unavoidable trade-off between the two errors, this result is clear unless one believes that the majority of the applicant pool (those judged to be Reds) could consist of insurgents. The sway of the asymmetric works in reverse relative to the case of steroid testing: here, the false-negative error can become highly toxic and highly public, while false-positive mistakes are well hidden and may come to light only through the painstaking work of activists like the Innocence Project. ~###~ The asymmetric costs associated with national-security screening sways examiners toward condoning false positives while minimizing false negatives, which has profound consequences for all citizens. It took Jeffrey Deskovic sixteen years of perseverance, plus a pinch of good luck with the new district attorney, to expose the grave false-positive error. In several recent high-profile cases of alleged espionage, the suspects, such as the Chinese-American scientist Dr. Wen Ho Lee, reportedly flunked polygraph exams but were ultimately cleared of spying, winning multimillion-dollar settlements for their troubles. These false alarms not only cost investigators time and money in chasing dead-end leads but also tarnished the reputations and destroyed the careers of the victims and frequently also their associates. Statistical analysis confirms that many more Deskovics, perhaps hundreds or thousands a year, are out there, most likely hapless. Even if we trust the accuracy level claimed by the Johns Hopkins researchers, we can conclude that for every true insurgent caught by PCASS, 93 regular folks would be falsely classified as deceptive, their apparent “crime” being at the wrong place at the wrong time (see Figure 4-2 ). The statistics largely mirror those of the earlier Situation A, in which even a tiny false-positive rate will be magnified by the presence of a large number of regular folks within the applicant pool (9,990 out of 10,000 in our example). The portable lie detector exacts a high cost for catching the 8 or 9 insurgents, with almost 800 innocents mistaken as deceptive. Figure 4-2 How PCASS Produces 100 False Alarms for Every Insurgent Caught This ominous cost-to-benefit ratio ought to frighten us in four ways. First, it embodies a morbid calculus in which a crowd of almost 100 gets rounded up in response to 1 person’s infraction, invoking unwelcome memories of the collective-accountability system. Second, among the Reds, there is no way of separating the 8 or 9 truly deceptive from the 800 falsely accused. Third, it makes a mockery of a “screening” device when it passes only about half of the subjects (4,995 out of 10,000) while calling most of the rest “inconclusive”; since we expect only 10 insurgents in the applicant pool, almost all of these Yellows are in fact harmless people. Fourth, there is still the unfinished business of the 1 insurgent incorrectly given the green or yellow light while almost 800 innocents see “red” haphazardly. Add to these problems the overstated accuracy level and the possibility of countermeasures, and we have one highly suspect technology. How many innocent lives should we ruin in the name of national security? This was the question Professor Fienberg raised when he warned against PCASS and other lie detection techniques. “It may be harmless if television fails to discriminate between science and science fiction, but it is dangerous when government does not know the difference.” ~###~ Truth be told, detection systems are far from perfect. Steroid testing suffers from a bout of false-negative errors, so drug cheats like Marion Jones and many others can hide behind strings of negatives. It is one thing to look for known molecular structures inside test tubes; it is quite another thing to vet the words of suspected liars. As Jose Canseco realized, the polygraph is one of few instruments our society trusts in these situations. However, statisticians say lie detectors produce excessive false-positive errors that result in false accusations, coerced confessions, dead-end leads, or ruined lives; the cruel fate visited upon Jeffrey Deskovic and undoubtedly numerous others serves to warn us against such excesses. Worse, the accuracy of detection systems slips markedly when the targets to be detected occur rarely or are measured indirectly; this explains why preemployment screening for potential security threats is harder than screening for past security violations through indirect physiological measures, which is harder than detecting a specific steroid molecule. In the meantime, the public discourse is focused on other matters. In steroid testing, we keep hearing about the false-positive problem—how star athletes are being hunted by supercilious testers. In national security, we fear the false negative—how the one terrorist could sneak past the screening. As a result, the powers that be have decided that falsely accusing athletes and failing to detect terrorists are more expensive than undetected drug cheats and wrongful convictions. Statisticians tell us to evaluate both types of errors at the same time, because they are interconnected through an unavoidable trade-off. In practice, the two errors often carry asymmetric costs, and in calibrating detection systems, decision makers, knowingly or not, will be swayed by the error that is public and toxic. For drug tests, this is the false positive, and for polygraphs, it is the false negative. But the trade-off ensures that any effort to minimize this error will aggravate the other; and because the other error is less visible, its deterioration is usually unnoticed. Short of a technological breakthrough that dramatically improves the overall accuracy of polygraphs, it is not possible to reduce false positives and false negatives simultaneously, leaving us with an unacceptable, unpleasant trade-off. This trade-off is as true in PCASS as in other large-scale screening initiatives, including various data-mining constructs rumored to have sprouted in the “War on Terror.” After September 11, 2001, a vast new market opened up for data-mining software, previously purchased primarily by large businesses. It is generally accepted that the terrorist attacks could have been prevented if our intelligence agencies had only “connected the dots” “in time.” Thus, by building gigantic databases that keep tabs on everyone—storing all phone calls, e-mails, websites visited, bank transactions, tax records, and so on—and by unleashing search agents, spiders, bots, and other exotically named software species to sift through the data at lightning speeds—shaking out patterns and tendencies—our government can uncover plots before the terrorists strike. These secretive, expansive programs go by creative monikers such as TIA (Total Information Awareness; later renamed Terrorism Information Awareness), ADVISE (that’s Analysis, Dissemination, Visualization, Insight, and Semantic Enhancement), and Talon (apparently not an acronym). A celebratory confidence pervades the data-mining community as they make bold promises, as in the following example from Craig Norris, CEO of Attensity, a Palo Alto, California–based start-up that counts the National Security Agency and Department of Home-land Security as customers: “You don’t even have to know what it is you’re searching for. But you’ll know it once you find it. If a terrorist is planning a bombing, they might say, ‘Let’s have a barbecue.’ The software can detect if the word barbecue is being used more often than usual.” If only real life were so perfect. Using data-mining software to find terrorist plots is comparable to using polygraphs for preemployment screening in that we collect information about past or current behavior in order to predict future misconduct. In either case, reliance on indirect evidence and the sway of false negatives relative to false positives tend to produce lots of false alarms. Moreover, both applications involve prediction of rare events, and terrorist plots are even rarer than spies! Rarity is measured by how many relevant objects (say, spies) exist among the total pool of objects (say, employees). As every detail of our daily lives is sucked into those gigantic databases, the number of objects examined swells at a breakneck pace, while the number of known terrorist plots does not. Therefore, relevant objects become rarer and harder to find. If data-mining systems perform as accurately as polygraphs, they will drown under the weight of false positives in less time than it takes to sink PCASS. Security expert Bruce Schneier has looked at data-mining systems the same way we evaluated steroid tests and polygraphs: “We’ll assume the [data-mining] system has a one in 100 false-positive rate . . . and a one in 1,000 false-negative rate. Assume one trillion possible indicators to sift through: that’s about 10 events—emails, phone calls, purchases, web destinations, whatever—per person in the United States per day. Also assume that 10 of them are actually terrorists plotting. This unrealistically accurate system will generate one billion false alarms for every real terrorist plot it uncovers. Every day of every year, the police will have to investigate 27 million potential plots in order to find the one real terrorist plot per month. Raise that false-positive accuracy to an absurd 99.9999 percent and you’re still chasing 2,750 false alarms per day but that will inevitably raise your false negatives, and you’re going to miss some of those 10 real plots.” But a realistic data-mining system does not surpass the accuracy level of polygraphs, so Schneier’s numbers (diagrammed in Figure 4-3 ) are wildly optimistic, as he admonished. Statisticians who perform the type of exploratory analysis Norris described, in which the computer discovers you-know-it-once-you-see-it patterns, know such findings are only approximate. To appropriate Norris’s example, if no prior terrorist has ever used barbecue as a code word, no data-mining system will tag it as suspicious. If there were such a prescient system, it would throw off millions of false alarms ( picnic, umbrella, beach, sneakers , etc.). We would then have to inaugurate a new class of crime, excessive communal verbal redundancy, to describe the dangerous state of repeating a word or a phrase too many times on one’s own or within one’s social network. Figure 4-3 How Data-Mining Technologies Produce Billions of False Alarms Expecting intelligence agencies to “connect the dots” is a pipe dream. Which dots mattered revealed themselves only after 9/11. The idea that we knew the dots and only needed someone to join them was classic 20/20 hindsight. Imagine: if trains rather than planes had been involved, we would now be fidgeting about other dots! The endless drumbeat about the miracle of data-mining systems tells us we have drawn the wrong lessons from 9/11. Sure, the tragedy made tangible the unimaginable cost of a false-negative mistake, of failing to identify potential terrorists. But too much fear of false negatives has inevitably resulted in too many false positives. It therefore makes statistical sense that few Guantanamo inmates have been convicted and many detainees were declared innocent or released without charge. When marketers use data mining to guess which customers will respond positively to sale offers, false positives may cause selected customers to receive junk mail; when banks use data mining to guess which credit card transactions may be fraudulent, false positives may cost honest customers time to call and verify blocked charges. These are inconveniences when compared with the psychological trauma and shattered lives that could stem from a charge of “excessive communal verbal redundancy.” Apart from false imprisonment and loss of civil liberties, we must also consider how demoralizing, how expensive, and how counterproductive it is for our intelligence agents to be chasing down millions of bad leads. What we should have learned from 9/11 is that terrorist plots are extremely rare events. Existing detection technologies are not accurate enough to qualify for the job; we know polygraphs can’t do it, and large-scale data-mining systems perform even worse. The unacceptable trade-off remains just as unacceptable. The Magic Lasso is still elusive. We need something much, much better.",
        "char_count": 75885
      },
      {
        "heading": "Chapter 8",
        "text": "5 Jet Crashes / Jackpots The Power of Being Impossible The safest part of your journey is over. Now drive home safely. —A NONYMOUS PILOT 1,000,000,000,000,000,000,000,000,000,000, 000,000,000,000,000,000 —A QUINDECILLION On August 24, 2001, a store clerk in Ontario, Canada, claimed a CDN$250,000 prize in the Encore lottery. On October 31, 1999, a Boeing 767 jetliner plunged into the Atlantic Ocean off Nantucket Island, Massachusetts, leaving no survivors. On the surface, these two events—winning a fortune and losing everything—had nothing to do with each other. Except when one considers how improbable either of these events was. Statisticians who keep score tell us that the odds of winning the Encore lottery are one in ten million, roughly comparable to the odds of dying in a plane crash. At these long odds, practically none of us will live long enough to win the Encore lottery or to perish in a plane crash. Yet about 50 percent of Americans play the state lotteries, and at least 30 percent fear flying. Our belief in miracles underlies both these attitudes: even if rare events do not happen often, when they do happen, they will happen to us. If someone’s ticket is going to win the million-dollar jackpot, it will be ours, so we gamble. If a plane is going to vanish in the Atlantic, it will be the one taking us, so we avoid flying. By contrast, statisticians typically take the contrary view: they write off the chance of jackpots and are not worried about jet crashes. Why would they expose themselves to the risk of death but exclude themselves from the dream of riches? Can they be serious? ~###~ It was almost 2:00 A.M ., on October 31, 1999—the Sunday morning of a Halloween weekend, long after the residents of the pristine Nantucket Island had waved off their reveling friends on an unseasonably cool night. Stuart Flegg, a carpenter who had moved to a southeastern cliff of Nantucket eleven years before, was lounging in his backyard with buddies and beers, under the stars. Without warning, an orange fireball growled in the night sky and then faded quietly into the darkness. Stuart rubbed his eyes, as if to check his state of mind, and poked his friend on the back, pointing in the direction of the flash. It was unlike anything he had ever seen. Stuart and his friends prattled on for a bit, and then they let the thread drop. Word seemed to come out of nowhere and creep through the neighborhood like wild vines. A few minutes before, from thirty-three thousand feet above sea level, a Boeing 767 jet had cut out a sixty-six-degree angle as it split and nose-dove, scattering 217 souls in the azure Atlantic waters. The horrified passengers on board EgyptAir Flight 990 had endured a precipitous fall at four hundred feet per second, followed by an abrupt surge up eight thousand feet, only to tumble again, this time in finality. Many more details would trickle out over the coming months and years. At this time and place, to those witnesses, to the relatives of the perished, and their friends and neighbors, the impact was head-on and devastating. Recognition of the disaster quickly gave way to disbelief, then to scant hope; soon information brought about acceptance of the tragic and an outpouring of sadness. With little delay, curiosity set in as well, in the form of loving concern: Do I know anyone scheduled to fly tonight? From Boston Logan? On EgyptAir? Heading to Cairo? A single no brought relief, while four yeses brought fear, denial, and busy fingers on a cell phone. For most, the fear of losing a loved one would come and go, though uncertainty would linger, now in the form of foresight: Better to cancel business trips and vacations for the near future. Better to travel on land than by air. Better to shun those dangerous foreign airlines. Better to avoid Logan, or night flights, or layovers in JFK. Never again save a penny. ~###~ Ninety miles away in Boston, the newsrooms buzzed to life. By midmorning, CBS, NBC, Fox, ABC, CNN, MSNBC, and Fox News had all swapped out their regular programming to carry continuous coverage of The Crash. Few businesses thrive on the morbid as much as the media, particularly on sleepy weekends bereft of ready-made headlines. Journalists on the disaster beat knew this was their time to shine. For the next week, if not the entire month, their reports would land on the front page and stay in the public’s conscience. The extent of the media coverage is reflected in the statistics of New York Times front-page stories: researchers found 138 articles for every 1,000 plane crash deaths, but only 2 articles for every 1,000 homicides, and only 0.02 article for every 1,000 cancer deaths. The Sunday of the crash, the front pages of newspapers big and small announced the air disaster with absolute solemnity. Sorting through the headlines, one might recognize the five prototypal disaster beat stories: the tragedy narrative about the available facts of the case; the human interest story singling out one unfortunate victim; the feel-good story about communities pulling together to cope with the disaster; the detective report citing analyses from all angles, from engineers, insurers, passersby, psychologists, and even psychics; and the big-picture synthesis, courtesy of the editors. The editorial piece has a predictable structure, frequently referencing a list of recent air tragedies, compiled in a table similar to this one: Corridor of Conspiracy Presented with such a table, we look for patterns of occurrence. Seek and ye shall find —that is a law of statistics. It doesn’t take a genius, or a news editor, to notice that between 1996 and 1999, a succession of jets plunged into the Atlantic near Nantucket: TWA, Swissair, EgyptAir, and John F. Kennedy Jr.’s private plane. Speaking to an Associated Press reporter, a local diving instructor lamented, “Nantucket is like the Bermuda Triangle of the Northeast.” He was not the only one making that connection. Many reporters also connected the dots, so to speak. Rounding out the piece, the editors would cite the latest polls confirming the heightened level of worry about air travel. Then they would advise readers to remain calm, reminding them that experts still consider flying to be safe relative to other forms of transportation. The editorial stance on the EgyptAir disaster was predictable, and so was the lukewarm reaction to its call for calm. It is common during such times that emotions clash against logic, superstition against science, faith against reason. Hovering in the air was the obvious question: what had caused EgyptAir 990 to crash? The journalists were running at full tilt, consulting any and all experts, whose theories more often than not conflicted with each other. No chain of logic was denied, as one report after another flooded the news. The more information provided to the public, the greater confusion it caused, and the more speculation it created. Starting with the rational explanations, such as equipment failure or atmospheric anomaly, suspicion shifted to the sinister, such as terrorist attack or drunken pilot, and then to the bizarre, like electromagnetic interference, missile attack, or pilot suicide. Finally, logical reasoning gave way to raw emotion. Unable to point the finger at a specific airline, airport, jet manufacturer, or day of the week, the public turned its back on the concept of flying altogether. Many travelers canceled or postponed their planned trips, while others opted to jump into their cars instead. Fully half the people polled by Newsweek after the EgyptAir crash said they experienced fear when flying, and about the same proportion indicated they would avoid airlines from Egypt and other Middle Eastern countries. Wary of its stigma, the airline quietly retired the flight’s number. This fog of emotions would not clear for a few years, which is how long it takes for official air traffic accident investigations to conclude. Taking a self-imposed moratorium on air travel is not much different from performing the rain dance to fight off a severe drought or beating drums to scare off locusts. When reason is exhausted, emotions fill up the void. But experience should teach us that logical reasoning bears the best hope, even in the face of inexplicable calamity. During the locust outbreak of 2004, African leaders convened and resolved to employ drums—the kind that hold pesticide. At this point, you may be expecting a gotcha about misunderstanding relative risk, but we will not go there. If a lot of people come to the same conclusion about something, there must be a certain logic behind it. Interviews with people who said they would stop flying after hearing about a major crash showed that their anxiety was deeply felt. They understood that plane crashes were exceptionally rare; after all, only a handful of fatal accidents hit the developed world during the 1990s. But people feared that these accidents were more likely to occur on their flights than on others. They were asking, if air crashes were random, what could explain the unlikely coincidence of four fatal accidents in four years occurring in the same air space? They felt sure the morbid record was a conspiracy of the unknown: though nobody had yet identified the culprit, they knew something must have caused the crash. They thought the pattern was too tidy to have been the dirty work of random chance. In 1999, many were blaming the “Bermuda Triangle” over Nantucket. While such allegations sound outlandish, the line of reasoning behind them reflects sound statistical thinking. Based on the pattern of occurrence, these folks rejected the idea that air crashes happened at random; instead, they believed in some sort of predetermination (Bermuda Triangle, equipment failure, drunken pilot, and the like). Statisticians call this logic “statistical testing,” and we use it all the time, often without knowing. If that is so, then why do the experts get so worked up over people’s fears after any plane crash? In 2001, Professor Arnold Barnett, the nation’s foremost airline safety expert, dared to ask rhetorically, “Is aviation safety . . . a problem that has been essentially solved [in the First World], to the extent that talking about it might suggest a personality disorder?” In even starker terms, Professor Barry Glassner, a psychologist who wrote The Culture of Fear , reckoned that the hysteria after a plane crash is as deadly as the crash itself because people who abandon their flight plans face a greater risk of dying—from road accidents. Why did these experts look at the same list of fatalities but come to the opposite conclusion? How could they explain the coincidence of four crashes in four years in the same general area? More importantly, how could they continue to trust foreign airlines? ~###~ On August 24, 2001, the Ontario Lottery and Gaming Corporation (OLG) awarded a CDN$250,000 check to Phyllis and Scott LaPlante, lucky winners of the Encore lottery on July 13, 2001. Each CDN$1 Encore ticket bought a chance to win CDN$250,000 if all six digits matched. With the odds of winning listed as one in ten million, someone who spends CDN$1 on Encore every day can expect to win once every twenty-seven thousand years, which rounds to about . . . never. Barnett, the air safety expert, has estimated that the chance of dying from a plane crash on a U.S. domestic nonstop flight is also one in ten million. Someone who takes one such flight every day would live twenty-seven thousand years before encountering a fatal crash. Thus, either event has about the same microscopic chance of happening. What made Phyllis LaPlante’s case special was her insider status: she and her husband owned Coby Milk and Variety, a small store in Coboconk, Ontario, which sold, among other things, lottery tickets. When she scanned the winning ticket, the machine chimed twice, announcing a major win. As her prize money exceeded CDN$50,000, it triggered an “insider win” investigation. Tracing the trail of tickets, the OLG staff cleverly deduced that the winner stuck to a regular set of numbers (9 4 2 9 8 1) in every lottery. So they asked for some old tickets, and the LaPlantes duly provided a few. The numbers matched. What had actually taken place was that Phyllis LaPlante had just robbed an eighty-two-year-old man of a quarter of a million dollars. It took a statistician to prove the case decisively—using the logic of statistical testing—and determine if LaPlante was simply lucky or mighty crafty. In addressing this question, Jeffrey Rosenthal at the University of Toronto examined seven years of draws and winners of Ontario jackpots. Between 1999 and 2005, there were 5,713 “major” winners of prizes valued at CDN$50,000 or more. Rosenthal estimated that store owners and employees accounted for about CDN$22 million of the CDN$2.2 billion spent on Ontario lotteries during this period—that is to say, about CDN$1 out of every CDN$100 the OLG received. He reasoned that if store owners and employees were no luckier than everyone else, they would have won 1 out of every 100 major prizes, meaning about 57 of the 5,713 wins. But as shown in Figure 5-1 , by the time Rosenthal completed his count, store insiders had actually struck gold more than 200 times! Either we had to believe that LaPlante and other store owners were blessed with extraordinary luck, or we might suspect foul play. Rosenthal was convinced of the latter. “The fifth estate,” a television program of the Canadian Broadcasting Corporation (CBC), broke the scandal on October 25, 2006, when it told the story of Bob Edmonds, the eighty-two-year-old senior citizen and bona fide winner of that Encore lottery. The winning numbers were a combination of birthdays: his own, his wife’s, and his son’s. The CBC hired Rosenthal to be the expert witness. He announced that the odds of lottery store insiders taking 200 of the OLG’s 5,713 major prizes by luck alone were one in a quindecillion. (That’s the number 1 followed by forty-eight zeros.) No reasonable person could believe in such luck. On the strength of Rosenthal’s statistical analysis, the sorry story expanded beyond Phyllis LaPlante; up to 140 store insider wins now appeared highly dubious, and complaints deluged the OLG. Figure 5-1 Expected Wins Versus Actual Wins by Retailer Insiders, 1999–2005: Evidence of Foul Play You may be wondering just how the LaPlantes produced those old lottery tickets matching Edmonds’s regular numbers. It was an old-fashioned con game, preying on a genial old man. When Bob Edmonds handed his ticket to the clerk on his lucky day, the scanning machine buzzed twice, indicating a big win. Distrusting his own ears, Edmonds instead believed LaPlante when she told him he had won the lesser prize of a free ticket. When LaPlante reported her “win” to OLG, she was clued in about the automatic insider-win investigation. The next day, her husband called Edmonds to the store, and they peppered him with questions. They learned that the winning numbers were his regular numbers and even obtained some of Edmonds’s old losing tickets. Edmonds probably did not think expired, losing tickets would be valuable to anyone. He thought he was friends with the clerks at the corner store, but he was wrong. In an interview, he even suggested LaPlante might have been coming on to him that day! He was definitely wrong there. He realized his mistakes when the local newspaper reported that the LaPlantes were lucky winners of the Encore lottery, and he immediately filed a complaint with OLG, which eventually led to the CBC’s investigation. The story had a happy ending, though. The investigation by “the fifth estate” unleashed a maelstrom of controversy. Ontario’s premier, Dalton McGuinty, was particularly alarmed because in Canada, proceeds from lotteries support the provincial budgets. In Ontario, this sum amounted to CDN$650 million in 2003–2004. About CDN$30 out of every CDN$100 spent on lotteries makes its way to the government coffers (while only CDN$54 out of every CDN$100 is paid out in prize money, ensuring that on average, the house always wins handily). A collapse in public trust in these lotteries could seriously affect Ontario’s health care, education, and infrastructure. Therefore, McGuinty directed the provincial ombudsman to investigate the OLG’s handling of complaints from customers. Put on the defensive, the OLG belatedly apologized to and recompensed Edmonds, released him from a prior gag order, and announced tighter regulations on insider players. The LaPlantes were sued for fraud but settled out of court after surrendering CDN$150,000 to Edmonds. ~###~ Upon analyzing the lottery win data, Rosenthal uncovered an unusual pattern of wins by retail store insiders, much too unusual to have been produced by chance. With similar logic, some people stopped flying after the EgyptAir crash because to them, four crashes in four years seemed like an unusual pattern of disasters in the same region—too many to have happened completely at random. Did such behavior constitute a “personality disorder”? The facts on the ground were immutable: the four flights, the location, the accident times, and the number of casualties were there for all to see. Many rejected random chance as an explanation for the pattern of crashes. Yet, to Professor Barnett, four in four looked just like the work of chance. He even used the same tool of statistical testing but arrived at a different conclusion. The difference lay in how he assimilated the data. Statisticians are a curious lot: when given a vertical set of numbers, they like to look sideways. They look into the nooks and crannies; they look underneath the cracks; they turn over every pebble. From decades of experience, they learn that what is hidden is just as important as what is in front of their eyes. No one ever gets to see the whole picture, so the key is to know what you don’t know . When you read the table of fatalities presented earlier, you may have visualized four black dots over the “Nantucket Triangle” and connected the dots; Barnett, by contrast, saw four black dots plus millions of white dots. Each white dot stood for one flight that safely traversed the air space during those four years. Seen in this light, we would hardly find the black dots, let alone connect them. Then, taking it further, Barnett envisioned ten, even twenty, years of flights over the Nantucket Triangle, bringing millions more white dots into the picture, and only dozens of additional black dots. This method creates a new picture, one altogether different from the list of worst disasters frequently displayed in postcrash news reports. Listed separately, the four accidents stuck out like stars in the night sky; however, they became all but invisible when buried within a sea of whiteness (see Figure 5-2 ). Considering that the Northeast Corridor is one of the busiest airways in the world, it would follow that this area would see a larger number of fatal accidents. As to whether fear of flying could be considered a “personality disorder,” one esteemed statistician answered firmly in the negative during a lecture to an audience at Boeing. He suggested that as the airline industry has fended off systematic causes of jet crashes such as equipment failure, new types of risks are rising to the surface. He cited three “menaces that caused scant fatalities in the 1990s but which could cause more deaths in forthcoming years”: sabotage, runway collisions, and midair collisions. The lecture, titled “Airline Safety: End of a Golden Age?” could not have been more aptly timed; it was delivered on September 11, 2001. The future he had anticipated arrived early. Figure 5-2 The Statistician’s Worldview Who was this professor with such impressive foresight? None other than Arnold Barnett, who has been studying airline safety data for more than thirty years at the MIT Sloan School of Management. In the 1970s, he initiated a remarkably productive research program that has continuously tracked the safety record of airlines worldwide. Before he arrived on the scene, people considered it impossible to measure airline safety accurately, because the contributing factors could not be directly observed. How could one appraise the attitudes of corporate managers toward safety? How could one compare the efficacy of different training programs? How could one take into account disparate flight routes, airports, flight lengths, and age of airlines? Barnett the statistician made an end run around these obstacles, realizing he did not need any of those unknowns. When a passenger boards a plane, his or her fear is solely of dying in a fatal crash; it is thus sufficient to merely track the frequency of fatal accidents and the subsequent survival rates. Similarly, universities rely on SAT scores and school ranks to evaluate applicants because they cannot possibly visit every family, every home, and every school. How to compare Mary’s parents to Julia’s? How to rank Michael’s gymnasium against Joseph’s? So, instead of measuring such specific influences on student achievement as parental upbringing and quality of education, educators merely track the actual scholastic ability as represented by SAT scores and school ranks. Under Barnett’s watch, airlines in the developed world saw the risk of death drop from 1 in 700,000 in the 1960s to 1 in 10 million in the 1990s, a fourteen-fold improvement in three decades. He was the first to prove that American carriers were the safest in the world, and by 1990, he was telling everyone about a golden age of air safety. The rest of the developed world has since caught up, while the developing world still lags by two decades. Barnett believes that fatal air crashes have essentially become random events with a minuscule strike rate. In other words, it is no longer possible to find any systematic cause of an air disaster, like mechanical failure or turbulence. Air crashes today are practically freak accidents. What does the visionary Barnett say about two of our biggest fears? 1. Don’t choose between U.S. national airlines based on safety. Jet crashes occur randomly, so the carrier that suffers a recent crash would have been merely unlucky. Between 1987 and 1996, USAir happened to be the unlucky airline. It operated 20 percent of domestic flights but accounted for 50 percent of all crash fatalities, by far the worst record among the seven major airlines in the United States (see Figure 5-3 ). Barnett asked what the chance was that such a lopsided allocation of deaths could have hit any one of the seven carriers. The chance was 11 percent; it was quite likely to happen, and if not USAir, another airline would have borne the brunt. In another study, Barnett found that no U.S. airline has sustained an advantage in safety: the top-ranked airline in one period frequently came in last in the next period, giving further proof that all operators were materially equal in safety. It is just not possible to predict which airline will suffer the next fatal crash. Passengers have nowhere to run for air safety. Figure 5-3 Relative Proportion of Flights and Deaths for USAir and Six Other U.S. Carriers, 1987–1996: Evidence That USAir Was Less Safe? 2. Don’t avoid foreign airlines, even after one of their planes has crashed. Flights operated by developing-world airlines are just as safe as those run by U.S. airlines on routes where they directly compete with one another, typically those between the developed and developing worlds. Where they do not overlap, foreign airlines suffer many more crashes, for unknown reasons. (Some speculate that they may be assigning better crews to international flights.) Because of their poor domestic record, the overall risk of death associated with developing-world carriers was eight times worse than for their developed-world peers. But Barnett found no difference between these two groups of operators on competing routes: the risk was about 1 in 1.5 million during 2000–2005. The once-a-day frequent flier could expect to die in a jet crash in 4,100 years, on any of the operators that offer service on these routes. Moreover, while the worldwide risk of aviation fatality has been more than halved since the 1980s, the risk differential between developing-world and developed-world operators has stayed minute. Thus, we can trust these supposedly hulking, inefficient state enterprises with old planes, undertrained pilots, and unmotivated staff to take us overseas safely. Like Rosenthal, Barnett used statistical testing to prove his point. For the decade leading up to 1996, developing-world airlines operated 62 percent of competitive flights. If they were just as safe as U.S. airlines, they should have caused about 62 percent of passenger deaths, or well over 62 percent if they were more prone to disasters. In those ten years, developing-world carriers caused only 55 percent of the fatalities, indicating that they did no worse (see Figure 5-4 ). Figure 5-4 Relative Proportion of Flights and Deaths for Developed-World and Developing-World Carriers, 1987–1996: No Evidence That Developing-World Carriers Were Less Safe on Comparable Routes ~###~ The news about the Ontario lottery investigation spread all over Canada, and in every province, the lottery corporations were overrun by phone calls and e-mails from concerned citizens. British Columbia’s ombudsman, in reviewing past winners, unmasked dozens of extraordinarily lucky store owners, including one who took home CDN$300,000 over five years, winning eleven times. When the president of the British Columbia Lottery Corporation, which runs the province’s lottery, was fired, his buddy, himself a former president, came to his defense: “Of course, it’s possible retailers cheated players of their prize money, but only if you’re a fool.” In New Brunswick, the Atlantic Lottery Corporation, which runs lotteries in four provinces, attempted to reshape the publicity by hiring an external consultant to audit past wins using the same method as Rosenthal. The analysis, however, showed that between 2001 and 2006, store owners claimed 37 out of 1,293 prizes of CDN$25,000 or more, when they were expected to have won fewer than 4 of those. It was inconceivable that this group of players could have won so many prizes if each ticket had an equal chance of winning. Meanwhile, the CBC hired Rosenthal again, this time to examine the pattern of wins in the lotteries in the Western provinces from November 2003 to October 2006. The professor found that insiders earned sixty-seven wins of CDN$10,000 or more— twice as many as could be expected if the lotteries were fair to all players. Just how lucky were these insiders? Using statistical testing, Rosenthal further explained that the chance was 1 in 2.3 million that insiders could have racked up so many wins under a fair lottery system. While not as extreme as in Ontario, these odds were still negligible. Again, Rosenthal could hardly believe that the store owners were that much luckier than the rest of the ticket holders, so he suspected fraud. (Unlike in Ontario, neither the Atlantic nor the Western Lottery Corporation has been able to catch any individual cheater.) To restore the public’s confidence, the lottery authorities announced a series of measures to protect customers, including installation of self-service scanning machines, reconfiguration of monitors to face out to the customers, improvement in win-tracking technology, background checks for retailers, and the requirement of winners to sign the back of their winning tickets. It remains to be seen whether these policies will succeed at lifting the cloud of suspicion. ~###~ Both statisticians grappled with real-life data, noticed unusual patterns, and asked whether they could occur by chance. Rosenthal’s answer was an unequivocal no, and his result raised myriad doubts about insider wins in Ontario lotteries. Employing the same type of logic, Barnett alleviated our fear of flying by showing why air travelers have nowhere to run, because freak accidents can hit any unlucky carrier, anywhere. You may still be wondering why statisticians willingly accept the risk of death while they show little appetite for playing with chance. Why do they behave differently from most people? We know it is not the tools at their disposal that affect their behavior; we all use the same sort of statistical testing to weigh the situational evidence against chance, whether we realize it or not. The first difference lies in the way that statisticians perceive data: most people tend to hone in on unexpected patterns, but statisticians like to evaluate these against the background. For Barnett, the background is the complete flight schedule, not just a list of the worst disasters, while for Rosenthal, it includes all lottery players, not just retailers with major wins. Moreover, in the worldview of statisticians, rare is impossible: jackpots are for dreamers, and jet crashes for paranoids. For Rosenthal to believe that all retail store insiders acted with honor, he would have had to accept that an extremely rare event had taken place. That would require disavowing his statistical roots. Barnett keeps on flying, twice a week, as he believes air disasters are nigh extinct. Had he stopped out of fear at any point, he would have had to admit that an incredibly unlikely incident could occur. That, too, would contravene his statistical instinct. Rather than failing at risk assessment, as many have alleged, the people who avoid flying after air crashes also are reasoning like statisticians. Faced with a raft of recent fatal crashes, they rule out the possibility of chance. What leads them to draw different conclusions is the limited slice of data available to them. There are many everyday situations in which we run statistical tests without realizing it. The first time our bags get searched at the airport, we might rue our luck. If it happens twice, we might start to wonder about the odds of being picked again. Three or four times, and we might seriously doubt whether selection has been random at all. Rare is impossible. ~###~ At the request of two senators in 1996, the Federal Aviation Administration acted to close the information gap between the experts and the public by releasing limited air safety data on its website. How have we done since? Poorly, unfortunately. As of 2006, anyone can find black dots (the disasters) in those databases but not the white dots (the safe arrivals). Every incident from total loss to no damage is recorded with ample details, making it difficult to focus on the relevant events. Clearly, weak execution has run afoul of good intention. It is time we started turning over those pebbles! As the professors showed us, a few well-chosen numbers paint a far richer picture than hundreds of thousands of disorganized data.",
        "char_count": 30955
      },
      {
        "heading": "Chapter 9",
        "text": "Conclusion Statistical thinking is hard,” the Nobel prize winner Daniel Kahneman told a gathering of mathematicians in New York City in 2009. A revered figure in the world of behavioral economics, Professor Kahneman spoke about his renewed interest in this topic, which he first broached in the 1970s with his frequent collaborator Amos Tversky. The subject matter is not inherently difficult, but our brains are wired in such a way that it requires a conscious effort to switch away from the default mode of reasoning, which is not statistical. Psychologists found that when research subjects were properly trained, and if they recognized the statistical nature of the task at hand, they were much likelier to make the correct judgment. Statistical thinking is distinct from everyday thinking. It is a skill that is learned. What better way to master it than to look at positive examples of what others have accomplished. Although they rarely make the headlines, many applied scientists routinely use statistical thinking on the job. The stories in this book demonstrate how these practitioners make smart decisions and how their work benefits society. In concluding, I review the five aspects of statistical thinking: 1. The discontent of being averaged: Always ask about variability . 2. The virtue of being wrong: Pick useful over true . 3. The dilemma of being together: Compare like with like . 4. The sway of being asymmetric: Heed the give-and-take of two errors . 5. The power of being impossible: Don’t believe what is too rare to be true. Some technical language is introduced in these pages; it can be used as guideposts for those wanting to explore the domain of statistical thinking further. The interstitial sections called “Crossovers” take another look at the same stories, the second time around revealing another aspect of statistical thinking. The Discontent of Being Averaged Averages are like sleeping pills: they put you in a state of stupor, and if you overdose, they may kill you. That must have been how the investors in Bernie Madoff’s hedge fund felt in 2008, when they learned the ugly truth about the streak of stable monthly returns they’d been receiving up until then. In the dream world they took as real, each month was an average month; variability was conquered—nothing to worry about. Greed was the root cause of their financial ruin. Those who doubted the absence of variability in the reported returns could have saved themselves; instead, most placed blind faith in the average. The overuse of averages pervades our society. In the business world, the popular notion of an annualized growth metric, also called “compound annual growth rate,” is borne from erasing all year-to-year variations. A company that is expanding at 5 percent per year every year has the same annualized growth rate as one that is growing at 5 percent per year on average but operates in a volatile market so that the actual growth can range from 15 percent in one year to −10 percent in another. The financing requirements of these two businesses cannot be more different. While the compound annual growth rate provides a useful basic summary of the past, it conveys a false sense of stability when used to estimate the future. The statistical average simply carries no information about variability. Statistical thinking begins with noticing and understanding variability. What gets commuters upset? Not the average travel time to work, to which they can adjust. They complain about unexpected delays, occasioned by unpredictable accidents and weather emergencies. Such variability leads to uncertainty, which creates anxiety. Julie Cross, the Minnesota commuter in Chapter 1 , was surely not the only driver who found “picking the fastest route” to be “a daily gamble.” It is therefore no surprise that effective measures to control congestion attack the problem of variability. For Disney guests arriving during busy hours, FastPass lines eliminate the uncertainty of waiting time by spacing out spikes in demand. Similarly, metered ramps on highways regulate the inflow of traffic, promising commuters smoother trips once they enter. The Disney “Imagineers” and the highway engineers demonstrated impressive skills in putting theoretical science into practice. Their seminal achievements were in emphasizing the behavioral aspect of decision making. The Disney scientists learned to focus their attention on reducing perceived wait times, as distinct from actual wait times. In advocating perception management, they subordinated the well-established research program in queuing theory , a branch of applied mathematics that has produced a set of sophisticated tools for minimizing actual average wait times in queues. As with traditional economics, queuing theory makes an assumption about rational human behavior that does not match reality. For example, in putting up signs showing inflated estimates of waiting time, the Disney engineers counted on irrationality, and customer surveys consistently confirmed their judgment. For further exploration of the irrational mind, see the seminal work of Daniel Kahneman, starting with his 2003 overview article “Maps of Bounded Rationality: Psychology for Behavioral Economics” in American Economic Review , and Predictably Irrational by Dan Ariely. Political considerations often intrude on the work of applied scientists. For instance, Minnesota state senator Dick Day seized upon the highway congestion issue to score easy points with his constituents, some of whom blamed the ramp-metering policy for prolonging their commute times. A huge commotion ensued, at the end of which the highway engineers were vindicated. The Minnesota Department of Transportation and the senator agreed to a compromise solution, making small changes to how the meters were operated. For applied scientists, this episode conveyed the valuable lesson that the technical good (reducing actual travel time) need not agree with the social good (managing the public’s perception). Before the “meters shutoff” experiment, engineers doggedly pursued the goal of delaying the onset of congestion, which preserves the carrying capacity of highways and sustains traffic flow. The experiment verified the technical merit of this policy: the benefits of smoother traffic on the highway outweighed the drawback of waiting at on-ramps. Nevertheless, commuters disliked having to sit and stew at the ramps even more than they disliked the stop-and-go traffic on jam-packed highways. Statisticians run experiments to collect data in a systematic way to help make better decisions. In the Minnesota experiment, the consultants performed a form of pre–post analysis . They measured traffic flow, trip time, and other metrics at preselected sections of the highways before the experiment and again at its conclusion. Any difference between the pre- period and post- period was attributed to shutting off the ramp meters. But note that there is a hidden assumption of “all else being equal.” The analysts were at the mercy of what they did not, or could not, know: was all else really equal? For this reason, statisticians take absolute caution in interpreting pre–post studies, especially when opining on why the difference was observed during the experiment. The book Statistics for Experimenters by George Box, Stuart Hunter, and Bill Hunter is the classic reference for proper design and analysis of experiments. (The Minnesota experiment could have benefited from more sophisticated statistical expertise.) Crossovers Insurance is a smart way to exploit variability, in this case, the ebb and flow of claims filed by customers. If all policyholders required payout concurrently, their total losses would swallow the cumulative surplus collected from premiums, rendering insurers insolvent. By combining a large number of risks acting independently, actuaries can reliably predict average future losses and thus set annual premiums so as to avoid financial ruin. This classic theory works well for automotive insurance but applies poorly to catastrophe insurance, as Tampa businessman Bill Poe painfully discovered. For auto insurers, the level of total claims is relatively stable from year to year, even though individual claims are dispersed over time. By contrast, catastrophe insurance is a “negative black swan” business, to follow Nassim Taleb’s terminology. In Taleb’s view, business managers can be lulled into ignoring certain extremely unlikely events (“black swans”) just because of the remote chance of occurrence, even though the rare events have the ability to destroy their businesses. Hurricane insurers hum along merrily, racking up healthy profits, until the big one ravages the Atlantic coast, something that has little chance of happening but wreaks extreme damage when it does happen. A mega-hurricane could cause $100 billion in losses—fifty to a hundred times higher than the damage from the normal storm. The classic theory of insurance, which invokes the bell curve, breaks down at this point because of extreme variability and severe spatial concentration of this risk. When the black swan appears, a large portion of customers makes claims simultaneously, overwhelming insurers. These firms might still be solvent on average —meaning that over the long run, their premiums would cover all claims—but the moment cash balances turn negative, they implode. Indeed, catastrophe insurers who fail to plan for the variability of claims invariably find themselves watching in horror as one ill wind razes their entire surplus. Statisticians not only notice variability but also recognize its type. The more moderate type of variability forms the foundation of the automotive insurance business, while the extreme type threatens the hurricane insurers. This is why the government “take-out” policy, in which the state of Florida subsidizes entrepreneurs to take over policies from failed insurers, made no sense; the concentrated risks and thin capital bases of these start-up firms render them singularly vulnerable to extreme events. ~###~ Variability is the reason why a steroid test can never be perfectly accurate. When the International Cycling Union (UCI), the governing body for cycling, instituted the hematocrit test as a makeshift method for catching EPO dopers, it did not designate a positive finding as a doping violation; rather, it set a threshold of 50 percent as the legally permissible hematocrit level for participation in the sport. This decision reflected UCI’s desire to ameliorate the effect of any false-positive errors, at the expense of letting some dopers escape detection. If all normal men were to have red blood cells amounting to precisely 46 percent of their blood volume (and all dopers were to exceed 50 percent), then a perfect test can be devised, marking up all samples with hematocrit levels over 46 percent as positive, and those below 46 percent as negative. In reality, it is the proverbial “average male” who comes in at 46 percent; the “normal” hematocrit level for men varies from 42 to 50 percent. This variability complicates the tester’s job: someone with red cell density of, say, 52 percent can be a blood doper but can also be a “natural high,” such as a highlander who, by virtue of habitat, has a higher hematocrit level than normal. UCI has since instituted a proper urine test for EPO, the hormone abused by some endurance athletes to enhance the circulation of oxygen in their blood. Synthetic EPO, typically harvested from ovary cells of Chinese hamsters, is prescribed to treat anemia induced by kidney failure or cancer. (Researchers noted a portion of the annual sales of EPO could not be attributed to proper clinical use.) Because EPO is also naturally secreted by the kidneys, testers must distinguish between “natural highs” and “doping highs.” Utilizing a technique known as isoelectric focusing, the urine test establishes the acidity profiles of EPO and its synthetic version, which are known to be different. Samples with a basic area percentage (BAP), an inverse measure of acidity, exceeding 80 percent were declared positive, and these results were attributed to illegal doping (see Figure C-1 ). To minimize false-positive errors, timid testers set the threshold BAP to pass virtually all clean samples including “natural highs,” which had the effect of also passing some “doping highs.” This led Danish physician Rasmus Damsgaard to assert that many EPO-positive urine samples were idling in World Anti-Doping Agency (WADA) labs, their illicit contents undetected. If testers would lower the threshold, more dopers would get caught, but a few clean athletes would be falsely accused of doping. This trade-off is as undesirable as it is unavoidable. The inevitability stems from variability between urine samples: the wider the range of BAP, the harder it is to draw a line between natural and doping highs. Figure C-1 Drawing a Line Between Natural and Doping Highs Because the anti-doping laboratories face bad publicity for false positives (while false negatives are invisible unless the dopers confess), they calibrate the tests to minimize false accusations, which allows some athletes to get away with doping. The Virtue of Being Wrong The subject matter of statistics is variability, and statistical models are tools that examine why things vary. A disease outbreak model links causes to effects to tell us why some people fall ill while others do not; a credit-scoring model identifies correlated traits to describe which borrowers are likely to default on their loans and which will not. These two examples represent two valid modes of statistical modeling. George Box is justly celebrated for his remark “All models are false but some are useful.” The mark of great statisticians is their confidence in the face of fallibility. They recognize that no one can have a monopoly on the truth, which is unknowable as long as there is uncertainty in the world. But imperfect information does not intimidate them; they seek models that fit the available evidence more tightly than all alternatives. Box’s writings on his experiences in the industry have inspired generations of statisticians; to get a flavor of his engaging style, see the collection Improving Almost Anything , lovingly produced by his former students. More ink than necessary has been spilled on the dichotomy between correlation and causation. Asking for the umpteenth time whether correlation implies causation is pointless (we already know it does not). The question Can correlation be useful without causation? is much more worthy of exploration. Forgetting what the textbooks say, most practitioners believe the answer is quite often yes. In the case of credit scoring, correlation-based statistical models have been wildly successful even though they do not yield simple explanations for why one customer is a worse credit risk than another. The parallel development of this type of model by researchers in numerous fields, such as pattern recognition, machine learning, knowledge discovery, and data mining, also confirms its practical value. In explaining how credit scoring works, statisticians emphasize the similarity between traditional and modern methods; much of the criticism leveled at credit-scoring technology applies equally to credit officers who make underwriting decisions by handcrafted rules. Credit scores and rules of thumb both rely on information from credit reports, such as outstanding account balances and past payment behavior, and such materials contain inaccurate data independently of the method of analysis. Typically, any rule discovered by the computer is a rule the credit officer would also use if he or she knew about it. While the complaints from consumer advocates seem reasonable, no one has yet proposed alternatives that can overcome the problems common to both systems. Statisticians prefer the credit-scoring approach because computers are much more efficient than loan officers at generating scoring rules, the resulting rules are more complex and more precise, and they can be applied uniformly to all loan applicants, ensuring fairness. Industry leaders concur, pointing out that the advent of credit scoring precipitated an explosion in consumer credit, which boosted consumer spending, hoisting up the U.S. economy for decades. Consider this: since the 1970s, credit granted to American consumers has exploded by 1,200 percent, while the deep recession that began in 2008 has led to retrenchment at less than 10 percent a year. Statistical models do not relieve business managers of their responsibility to make prudent decisions. The credit-scoring algorithms make educated guesses on how likely each applicant will be to default on a loan but shed no light on how much risk an enterprise should shoulder. Two businesses with different appetites for risk will make different decisions, even if they use the same credit-scoring system. When correlation is not enough to be useful without causation, the stakes get dramatically higher. Disease detectives must set their sights on the source of contaminated foods, as it is irresponsible to order food recalls, which cripple industries, based solely on evidence of correlation. The bagged spinach case of 2006 revealed the sophistication required to solve such a riddle. The epidemiologists used state-of-the-art statistical tools like the case–control study and information-sharing networks; because they respect the limits of these methods, they solicited help from laboratory and field personnel as well. The case also demonstrated the formidable challenges of outbreak investigations: urgency mounted as more people reported sick, and key decisions had to be made under much uncertainty. In the bagged-spinach investigation, every piece of the puzzle fell neatly into place, allowing the complete causal path to be traced, from the infested farm to the infected stool. Investigators were incredibly lucky to capture the P227A lot code and discover the specific shift when the contamination had occurred. Many other investigations are less than perfect, and mistakes not uncommon. For example, a Taco Bell outbreak in November 2006 was initially linked to green onions but later blamed on iceberg lettuce. In 2008, when the Food and Drug Administration (FDA) claimed tomatoes had caused a nationwide salmonella outbreak, stores and restaurants immediately yanked tomatoes from their offerings, only to discover later that they had been victims of a false alarm. Good statisticians are not daunted by these occasional failures. They understand the virtue in being wrong, as no model can be perfect; they particularly savor those days when everything works out, when we wonder how they manage to squeeze so much out of so little in such a short time. Crossovers Disney fans who use Len Testa’s touring plans pack in an amazing number of attractions during their visits to Disney theme parks, about 70 percent more than the typical tourist; they also shave off three and a half hours of waiting time and are among the most gratified of Disney guests. In putting together these plans, Testa’s team took advantage of correlations. Most of us realize that many factors influence wait times at a theme park, such as weather, holiday, time of the day, day of the week, crowd level, popularity of the ride, and early-entry mornings. Similar to credit-scoring technology, Testa’s algorithm computed the relative importance of these factors. He told us that the popularity of rides and time of day matter the most (both rated 10), followed by crowd level (9), holiday (8), early-entry morning (5), day of week (2), and weather (1). Thus, in terms of total waiting time, there really was no such thing as an off-peak day or a bad-weather day. How did Testa know so much? Testa embraced what epidemiologists proudly called “shoe leather,” or a lot of walking. On any brilliant summer day in Orlando, Florida, Testa could be spotted among the jumpy 8:00 A.M . crowd at the gates of Walt Disney World, his ankles taped up and toes greased, psyched up for the rope drop. The entire day, he would be shuttling between rides. He would get neither in line nor on any ride; every half hour, upon finishing one loop, he would start over at the first ride. He would walk for nine hours, logging eighteen miles. To cover even more ground, he had a small staff take turns with different rides, all year round. In this way, they collected wait times at every ride every thirty minutes. Back at the office, the computers scanned for patterns. Testa’s model did not attempt to explain why certain times of the day were busier than others; it was enough to know which times to avoid. As interesting as it would be to know how each step of a touring plan decreased their wait times, Testa’s millions of fans care about only one thing: whether the plan let them visit more rides, enhancing the value of their entry tickets. The legion of satisfied readers is testimony to the usefulness of this correlational model. ~###~ Polygraphs rely strictly on correlations between the act of lying and certain physiological metrics. Are correlations useful without causation? In this case, statisticians say no. To avoid falsely imprisoning innocent people based solely on evidence of correlation, they insist that lie detection technology adopt causal modeling of the type practiced in epidemiology. They caution against logical overreach: Liars breathe faster. Adam’s breaths quickened. Therefore, Adam was a liar. Deception, or stress related to it, is only one of many possible causes for the increase in breathing rate, so variations in this or similar measures need not imply lying. As with epidemiologists studying spinach and E. coli , law enforcement officials must find corroborative evidence to strengthen their case, something rarely accomplished. A noteworthy finding of the 2002 NAS report was that scientific research into the causes of physiological changes associated with lying has not kept up with the spread of polygraphs. The distinguished review panel on the report underlined the need for coherent psychological theories that explain the connection between lying and various physiological measures. For the same reason, data-mining models for detecting terrorists are both false and useless. Data-mining models uncover patterns of correlation. Statisticians tell us that rounding up suspects based on these models will inevitably ensnare hundreds or thousands of innocent citizens. Linking cause to effect requires a much more sophisticated, multidisciplinary approach, one that emphasizes shoe leather, otherwise known as human intelligence gathering. The Dilemma of Being Together In 2007, the average college-bound senior scored 502 in the Critical Reading (verbal) section of the SAT. In addition, girls performed just as well as boys (502 and 504, respectively), so nothing was lost by reporting the overall average score, and a bit of simplicity was gained. The same could not be said of blacks and whites, however, as the average black student tallied 433, almost 100 points below the average white student’s score of 527. To aggregate or not to aggregate: that is the dilemma of being together. Should statisticians reveal several group averages or one overall average? The rule of thumb is to keep groups together if they are alike and to set them apart if they are dissimilar. In our example, after the hurricane disasters of 2004–2005, insurers in Florida reassessed the risk exposure of coastal residents, deciding that the difference relative to inland properties had widened so drastically that the insurers could no longer justify keeping both groups together in an undifferentiated risk pool. Doing so would have been wildly unfair to the inland residents. The issue of group differences is at the heart of the dilemma. When group differences exist, groups should be disaggregated. It is a small tragedy to have at our disposal ready-made groups to partition people into, such as racial groups, income groups, and geographical groups. This easy categorization conditions in us a cavalier attitude toward forming comparisons between blacks and whites, the rich and the poor, red and blue states, and so on. Statisticians tell us to examine such group differences carefully, as they frequently cover up nuances that break the general rule. For instance, the widely held notion that the rich vote Republican fell apart in a review of state-by-state data. Andrew Gelman, a statistician at Columbia University, found that this group difference in voting behavior surfaced in “poor” states like Mississippi but not in “rich” states like Connecticut. (See his fascinating book Red State, Blue State, Rich State, Poor State for more on this topic.) Similarly, the Golden Rule settlement failed because the procedure for screening out unfair test items lumped together students with divergent ability levels. The mix of ability levels among black students varied from that among whites, so this rule produced many false alarms, flagging questions as unfair even when they were not. Statisticians regard this as an instance of the famous Simpson’s paradox : the simultaneous and seemingly contradictory finding that no difference exists between high-ability blacks and high-ability whites; no difference exists between low-ability blacks and low-ability whites; and when both ability levels are combined, blacks fare significantly worse than whites. To our amazement, the act of aggregation manufactures an apparent racial gap! Here is what one would expect: since the group differences are zero for both high- and low-ability groups, the combined difference should also be zero. Here is the paradox: the statistics show that in aggregate, whites outperform blacks by 80 points (the bottom row of Figure C-2 ). However, the confusion dissipates upon realizing that white students typically enjoy better educational resources than blacks, a fact acknowledged by the education community, so the average score for whites is more heavily weighted toward the score for high-ability students, and the average for blacks toward the score for low-ability students. In resolving the paradox, statisticians compute an average for each ability level so as to compare like with like. Simpson’s paradox is a popular topic in statistics books, and it is a complicated concept at first glance. Figure C-2 Aggregation Creates a Difference: An Illustration of Simpson’s Paradox The recognition of Simpson’s paradox led to a breakthrough in fair testing. The procedure for differential item functioning (DIF) analysis, introduced in Chapter 3 , divides examinees into groups of like ability and then compares average correct rates within these groups. Benefiting from research by the Educational Testing Service (ETS) in the 1980s, DIF analysis has rapidly gained acceptance as the scientific standard. In practice, ETS uses five ability groups based on total test score. For the sake of simplicity, we only concerned ourselves with the case of two groups. The strategy of stratification (analyzing groups separately) is one way to create like groups for comparison. A superior alternative strategy is randomization , when feasible. Statisticians frequently assign test subjects randomly into one group or another; say, in a clinical trial, they will select at random some patients to be given placebos, and the remainder to receive the medicine under study. Because of random assignment, the groups will have similar characteristics: the mix of races will be the same, the mix of ages will be the same, and so on. In this way, “all else being equal” is assured when one group is chosen for special treatment. If the treatment has an effect, the researcher does not have to worry about other contributing factors. While statisticians prefer randomization to stratification, the former strategy is sometimes infeasible. For example, in DIF analysis, social norms would prevent one from exposing some students randomly to higher-quality schools and others to lower-quality schools. By contrast, the attempt by Florida insurers to disaggregate the hurricane risk pools has pushed the entire industry to the brink in the late 2000s. This consequence is hardly surprising if we recall the basic principle of insurance—that participants agree to cross-subsidize each other in times of need. When the high-risk coastal policies are split off and passed to take-out companies with modest capital bases, such as Poe Financial Group, or to Citizens Property Insurance Corporation, the state-run insurer of last resort, these entities must shoulder a severe concentration of exposure, putting their very survival into serious question. In 2006, Poe became insolvent after 40 percent of its customers bled a surplus of ten years dry in just two seasons. Crossovers By Arnold Barnett’s estimation, between 1987 and 1996, air carriers in the developing world sustained 74 percent of worldwide crash fatalities while operating only 18 percent of all flights (see Figure C-3 a). If all airlines were equally safe, we would expect the developing-world carriers to share around 18 percent of fatalities. To many of us, the message could not be clearer: U.S. travelers should stick to U.S. airlines. Yet Barnett contended that Americans gained nothing by “buying local,” because developing-world carriers were just as safe as those in the developed world. He looked at the same numbers as most of us but arrived at an opposite conclusion, one rooted in the statistics of group differences. Barnett discovered that the developing-world airlines had a much better safety record on “between-worlds” routes than on other routes. Thus, lumping together all routes created the wrong impression. Since domestic routes in most countries are dominated by home carriers, airlines compete with each other only on international routes; in other words, about the only time American travelers get to choose a developing-world carrier is when they are flying between the two worlds. Hence, only the between-worlds routes are relevant. On these relevant routes, over the same period, developing-world carriers suffered 55 percent of the fatalities while making 62 percent of the flights (see Figure C-3 b). That indicates they weren’t more dangerous than developed-world airlines. Figure C-3 Stratifying Air Routes: Relative Proportion of Flights and Deaths by Developing-World and Developed-World Carriers, 1987–1996 Group differences entered the picture again when comparing developed-world and developing-world carriers on between-worlds routes only. The existence of a group difference in fatality rates between the two airline groups is what would compel us to reject the equal-safety hypothesis. Any stratification strategy should come with a big warning sign, statisticians caution. Beware the cherry-picker who draws attention only to one group out of many. If someone presented only Figure C-3 b, we could miss the mediocre safety record of developing-world carriers on their domestic routes, surely something we ought to know while touring around a foreign country. Such mischief of omission can generally be countered by asking for information on every group, whether relevant or not. ~###~ Stratification produces like groups for comparison. This procedure proved essential to the proper fairness review of questions on standardized tests. Epidemiologists have known about this idea since Sir Bradford Hill and Sir Richard Doll published their landmark 1950 study linking smoking to lung cancer, which heralded the case–control study as a viable method for comparing groups. Recall that Melissa Plantenga, the analyst in Oregon, was the first to identify the eventual culprit in the bagged-spinach case, and she based her hunch on a 450-item shotgun questionnaire, which revealed that four out of five sickened patients had consumed bagged spinach. Disease detectives cannot rely solely on what proportion of the “cases” (those patients who report sickness) were exposed to a particular food; they need a point of reference—the exposure rate of “controls” (those who are similar to the cases but not ill). A food should arouse suspicion only if the cases have a much higher exposure rate to it than do the controls. Statisticians carefully match cases and controls to rule out any known other factors that may also induce the illness in one group but not the other. In 2005, a year before the large E. coli outbreak in spinach, pre-packaged lettuce salad was blamed for another outbreak of E. coli , also of class O157:H7, in Minnesota. The investigators interviewed ten cases, with ages ranging from three to eighty-four, and recruited two to three controls, with matching age, for each case patient. In the case–control study, they determined that the odds of exposure to prepackaged lettuce salad was eight times larger for cases than for controls; other evidence subsequently confirmed this hypothesis. The result of the study can also be expressed thus: among like people, those in the group who fell ill were much more likely to have consumed prepackaged lettuce salad than those in the group who did not become ill (see Figure C-4 ). In this sense, the case–control study is a literal implementation of comparing like with like. When like groups are found to be different, statisticians will treat them separately. Figure C-4 The Case–Control Study: Comparing Like with Like The Sway of Being Asymmetric If all terrorists use barbecue as a code word and we know Joe is a terrorist, then we are certain Joe also uses the word barbecue . Applying a general truth (all terrorists) to a specific case (Joe the terrorist) is natural; going the other way, from the specific to the general, carries much peril, and that is the playground for statisticians. If we are told Joe the terrorist says “barbecue” a lot, we cannot be sure that all other terrorists also use that word, as even one counter-example invalidates the general rule. Therefore, when making a generalization, statisticians always attach a margin of error , by which they admit a chance of mistake. The inaccuracy comes in two forms: false positives and false negatives , which are (unhelpfully) called type I and type II errors in statistics texts. They are better understood as false alarms and missed opportunities. Put differently, accuracy encompasses the ability to correctly detect positives as well as the ability to correctly detect negatives. In medical parlance, the ability to detect true positives is known as sensitivity , and the ability to detect true negatives is called specificity . Unfortunately, improving one type of accuracy inevitably leads to deterioration of the other. See the textbook Stats: Data and Models by Richard D. De Veaux for a formal discussion under the topic of hypothesis testing , and the series of illuminating expositions on the medical context by Douglas Altman, published in British Medical Journal . When anti-doping laboratories set the legal limit for any banned substance, they also fix the trade-off between false positives and false negatives. Similarly, when researchers configure the computer program for the PCASS portable lie detector to attain desired proportions of red, yellow, and green results, they express their tolerance of one type of error against the other. What motivates these specific modes of operation? Our discussion pays particular attention to the effect of incentives . This element falls under the subject of decision theory , an area that has experienced a burst of activity by so-called behavioral social scientists. In most real-life situations, the costs of the two errors are unequal or asymmetric , with one type being highly publicized and highly toxic, and the other side going unnoticed. Such imbalance skews incentives. In steroid testing, false negatives are invisible unless the dopers confess, while false positives are invariably mocked in public. No wonder timid testers tend to underreport positives, providing inadvertent cover for many dopers. In national-security screening, false negatives could portend frightening disasters, while false positives are invisible until the authorities reverse their mistakes, and then only if the victims tell their tales. No wonder the U.S. Army configures the PCASS portable polygraph to minimize false negatives. Not surprisingly, what holds sway with decision makers is the one error that can invite bad press. While their actions almost surely have made the other type of error worse, this effect is hidden from view and therefore neglected. Because of such incentives, we have to worry about false negatives in steroid testing and false positives in polygraph and terrorist screening. For each drug cheat caught by anti-doping labs, about ten other cheaters have escaped detection. For each terrorist trapped by polygraph screening, hundreds if not thousands of innocent citizens have been falsely implicated. These ratios are worse when the targets to be tested are rarer (and spies or terrorists are rare indeed). The bestselling Freakonomics provides a marvelously readable overview of behavioral economics and incentives. The formulas for false positives and false negatives involve conditional probabilities and the famous Bayes’ rule , a landmark of any introductory book on statistics or probability. For the sake of simplicity, textbook analysis often assumes the cost of each error to be the same. In practice, these costs tend to be unequal and influenced by societal goals such as fairness as well as individual characteristics such as integrity that may conflict with the objective of scientific accuracy. Crossovers Banks rely on credit scores to make decisions on whether to grant credit to loan applicants. Credit scores predict how likely customers are to repay their loans; arising from statistical models, the scores are subject to errors. Like polygraph examiners, loan officers have strong incentives to reduce false negatives at the expense of false positives. False-negative mistakes put money in the hands of people who will subsequently default on their loans, leading to bad debt, write-offs, or even insolvency for the banks. False-positive errors result in lost sales, as the banks deny worthy applicants who would otherwise have fulfilled their obligations. Notice, however, that false positives are invisible to the banks: once the customers have been denied loans, the banks could not know if they would have met their obligations to repay the loan or not. Unsurprising, such asymmetric costs coax loan officers into rejecting more good customers than necessary while reducing exposure to bad ones. It is no accident that these decisions are undertaken by the risk management department, rather than sales and marketing. The incentive structure is never static; it changes with the business cycle. During the giant credit boom of the early 2000s, low interest rates pumped easy money into the economy and greased a cheap, abundant supply of loans of all types, raising the opportunity cost of false positives (missed sales). At the same time, the economic expansion lifted all boats and lessened the rate of default of the average borrower, curtailing the cost of false negatives (bad debt). Thus, bank managers were emboldened to chase higher sales at what they deemed lower risks. But there was no free lunch: dialing down false positives inevitably generated more false negatives, that is, more bad debt. Indeed, by the late 2000s, banks that had unwisely relaxed lending standards earlier in the decade sank under the weight of delinquent loans, which was a key factor that tipped the United States into recession. ~###~ Jeffrey Rosenthal applied some statistical thinking to prove that mom-and-pop store owners had defrauded Ontario’s Encore lottery. Predictably, a howl of protests erupted from the accused. Leaders of the industry chimed in, too, condemning his damning report as “outrageous” and maintaining that store owners had “the highest level of integrity.” Was it a false alarm? From the statistical test, we know that if store owners had an equal chance in the lotteries as others, then the probability they could win at least 200 out of 5,713 prizes was one in a quindecillion (1 followed by forty-eight zeros), which was practically zero. Hence, Rosenthal rejected the no-fraud hypothesis as impossible. The suggestion that he had erred was tantamount to believing that the insiders had beaten the rarest of odds fair and square. The chance of this scenario occurring naturally—that is, the chance of a false alarm—would be exactly the previous probability. Thus, we are hard-pressed to doubt his conclusion. (Recall that there is an unavoidable trade-off between false positives and false negatives. If Rosenthal chose to absorb a higher false-positive rate—as much as one in a hundred is typical—he could reduce the chance of a false negative, which is the failure to expose dishonest store owners. This explains why he could reject the no-fraud hypothesis for western Canada as well, even though the odds of 1 in 2.3 million were higher.) The Power of Being Impossible Statistical thinking is absolutely central to the scientific method, which requires theories to generate testable hypotheses. Statisticians have created a robust framework for judging whether there is sufficient evidence to support a given hypothesis. This framework is known as statistical testing , also called hypothesis testing or significance testing . See De Veaux’s textbook Stats: Data and Models for a typically fluent introduction to this vast subject. Take the fear of flying developing-world airlines. This anxiety is based on the hunch that air carriers in the developing world are more prone to fatal accidents than their counterparts in the developed world. Arnold Barnett turned around this hypothesis and reasoned as follows: if the two groups of carriers were equally safe, then crash fatalities during the past ten years should have been scattered randomly among the two groups in proportion to the mix of flights among them. Upon examining the flight data, Barnett did not find sufficient evidence to refute the equal-safety hypothesis. All of Barnett’s various inquiries—the comparison between developed-world and developing-world carriers, the comparison among U.S. domestic carriers—pointed to the same general result: that it was not impossible for these airlines to have equal safety. That was what he meant by passengers having “nowhere to run”; the next unlikely crash could befall any carrier. Statistical tests can also lead to the other conclusion, that what happened is impossible. For example, Jeffrey Rosenthal demonstrated that it was impossible for store insiders to win the Encore lotteries with such frequency if one were to assume they had the same chance of winning as everyone else. The minute probability he computed, one in a quindecillion, is technically known as the p-value and signifies how unlikely the situation was. The smaller the p-value, the more impossible the situation, and the greater its power to refute the no-fraud scenario. Then, statisticians say, the result has statistical significance . Note that this is a matter of magnitude, rather than direction. If the p-value were 20 percent, then there would be a one-in-five chance of seeing at least 200 insider wins in seven years despite absence of fraud, and then Rosenthal would not have sufficient evidence to overturn the fair-lottery hypothesis. Statisticians set a minimum acceptable standard of evidence, which is a p-value of 1 percent or 5 percent. This practice originated with Sir Ronald Fisher, one of the giants of statistical thinking. For a more formal treatment of p-values and statistical significance, look up the topics of hypothesis testing and confidence intervals in a statistics textbook. The statistical testing framework demands a disbelief in miracles. If we were not daunted by odds of one in a quindecillion, then we could believe that Phyllis LaPlante was just an incredibly, incredibly lucky woman. But then we had better believe that the next flight we take could be our last. Since statisticians are trained to think rare is impossible, they do not fear flying, and they do not play lotteries. Crossovers Psychometricians use the principle of statistical testing to deter-mine the presence of DIF (differential item functioning) in a standardized test. A test item is said to have DIF if one group of examinees finds it more difficult than does another group of examinees with similar abilities. If the group difference is 1 percent, one would hesitate to conclude that the test item is unfair. However, if the gap is 15 percent, one would be likely to sound the alarm. As in the lottery analysis, the matter concerns the magnitude, not so much the direction, of the difference. Indeed, ETS policy brands significant differences in either direction as unacceptable. In effect, the ETS researchers ask, “If the test item is fair to both groups, how rare would it be for the difference between black and white examinees to be as large as presently observed (or larger)?” They seek the answer by using actual scores from experimental sections of the SAT. In the 1980s, ETS realized that for this analysis to make sense, the examinees must first be matched on their “ability”; otherwise, ETS could not attribute any gap in performance directly to unfair item design. Statisticians say matching removes the confounding of the two factors, item design and quality of education. While several methods exist to measure DIF, they all make use of the framework of statistical testing. ~###~ In Minnesota, an ambitious experiment was organized to measure how turning off ramp meters on the highway entrances would affect the state of congestion. From the viewpoint of statistical testing, the doubters led by Senator Day wanted to know, if ramp metering was useless, what was the likelihood that the average trip time would rise by 22 percent (the improvement claimed by engineers who run the program) after the meters were shut off? Because this likelihood, or p-value, was small, the consultants who analyzed the experiment concluded that the favorite tool of the traffic engineers was indeed effective at reducing congestion. Since statisticians do not believe in miracles, they avoided the alternative path, which would assert that a rare event—rather than the shutting off of ramp meters—could have produced the deterioration in travel time during the experiment. Such an event might have been a twenty-five-year snowstorm or a fifty-car pileup (neither happened). In practice, if an experiment had indeed occurred under abnormal conditions, it would yield no insight on the question under study, and a new experiment should be arranged. Numbers Rule Your World While reading this book, it may dawn on you that numbers of all kinds rule your world. When you drive on the highway, engineers are measuring your speed at the on- and off-ramps. If your family goes to Walt Disney World, you may notice that cameras pick up your movement between rides, or you may bump into Len Testa or his crew counting heads. You now know that credit scores don’t have to make sense in order to work in your favor. But when the FDA recalls this food or that, you would want to know if the agency has located those lot codes. If you or your children have taken a standardized test, you should know how the test developers choose questions that are fair to everyone. Those living in hazard-prone areas can now see why private insurers are staying away. The next time you hear a busted athlete complain about a witch hunt by steroid testers, you may wonder about those negative samples lying around in the labs. When the next lie detection program arrives to screen out potential terrorists, you may wonder about those innocent people put behind bars by mistake. After you board a plane, you will relax, knowing that you have nowhere to run. And when you decide to play the lottery, you will look closely at the person selling you the ticket. If you react in those ways, as I hope you do, you will be thinking like a statistician. Perhaps now, when you next get on the Internet to pull up the stock charts, you will think about how the variability of returns should affect your investment strategy. When the FDA yanks another blockbuster drug from the market, you will ask how certain the agency had been that this drug caused patients to get better in the first place. While checking out the latest discovery of a new health supplement, you will scrutinize which groups are being compared, whether they are comparable, and whether you belong to one of them. In the supermarket, you won’t be surprised when the computer issues you a seemingly nonsensical discount coupon, pitching a product you’d never use—indeed, you may ponder the relative cost of the two errors (false positive and false negative). When offered another mouth-watering investment idea, you’d want to know how tiny the chance is of sustaining stable financial returns over thirty years if you assume the fund manager is not a swindler. If you know how to use numbers in making everyday decisions, you rule your world.",
        "char_count": 49369
      },
      {
        "heading": "Chapter 10",
        "text": "Notes In these notes, I document key sources, recommend further reading, and fill in certain details that were left out of the preceding chapters. A complete bibliography is available at the book’s link on my website, www.junkcharts.typepad.com . General References Books on statistical thinking fall into three general categories. The popular category of “damned lies and statistics,” in which authors collect insightful, uproarious examples of mischief with numbers, came into its own with Darrell Huff’s How to Lie with Statistics , still the cream of the crop five decades after its publication. Other notable contributors include Howard Wainer, a leading industry statistician ( Graphic Discovery , Visual Revelations , among others); John Allen Paulos, a tireless advocate of numerical literacy ( Innumeracy , A Mathematician Reads the Newspaper , among others); and Ed Tufte, an expert in graphical presentation of information ( The Visual Display of Quantitative Information , Visual Explanations , among others). My blog, called Junk Charts ( www.junkcharts.typepad.com ), critiques and reconstitutes graphics from the mainstream press. The science reporter Ben Goldacre debunks statistical fallacies regularly on his Bad Science blog ( www.badscience.net ). The second category, history and biographies, is evergreen. For those with some training in mathematics, the two books by Stephen Stigler on the historical development of statistical thinking are indispensable. Stigler, a professor at the University of Chicago, wrote elegant essays on the “average man” and other Adolphe Quetelet discoveries. Biographies of important statisticians such as Karl Pearson and Sir Francis Galton are available. Trade books on statistics tend to emphasize its probabilistic foundations and are filled with historical or hypothetical examples and biographical sketches. Among these, Jeffrey Rosenthal’s Struck by Lightning is short and sweet. In addition, the following more specialized books are exceptional: Stephen Senn’s Dicing with Death focuses on applications in medical sciences; John Haigh’s Taking Chances demystifies lotteries and games of chance; William Poundstone’s Fortune’s Formula dissects a specific gambling strategy; and Ian Ayres’s Super Crunchers considers the use of data mining by businesses. Finally, among textbooks, the set by Richard D. De Veaux, Paul Velleman, and David Bock ( Intro Stats , Stats: Modeling the World , Stats: Data and Models ) earns my highest recommendation for their intuitive approach. A common feature of statistics textbooks is their organization around mathematical techniques such as linear regression, analysis of variance, and hypothesis testing. By contrast, I bring out the key concepts underlying those techniques, such as variability, correlation, and stratification. With most books focused on exciting new theories, the work of applied scientists has suffered from general neglect. Freakonomics is a notable exception, covering the applied research of the economics professor Steven Levitt. Two books in the finance area also fit the bill: in The Black Swan , Nassim Taleb harangues theoreticians of financial mathematics (and other related fields) on their failure in statistical thinking, while in My Life as a Quant , Emanuel Derman offers many valuable lessons for financial engineers, the most important of which is that modelers in the social sciences—unlike physicists—should not seek the truth. Daniel Kahneman summarized his Nobel-prize-winning research on the psychology of judgment, including the distinction between intuition and reasoning, in “Maps of Bounded Rationality: Psychology for Behavioral Economics,” published in American Economic Review . This body of work has tremendous influence on the development of behavioral economics. The psychologist Richard Nisbett and his cohorts investigated the conditions under which people switch to statistical thinking; see, for example, “The Use of Statistical Heuristics in Everyday Inductive Reasoning,” published in Psychological Review . In an earlier book, Judgment Under Uncertainty , a true classic, Kahneman compiled a list of heuristics that are statistical fallacies. Slow Merges The study of waiting has a distinguished history in mathematics and in the discipline of operations research, under the name queuing theory . Related research at business schools tends to focus on the evaluation and optimization of real-world queuing systems in places such as banks, call centers, and supermarkets. Much of this research focuses on analyzing long-run average behavior. Professor Dick Larson at MIT was an early voice in shifting attention from averages to the variability of wait times, as well as the psychology of waiting. His opinion pieces in Technology Review and MIT Sloan Management Review are worth seeking out. It was David Maister’s influential paper “The Psychology of Waiting Times” that set the agenda for studying the psychological aspects of queuing, with the important insight that shortening the perceived waiting time could work just as well as reducing the actual waiting time. The feature articles by Robert Matthews (in New Scientist ) and Kelly Baron (in Forbes ), both coincidentally titled “Hurry Up and Wait,” depict a range of applications of queuing theory. For the business operations perspective of queuing theory, see Matching Supply with Demand by Wharton School professors Gérard Cachon and Christian Terwiesch; for the standard mathematical exposition, see the introductory textbooks by Randolph Hall or Robert Cooper. The topic of variability is underexposed in statistics books, despite its central importance. The subject is usually filed under measures of dispersion —that is to say, median, standard deviation, and percentiles—but the mathematical formulation clouds the practical significance of variability. The Minnesota Department of Transportation (Mn/DOT) published comprehensive reports on all phases of the “meters shutoff” experiment, including supporting data and implementation details. Cambridge Systematics, the consulting firm hired by Mn/DOT, issued reports on a variety of transportation-related projects, available from the firm’s website. The Minneapolis Star Tribune employed several top-notch beat writers on transportation, including Jim Foti (known as the Roadguy) and Laurie Blake; the Road-guy blog ( http://blogs2.startribune.com/blogs/roadguy ) features spirited dialogue between commuters, supplying many quotes for the chapter, including the first opening haiku by Nathan. It was Blake who interviewed Julie Cross, the commuter who experienced variable trip times as a problem of unreliability. Both the Star Tribune and St. Paul Pioneer Press captured the public reaction before, during, and after the ramp meter experiment, including the quoted comments by Day, Lau, Pawlenty, and Cutler. Taking advantage of the proximity to an extensive highway system, the renowned University of California, Berkeley, research group known as PATH (Partners for Advanced Transit and Highways) performed groundbreaking work on the freeway congestion paradox, from which they derived the theoretical justification for ramp metering. The article by Chen Chao, Jia Zhanfeng, and Pravin Varaiya, “Causes and Cures of Highway Congestion,” is an excellent summary of this impressive body of work. A key to their success must surely be theories built in the service of actual traffic data, not theories for their own sake. Also worth exploring are two reports issued by the Federal Highway Administration: a handbook on ramp management and a primer on traffic bottlenecks. In Still Stuck in Traffic , the economist Anthony Downs wrote the definitive study of traffic congestion, covering both technical and nontechnical aspects of the issue. His principle of “triple convergence” is a winning argument against adding capacity as the final solution to congestion because new capacity will just induce new demand. Downs put forth the provocative thesis that congestion itself is the market’s solution to a problem of mismatched supply and demand. National statistics on commuting were taken from Elisabeth Eaves’s article “America’s Worst Commutes,” published in Forbes . The American Society of Civil Engineers issues an annual Report Card for America’s Infrastructure, which measures road congestion in all fifty states. The engineering community has only recently recognized the importance of managing the reliability (variability) of trip time; see Richard Margiotta’s presentation to the National Transportation Operations Coalition, available online, for the state of the art. There are many more fascinating statistical problems in public transportation. Interested readers should look into high-occupancy-vehicle (HOV) or high-occupancy-toll (HOT) lanes, clustering of buses and subway trains, Braess’s paradox, the waiting-time paradox, train scheduling, and vehicle routing, among others. Fast Passes The Walt Disney Company has earned a sterling reputation for perfecting the guest experience. Some of its industry-leading practices for managing waiting lines were described by Duncan Dickson, Robert Ford, and Bruce Laval in “Managing Real and Virtual Waits in Hospitality and Service Organizations,” in which they developed a useful framework for business managers. FastPass is a tremendous hit with Disney fans. The analysis of wait times with and without FastPass came from Allan Jayne Jr.’s “An Unofficial Walt Disney World Web Page,” and the tips for using FastPass from Julie Neal’s blog, hosted by Amazon.com. Disney fans love to write about their experiences, and these trip reports populate many websites, including MousePlanet.com, DISboards.com and AllEars.net. The various quotations in the chapter were sourced from articles by Steven Ford (in the Orlando Sentinel ), Marissa Klein (in the Stanford Daily ), Mark Muckenfuss (in the Press-Enterprise—Riverside, CA ), and Catherine Newton (in the Times Union ), and from The Unofficial Guide to Walt Disney World by Bob Sehlinger and Len Testa. The second chapter-opening haiku was contributed anonymously to an idiosyncratic fan website called DisneyLies.com, in which the author fact-checks everything about Disney. The touring plans developed by Len Testa and his associates, including the Ultimate Touring Plan, are found in The Unofficial Guide as well as the affiliated TouringPlans.com website. Fans of this irreverent tour guide have snapped up millions of copies of the book. The feat of Waller and Bendeck was recorded on TouringPlans.com. The same website has a write-up of the predictive model, including the relative importance of different factors affecting waiting times. The technical problem Testa addressed belongs to the same family as the notoriously difficult traveling-salesman problem. In brief, it is the search for the quickest route through a list of stops ending back at the origin. A comprehensive reference is The Traveling Salesman Problem: A Computational Study by David Applegate, Robert Bixby, Vasek Chvatal, and William Cook. Bagged Spinach In January 2000, the New England Journal of Medicine published a list of the greatest twentieth-century achievements in medicine, bringing deserving recognition to the work of statisticians. Epidemiology is much bigger than just investigating outbreaks of diseases. Kenneth Rothman wrote the standard text on the subject, Modern Epidemiology . Also recommended is the article “Statistical Models and Shoe Leather,” containing keen observations by the statistician David Freedman. Epidemiologists investigate many types of diseases beyond food-borne illnesses. Legends abound about the discovery of the causes of Legionnaires’ disease, the Ebola virus, Gulf War syndrome, and so on. These stories of suspense and adventure are well told in books such as C. J. Peters’s Virus Hunter and Berton Roueché’s The Medical Detectives . A wealth of superbly produced materials is accessible to the public via the Public Health Training Network of the Centers for Disease Control and Prevention (CDC) and the Young Epidemiology Scholars program run by the College Board. The fundamental philosophical debate in epidemiology concerns causation and correlation . Standard textbooks embed this topic inside the discussion of regression , the workhorse of statistical modeling. More advanced books examine the intertwined subjects of observational studies and randomized experiments . Regarded as the “gold standard,” the randomized experiment is carefully designed to enable direct and robust attribution of cause to effect. However, epidemiologists must fall back on the observational study, because it is unethical to expose people randomly to E. coli or other disease agents. For this type of study, eliciting the cause–effect relationship is achieved by accepting unprovable and sometimes heroic assumptions—hence the controversy. For a discussion of randomized experiments, see the classic reference Statistics for Experimenters by George Box, Stuart Hunter, and Bill Hunter; for observational studies, consult the monograph by Paul Rosenbaum and Don Rubin’s Matched Sampling for Causal Effects for constructive points of view; and to comprehend the limitations, study the papers of David Freedman, who was a professor of statistics at Berkeley. The ongoing discussion among epidemiologists on the imperfection of their statistical methods offers a practical perspective on causality to supplement the aforementioned academic references. Gary Taubes, a science reporter, offers the best starting point in “Epidemiology Faces Its Limits,” published in Science , and for more, see commentaries by Erik von Elm (in the British Medical Journal ), Dimitrios Trichopoulos (in Sozial und Praventivmedizin ), Sharon Schwartz (in the International Journal of Epidemiology ), and Kenneth Rothman (in the American Journal of Public Health ). Alfred Evans gives the subject a book-length treatment in Causation and Disease . Steven Levitt and Stephen Dubner describe some riveting case studies in the field of economics; their book Freakonomics contains a list of useful references. The FDA and CDC kept the official record of the E. coli investigation of 2006, and the Congressional Research Service published a useful summary. A report by the California Food Emergency Response Team covered the inspection of Californian farms. Local newspapers and media followed events as they unfolded; my sources included the Los Angeles Times , the San Francisco Chronicle , the Monterey County (CA) Herald , Inside Bay Area , the Manitowoc (WI) Herald Times , the Appleton (WI) Post-Crescent , Lakeshore Health Notes , radio station WCCO in Minneapolis, and the Why Files . In an unusual research report released in 2007, the Food Policy Institute at Rutgers University assessed the media’s influence in the crisis. Todd Weiss evaluated the role of computer networks for Computerworld . Suzanne Bohan cited Caroline Smith DeWaal’s endorsement of the government action in an Oakland Tribune article. Scientific details came from federal and state epidemiologists Michael Lynch, Robert Tauxe, Linda Calvin, Jack Guzewich, Paul Cieslak, and Lorrie King. Kenneth Schulz and David Grimes gave an excellent technical overview of the case–control study in The Lancet . Examples of questionnaires used in these studies are available from many state epidemiology departments. A brief biography of Alexander Langmuir, the founder of the CDC’s Epidemic Intelligence Service unit, is given by Jeffrey Koplan and Stephen Thacker in the American Journal of Epidemiology . Bad Score Commercial credit-scoring algorithms come in many forms, as described in the handsome piece “Statistical Classification Methods in Consumer Credit Scoring: A Review,” published in the Journal of the Royal Statistical Society: Series A , by David Hand, a statistician at Imperial College London. The innards of credit-scoring models are guarded as commercial secrets. FICO, formerly Fair Isaac Corporation, originated the most widely used credit scores in the United States, known as FICO scores. An excellent presentation called “Credit Scoring 101,” created by Fair Isaac, is available at the Federal Trade Commission (FTC) website, www.ftc.gov . Edward Lewis, a former officer of Fair Isaac, wrote a more technical, still readable, but dated reference titled An Introduction to Credit Scoring . Bruce Hoadley, also with Fair Isaac, discussed more recent technical innovations, including some practical issues, in the journal Statistical Science , while commenting on an important article by Leo Breiman, “Statistical Modeling: The Two Cultures.” For a simplified but generally accurate overview of data-mining techniques used in business, see Michael Berry and Gordon Linoff’s Mastering Data Mining . The FICO algorithm is typically formulated as a scorecard, as in Lewis’s book, or as mathematical equations, as in Hoadley’s article. I adopted the simpler form of IF-THEN rules, which is equivalent but more intuitive. In practice, the other formulations are more efficiently implemented. The decision rules cited in Chapter 2 are for illustration only. The rule using debt ratios was mentioned in John Straka’s report “A Shift in the Mortgage Landscape: The 1990s Move to Automated Credit Evaluations” in the Journal of Housing Research , while the one concerning painters came from Lewis’s book. Many authors have studied the impact of credit scoring on our society; of these efforts, I recommend the book Paying with Plastic by David Evans and Richard Schmalensee, and the PBS report on “Credit Scores—What You Should Know About Your Own” by Malgorzata Wozniacka and Snigdha Sen. Although little direct evidence has been published, industry insiders agree on the substantial benefits of credit-scoring models, and their rapid penetration into many industries provides indirect proof. Federal Reserve chairman Alan Greenspan and FTC chairman Timothy Muris made the cited comments at various conferences and hearings. Consumer advocacy organizations, including the National Consumer Law Center, Center for Economic Justice, and Consumers Union, issued reports critical of credit scoring. The quotation of Representative Steven Wolens was reported by Gary Boulard in State Legislatures . Robert Avery at the Federal Reserve organized an innovative study, published in the Federal Reserve Bulletin , which concluded that the accuracy of credit report data had only modest impact on consumers. James White’s plight was described by Kathy Chu of the Wall Street Journal . The piggy-backing scam was detailed in a report by J. W. Elphinstone of the Associated Press. Claritas, currently owned by Nielsen, is well known among marketing professionals for its proprietary PRIZM segmentation scheme, which divides U.S. households into sixty-six segments with distinct demographic and behavioral characteristics. In his book The Clustered World , Michael Weiss presented the profiles of the market segments, as defined by an older generation of PRIZM. Companies use this product to shift from one-size-fits-all marketing to targeted marketing. Customer segmentation typically utilizes cluster analysis, which is a class of statistical models based on correlations. Berry and Linoff’s aforementioned book on data mining has a chapter on cluster analysis, which they call “automatic cluster detection.” Item Bank The seminal reference on DIF analysis remains the volume Differential Item Functioning compiled by Paul Holland and Howard Wainer, which covered the influential work conducted by ETS statisticians during the 1980s. The talented staff at ETS publishes a series of research reports, including many papers on DIF; among them is “Revising SAT-Verbal Items to Eliminate Differential Item Functioning” by Ed Curley and Alicia Schmitt, from which I took the sample SAT verbal items. Ed says to look out for new developments, as ETS has launched another cycle of research in this area. Other materials of interest from ETS include a description of its fairness review procedures, a primer on DIF analysis, and summary statistics of historical SAT scores. Several techniques are currently acceptable for DIF analysis: standardized differences, Mantel–Haenszel statistics, and item-response models. Curley and Schmitt employed the standardization approach. In applying this method to study the group difference by gender, for instance, they computed the correct rate for male examinees as if males had the same mix of ability as females. The group difference is said to have been controlled for ability. The other two methods are more mathematically advanced. See the papers “Differential Item Performance and the Mantel–Haenszel Procedure” by Paul Holland and Dorothy Thayer, and “Detection of Differential Item Functioning Using the Parameters of Item Response Models” by David Thissen, Lynne Steinberg, and Howard Wainer. When an item is found to be unfair to certain groups, the source of inequity frequently defies explanation. The quotation and the anecdote of Lloyd Bond were sourced from his contribution to Holland and Wainer’s seminal volume. Some authors use the word biased to describe unfair test items and the term item bias to describe this field of study. To statisticians, bias merely means difference, without the implication of negative intention; I avoided this controversial term altogether, preferring unfair . The cumbersome technical term, differential item functioning , was coined for a similar reason; it suggests that the unfair items “function” differently from other questions in the test. DIF analysis requires classifying examinees by their “ability,” which also happens to be what the SAT is supposed to measure. Thus, no external source exists for such classification. Clever statisticians tackle this issue by using an internal criterion of ability: an examinee’s score on the test after excluding any unfair items. Critics charge that such a metric fails if the test itself fails to measure ability properly. This is a challenge of the validity of standardized testing in general, dressed up as commentary on DIF analysis. The book Methods for Identifying Biased Test Items by psychometricians Gregory Camilli and Lorrie Shepard gives a balanced evaluation of several techniques. For contemporary views on the Golden Rule settlement, see the special issue (June 1987) of Educational Measurement . Nancy Cole, past president of ETS, reviewed the history of fairness reviews in testing in the article “The New Faces of Fairness,” published in the Journal of Educational Measurement . Daniel Koretz’s Measuring Up is a terrific introduction to psycho-metrics, the application of statistics to educational issues. He devoted a chapter to the achievement gap between black and white students. This phenomenon has been extensively documented and heavily studied. Linda Darling-Hammond distilled the state of our knowledge circa 2007 in the Third Annual Brown Lecture in Education Research, published as “The Flat Earth and Education: How America’s Commitment to Equity Will Determine Our Future” in Educational Researcher . In his book, Koretz also reviewed the evidence on whether SAT scores predict college GPA. Tia O’Brien wrote about parents in Marin County in the San Francisco Chronicle . Simpson’s paradox shows up frequently in practice, and its appearance indicates the presence of group differences that cannot be ignored. In the article “Sex Bias in Graduate Admissions: Data from Berkeley,” P. J. Bickel, E. A. Hammel, and J. W. O’Connell supplied a famous example of the statistical paradox. Howard Wainer analyzed several other examples, such as those presented in the article “Two Statistical Paradoxes in the Interpretation of Group Differences.” Risk Pool For a general introduction to the insurance principle, see Christopher Culp’s The ART of Risk Management and Chapter 5 of the 2007 Economic Report of the President . Both references mention the peculiarities of natural-disaster insurance. For a soft introduction to the mathematics, start with The Mathematics of Natural Catastrophes by Gordon Woo, an expert at Risk Management Solutions. Journalist Peter Gosselin reviewed the state of the business of catastrophe insurance in the Los Angeles Times . Other useful reading includes Climate Extremes and Society , a compilation of recent research; papers by Howard Kunreuther and David Crichton, at the Wharton School of Business and the Aon Benfield UCL Hazard Research Centre (U.K.), respectively; and the presentation by Henry Keeling, CEO of XL Re, to the 2003 Aon Natural Hazards Conference. Florida newspapers provide excellent accounts of hurricane disasters and comprehensive coverage of insurance-related matters; these include the St. Petersburg Times , Tampa Tribune , Palm Beach Post , and Sarasota Herald-Tribune. Best’s Review analyzes industry news. Bob Hartwig is the chief economist at the Insurance Information Institute, which is funded by the insurance industry, and his colorful presentations archived at the institute’s website ( www.iii.org ) contain much valuable data. Reinsurers, who invest heavily in quantitative modeling, articulate their technical positions in published reports. See especially those written by Munich Re ( www.munichre.com ) or Swiss Re ( www.swissre.com ). Ernst Rauch commented on the accuracy of storm models in a Munich Re report. In 2005, Towers Perrin issued an exhaustive review of Hurricane Katrina’s impact on the insurance industry. The Florida Office of Insurance Regulation commissioned several reports on the state of the insurance market. Statistics affect the insurance business in multiple ways. One key concern is the prediction of expected losses by quantitative-modeling firms. The leading firms that supply insurers with storm models include Risk Management Solutions (located in Newark, New Jersey), AIR Worldwide (Boston), and EQE International (Oakland, California). The New York Times Magazine feature article “In Nature’s Casino,” by Michael Lewis, contained an engaging profile of the entrepreneurs who invented the quantitative-modeling business, explaining how Wall Street benefited by launching markets for catastrophe bonds, which are risky bets on natural disasters not happening during specified periods of time. Catastrophe bonds form a unique class of financial assets that show nearly zero correlation with other assets. The accuracy of catastrophe models has been challenged, but their impact on the industry is unmistakable. Chris Mooney conveyed this material well in his book Storm World , particularly the controversy about whether climate change is causing a surge in the intensity or frequency of hurricanes. The renowned investor Warren Buffett runs a variety of insurance businesses under the Berkshire Hathaway umbrella, and his sage advice on how to stay afloat is sprinkled throughout the chair-man’s letters to shareholders. In his writings and public comments, Buffett also warned about the growth in financial derivatives and the complexity of interlocking reinsurance contracts. In recent years, insurers have become quite sophisticated at differentiating between high- and low-risk properties. While the distance from the coast is a clear determinant of potential exposure, actuaries also consider other factors, such as whether customers have taken mitigating measures and whether properties conform to newer building codes. Kunreuther, an insurance expert at the Wharton School of Business, argues that the industry must move to adopt such risk-based pricing. The quotations of J. Patrick Rooney came from Lorraine Woellert (in Business Week ) and J. K. Wall (in the Indianapolis Business Journal ). Magic Lassos Much of the information about the science of polygraphs, including the scientific evaluation of this technology, is drawn from The Polygraph and Lie Detection , the 2002 study by the National Academy of Sciences (NAS), an authoritative synthesis of the best available research; and from papers by Stephen Fienberg, professor of statistics at Carnegie Mellon University and the technical director of the NAS study. These sources contain much more on the mathematics of the trade-off and introduce ROC curves , a different way of presenting the numbers and the focus of much current research. In a series of articles in the British Medical Journal , Douglas Altman and his associates have succinctly introduced the key statistical issues in diagnostic testing, such as sensitivity and specificity, false-positive and false-negative rates, and ROC curves. Both the supporters and adversaries of the polygraph speak loudly: national and local polygraph associations maintain websites, while the opponents gather at AntiPolygraph.org. There exists an earlier study on polygraphs (1983) organized by the Office of Technology Assessment of the U.S. Congress. The present obsession with data warehouses and data-mining systems in the service of national security will surely fade, as the statistical science of predicting rare events cannot provide sufficient precision to cope with the heavy costs of both false-positive and false-negative mistakes. Better than chance is surely not sufficient. Bruce Schneier’s writings—such as those in Forbes and Wired magazines—are unusual in the mainstream media for their clear-headed grasp of these technical issues. Craig Norris, CEO of Attensity, was cited in the article “‘Wholesale’ Snooping” by San Jose Mercury News reporters Elise Ackerman and K. Oanh Ha. Michael Berry and Gordon Linoff’s book, Mastering Data Mining , provides a competent introduction to basic data-mining concepts. At Stanford University, the venerable research team of Trevor Hastie, Robert Tibshirani, and Jerome Friedman gives the graduate-school-level treatment of these topics in The Elements of Statistical Learning . The tragic case of Jeff Deskovic highlights the human cost of a false-positive error in real life. Westchester County district attorney Janet DiFiore made the fateful decision to review Deskovic’s case, and her office published the authoritative account of it. The New York Times followed up with two touching stories, giving us a glimpse into how Deskovic struggled to steer his life back on track after his vindication. Deskovic currently writes a column for the Westchester Guardian newspaper and is an activist and motivational speaker. The important work of the Innocence Project, which pursued Deskovic’s case as well as hundreds of other wrongful convictions, brings home the reality that perfection is elusive, even though our criminal-justice philosophy condones some false negatives in order to diminish false positives, just as our anti-doping programs do. Professor Saul Kassin has written broadly on false confessions and the extent to which they affect convictions. See, for instance, “False Confessions: Causes, Consequences, and Implications for Reform” and “Confession Evidence: Commonsense Myths and Misconceptions.” Journalist Bill Dedman of MSNBC.com broke the PCASS story in April 2008. The original article, as well as accompanying materials, including the declassified memo by David Thompson at Camp Cropper, can be found on the MSNBC.com website. Surprisingly, few other media outlets picked up the story. The report by Johns Hopkins University scientists John Harris and Allan McQuarrie, titled “The Preliminary Credibility Assessment System Embedded Algorithm Description and Validation Results,” contains more details on PCASS, such as how error rates were calibrated. The Wen Ho Lee case was examined thoroughly by Matthew Purdy for the New York Times and in Appendix C of the aforementioned 2002 NSA report. A similar case involving another scientist, Dr. Thomas Butler, was reported in depth by the Cleveland Plain Dealer in April 2006. Timid Testers I use the word steroids to refer to performance-enhancing drugs (PEDs) in general; strictly speaking, steroids form a class of PEDs. David Mottram’s book Drugs in Sports presents a wealth of information about PEDs in sports. Robert Saunders, on his Flies and Bikes blog ( www.robertsaunders.org.uk ), and Bruce Lynn, in a presentation called “Blood Doping, Erythropoietin, and Altitude Training,” described the hematocrit test and the isoelectric focusing test. The World Anti-Doping Agency (WADA) maintains the technical specification of the EPO test, originally developed by Don Caitlin, who leads one of the world’s renowned anti-doping laboratories in California. The statistical analysis of steroid testing follows the textbook approach using conditional probabilities and the famous Bayes’ rule, a topic found in every book on probability and statistics. The standard approach focuses on the chance of a chemical false-positive error in the “A” sample; see, for example, Donald Berry’s take, published in Nature , on the Floyd Landis case. I believe the public cares about the popular —not the chemical—false positive. By “popular” false positive, I mean a clean athlete who is falsely accused of doping. This is not the same as a “chemical” false positive, which is a clean blood or urine sample that the testing lab erroneously marks as positive. For a positive “A” sample finding to trigger a popular false positive, the “B” sample must also show abnormal chemistry, the samples must pass additional, more sophisticated lab tests, the process must meet quality-control standards, the result must withstand spirited defense from athletes and lawyers, and the arbitrators must accept cheating as the cause of the positive test. Due to these built-in protections, the chance of a popular false positive can be negligible, even when the rate of a chemical false positive in the “A” sample is not. Because the error rates of many steroid-testing procedures are not known to the public, textbook analyses make assumptions about the accuracy, usually above 90 percent, which then results in unrealistic positive rates (the sum of true positives and false positives) in the range of 10 to 20 percent. Such rates of positive findings contradict the official records at recent sporting events. For example, Nicolas Brulliard of the Wall Street Journal reported that 0.7 percent of tests performed at the 2004 Athens Olympics came back positive; Juliet Macur of the New York Times said 2 percent of tests conducted by WADA in 2005 came back positive; and according to Simon Turnbull of The Independent , 0.2 percent of tests conducted at the 2008 Beijing Olympics came back positive. Note that these rates put a ceiling on the feasible number of false positives, since a false positive is first and foremost a positive. Experts have no illusion about the false-negative problem: Dr. Charles Yesalis wrote about it in the article “The Strengths and Frailties of Drug Tests,” published in the New York Times , and Dr. Rasmus Damsgaard’s comment about undetected positive samples was mentioned in Matt McGrath’s report for BBC News. Almost all challenges to positive steroid findings in effect confirm the chemical positive, so the real issue of contention concerns competing causes to explain the positive result, pitting cheating against tainted vitamins, spiked drinks, and the like. This latter matter moves us beyond the realm of science into the field of lie detection. By obtaining a therapeutic-use exemption (TUE) before competing, an athlete is legally allowed to use certain drugs on the banned-substances list, such as anabolic steroids and corticosteroids. One report disclosed that 60 percent of the 105 cyclists at the 2006 Tour de France received a TUE of one kind or another. More than 100 Major League Baseball players were granted TUEs for attention deficit disorder, according to the official in charge of steroid testing. Most asthmatic Olympic swimmers have obtained TUEs to use certain steroids, and up to half of the elite swimmers suffer from asthma, compared with 5 percent in the general population, as discussed by Carrie Dahlberg of The Sacramento Bee . The blog Steroid Nation, written by Dr. Gary Gaffney, is unrivaled in delivering timely coverage and insightful commentary on steroids in sports. Mike Lowell’s comment about HGH testing was reported by the Boston Globe. Game of Shadows , the powerful book by San Francisco Chronicle journalists Mark Fainaru-Wada and Lance Williams, provides a riveting behind-the-scenes look at the BALCO investigation, revealing many interlocking stories of competition, greed, jealousy, suspicion, temptation, peer pressure, groupthink, honor, dishonesty, and morality. It will change your perspective on elite athletes. These two investigative journalists deserve praise for their superbly narrated book, which follows a series of scandalous features in their hometown newspaper. Jose Canseco’s books, Juiced and Vindicated , are eccentric and polemical but also thought-provoking and laugh-out-loud funny. Canseco believes that controlled use of steroids is good for sports and good for individuals. In a central chapter of Vindicated , he includes transcripts of two polygraph examinations that “prove” his truth-telling. The Mitchell Report, published online, named more than eighty baseball players. The testimony of Mark McGwire, Rafael Palmeiro, and Jose Canseco to Congress was widely reported and is readily available online. They no longer play in Major League Baseball. The New York Daily News first reported on Rick Ankiel’s business with a Florida pharmacy. Readers should turn to page 173 of Marion Jones: Life in the Fast Lane to see her bold-red declaration of innocence years before she finally admitted to doping. It was Sue Mott who made the perceptive remarks about the false negative in the Daily Telegraph , the same paper that published Michael Johnson’s commentary. Jones retired from track and field. Her coach Trevor Graham stood trial for perjury in 2008 and was later banned for life from track and field. Steve Riddick, another former coach, was convicted in 2006 for his role in a money-laundering scheme involving both Jones and Tim Montgomery. Kelli White was suspended for two years and retired from track; one of the few to admit her mistake and apologize, she later earned an MBA and continues to educate the next generation against doping. Wikipedia has a nice summary of the multiple doping scandals of the Tour de France, including the list of disgraced former champions. Tyler Hamilton was cited from articles in the Boston Globe and Aspen Times and his own news release. Arbitrators did not accept his vanishing-twin theory; after serving a two-year ban, he returned to cycling in November 2006 but was suspended again in May 2007 as his name surfaced in the Operacion Puerto drug scandal. In 2009, after failing yet another drug test, Hamilton was served an eight-year suspension, which effectively ended his career. Samuel Abt told the story of Bjarne Riis in the International Herald Tribune . Mark Hedden described Riis’s awe-inspiring victory at KeysNews.com. Dick Pound personifies the zealous tester turning over every stone to flush out dopers. A former head of WADA and former Olympic swimmer, he is the larger-than-life figure in the anti-doping movement, and his books include Inside the Olympics and Inside Dope . Travis Tygart, CEO of the U.S. Anti-Doping Agency, made the clever remark on denials by athletes in an interview with Ferren Christou at the Daily Peloton . So many excuses or explanations for positive tests have been proffered by accused athletes that they have been collected and organized as an online quiz at www.sometests.com . Jet Crashes Arnold Barnett’s research program at Massachusetts Institute of Technology is the most authoritative source on aviation safety. All of the program’s work is empirical, developed from historical flight data, and accessible. Statistical testing is their preferred framework. See Barnett’s many publications for the analysis of developing-world carriers, USAir, regional carriers, discount airlines, commuter flights, and many other related questions. It was during the Blackett Memorial Lecture in 2001 when Barnett raised the provocative question about fear of flying as a personality disorder. Barnett’s team estimated the risk of fatality to be about 1 in 700,000 for “between-worlds” flights during 1987 and 1996 for both developed-world carriers and their counterparts in the developing world. Imagine a passenger who draws randomly from all scheduled nonstop flights that satisfy her needs; the risk of fatality assesses the likelihood she will perish on the randomly chosen flight. Further, if she were to ride one flight each day, selected at random, it would take 1,900 years before she would be expected to die in a plane crash. This calculation takes into account the probability of the crash in addition to the proportion of passengers who would survive it. What I called “developed world” Barnett labeled the “First World.” Like all disasters, the EgyptAir tragedy received abundant coverage by the media, including the New York Times , Boston Globe , and Newsday . Frank Ahrens used a version of the “Corridor of Conspiracy” table in the Washington Post . John Tierney of the New York Times cited the study of front-page stories in his paper. Arnold Barnett conducted this study as well. Psychologist Barry Glassner dissected the fear of flying in the Wall Street Journal and in Chapter 8 of his book The Culture of Fear . The quotation of the anonymous pilot came from the former. The Gallup Poll occasionally reports on the popularity of lotteries and the fear of flying. Jackpots The Canadian Broadcasting Corporation broke the story of the Encore lottery fraud in October 2006. The audio recording of the CBC program, titled “Luck of the Draw,” is available from their website, where Jeffrey Rosenthal’s analysis can also be retrieved. The quotation from the Ontario Convenience Stores Association was reported by Ian Robertson of the Toronto Sun . CBC News has reported extensively on the numerous investigations; in particular, Timothy Sawa provided a useful summary of the situation in Western Canada. Statisticians are not big spenders at casinos, but lotteries and other games of chance are, ironically, their favorite spectator sports. They have studied everything from picking the best numbers to figuring out whether the drawn numbers are truly random. Statistician John Haigh has produced an excellent summary of this research in Taking Chances , while William Poundstone’s Fortune’s Formula traced the fortunes of a particular gambling strategy known as Kelly’s formula. Odds and Ends The terms probability , odds , and likelihood are used interchangeably in my book, as per popular usage, but in technical vocabulary, they have specific and different definitions. The U.S. Census Bureau defines the average day for its American Time Use Survey. Digg is a website ( http://digg.com ) that ranks online articles by the number of positive responses (“diggs”) submitted by Internet readers. Its home page is continuously updated with links to the highest-rated articles.",
        "char_count": 43200
      },
      {
        "heading": "Chapter 11",
        "text": "Index African Americans. See Racial/minority groups Airplane crashes, 137 –43, 146 –51, 152 –54, 179 , 181 developing-world carriers and, 150 –51, 171 –73, 178 domestic airline choice and, 149 fear of flying and, 138 , 141 , 142 , 147 , 148 Nantucket “Bermuda Triangle” theory, 140 , 142 , 146 –47 odds of dying in, 137 , 143 , 148 Altman, Douglas, 175 Ankiel, Rick, 99 –100 Anrig, Greg, 74 , 76 Ariely, Dan, 158 Asymmetric costs, 95 –135, 174 –78. See also Data mining; Drug tests; Polygraph tests “Average man” concept, 2 –3, 4 , 24 Averages, 1 –24, 156 –63. See also Commuting time; Disney World queue waiting time Baillie, John, 39 BALCO, 95 , 99 , 104 , 105 , 106 , 116 Barnett, Arnold, 142 , 143 , 146 –51, 152 , 153 , 171 , 178 Bayes’rule, 176 Bendeck, Yvette, 5 Besser, John, 41 Birnbaum, Birny, 54 “Black swan,” 159 Body mass index (BMI; Quetelet index), 3 , 4 Bond, Lloyd, 63 , 71 , 75 Bonds, Barry, 99 , 106 Box, George, 61 , 159 , 163 Buffett, Warren, 87 , 89 Bush, George W., 99 Cambridge Systematics, 12 , 21 , 23 Canseco, Jose, 95 , 99 , 114 –16, 117 , 130 Capacity planning, 8 , 12 –13, 15 –16 Case–control studies, 42 –43, 165 , 173 –74 group differences and, 42 , 173 –74 invention of, 43 matched controls in, 42 Cause–effect, 40 , 43 , 54 –56, 60 –61, 163 –67 Hill’s nine viewpoints, 43 and credit scoring, 54 –56, 163 –65 statistical models and, 60 –61, 163 –64 Chadwick, Sir Edwin, 35 Chambers, Dwain, 104 Chapin, Charles, 35 Cholera epidemic, 34 –35, 38 Citizens Property Insurance Corporation, 92 –93, 171 Claritas, 45 Clemens, Roger, 116 Collins, Michelle, 104 Commuting time, 4 , 9 –16 freeway congestion paradox and, 13 –14 ramp metering and, 13 –15, 16 , 19 , 20 –24, 157 , 158 –59, 180 –81 Compound annual growth rate, 156 –57 Conditional probabilities, 176 Confounding, 180 Conte, Victor, 104 , 116 Correa, Angela, 119 –21, 124 –25 Correlation vs. causation, 29 , 55 –56, 60 , 163 –64, 165 , 166 –67 Credit cards, 45 , 46 , 48 , 52 , 58 Credit crisis of 2008, 177 Credit scores, 26 , 44 –61, 163 –65, 176 –77, 181 advantages of, 51 –54 credit decision making prior to, 47 –48 criteria used in, 48 –51 criticism of, 54 –59 cutoff level in, 50 description and purpose of, 46 –47 level of use of, 28 –29 piggybacking on, 58 Culture of Fear, The (Glassner), 142 Curley, Edward, 77 , 79 , 80 Cutler, Marc, 23 Damsgaard, Rasmus, 108 , 161 Data mining, 131 –35, 167 Davis, Jeffrey, 30 , 31 , 33 Day, Dick, 20 , 21 , 158 , 180 De Veaux, Richard D., 175 , 178 Decision theory, 175 Deskovic, Jeffrey, 119 –21, 124 –27, 128 , 130 DeWaal, Caroline Smith, 38 Differential item functioning (DIF) analysis, 74 , 77 –82, 170 , 179 –80 DiFiore, Janet, 124 –25 Disney World queue waiting time, 4 , 5 –9, 10 , 15 –20, 21 , 24 , 157 –58, 181 FastPass and, 17 –20, 24 , 157 perception management and, 16 –20, 23 , 157 tactics to shorten, 17 –18 touring plan and, 5 , 166 –67 Disney’s Imagineering division, 8 , 156 –57 Doll, Sir Richard, 173 Downs, Anthony, 12 –13 Drug tests, 95 –96, 97 –113, 130 –31, 160 –63, 175 –76, 181 . See also False negatives; False positives polygraph challenge to, 114 –16 polygraphs compared with, 121 –22, 127 tactics used to beat, 108 –9 timid tester problem, 109 –10, 112 , 161 , 175 E. coli outbreak, 26 –27, 29 –34, 35 –43, 165 , 167 , 173 –74 economic impact of, 38 –39 foods linked to, 39 investigation of cause, 30 –34 source of contamination discovered, 37 Edmonds, Bob, 144 –46 Educational Testing Service (ETS), 64 , 65 –66, 68 , 71 , 73 –74, 76 –77, 81 , 170 , 180 Employee Polygraph Protection Act, 118 Epidemic Intelligence Service (EIS), 35 , 36 Epidemiology, 26 –27, 29 –45, 60 –61, 163 , 173 –74. See also E. coli outbreak challenges in, 44 information-sharing networks in, 41 –42, 165 limits of statistics in, 40 –41 source of contamination, 34 –35 Fair, Bill, 48 Fair and Accurate Credit Transactions Act, 57 Fair Credit Reporting Act, 54 Fallows, James, 1 –2, 3 –4 False confessions, 125 –27 False negatives, 174 –76 on credit scores, 176 –77 in data mining, 132 on drug tests, 102 , 106 –10, 111 , 112 , 128 , 130 , 162 , 163 , 175 –76 false positive trade-off with, 97 –98, 110 , 112 , 121 –22, 128 , 131 , 175 , 178 on polygraphs, 97 , 121 –22, 127 , 131 False positives, 174 –76 on credit scores, 176 –77 in data mining, 132 –35 on drug tests, 96 , 97 , 100 –102, 105 –6, 107 , 110 , 111 , 112 , 128 , 131 , 160 , 161 , 162 , 163 false negative trade-off with, 97 –98, 110 , 112 , 121 –22, 128 , 131 , 175 , 178 on polygraphs, 121 –22, 123 –24, 125 , 127 , 128 –29, 175 –76 Fast Pass, 17 –20, 24 , 157 Fehr, Donald, 100 FICO, 46 , 47 , 50 , 51 , 58 , 61 Fienberg, Stephen, 121 , 123 , 130 Fisher, Sir Ronald, 60 –61, 179 Flynt, Larry, 116 –17 Food Net, 41 , 42 Foti, Jim, 10 –11, 14 –15 Freakonomics (Levitt and Dubner), 176 Game of Shadows (Fainaru-Wada and Williams), 95 Garcia, Norma, 54 Gatlin, Justin, 112 Gelman, Andrew, 168 Giambi, Jason, 99 , 114 Gingrich, Newt, 63 Glassner, Barry, 142 Golden Rule settlement, 64 , 65 , 68 , 73 –74, 76 , 81 , 91 , 168 –69 Gonzalez, Juan, 114 Graham, Trevor, 99 , 104 Greenspan, Alan, 28 , 53 –54 Grogan, John, 115 –16 Group differences, 63 –94, 168 –74. See also Airplane crashes; Case–control studies; Hurricane insurance; Test item fairness; Voting behavior Hamilton, Tyler, 101 , 103 , 105 , 106 , 109 , 112 Harrison, Calvin and Alvin, 104 Hartwig, Bob, 63 , 90 Hematocrit test and EPO abuse, 110 –11 Hill, Sir Bradford, 43 , 60 –61, 173 Hunter, Bill, 159 Hunter, Stuart, 159 Hurricane insurance, 82 –94, 159 –60 government role, 83 –84, 86 , 91 –93, 94 , 160 market adjustments, 85 –86, 90 –91, 94 100-year storm fixation, 88 risk pools, 86 –87, 89 –94, 168 , 171 and statistical models of losses, 87 –88, 93 Hypothesis testing, 175 , 178 . See also Statistical testing Improving Almost Anything (Box), 163 Incentives, 175 Innocence Project, 124 , 125 , 128 Insurance automobile, 86 –87, 159 credit scores and, 52 , 53 , 54 , 55 economics of, 86 –88 hurricane ( see Hurricane insurance) Isaac, Earl, 48 Jacobs, Regina, 104 Johns Hopkins University, 97 , 122 , 127 , 128 Johnson, Ben, 99 , 108 , 112 Johnson, Michael, 108 Jones, Chancey, 71 –72 Jones, Marion, 103 –6, 108 , 116 , 130 Joyner, Molly, 31 Juiced (Canseco), 95 , 99 , 114 Junk Charts blog, 183 Kahneman, Daniel, 155 , 158 Kassin, Saul, 125 , 126 Kederis, Konstantinos, 109 Keene, Bill, 31 , 33 , 42 Korda, Petr, 112 Koretz, Daniel, 73 Landis, Floyd, 109 , 112 Langmuir, Alexander, 35 LaPlante, Phyllis, 143 –46, 179 Larson, Dick (“Dr. Queue”), 20 , 23 Lau, Rich, 21 Laval, Bruce, 17 Lee, Wen Ho, 128 Lewis, Carl, 112 Lewis, Michael, 9 , 87 Lotteries, 137 –38, 181 insider wins, 143 –46, 151 –53, 177 –78, 179 odds of winning, 137 , 143 percentage of Americans playing, 138 Lowell, Mike, 96 , 98 , 100 , 102 , 107 , 112 , 124 Lund, Zach, 112 Madoff, Bernie, 156 Major League Baseball, 9 , 98 –100, 106 –7, 112 , 114 –16 Manhattan Project, 9 Margin of error, 174 Marston, William, 113 , 117 Martinez, David, 112 McGuinty, Dalton, 145 McGwire, Mark, 95 , 98 –99, 107 , 114 Measuring Up (Koretz), 73 Minnesota Department of Transportation, 15 , 21 , 158 “Minnesota Merge,” 14 –15 Mitchell, George, 100 , 116 Moneyball (Lewis), 9 Moral hazard, 93 Munich Re, 87 Muris, Tim, 29 , 46 Nightingale, Florence, 3 Norris, Craig, 95 , 132 , 133 Obama, Barack, 2 , 116 Odds, improbable, 137 –54, 178 –81. See also Airplane crashes; Lotteries O’Malley, T. V., 118 OutbreakNet, 41 Palmeiro, Rafael, 99 , 112 , 114 Pawlenty, Tim, 22 Performance-enhancing drugs, 95 –96, 98 –116, 130 –31, 160 –63, 175 –76 Plantenga, Melissa, 33 , 41 , 42 , 173 Poe Financial Group (Bill Poe), 82 –86, 89 , 91 –92, 159 , 171 Polygraph tests, 113 –33, 167 , 181 . See also False negatives; False positives confessions elicited by, 118 , 120 –21, 125 –27, 130 countermeasures, 114 , 122 examiner characteristics and role, 113 –14 the legal system on, 117 –18 major problems with, 129 –30 in national-security screening, 96 –97, 118 , 121 –24, 127 –30, 175 –76 PCASS, 118 , 121 –24, 127 –30, 131 , 132 , 175 popularity of, 116 –18 screening vs. targeted investigation, 123 –24 Pre–post analysis, 158 –59 Predictably Irrational (Ariely), 158 Prediction of rare events, 124 PulseNet, 31 , 41 P-value, 179 , 180 Quetelet, Adolphe, 2 –3, 4 Queuing theory, 157 –58 Quindecillion, 137 , 144 , 177 Racial/minority groups credit scores and, 52 , 54 test fairness and, 64 , 65 , 70 , 72 –82, 94 , 168 –70, 180 Ramp metering, 13 –15, 16 , 19 , 20 –24, 157 , 158 –59, 180 –81 Randomization, 170 Rauch, Ernst, 87 Red State, Blue State, Rich State, Poor State (Gelman), 168 Reliability, 10 , 12 , 14 , 19 Riddick, Steve, 105 Riis, Bjarne, 103 , 105 , 110 Risk Management Solutions, 87 Risk pools, 86 –87, 89 –94, 168 , 171 Rodriguez, Alex, 114 Rodriguez, Ivan, 114 Rolfs, Robert, 36 Rooney, J. Patrick, 63 –65, 72 –74, 81 , 82 Rosenthal, Jeffrey, 143 –44, 146 , 150 , 151 –52, 153 , 177 –78, 179 Rowling, J. K., 116 SAT, 64 , 66 –82, 148 , 168 –70 average scores, 73 construction of, 71 –72 experimental section, 67 –68, 77 , 81 , 180 sample items, 68 –70, 75 , 77 –80 Schmitt, Alicia, 77 , 79 , 80 Schneier, Bruce, 133 Sensitivity, 175 September 11 terrorist attacks, 2 , 131 , 134 –35, 147 “Shoe leather,” 166 , 167 Simpson’s paradox, 169 –70 Simulation, 9 Sinclair, Larry, 116 Skilling, Jeff, 116 Smith, Michelle, 108 Smoking–lung cancer correlation, 43 , 60 –61, 173 Snow, John, 34 –35, 38 Soboleva, Yelena, 109 Sosa, Sammy, 98 Specificity, 175 Spinach contamination, 26 –27, 33 –34, 35 –43, 165 , 167 , 173 –74. See also E. coli outbreak Statistical models, 25 –61, 163 –67. See also Cause–effect; Credit scores; Epidemiology defined, 60 the educated guess in, 25 , 29 , 30 , 41 , 44 , 47 , 164 of storm losses, 87 –88, 93 the virtue of being wrong, 44 , 61 , 163 , 165 Statistical significance, 179 Statistical testing, 142 , 143 , 146 , 150 , 152 –53, 178 Statistical thinking, 3 , 41 –42 everyday thinking compared with, 155 examples of, 155 –81 Statistics for Experimenters (Box, Hunter, and Hunter), 159 Stats: Data and Models (De Veaux), 175 , 178 Still Stuck in Traffic (Downs), 13 Stratification, 91 , 170 , 172 , 173 Taleb, Nassim, 159 Terrorists, identifying, 131 –35, 167 , 176 Test item fairness, 65 –82, 91 , 94 , 168 –70, 173 , 179 –80. See also SAT Testa, Len, 5 , 166 –67, 181 Thompson, David, 96 , 97 , 122 Thun, Michael, 25 Towers Perrin, 90 “Triple convergence” principle, 13 Tversky, Amos, 155 Tygart, Travis, 102 , 110 University of California, Berkeley, 13 –14 Variability, 156 –57 commuting time and, 9 –12, 14 , 15 –16, 24 Disney World queue waiting time and, 8 , 15 –16, 19 –20 drug tests and, 160 –63 hurricane insurance and, 159 –60 Vindicated (Canseco), 114 Vitter, David, 117 Voting behavior, 168 Wallace, Mike, 116 Waller, Edward, 5 White, Kelli, 104 , 109 Wolens, Steven, 25 , 28 , 59 World Anti-Doping Agency (WADA), 96 , 111 , 161 Wu, Chi Chi, 54 Yesalis, Charles, 108",
        "char_count": 10923
      },
      {
        "heading": "Chapter 12",
        "text": "Table of Contents Cover Page Numbers Rule Your World Copyright Page Dedication Contents Acknowledgments Introduction 1 Fast Passes / Slow Merges The Discontent of Being Averaged 2 Bagged Spinach / Bad Score The Virtue of Being Wrong 3 Item Bank / Risk Pool The Dilemma of Being Together 4 Timid Testers / Magic Lassos The Sway of Being Asymmetric 5 Jet Crashes / Jackpots The Power of Being Impossible Conclusion Notes Index",
        "char_count": 424
      }
    ]
  },
  "collider": {
    "meta": {
      "key": "collider",
      "title": "Collider",
      "creator": "Paul Halpern",
      "filepath": "G:/My Drive/15_E-BOOKS/file011688.epub",
      "subject": "Physics"
    },
    "chapters": [
      {
        "heading": "Chapter 1",
        "text": "Table of Contents Title Page Copyright Page Dedication Praise Acknowledgements Prologue Introduction Chapter 1 - The Secrets of Creation Chapter 2 - The Quest for a Theory of Everything Chapter 3 - Striking Gold Rutherford ’s Scattering Experiments Chapter 4 - Smashing Successes Chapter 5 - A Compelling Quartet Chapter 6 - A Tale of Two Rings Chapter 7 - Deep in the Heart of Texas Chapter 8 - Crashing by Design Chapter 9 - Denizens of the Dark Chapter 10 - The Brane Drain Chapter 11 - Microscopic Black Holes Conclusion Notes Further Reading Index",
        "char_count": 552
      },
      {
        "heading": "Chapter 2",
        "text": "This book is printed on acid-free paper. Copyright © 2009 by Paul Halpern. All rights reserved Published by John Wiley & Sons, Inc., Hoboken, New Jersey Published simultaneously in Canada Photo credits: Courtesy of the AIP Emilio Segre Visual Archives, 123; courtesy of the AIP Emilio Segre Visual Archives, Physics Today Collection, 91; courtesy of the AIP Emilio Segre Visual Archives, Rutherford Collection, 54; photographs by Maximilien Brice, copyright © CERN, published by permission of CERN, 171, 173; photograph by Joao Pequenao, copyright © CERN, published by permission of CERN, 215; all other photos are from the author’s collection. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600, or on the web at www.copyright.com . Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions . Limit of Liability/Disclaimer of Warranty: While the publisher and the author have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Neither the publisher nor the author shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages. For general information about our other products and services, please contact our Customer Care Department within the United States at (800) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic books. For more information about Wiley products, visit our web site at www.wiley.com . Library of Congress Cataloging-in-Publication Data: Halpern, Paul, date. Collider : the search for world’s smallest particles / by Paul Halpern. p. cm. Includes bibliographical references and index. eISBN : 978-0-470-48621-4 1. Large Hadron Collider (France and Switzerland) 2. Particles (Nuclear physics) 3. European Organization for Nuclear Research. I. Title. QC787.P73H35 2009 539.7’376094—dc22 2009007114",
        "char_count": 3070
      },
      {
        "heading": "Chapter 3",
        "text": "Acknowledgments Thanks to the many researchers at CERN who took the time to speak with me about their work and show me around the facilities during my visit. In particular, I would like to thank Michael Rijssenbeek, head of the Stony Brook group working on ATLAS, for his hospitality in discussing aspects of the project with me and for organizing a full schedule of meetings that were extremely informative. I would also like to express my deep appreciation to Venetios Polychronakos, Larry Price, Charlie Young, Ashfaq Ahmad, Adam and Katie Yurkewicz, Alexander Khodinov, Jason Farley, Julia Gray, and Jet Goodson. Many thanks to David Cassidy and Adam Yurkewicz for reading over sections of the text and making suggestions. I would also like to thank J. David Jackson of UC Berkeley and the Lawrence Berkeley National Laboratory for his useful comments. Thanks to David Brin for kindly offering permission to include a quote from his novel Earth and to Herman Wouk for graciously allowing me to include a quote from A Hole in Texas. I thank my editors at Wiley, Constance Santisteban and Eric Nelson, for their confidence, help, ideas, and vision, and my agent, Giles Anderson, for his thoughtful guidance and support. I appreciate the support of my colleagues at the University of the Sciences in Philadelphia for this and other writing projects, including Phil Gerbino, Elia Eschenazi, Jude Kuchinsky, Brian Kirschner, Phyllis Blumberg, Steve Rodrigue, Sergio Freire, Bernard Brunner, Jim Cummings, Ping Cunliffe, Roy Robson, David Traxel, Justin Everett, Deirdre Pettipiece, K. Shwetketu Virbhadra, and many others. Thanks also to my friends with whom I have exchanged many intriguing ideas throughout the years, including Fred Schuepfer, Michael Erlich, Fran Sugarman, Mitchell and Wendy Kaltz, Simone Zelitch, Doug Buchholz, Bob Jantzen, Robert Clark, Scott Veggeberg, Evan Thomas, Dubravko Klabucar, Elana Lubit, and the late Donald Busky. Many thanks to my wife, Felicia, and my sons, Aden and Eli, for offering a steady source of love, warmth, and ideas. I also appreciate the support of my parents, Stan and Bunny Halpern; my in-laws, Joseph and Arlene Finston; Shara and Richard Evans; Lane and Jill Hurewitz; Janice, Richard, Jerry, Dolores, Michael, and Maria Antner; Dena and Amritpal Hatton; Aaron Stanbro; Kenneth, Alan, Beth, Tessa, Richard, Anita, Emily, and Jake Halpern; and the rest of my family.",
        "char_count": 2419
      },
      {
        "heading": "Chapter 4",
        "text": "Prologue Journey to the Heart of the Large Hadron Collider The ATLAS complex, home to the largest scientific measuring device in the world dedicated to particle physics, offers no hint of its grandeur from street level. From Route de Meyrin, the heavily trafficked road that separates its ground-level structure from CERN’s main campus, it looks just like a warehouse near an ordinary filling station. Until I walked through the doors of its main entrance, I wasn’t quite sure what to expect. CERN, the European Organization for Nuclear Research (from the French acronym for Conseil Européen pour la Recherche Nucléaire), located on the Swiss-French border near Geneva, prides itself on its openness. Unlike a military facility, it allows anyone with permission to visit to snap pictures anywhere. Nevertheless, the dangerous and delicate nature of modern particle detectors warrants extremely tight protocols for entering the “caverns” where they are housed. To tour a site that wasn’t yet completely finished, I put on a helmet like that a construction worker would use. My hosts, researchers Larry Price and Charlie Young, were wearing radiation badges—practice for the precautions needed when the beam line would be running. After getting final clearance, they entered the code for the gateway to the inner sanctum, and it electronically opened. Before journeying underground, we viewed the two enormous shafts used to lower the detector’s components more than 350 feet down. I stood on the brink of one of these wells and gazed into the abyss. Awe and vertigo rivaled for my attention as I craned my neck to try to see the bottom. Above the other well a giant crane was poised to lower parts down below. Transporting the original components of the detector from the various places they were manufactured and then putting them all together within such deep recesses in such a way that their delicate electronics weren’t destroyed surely was an incredible undertaking. The meticulous planning for such a complex project was truly phenomenal—and it continues. We took a speedy elevator ride down to what is called “beam level.” Now we were at the same depth as the beam pipes for the Large Hadron Collider (LHC)—the vast ring that will be used to collect protons and other particles, accelerate them in opposite directions, and smash them together at record energies. The ATLAS detector is located at one of the intersection points where protons will collide head on. Half of the detector is above the beam level and half below to accommodate the floods of particles gushing out in all directions from these crashes. The passages from the elevator to the control rooms and viewing platform are twisty, to provide barriers in case of a radiation leak. Most forms of radiation cannot travel through thick walls. Gauges sample the radiation levels to try to minimize human exposure. The air in the hallways below seemed a bit stale. Pumped in by means of the ventilation system, it is monitored extremely closely. One of the components of the detector is liquid argon, cooled to only a few degrees above absolute zero—the baseline of temperature. If for some reason the argon heated up suddenly, became gaseous, and leaked, it could rapidly displace all of the breathable air. Warning systems are everywhere; so if such a danger were imminent, workers would be urged to escape via elevator before it was too late. I finally reached the viewing platform and was astounded by the panorama in front of me. Never before had I seen such a vast array of sparkling metal and electronics, arranged in a long, horizontal cylinder capped with a giant shiny wheel of myriad spokes—nicknamed the “Big Wheel.” It was like encountering the largest alien spaceship imaginable—docked in an equally vast spaceport. If massive new particles are discovered in coming years—such as the Higgs boson, theorized to supply mass to other natural constituents—this could well be the spawning ground. It would come not with the push of a button and a sudden flash but rather through the meticulous statistical analysis of gargantuan quantities of data collected over a long period of time. Not quite as romantic as seeing a new particle suddenly materialize from out of the blue, but statistics, not fireworks, is the way particle discoveries transpire these days. The inner part of the detector had been hermetically sealed long before my visit, so it was impossible to see inside. Of the outer part, I could barely make out the vast toroidal (doughnut-shaped) magnets that serve to steer the charged elementary particles that escape the inner core. Researchers call these penetrating particles, similar to electrons but more massive, muons. Indeed the main reason for the detector’s huge size is to serve as the world’s finest muon-catcher. Each “spoke” of the Big Wheel is a muon chamber. Modern particle detectors such as ATLAS are a bit like successive traps—each designed to catch something different. Particles that slip through one type might be caught in another. The net effect of having an assortment is to capture almost everything that moves. Suppose a house is full of various vermin and insects. Placing a mousetrap on the kitchen floor might snag some of the rodents but would allow ants to roam free. An ant trap might lure some of those insects but would be inadequate for flies. Similarly, ATLAS consists of multiple layers—each designed to pin down the properties of certain categories of particles. Some particles, such as electrons and photons (particles of light), are captured by one of the inner layers, called the electromagnetic calorimeter. That’s where the light-sensitive liquid argon takes part in measuring their energy released. Other particles, such as protons and neutrons, are stopped by a denser layer just beyond, called the hadronic calorimeter. Those were the inner layers I couldn’t see. For the most part, muons evade the inner detector completely. They are the only charged particles that manage to make it through. That’s why the outer envelope of the detector is called the muon system. It consists of what looks like a sideways barrel—centered on the beam line—framed on both sides by two massive “end-caps.” These serve to track as many muons as possible—making the detector ideal for any experiments that produce such particles. As good as ATLAS is at trapping particles, some do manage to make it through all of the hurdles. Extremely lightweight neutral particles, called neutrinos, escape unhindered. There’s not much the researchers can do about that, except to calculate the missing energy and momentum. Neutrinos are notoriously hard to detect. Also, because the beam line obviously can’t be plugged up, collision products are missed if they head off at low enough angles. Given that most interesting results involve particles whirling off at high angles from the beam line, the lack of information about those traveling close to the beam line is not critical. A Medusa’s head of cables connects the detector’s delicate electronics with the outside world, allowing for remote data collection. These connections make it so that relatively few scientists working on the project will need to venture down to the actual detector, once it is operational. Using a system called the Grid, scientists will be able to access and interpret the torrent of information produced via computers located in designated centers around the globe. Then they will look for special correlations, called signatures, corresponding to the Higgs boson and other sought-after particles. It was humbling to think that the huge artificial cave housing ATLAS comprises but a portion of the LHC’s scope. Through one of the cavern walls, beam pipes extend from ATLAS into the formidable tunnel beyond. Miles from where I stood lay other grottos housing various other experiments: CMS, a multipurpose detector with a strong central magnet; ALICE, a specialized detector designed to examine lead-ion collisions; LHCb, another specialized detector focusing on the interactions of what are called bottom quarks; and several other devices. Back on the surface, I took some time to explore the French countryside above the LHC ring. Most of the seventeen-mile-long circular tunnel lies under a bucolic border region known as Pays de Gex, or “Gex Country.” Passport in hand, I caught the bus from Geneva’s central station that heads toward the French village of Ferney-Voltaire. According to the map I had with me, the village is roughly situated above one part of the LHC tunnel. In that quaint locale, where Voltaire once philosophized, mail is still delivered by bicycle. Boulangeries bake fresh baguettes according to the ancient tradition, and fromageries serve regional cheeses such as tangy Bleu de Gex. Stucco houses, faded yellow or green and capped with burgundy-tiled roofs, line the roads out of town. On the face of it, the community seemed little touched by modernity. The illusion was suddenly broken when I saw a white van turn the corner. Its prominently displayed CERN logo reminded me that this cozy village and its pastoral surroundings play a role in one of the leading scientific endeavors of the twenty-first century. Back on the Meyrin campus of CERN, I noted a similar juxtaposition of old and new. CERN is a laboratory keenly aware of its history. Its streets are named after a wide range of people who have spent their careers trying to discover the fundamental components of nature—from Democritus to Marie Curie and from James Clerk Maxwell to Albert Einstein. Scattered around its museum area are an assortment of accelerators and detectors of various shapes, sizes, and vintage. Comparing the small early detectors to ATLAS served to highlight the unbelievable progress made in particle physics during the last seventy-five years. CERN makes good use of many of its historical devices. Particles entering the LHC will first be boosted by several different older accelerators—the earliest built in the 1950s. It is as if the spirits of the past must offer their blessings before the futuristic adventures begin. With this lesson in mind, before propelling ourselves into modern issues and techniques, we must first boost ourselves up to speed with a look at the history of elementary particles and the methods used to unravel their secrets. I intend this book not just as a guide to the Large Hadron Collider and the extraordinary discoveries likely to be made there, but also as a scientific exploration of humankind’s age-old quest to identify nature’s fundamental ingredients. Like a ride through a high-energy accelerator, it is a fantastic journey indeed.",
        "char_count": 10677
      },
      {
        "heading": "Chapter 5",
        "text": "Introduction The Machinery of Perfection Does not so evident a brotherhood among the atoms point to a common parentage? . . . Does not the entireness of the complex hint at the perfection of the simple? . . . Is it not because originally, and therefore normally, they were One—that now, in all circumstances—at all points—in all directions—by all modes of approach—in all relations and through all conditions—they struggle back to this absolutely, this irrelatively, this unconditionally one? —EDGAR ALLAN POE (EUREKA) Deep in the human heart is an irrepressible longing for unity. Symmetry and completeness guide our sense of beauty and steer us toward people, places, and things that seem balanced and whole. Architects understand this quest when they make use of geometric principles to design aesthetically pleasing structures. Photographers tap into this yearning when they frame their images to highlight a scene’s harmonies. And lovers realize this desire when they seek the comfort of profound connection. Where might we find perfection? Is it by digging deep into our past to an ancient time before symmetry was shattered? Or is it by digging deep underground, crafting mighty machinery, and shattering particles ourselves—hoping that in the rubble we might somehow find fossils of a paradise lost? The opposite of beauty is the macabre. Unbalanced things, like broken art or atonal music, make us uneasy. Perhaps no writer better expressed this contrast than Edgar Allan Poe—a master at capturing the gorgeous and the gruesome—who spent much of his final years developing and promoting an attempt to understand the deep unity underlying creation. His prose poem Eureka suggests that the universe’s original oneness longs to reconstitute itself; like the unsteady House of Usher, it pines for its native soil. Contemporary physics, a triumph of generations of attempts to map the properties of nature, contains satisfying islands of harmony. Yet it is a discipline with uncomfortable inequities and gaps. Completing the cartography of the cosmos has called for intrepid exploration by today’s ablest researchers. In understanding the forces that steer the universe, and trying to unify them into a single explanation of everything, most of the greatest strides have been made in the past two centuries. In the mid-nineteenth century, the brilliant Scottish physicist James Clerk Maxwell demonstrated that electricity and magnetism are integrally connected, and that the relationship between them could be expressed through a set of four simple equations. Maxwell’s equations are so succinct they can literally fit on a T-shirt—as evidenced by a popular fashion choice at many physics conferences. These relationships offer a startling conclusion: all light in the world, from the brilliant yellow hues of sunflowers to the scarlet shades of sunsets, consists of electromagnetic waves—electricity and magnetism working in tandem. By the early twentieth century, physicists had come to realize that these waves always travel in discrete packets of energy, called photons. These hop at the speed of light between electrically charged objects, causing either attraction or repulsion. Hence, all electromagnetic phenomena in the world, from the turning of a compass needle to the blazing of lightning in the sky, involve the exchange of photons between charged particles. In addition to electromagnetism, the other known natural interactions include two forces that operate on the nuclear scale—called the weak and strong interactions—and the apple-dropping, planet-guiding force of gravitation. These four forces proscribe all of the ways material objects can attract, repel, or transform. Whenever motion changes—a sudden jolt, a subtle twist, a quiet start, or a screeching halt—it is due to one or more of the four natural interactions. Each interaction occurs by means of its own exchange particle, or set of particles. An exchange particle works by drawing other particles together, pushing them apart, or changing their properties. It’s like a Frisbee game in which the players move closer to catch the Frisbee or step back when it hits them. The process of tossing something back and forth cements the players’ connection. Given Maxwell’s fantastic success with marrying electricity and magnetism, many physicists have tried to play matchmaker with the other forces. Like party hosts trying to facilitate connections among their guests, researchers have looked for commonalities as a way of making introductions. Could all four interactions be linked through a mutual set of relationships? The most successful unification so far has been the melding of electromagnetism and the weak force, performed by American physicists Steven Weinberg and Sheldon Glashow and Pakistani physicist Abdus Salam (each working independently). In unity, these would be known as the electroweak interaction. There were many tricky details that needed to be ironed out, however, before the match could be made. One of the major issues had to do with a great disparity in the masses of the exchange particles corresponding to each force. While photons have zero mass, the carriers of the weak interaction are bulky—signified by the latter force’s much shorter range. The difference between electromagnetic and weak exchanges is a bit like tossing a foam ball across a field and then trying to do the same with a lead bowling ball. The latter would scarcely spend any time in the air before plunging to the ground. With such different volleys, how could the two forces play the same game? Sometimes, however, inequities emerge from once-balanced situations. Symmetry, as collectors of ancient sculpture know, can be fragile. Perhaps the very early universe, instants after the fiery Big Bang that ushered in its birth, was in a fleeting state of harmony. All forces were perfectly balanced, until some transformation tilted the scales. Equity shattered, and some of the exchange particles became bulkier than others. Could today’s unequal forces constitute the culmination of a universal symmetry-breaking process? In 1964, British physicist Peter Higgs proposed a promising mechanism for spontaneously breaking the universe’s initial symmetry. His mechanism requires a special entity, dubbed the Higgs field, that pervades all of space and sets its fundamental energy scale. (A field is a mathematical description of how properties of a force or particle change from point to point.) Within its internal structure is a marker called a phase angle that can point anywhere around a circle. At extremely high temperatures, such as the nascent moments of the universe, the direction of this marker is blurry, like a rapidly spinning roulette wheel. However, as temperatures lower, the roulette wheel freezes, and the marker points to a random direction. The Higgs field’s initial symmetry, with all angles being equal, has spontaneously broken to favor a single angle. Because the Higgs field sets the baseline for the vacuum (lowest energy) state of the universe, this transforms during the symmetry breaking from a situation called the true vacuum, in which the lowest energy is zero, to a false vacuum, in which it is nonzero. Following Albert Einstein’s famous dictum E = mc 2 (energy equals mass times the speed of light squared), the acquired energy becomes mass and is shared among many elementary particles, including the carriers of the weak interaction. In short, the halting of the Higgs field’s “roulette wheel” channels mass into the weak exchange (and other) particles and explains why they are bulky while the photons remain massless. With its phenomenal ability to bestow mass on other particles, the Higgs has acquired the nickname the “God particle.” If the Higgs mechanism is correct, a remnant of the original field should exist as a fundamental particle. Because of its high mass—more than a hundred times higher than the protons that compose the cores of hydrogen atoms—it would be seen only during energetic particle events, such as high-energy collisions. Despite decades of searching, this key ingredient for electroweak unification has yet to be found. Hence, the elusive God particle has become the holy grail of contemporary physics. Aside from the missing Higgs particle, electroweak unification has proven enormously successful. Its importance is such that it is known as the Standard Model. However, much to the physics community’s disappointment, attempts to unite the electroweak interactions with the other two forces have yet to bear fruit. At least the electroweak and strong forces can be written in the same language—the lexicon of quantum mechanics. Developed in the 1920s, quantum mechanics is a powerful toolbox for describing the subatomic realm. Although it offers accurate odds for the outcome of physical events such as scattering (the bouncing of one particle off another) and decay, it frustratingly contains a built-in fuzziness. No matter how hard you try to nail down the precise course of events for natural occurrences on the subatomic scale, you are often left with the flip of a coin or the roll of a die. Einstein detested having to make wagers on what ought to be known with crystal clarity and spent his later years trying to develop an alternative. Nevertheless, like a brilliant but naughty young Mozart, quantum mechanics has offered enough stunning symphonies to hide its lack of decorum. Physicists who relish exactness tend to turn toward Einstein’s own masterpiece, the general theory of relativity, which offers a precise way of describing gravity. Unlike theories of the other interactions, it is deterministic, not probabilistic, and treats space and time as participants rather than just background coordinates. Although there have been numerous attempts, there is no broadly accepted way of placing gravity on a quantum footing. It’s like trying to assemble a winning team for a spelling championship but finding that one of the four players, though an expert, speaks a completely different language. Researchers are left with an odd puzzle. Of the four fundamental interactions, two, electromagnetism and the weak, appear to fit together perfectly. The strong interaction seems as if it ought to fit, but no one has quite been able to match it up. And gravity seems to belong to another set of pieces altogether. How then to reconstruct the original symmetry of the cosmos? Other areas of asymmetry in contemporary physics include a huge discrepancy between the amount of matter and antimatter (like matter but oppositely charged) in the universe—the former is far more plentiful—and behavioral differences between the particles that build up matter, the fermions, and those that convey forces, the bosons. Like the Montagues and the Capulets, fermions and bosons belong to separate houses with distinct traditions. They like to group themselves in different ways, with fermions demanding more breathing room. Attempts to reconcile the two, in a grand cosmic union called supersymmetry, require that each member of one family have a counterpart in the other. These supersymmetric companions could also help explain a deep conundrum in astronomy: why galaxies appear to be steered by more mass than they visibly contain. Could supersymmetric companions constitute some or all of this dark matter? So far such invisible agents have yet to be found. Such gaps and discrepancies rattle the human spirit. We like our science to tell a full story, not a shaggy-dog tale. If we can’t think of a solid ending, perhaps we haven’t imagined hard enough—not that theoretical physicists haven’t tried. For each scientific mystery a bevy of possible explanations have sprung up with varying degrees of plausibility. Recent theoretical efforts to replace elementary particles with vibrating strands or membranes of energy—in what are called string theory and M-theory, respectively—have captured the imagination. These make use of supersymmetry or extra dimensions beyond space and time to explain in an elegant way some of the differences between gravity and the other interactions. An attractive mathematical feature of these theories is that while in prior approaches some calculations involving infinitesimal point particles yielded nonsensical results, using finite strands or membranes removes these problems. Given the difficulties with completing unification through extending the Standard Model, a number of prominent theorists have been won over to the mathematical elegance of these novel approaches. Steven Weinberg, for instance, once remarked, “Strings are the only game in town.” 1 Detractors of string theory and M-theory, on the other hand, question their physical relevance because they contain undetermined values and require unseen dimensions. In the array of all configurations, the real world is just a subset of myriad possibilities. If a theory has enough free parameters, opponents point out, it could represent virtually any kind of particle or interaction. It’s like a writer who compares himself to Dickens churning out tens of thousands of pages of uneven prose and instructing an editor to piece together the most Dickensian passages. To echo Truman Capote’s famous remark, “that’s not writing; that’s typing,” detractors could well say about string theory, “that’s not physics; that’s model-making.” Even the most stalwart supporters and fervent detractors would agree that the ultimate test of a theory lies in its experimental verification. So far, for string theory and M-theory, such evidence has been lacking. As noted theorist Bryce De Witt once told me, “With M-theory I feel dubious about graduate students [going into a field] where there is not one shred of experimental evidence supporting it.” 2 From the 1930s until the mid-1990s, enormous strides were made in particle physics by means of high-energy experimentation with various types of accelerators. An accelerator is a device that uses electric and magnetic fields in tandem to steer particles (such as protons) along tracks or rings while propelling them to higher and higher energies. These particles are then allowed to collide, converting their energy into a multitude of collision products. Following Einstein’s equation, the higher the energy at the collision point, the greater the chance of massive particles being produced. While older accelerators used fixed targets, physicists came to realize that smashing particles together head-on produced even higher energies. Accelerators in which particles crash into one another are called colliders. During those pivotal decades, by using various types of detectors to collect and analyze collision data, researchers were able to identify a zoo of elementary particles. The major theoretical breakthroughs of those times were motivated by a need to organize these particles into families and to understand their decays and interactions. Physicists discovered that all matter particles are either hadrons (subject to the strong force) or leptons (unaffected by the strong force). Protons are examples of hadrons and electrons are examples of leptons. Hadrons are composed of elementary components called quarks—either two or three per particle—bound together by gluons. Quarks come in six varieties called flavors: “down,” “up,” “strange,” “charm,” “bottom,” and “top.” There are also six types of antiquarks, which are similar to quarks but oppositely charged. In that era of discovery, whenever novel theories were proposed, such as the quark model, researchers set out to test them through further experimentation. Testability lent certain theories a special relevance and clout—allowing them to raise their voices above others and demand to be heard. Upon verification, they could then say, “I told you so.” For example, the top quark, predicted in the 1970s, was identified in 1995 through an analysis of the collision debris of what was then the mightiest accelerator in the world: the Tevatron, at Fermi National Accelerator Laboratory (Fermilab) in Batavia, Illinois. Inaugurated in 1983, the Tevatron propels streams of protons and antiprotons (negatively charged, antimatter counterparts of protons) up to energies of about 1 TeV (Tera electron volts) each before bashing them together. One electron volt is the amount of energy involved in transporting a single electron or proton between the termini of a one-volt battery. Multiply that quantity by one trillion, and the result is 1 TeV—a colossal amount of energy for a minuscule elementary particle. As it turned out, the discovery of the top quark represented the last major triumph of the Tevatron—and of experimental high-energy physics for some time. Finding the Higgs particle, identifying supersymmetric companions, and other important goals seemed to require more energy than even that mighty machine could muster. Without the opportunity for experimental confirmation the chorus of contending theories began to resemble a meaningless cacophony. Only by building more energetic colliders to test these competing ideas could the malaise of theoretical physics be remedied and significance restored to its voice. The European Organization for Nuclear Research, better known by the acronym CERN (Conseil Européen pour la Recherche Nucléaire), took up the challenge. With the aim of finding the Higgs particle, discovering possible supersymmetric companions, discerning the nature of dark matter, exploring the possibility of hidden extra dimensions, understanding why there is an abundance of matter over antimatter in the universe, reproducing some of the conditions of the Big Bang, and resolving a host of other critical scientific issues, CERN would channel its resources into the construction of the largest and most powerful accelerator in the world, built at its headquarters near Geneva, Switzerland. After more than fifteen years of planning and more than eight billion dollars in funding, the Large Hadron Collider (LHC), science’s groundbreaking effort to unlock the deepest secrets of particle physics, is finally complete. It is truly the grandest experiment of all time—the pinnacle of humanity’s quest for unification. Befitting the pursuit of cosmic grandeur and unity, it is set in a stunning location. Query a world traveler about locales of striking beauty and harmony, and chances are Switzerland would be high up on the list. From its majestic mountains and crystalline lakes to its quaint cog railways and charming medieval towns, it is hard to imagine a better place to base a search for unification. Indeed the Swiss confederation, uniting inhabitants divided into four different official languages (French, German, Italian, and Romansch), several major religions (Protestant, Catholic, and other faiths), and twenty-six distinct cantons, physically isolated in many cases from one another, represents a model for bringing disparate forces together into a single system. Though in past centuries Switzerland experienced its share of turmoil, in more recent times it has become a haven for peace and neutrality. As Europe’s political frontiers have receded, many scientific roadblocks have fallen as well. The LHC crosses the Swiss-French border with the ease of a diplomat. Its seventeen-mile-long circular underground tunnel, recycled from a retired accelerator called the Large Electron-Positron Collider (LEP), represents a triumph for international cooperation. Only by working in unison, it reminds us, might we discover the secrets of natural unity. American researchers form a large contingent in the major LHC experiments. They are proud to contribute to such a pivotal venture. Although the United States is not a member of CERN, it donates ample funds toward LHC research. While celebrating Europe’s achievements, however, many American physicists still quietly mourn what could have taken place at home. In 1993, the U.S. Congress voted to cut off funding for what would have been a far bigger, more powerful project, the Superconducting Super Collider (SSC). About fourteen miles of a planned fifty-four-mile tunnel in the region of Waxahachie, Texas, had already been excavated before the plug was pulled. Today that land sits fallow, except for the weed-strewn abandoned buildings on the site. Years of anticipation of novel discoveries were crushed in a single budgetary decision. President Bill Clinton sent a letter to the House Appropriations Committee expressing his strong concerns: “Abandoning the SSC at this point would signal that the United States is compromising its position of leadership in basic science—a position unquestioned for generations.” 3 Nevertheless, tight purse strings won out over sweeping visions. The cancellation of the SSC shattered the plans of those who had made multiyear commitments to the enterprise and discouraged young researchers from pursuing the field. It would prove a horrendous setback for American high-energy physics, shifting the momentum across the Atlantic. By delivering a planned 20-TeV burst of energy with each collision, the particle-smasher in Texas would have been energetic enough to conduct a thorough search for the elusive God particle. Perhaps in its hatchery, supersymmetric companion particles would have been born, presenting themselves through their characteristic decay profiles. Dark matter could have made itself known in caverns deep beneath the Texas soil. The ramifications of string theory and other unification models could have been explored. Like the moon landings, these expeditions could have been launched from U.S. soil. With the LHC’s completion, the Tevatron will soon be obsolete and no more large American accelerators are planned. What went wrong? The reason lies with long-term planning and commitment to science, an area where sadly the United States has in recent times often fallen short. Each European member of CERN pledges a certain amount every year, depending on its gross national product. Thus the designers of the LHC could count on designated funding over the many years required to get the enterprise up and running. Already, the upgrades of coming years are being programmed. Foresight and persistence are the keys to the LHC’s success. Not that there haven’t been frustrating glitches and delays. Contemporary high-energy physics requires delicate instrumentation that must be aligned perfectly and maintained in extreme environmental conditions such as ultracold temperatures. Despite researchers’ best efforts, systems often fail. Originally supposed to go on line in 2005, the LHC wasn’t yet ready. Its opening was delayed again in 2007 because of accidental damage to some of its magnets. On September 10, 2008, proton beams were circulated successfully for the first time around the LHC’s large ring. Project leader Lyn Evans and the international team of researchers working at the lab were elated. “It’s a fantastic moment,” said Evans. “We can now look forward to a new era of understanding about the origins and evolution of the universe.” 4 Nine days later, however, that heady summer of hope screeched to a halt due to a devastating malfunction. Before particle collisions had even been attempted, a faulty electrical connection in the wiring between two magnets heated up, causing the supercooled helium surrounding them to vaporize. Liquid helium is a critical part of the LHC’s cooling system that keeps its superconducting magnets functioning properly. In gaseous form, the helium began to leak profusely into the vacuum layer that surrounds the system, thwarting attempts by emergency release valves to channel it off safely. Then came the knockout punch. The flood of helium slammed into the magnets, jostled them out of position, and destroyed more wiring and part of the beam pipe. Upon inspection, technicians realized that it would take many months to repair the damage, recheck the electrical and magnetic systems around the ring, and attempt operations once more. Currently, the LHC is scheduled to go on line in September 2009. When it is up and running, the LHC will be a marvel to behold—albeit remotely, given that its action will take place well beneath the surface. Burrowed hundreds of feet beneath the earth but only ten feet in diameter, the LHC tunnel will serve as the racetrack for two opposing beams of particles. Steered by more than a thousand gigantic supercooled magnets—the coldest objects on Earth—these particles will race eleven thousand times per second around the loop, traveling up to 99.999999 percent of the speed of light. Reaching energies up to 7 TeV each, the beams will be forced to collide at one of four designated intersection points. One of these collision sites houses the ATLAS (A Toroidal LHC ApparatuS), detector, a colossal instrument seven stories high (more than half the height of the Statue of Liberty) and spanning 150 feet (half the length of a football field) from end to end. Using sensitive tracking and calorimetry (energy-measuring) devices, it will monitor the debris of protons crashing together in its center, collecting an encyclopedia of data about the by-products of each collision. Halfway around the ring, another general- purpose detector called CMS (Compact Muon Solenoid) will employ alternative tracking and calorimetry systems to similarly collect reams of valuable collision data. At a third site, a specialty detector called LHCb (Large Hadron Collider beauty) will search for the decays of particles containing bottom quarks, with the hope of discovering the reason for the dearth of antimatter in the cosmos. Finally, at a fourth collision site, another specialized detector called ALICE (A Large Ion Collider Experiment) will be reserved for times of the year when lead ions are collided instead of protons. By smashing these together, researchers hope to re-create some of the conditions of the early universe. From each detector, based on careful assessment of the signals for possible new particles, the most promising information will be sent off for analysis via a global computing network called the Grid. A vast group of researchers from numerous countries around the world will wait eagerly for the LHC results, hoping to find signs of the Higgs, supersymmetric companions, and other long-hoped-for particles. Discovery of any of these would spur a renaissance in physics and an enormous boost for the scientific enterprise—not to mention grounds for a Nobel Prize. The world would celebrate the achievements of those involved in this extraordinary undertaking, including the hardworking Evans and the thousands of workers contributing their vital efforts and ideas to the project. If the Higgs is found, depending on exactly what mass it turns out to be, the Standard Model could be either confirmed or found in need of major revision. Some supersymmetric alternatives to the Standard Model predict multiple Higgs particles at various energies. Finding evidence of these would be a triumph for supersymmetric theories, especially if other supersymmetric particles are discovered along with them. At the energies of the LHC, most physicists expect to see some new particles. If all goes well, there should be enough for theorists to chew on for many years. Anticipation is high for the LHC, but so is apprehension. More than any other scientific device in recent memory, there has been an undercurrent of fear that its operation somehow places the Earth or even the whole universe at risk. Disseminated largely through the Internet, these views have caught flame (and been flamed) in numerous blogs and user groups. The principal culprits for the LHC’s supposed threats to our existence include voracious microscopic black holes, ferocious hypothetical particles called “strangelets,” magnetic monopoles, and other purported catalysts of doom. Apocalyptic fears are nothing new; many people choose to spend their time worrying about potential calamities such as the collision of asteroids or the evaporation of Earth by a nearby stellar explosion. What is novel about the LHC theories are worries about the world-gobbling powers of theoretical objects that have never been detected and could very well not even exist. Of these LHC doomsday scenarios, perhaps the most widespread is the notion that the intensity of the collisions would forge a mini-black hole at the collision site that would then grow to Earth-swallowing dimensions by ingesting more and more material, like the gelatinous creature in the horror film The Blob. Indeed, there are some theoretical speculations about the creation of microscopic gravitationally intense objects. However, the idea that mini-black holes would act like blobs is an unfortunate misconception; any objects created would be far too minuscule to pose a threat. Ordinary black holes are the products of the late-stage collapse of heavy stars, at least three times as massive as the Sun. They are called such because of their intense gravitational fields, which are so strong that within an invisible barrier called the event horizon not even light can escape. Typically, the way some black holes accrue matter is if they have companion stars; then they slowly absorb their unfortunate partner’s material and grow gradually over time. Miniature black holes are a hypothetical concept based on the premise of concentrating a large amount of mass in a region the size of an elementary particle. Their event horizons would be so small that the minute bodies would have virtually no gravitational effect on the space a mere fraction of an inch away, let alone elsewhere in the Earth. Moreover, due to a process called Hawking radiation, they would almost immediately evaporate—decaying into other particles. Thus, mini-black holes would scarcely have the opportunity to exist, let alone to grow beyond subatomic proportions. In short, they’d have no chance of destroying even part of the LHC, let alone the Earth. As Peter Higgs told the Independent , “The black hole business has become rather inflated. Even the theorists who are suggesting that mini-black holes are things that could be produced are not predicting black holes large enough to swallow up chunks of the universe. I think the publicity has rather got out of hand and some people have misunderstood it.” 5 In the days before the aborted start-up in September 2008, apocalyptic worries dominated news stories about the collider. “Meet Evans the Atom, Who Will End the World on Wednesday,” proclaimed a headline to a piece in the British tabloid Daily Mail about the LHC’s project leader. The story begins by mentioning that as a child the Welsh-born Evans made explosives with his chemistry set that “blew the fuses of [his] whole house a few times.” 6 Could the whole world, the piece considers, be the next thing for him to blow up? One team of activists, led by former nuclear safety official Walter Wagner, has gone so far as to sue the LHC, pressing for a halt to its operations. In response to public concerns about the LHC’s purported dangers, researchers working on the project have issued detailed analyses of potential threats to the planet, demonstrating how none of these are worth fretting about. A 2003 report, “Study of Potentially Dangerous Events during Heavy-ion Collisions at the LHC,” found that “classical gravitational effects [of mini-black holes] are completely negligible for LHC energies and luminosities.” 7 A follow-up study conducted in 2008 similarly indicated that mini-black holes would present no danger. Both reports pointed out that if such entities could be created, they would have been produced in energetic cosmic rays that continuously rain down upon the Earth. The mere fact that we are here means that anything forged at such energies wouldn’t be threatening. Indeed, the French and Swiss residents living above the particle-smasher seem for the most part calm and happy. CERN prides itself on openness, publishing all of its decisions. It also takes great pains to respect the environment. The land above the collider is largely unspoiled and clean, flourishing with farms and vineyards. If the agency believed there was any reasonable chance that the LHC would imperil the Earth, the device would have been canceled. Another aspect of the LHC that has caused some consternation as well as excitement is its ability to reproduce some of the conditions believed to have occurred less than one-trillionth of a second after the Big Bang. Does that mean it will actually create a new cosmic explosion and potentially destroy our own universe? Hardly. Rather, it is the energy per particle that will resemble conditions from the dawn of time. Forget about astronomical bursts; by human standards the actual energies produced are small—less than a billionth of a dietary calorie per collision! For a subatomic particle, nevertheless, that’s one hefty meal. By recording and studying events at such energies, scientists will be able to understand what happened during the actual creation of the cosmos—without risking engendering a new one themselves. Unraveling the secrets of the origin and composition of the universe is hardly a new venture, although tools such as the LHC make this much easier. Philosophers and scientists have long wondered what happened during the earliest moments of time. What are the smallest things in the world and how do all of the pieces fit together? Could there be a theory of theories explaining all aspects of nature, from the tiniest particles to the cosmos itself? It is wondrous that such longstanding riddles may soon be answered.",
        "char_count": 33608
      },
      {
        "heading": "Chapter 6",
        "text": "1 The Secrets of Creation When in the height heaven was not named, And the earth beneath did not yet bear a name, And the primeval Apsu, who begat them, And chaos, Tiamut, the mother of them both Their waters were mingled together, And no field was formed, no marsh was to be seen; When of the gods none had been called into being, And none bore a name, and no destinies were ordained . . . —ENUMA ELISH, THE BABYLONIAN EPIC OF CREATION, TRANSLATED BY L. W. KING Hidden among the haze of cosmic dust and radiation, buried in the very soil we walk upon, locked away in the deep structure of everything we see, feel, or touch, lie the secrets of our universal origins. Like the gleaming faces of a beautiful but impenetrable diamond, each facet of creation offers a glimpse of a wonderful, yet inscrutable, unity. With probing intellect, humankind longs to cut through the layers and reach the core of truth that underlies all things. What is the universe made of? What are the forces that affect our universe? How was the universe created? Ancient Greek philosophers offered competing explanations of what constitutes the tiniest things. In the fifth century BCE, Leucippus and Democritus, the founders of atomism, argued that materials could be broken down only so far before their basic constituents would be reached. They imagined these smallest, unbreakable pieces, or “atoms,” as possessing a variety of shapes and sizes, like an exotic assortment of pebbles and shells. Another view, proposed by Empedocles, is that everything is a mixture of four elements: fire, water, air, and earth. Aristotle supplemented these with a fifth essence, the void. For two millennia these classical elements were the assumed building blocks of creation until scientific experimentation prodded Europe toward an empirical view of nature. In his influential book The Sceptical Chymist , Robert Boyle (1627-1691) demonstrated that fire, air, earth, and water couldn’t realistically be combined to create the extraordinary range of materials on Earth. He argued for a new definition of the term “element” based on the simplest ingredients comprising any substance. Chemists could identify these, he argued, by breaking things down into their most basic parts, rather than through relying on philosophical speculation. Boyle’s clever insight challenged experimenters to discover, through a variety of methods, the true chemical elements—familiar to us (in no particular order) as hydrogen, oxygen, carbon, nitrogen, sulphur, and so forth. Whenever children today combine assorted liquids and powders in their chemistry sets, set off bubbling reactions, and concoct colorful, smelly, gooey by-products, they owe a debt to Boyle. Boyle was an ardent atomist and a meticulous experimenter. Refusing to accept the hypothesis on faith alone, he developed a clever experiment designed to test the concept that materials are made of small particles—which he called corpuscles—with empty space between them. He started with a curved glass tube, exposed to the air on one end and closed on the other. Filling the open end with mercury, he trapped some of the air in the tube and pressed it into a smaller and smaller volume. Then, by slowly removing the mercury, he noted that the trapped air expanded in inverse proportion to its pressure (a relationship now called Boyle’s law). He reasoned that this could happen only if the air was made of tiny components separated by gaps. Manchester chemist John Dalton was an earnest young Quaker whose research about how different substances react with one another and combine led him to the spectacular insight that each chemical element is composed of atoms with distinct characteristics. Dalton was the first, in fact, to use the word “atom” in the modern sense: the smallest component of a chemical element that conveys its properties. Dalton developed a clever visual shorthand for showing how different atoms combine. He depicted each type of element as a circle with a distinctive mark in the center—for example, hydrogen with a dot, sodium (which he called “soda”) with two vertical lines, and silver with the letter “s.” Dalton counted twenty elements; today we know of ninety-two natural elements and at least twenty-five more that can be produced artificially. By arranging his circular symbols into various patterns, he showed how compounds such as water and carbon dioxide could be assembled from the “Lego blocks” of elements such as hydrogen, oxygen, and carbon. In what he called the law of multiple proportions, he demonstrated that the elements forming particular substances always combined in the same fixed ratios. Dalton also attempted to characterize atoms by their relative weights. Although many of his estimates were off, his efforts led to simple arithmetical ways of understanding chemistry. In 1808, Scottish chemist Thomas Thomson combined oxalic acid (a compound of hydrogen, carbon, and oxygen) with several different elements, including strontium and potassium, and produced a variety of salts. Weighing these salts, he found proportionalities corresponding to differences in the elements he used. Thomson’s results, published in his book A System of Chemistry , helped Dalton’s theories gain wide acceptance in the scientific community. One thing that Dalton’s theories couldn’t do was predict new elements. Arranging atoms in order of their relative weights didn’t offer enough information or impetus for scientists to infer that others existed. It’s as if a mother brought three of her sons to a new school to register them and reported only their names and ages. Without saying more about her family, the teachers there would have no reason to believe she had other kids that were older, younger, or in between. Indeed the family of elements was much larger than Dalton surmised. By the mid-nineteenth century the number of known elements had tripled to about sixty. Curiously, some of these had shared properties—even ones associated with much different atomic weights. For example, sodium and potassium, though separated in terms of weight, seemed to react with other substances in similar ways. In the late 1860s, Russian chemist Dmitry Mendeleyev decided to write a state-of-the-art chemistry textbook. To illustrate the great progress in atomic theory, he included a chart depicting all of the then-known elements in order of weight. In a bold innovation, he listed the elements in table form with each row representing elements with similar properties. By doing so, he illustrated that elements fall into patterns. Some of the spaces in what became known as the periodic table he left blank, pointing to elements he predicted would later be discovered. He was absolutely right; like a solved Sudoku puzzle, all of the gaps in his table were eventually filled. Science didn’t realize the full significance of Mendeleyev’s discovery until the birth of quantum mechanics decades later. The periodic table’s patterns reveal that the Democritean term “atom” is really a misnomer; atoms are indeed “breakable.” Each atom is a world unto itself governed by laws that supersede Newtonian mechanics. These laws mandate a hierarchy of different kinds of atomic states, akin to the rules of succession for a monarchy. Just as firstborn sons in many kingdoms assume the throne before second-born sons, because of quantum rules, certain types of elements appear in the periodic table before other kinds. The atom has sometimes been compared to the solar system. While this comparison is simplistic—planetary orbits don’t obey quantum rules, for one thing—there are two key commonalities. Both have central objects—the Sun and what is called the atomic nucleus—and both are steered by forces that depend inversely on the squares of distances between objects. An “inverse-square law” means that if the distance between two objects is doubled, their mutual force diminishes by a factor of four; if their distance is tripled, their force weakens ninefold, and so forth. Physicists have found that inverse-square laws are perfect for creating stable systems. Like a well-designed electronic dog collar it allows some wandering away from the house but discourages fleeing the whole property. While scientists like Boyle, Dalton, and Mendeleyev focused on discovering the ingredients that make up our world, others tried to map out and understand the invisible forces that govern how things interact and transform. Born on Christmas Day in 1642, Sir Isaac Newton possessed an extraordinary gift for finding patterns in nature and discerning the basic rules underlying its dynamics. Newton’s laws of mechanics transformed physical science from a cluttered notebook of sundry observations to a methodical masterwork of unprecedented predictive power. They describe how forces—pushes and pulls—affect the journeys through space of all things in creation. If you describe the positions and velocities of a set of objects and delineate all of the forces acting on them, Newton’s laws state unequivocally what would happen to them next. In the absence of force or with forces completely balanced, nonmoving objects would remain at rest and moving objects would continue to move along straight lines at constant speeds—called the state of inertia. If the forces on an object are unbalanced, on the other hand, it would accelerate at a rate proportional to the net force. The extent to which an object accelerates under the influence of a net force defines a physical property called mass. The more massive a body, the harder it is for a given force to change its motion. For example, all other factors being equal, a tow truck’s tug would have much less effect on a monstrous eighteen-wheeler than it would on a sleek subcompact car. Newton famously showed that gravity is a universal force, attracting anything with mass to anything else with mass. The moon, the International Space Station, and a bread crumb pushed off a picnic table by an ornery ant are all attracted to Earth. The more massive the objects, the greater their gravitational attraction. Thus, mass serves two purposes in physics—to characterize the strength of gravity and to determine the accelerating effect of a force. Because mass takes on both roles, it literally cancels out of the equation that determines the effect of gravitational force on acceleration. Therefore bodies accelerate under gravity’s influence independent of their masses. If it weren’t for the air whooshing by, an aquatic elephant and a mouse up for a challenge would plunge from the high diving board into a swimming pool straight below them at the same rate. The fact that gravitational acceleration doesn’t depend on mass places gravity on different footing from any other force in nature. The concept of attractive forces offers a means by which large objects can build up from smaller ones—at least on astronomical scales. Take scattered bits of slow-moving material, wait long enough for attractive forces to kick in and they’ll tend to clump together—assuming they aren’t driven apart by even stronger repulsive forces. Attraction offers a natural way for matter to build up from tiny constituents. Therefore it’s not surprising that Newton subscribed to the atomist view, believing that all matter, and even light, is made up of minute corpuscles. In his treatise on optics Newton wrote, “It seems probable to me that God in the beginning formed matter in solid, massy, hard, impenetrable, movable particles of such sizes and figures and with such other properties and in such proportion to space as most conduced to the end for which he formed them. And that these primitive particles being solids, are incomparably harder than any porous bodies compounded of them, even so hard as never to wear or break in pieces; no ordinary power being able to divide what God himself made one in the first creation.” 1 Newton’s belief that God fashioned atoms reflected his deeply held religious views about the role of divinity in creation. He believed that an immortal being needed to design, set into motion, and tweak from time to time an otherwise mechanistic universe. His example, in line with the views of the similarly devout Boyle, showed that atomism and religion were compatible. As Newton demonstrated, the solar system is guided by gravity. Gravity is important on astronomical scales, but it is far too weak a force on small scales to hold atoms together. The force that stabilizes atoms by holding them together is called the electrostatic force, part of what is known as the electromagnetic interaction. While gravity depends on mass, the electrostatic force affects things that have a property called electric charge. The renowned eighteenth-century American statesman Benjamin Franklin was the first to characterize electric charge as either positive or negative. Influenced by Franklin and Newton, British natural philosopher Joseph Priestley proposed that the electrostatic force, like gravity, obeys an inverse-square law, only depending on charge instead of mass. While gravity always brings objects together, the electrostatic force can be either attractive or repulsive; opposite charges attract and like charges repel. These conjectures were splendidly proven in the 1780s by French physicist Charles-Augustin de Coulomb, for whom the law describing the electrostatic force is named. Like the electrostatic force, magnetism is another force that can be either attractive or repulsive. The analogue of positive and negative electric charges is north and south magnetic poles. The ancients were familiar with magnetized iron, or lodestone, and knew that by suspending such a material in the air it would naturally align with the north-south direction of Earth. The term “magnetism” derives from the Greek for lodestone, just as “electricity” stems from the Greek for amber, a material that can be easily electrically charged. Newton’s model of forces envisioned them as linking objects by a kind of invisible rope that spans the distance between them. It’s like a boy in a first-floor alcove of a church pulling a thin cord that manages to ring a bell in its tower. We call this concept action at a distance. In a way, it is an extension of the Democritean concept of atoms moving in an absolute void. Somehow, two things manage to influence each other without having anything in between to mediate their interaction. British physicist Michael Faraday found the notion of action at a distance not very intuitive. He proposed the concept of electric and magnetic fields as intermediaries that enable electric and magnetic forces to be conveyed through space. We can think of a field as a kind of ocean that fills all of space. Placing a charge in an electric field or pole in a magnetic field is like an ocean liner disturbing the water around it and disrupting the paths of other boats in its wake. If you were kayaking off the coast of California and suddenly began rocking back and forth, you wouldn’t be surprised to see an approaching vessel generating major waves. Similarly, when a charge or pole feels a force it is due to the combined effect on the electric or magnetic field of other charges or poles. A child playing with a bar magnet in a room illuminated by an electric lightbulb would probably have little inkling that the two phenomena have anything to do with each other. Yet as Danish physicist Hans Christian rsted, Faraday, and other nineteenth-century researchers experimentally explored, electrical and magnetic effects can be generated by each other. For example, as rsted showed, flipping an electrical switch on and off while placing a compass nearby can deflect its magnetic needle. Conversely, as Faraday demonstrated, jiggling a bar magnet back and forth near a wire can create an electrical current (moving charge) within it—a phenomenon called induction. So a clever enough child could actually light her own play space with her own bar magnet, bulb, and wire. It took a brilliant physicist, James Clerk Maxwell, to develop the mathematical machinery to unite all electrical and magnetic phenomena in a single theory of electromagnetism. Born in Edinburgh, Scotland, in 1831, Maxwell was raised on a country estate and grew up with a fondness for nature. He loved walking along on the muddy banks of streams and tracing their meandering courses. In his adult life, as a professor at King’s College, University of London, he became interested in a different kind of flow, the paths of electric and magnetic field lines fanning out from their sources. In 1861, convinced that both electricity and magnetism could be explained through the same set of equations, Maxwell synthesized everything that was known at the time about their interconnections. Coulomb’s law showed how charge produced an electrostatic force, by way of an electric field. Another law, developed by French physicist André-Marie Ampère based on rsted’s work, indicated how electric current generated a magnetic field. Faraday’s law demonstrated that changing magnetic fields induce electric fields, and another result indicated that changing electric fields create magnetic fields. Maxwell combined these, added a corrective term to Ampère’s law, and solved the complete set of equations, resulting in his influential paper “On Physical Lines of Force.” Maxwell’s solution demonstrated that whenever charges oscillate, for example, electricity running up and down an antenna, they produce changing electric and magnetic fields propagating through space at right angles to each other. That is, if the electric field strength is changing in the vertical direction, the magnetic field is changing in the horizontal direction, and vice versa. The result is what is called an electromagnetic wave radiating outward from the source like ripples from a stone tossed into a pond. We can think of electromagnetic radiation as akin to a line dance alternating between men and women, with successive dancers engaged in different hand motions at right angles to each other. Suppose the first dancer is a man who raises his hands up and down. As soon as the woman behind him notices his arms dropping, she shifts her own hands left and right. Then, triggered by her motion, the man behind her lifts his arms up and down, and so forth. In this manner, a wave of alternating hand motions rolls from the front of the line to the back. Similarly, through successive electric and magnetic “gestures,” an electromagnetic wave flows from its source throughout space. One of the most surprising aspects of Maxwell’s discovery was his calculation of the speed of electromagnetic waves. He determined that the theoretical wave velocity matched the speed of light—leading him to the bold conclusion that electromagnetism is light. A mystery dating from ancient times was finally resolved—light is not a separate element (the “fire” of classical belief) but rather a radiative effect generated by moving electric charges. Until the turn of the nineteenth century, science was aware of only optical light: the rainbow of colors that make up the visible spectrum. Each pure color corresponds to a characteristic wavelength and frequency of electromagnetic waves. A wavelength is the distance between two succeeding peaks of the rolling sierra of electromagnetic oscillations. Frequency is the rate per second that peaks of a given wave pass a particular point in space—like someone standing on an express train platform and counting how many carriages zoom by in one second. Because light in the absence of matter always travels at the same speed, as defined by the results of Maxwell’s equations, its wavelength and frequency are inversely dependent on each other. The color with the largest wavelength, red, has the lowest frequency—like enormous freight cars taking considerable time to pass a station. Conversely, violet, the color with the shortest wavelength, possesses the highest frequency—akin to a tiny caboose whizzing by. The visible rainbow comprises but a small segment of the entire electromagnetic spectrum. In 1800, British astronomer William Herschel, best known for discovering the planet Uranus, was measuring the temperatures of various colors and was amazed to find an invisible region beyond the red end of the spectrum that still produced a notable thermometer reading. The low-frequency light he measured just beyond the range of visibility is now called infrared radiation. The following year, after learning about Herschel’s experiment, German physicist Johann Ritter decided to explore the region of the spectrum just beyond violet. He found that invisible rays in that zone, later called ultraviolet radiation, produced a noticeable reaction with the chemical silver chloride, known to react with light. Radio waves were the next type of electromagnetic radiation to be found. In the late 1880s, inspired by Maxwell’s theories, German physicist Heinrich Hertz constructed a dumbbell-shaped transmitter that produced electromagnetic waves of frequencies lower than infrared. A receiver nearby picked up the waves and produced a spark. Measuring the velocity and other properties of the waves, Hertz demonstrated that they were unseen forms of light—thereby confirming Maxwell’s hypothesis. The known spectrum was to expand even further in 1895 with German physicist Wilhelm Roentgen’s identification of high-frequency radiation produced by the electrical discharge from a coil enclosed in a glass tube encased in black cardboard. The invisible radiation escaped the tube and case, traveled more than a yard, and induced a chemically coated paper plate to glow. Because of their penetrating ability, X rays, as they came to be called, have proven extremely useful for imaging. They’re not the highest frequency light, however. That distinction belongs to gamma rays, identified by French physicist Paul Villard about five years after X rays were discovered and capping off the known electromagnetic spectrum. The picture of light described by Maxwell’s equations bears little resemblance to the Newtonian idea of corpuscles. Rather, it links electromagnetic radiation with other wave phenomena such as seismic vibrations, ocean waves, and sound—each involving oscillations in a material medium. This raises the natural question, What is the medium for light? Could light travel through absolute vacuum? Many nineteenth-century physicists believed in a dilute substance, called ether, filling all of space and serving as the conduit for luminous vibrations. One prediction of that hypothesis is that light’s measured speed should vary with the direction of the ether wind. A famous 1887 experiment by American researchers Albert Michelson and Edward Morley disproved the ether hypothesis by showing that the speed of light is the same in all directions. Still, given the compelling analogy to material waves, it was hard for the scientific community to accept that light is able to move through sheer emptiness. The constancy of the speed of light in a vacuum raised another critical question. In a scenario pondered by the young Albert Einstein, what would happen if someone managed to chase and catch up with a light wave? Would it appear static, like a deer frozen in a car’s headlights? In other words, in that case would the measured speed of light be zero? That’s what Newtonian mechanics predicts, because if two things are at the same speed, they should seem to each other not to be moving. However, Maxwell’s equations make no provision for the velocity of the observer. The speed of light always flashes at the same value, lit up by the indelible connections between electric and magnetic fluctuations. Einstein would devote much of his youthful creativity to resolving this seeming contradiction. Einstein’s special theory of relativity, published in 1905, cleared up this mystery. He modified Newtonian mechanics through extra factors that stretch out time intervals and shrink spatial distances for travelers moving close to light speed. These two factors—known respectively as time dilation and length contraction—balance in a way that renders the measured speed of light the same for all observers. Strangely, they make the passage of time and the measurement of length dependent on how fast an observer happens to be moving, but that’s the price Einstein realized he had to pay to reconcile Maxwell’s equations with the physics of motion. Einstein found that in redefining distance, time, and velocity, he also had to rework other properties from Newtonian physics. For example, he broadened the concept of mass to encompass relativistic mass as well as rest mass. While rest mass is the inherent amount of matter an object possesses, changing only if material is added or subtracted, relativistic mass depends on the object’s velocity. An initially nonmoving chunk of matter starts out with its rest mass and acquires a greater and greater relativistic mass if it speeds up faster and faster. Einstein determined that he could equate the total energy of an object with its relativistic mass times the speed of light squared. This famous formula, E = mc 2 , implied that under the right circumstances mass and energy could transform into each other, like ice into water. Yet another question to which Einstein would apply his legendary intellect concerned whether light’s energy depends solely on its brightness or has something to do with its frequency. The traditional theory of waves associates their energy with their amount of vibration; waves rising higher carry more energy than flatter waves. For example, pounding on a drum harder produces stronger vibrations that result in a louder, more energetic sound. Just as loudness represents the intensity of sound, a function of the amplitude or height of its waves, brightness characterizes the intensity of light, similarly related to its wave amplitude. An object that absorbs light perfectly is called a blackbody. Heat up a blackbody box (a carton covered with dark paper, say) and like any hot object it starts to radiate. If you assume that this radiation is in the form of electromagnetic waves distributed over every possible frequency and attempt to figure out how much of each frequency is actually produced, a problem arises. Just as more folded napkins can fit into a carton than unfolded napkins, more types of low-wavelength vibrations can fit into a box than high-wavelength vibrations. Hence, calculations based on classical wave models predict that armies of low-wavelength modes would seize the bulk of the available energy compared to the paltry set of high-wavelength vibrations. Thus, the radiation from the box would be skewed toward low-wavelength high-frequency waves such as ultraviolet and beyond. This prediction, called the ultraviolet catastrophe, is not what really happens, of course; otherwise if you heat up a food container that happens to have a dark coating and set it on a kitchen table, it would start emitting UV radiation like a tanning bed, harmful X rays, and even lethal gamma rays. Clearly the presumption that light is precisely like a classical wave is a recipe for disaster! In 1900, German physicist Max Planck developed a mathematical solution to the blackbody mystery. In contrast to the classical wave picture of light, which imagines it delivering energy proportional to its brightness, he proposed that light energy comes in discrete packages, called “quanta” (plural of “quantum,” the Greek for package), with the amount of energy proportional to the light’s frequency. The constant of proportionality is now called Planck’s constant. Planck’s proposal eliminated the ultraviolet catastrophe by channeling energy into lower frequencies. Five years later, Einstein incorporated the quantum idea into a remarkable solution of a phenomenon called the photoelectric effect. The photoelectric effect involves what happens when light shines on a metal, releasing electrons (negatively charged particles) in the process. Einstein showed that the light delivers energy to the electrons in discrete quanta. In other words, light has particlelike as well as wavelike qualities. His solution offered the fledgling steps toward a full quantum theory of matter and energy. With his special relativity, energy-matter equivalence, and photoelectric papers all published in 1905, no wonder it is known as Einstein’s “miracle year.” Soon thereafter, Russian German mathematician Hermann Minkowski recast special relativity in an extraordinary fashion. By labeling time the fourth dimension—supplementing the spatial dimensions of length, width, and height—he noticed that Einstein’s theory took on a much simpler form. Abolishing space and time as separate entities, Minkowski declared the birth of four-dimensional “space-time.” Einstein soon realized that space-time would be a fine canvas for sketching a new theory of gravity. Though he recognized the success of Newton’s theory, Einstein wished to construct a purely local explanation based on the geometry of space-time itself. He made use of the independence of gravitational acceleration on mass to formulate what he called the equivalence principle: a statement that there is no physical distinction between free-falling objects and those at rest. From this insight he found a way to match up the local effect of gravity in every region of space-time with the geometry of that region. Matter, he proposed, bends space-time geometry. This warping forces objects in the vicinity to follow curved paths. For example, due to the Sun’s distortion of space-time, the Earth must travel in an elliptical orbit around it. Thus, space-time curvature, rather than invisible, distant pulls, is the origin of gravity. Einstein published his masterful gravitational description—called the general theory of relativity—in 1915. A basic analogy illustrates the general relativistic connection between material and form. Consider space-time to be like a mattress. If nothing is resting on it, it is perfectly flat. Now suppose a sleepy elephant decides to take a nap. When it lies down, the mattress would sag. Any peanuts the elephant might have dropped on its surface while snacking would travel in curved paths due to its distortion. Similarly, because the Sun presses down on the solar system’s space-time “mattress,” all of the planets in the Sun’s vicinity must journey along curved orbits around it. One of the outstanding features of general relativity is that it offers clues as to the origin of the universe. Coupled with astronomical evidence, it shows that there was a beginning of time when the cosmos was extremely hot and dense. Over billions of years, space expanded from minute proportions to scales large enough to accommodate more than one hundred billion galaxies, each containing billions to hundreds of billions of stars. The idea of spatial expansion surprised Einstein, who expected that his theory of gravity would be consistent with a static universe. Inserting a sample distribution of matter into the equations of general relativity, he was astonished to find the resulting geometry to be unstable—expanding or contracting with just the tiniest nudge. It was like a rickety building that would topple over with the mere hint of a breeze. Given his expectations for large-scale constancy, that wouldn’t do. To stabilize his theory he added an extra term, called the cosmological constant, whose purpose was essentially to serve as a kind of “antigravity”—preventing things on the largest scale from clumping together too much. Then in 1929, American astronomer Edwin Hubble made an astonishing discovery. Data taken at the Mount Wilson Observatory in Southern California demonstrated that all of the other galaxies in the universe, except for the relatively close ones, are moving away from our own Milky Way galaxy. This showed that space is expanding. Extrapolating backward in time led many researchers to conclude that the universe was once far, far smaller than it is today—a proposal later dubbed the Big Bang theory. Once he realized the implications of Hubble’s findings, Einstein discarded the cosmological constant term, calling it his “greatest blunder.” The result was a theory that modeled a steadily growing universe. As Russian theorist Alexander Friedman had demonstrated in previous work, depending on the density of the universe compared to a critical value, this growth would either continue forever or reverse course someday. Recent astronomical results have indicated, however, that not only is the universe’s expansion continuing, it is actually speeding up. Consequently, some theorists have suggested a revival of the cosmological constant as a possible explanation of universal acceleration. Today, thanks to detailed measurement of the background radiation left over from the Big Bang, the scientific community understands many aspects of how the early universe developed and acquired structure. This radiation was released when atoms first formed and subsequently cooled as space expanded. Hence, it offers a snapshot of the infant universe, showing which regions were denser and which were sparser. Einstein’s theoretical achievements combined with modern astronomical observations have opened a window into the past—enabling scientists to speak with authority about what happened just seconds after the dawn of time. Science has made incredible strides in answering many of the fundamental questions about the cosmos. Our sophisticated understanding of the building blocks of matter, the fundamental forces, and the origins of the universe reflect astonishing progress in chemistry, physics, astronomy, and related fields. Yet our curiosity compels us to press even further—to attempt to roll back the hands of time to the nascent instants of creation, a mere trillionth of a second after the Big Bang, and understand the fundamental principles underlying all things. Since we cannot revisit the Big Bang, the Large Hadron Collider (LHC) will serve as a way of reproducing some of its fiery conditions through high-energy particle collisions. Through the relativistic transformation of energy into mass, it will offer the possibility of spawning particles that existed during the embryonic moments of physical reality. It will also offer the prospect of exploring common origins of the natural forces. Thus, from the chaotic aftermath of particles smashing together at near light speeds, we could possibly unlock the secrets of a lost unity. Distilling novel ideas from turbulence is nothing new to the people of Geneva. Only six miles southeast of the LHC is Geneva’s stunningly beautiful old town. The historic streets and squares, where Jean Calvin once preached religious independence and Jean-Jacques Rousseau once taught about social contracts, are used to all manner of revolutionary currents. Soon Geneva could witness yet another revolution, this time in humanity’s comprehension of the fundamental nature of the cosmos.",
        "char_count": 35025
      },
      {
        "heading": "Chapter 7",
        "text": "2 The Quest for a Theory of Everything What immortal hand or eye Dare frame thy fearful symmetry? —WILLIAM BLAKE (“THE TYGER,” 1794) In the heart of Geneva’s old town stands the majestic Cathedral of St. Pierre. Between 1160 and 1232, it was constructed in the austere, measured Romanesque style characteristic of the times. Emphasizing the basic unity of God’s plan, its vaulting arches and lofty towers were planned to form a careful equilibrium—the left side balancing the right. Over the ages, the shifting currents of religious belief eroded the cathedral’s original design. In the sixteenth century, the Reformation ushered in a fanatical desecration of its interior artwork, including the destruction of statues and the whitewashing of frescoes painted on the walls. Adding to the architectural jumble, the original frontage was replaced with a neoclassical facade in 1750. Many physicists believe that the universe was once a simple cathedral, elegant and balanced. According to this view, like a perfectly fashioned nave, the cosmos began with an equal mixture of opposites—positive and negative charge, matter and antimatter, leptons and quarks, fermions and bosons, and so forth. As the universe cooled down from its initial hot, ultracompact state, these symmetries spontaneously broke down. Presently the cosmos is thereby a bit of a jumble, like St. Pierre’s. One of the principal missions of the Large Hadron Collider (LHC) involves a kind of archeological expedition—attempting to piece together some of nature’s original symmetries. Searching for these symmetries pertains to the ultimate quest to unify all of the particles and forces in the universe under a single umbrella. Looking back to the first moments of the universe could provide the answer. The LHC’s extraordinary energies, when applied on the particle scale, reproduce some of the conditions a tiny fraction of a second after the Big Bang. On a minuscule level, it offers a kind of journey back in time. The LHC isn’t re-creating the actual Big Bang itself. Although the LHC’s experiments involve comparable energy per particle , they produce incomparably less energy overall. It’s like pouring a thimbleful of water on a smidgen of sand to test beach erosion; although it might simulate the effect of a lap of the ocean on a bit of the beach, it would hardly reproduce the might of the entire Pacific. Theoretical clues as to the original state of symmetry present themselves through conserved or near-conserved quantities in nature today. This near-symmetry led to the development of the elegant Standard Model. The Standard Model is a mathematical way of expressing two of nature’s fundamental forces—electromagnetism and the weak interaction (a cause of certain types of radiation). There have been numerous attempts to unify these interactions with either or both of the two other natural forces, the strong interaction (that binds nuclei together) and gravity. For example, Einstein spent the final decades of his life trying to unite electromagnetism with gravity through various extensions of general relativity. He believed that the laws of nature offered subtle signs of an original harmony. These hidden universal principles, he hoped, would eventually reveal themselves through diligent mathematical exploration. Alas, all of his efforts were to no avail. He died in 1955 without finding a satisfactory resolution of his quest. In the decades after Einstein’s death, the Standard Model of the electroweak interaction—as the merger of electromagnetism with the weak interaction is called—took shape as the only fully successful unification model to date. Even this matchup took much hard work and creative thinking. Under mundane conditions, electromagnetism and the weak interaction have several noticeable distinctions. Electromagnetism acts over an incredibly wide range of distances, from the minute scale of atoms to the colossal spans of lightning bolts. The weak interaction, in comparison, acts exclusively on the subatomic level. Moreover, while the electromagnetic force can bring together or push apart charged particles, it never alters their actual charges or identities. Thus, a positively charged proton tugging on a negatively charged electron each remain just that. In contrast, the weak interaction, in its typical dealings, acts like a minuscule marauder, robbing particles of their charge and other properties. For example, it causes beta decay, a process that involves the transformation of a neutral neutron into a proton (along with other particles). Clever theorists noted, however, that neutrons and protons have similar (but not identical) mass. They pondered, therefore, if the transformation of one into the other could be a one-time symmetry that somehow cracked. Like the Liberty Bell, perhaps it once rang like others forged in the same foundry but then acquired imperfections over the course of time. Could it be that electromagnetism and the weak interaction were born twins but had distinct formative experiences? The concept of spontaneous symmetry breaking, on which the Standard Model is based, stems from a completely different field of physics: the study of superconductivity. Certain materials, when extremely cold, lose all resistance and conduct electricity perfectly. The “supercurrents” block external magnetic fields from entering and keep internal fields intact. Superconducting magnets are used throughout the LHC to generate the ultrahigh fields needed to steer particles around the ring and to keep them focused in tight bunches. In 1957, John Bardeen, Leon Cooper, and J. Robert Schrieffer (BCS) developed a successful quantum theory of how materials organize themselves to produce such a superconducting state. The theory relies on special correlations between electrons, known as Cooper pairs. The paired electrons organize themselves and, like dutiful soldiers, march in unison. Hence, they are able to overcome all resistance and become perfect electrical conductors. The reason paired electrons are able to move in lockstep while single electrons cannot has to do with a feature called the Pauli exclusion principle. Elementary particles fall into two different categories called fermions and bosons. Electrons (if not in Cooper pairs) are an example of fermions and photons are an example of bosons. The Pauli exclusion principle, a critical rule of quantum mechanics, states that no two fermions can share the same quantum state. The principle doesn’t apply to bosons, for which any quantity can occupy the same state. It’s like a summer camp for which any number of kids (the bosons) are allowed to share the same bunk, but counselors (the fermions) each get a room to themselves. Naturally the former would be much more clustered than the latter—explaining why bosons can act in tandem more easily. Although composed of two fermions each, Cooper pairs behave like bosons, explaining their lockstep behavior. The mortal enemy of superconductivity is heat. At a sufficiently high temperature, depending on the material, synchronized motion breaks down and superconductivity reverts to normal electrical behavior. The changeover resembles the transformation from crystalline ice into liquid water and is called a phase transition. Four years after the BCS theory was published, Japanese-born physicist Yoichiro Nambu cleverly demonstrated that its assumptions could similarly describe how symmetry could spontaneously break down in particle physics. With a lowering of temperature, such as in the instants after the Big Bang, a phase transition could occur in which bosons suddenly synchronize themselves and turn aimless behavior into coordinated patterns. He would share the 2008 Nobel Prize for this key finding. Then, in 1964, British physicist Peter Higgs proposed a new type of boson that would acquire mass through a special kind of spontaneous symmetry breaking. In acquiring mass it would also bestow mass on other particles. Although the boson ended up being named after him, there were several other similar mechanisms proposed independently at the time, including in one paper by Gerald Guralnik, C. Richard Hagen, and Tom Kibble, and another by François Englert and Robert Brout. In quantum physics, energetic fields take shape due to the potentials they live in. A potential is a kind of a slope, well, or barrier that delineates how energy changes with position. A clifflike potential, for instance, represents a much steeper energy transformation than a plateaulike potential. Higgs assigned his boson a peculiar potential shaped like the bottom of a basin for higher temperatures but like the rim of a basin for lower temperatures. By lowering the temperature below a critical value, the boson is forced from the center of the basin (a zero-energy state, known as the true vacuum), to a place along the rim (a non-zero energy state, called the false vacuum). The arbitrary place on the rim where the Higgs boson ends up—indicating its phase (a type of internal parameter that can assume different angles, like the hands on a clock)—locks in the phase of the ground state of all of space. That’s because, unlike an individual particle, a vacuum must be unique and can’t have different phases at each point. Hence, the original symmetry is spontaneously broken. To envision this situation, consider a new property development that is a checkerboard of perfectly square tracts. Before houses are built on the land, each tract is absolutely symmetric with no features distinguishing the north side from the south. Now suppose that a regional ordinance mandates that houses must be spaced a certain distance apart. If the house to be built sits precisely in the center of one of the tracts, then all of the others could follow, and the tracts would each remain symmetric. That’s similar to the high-temperature case for Higgs bosons. However, suppose the first house appears in the southwest corner of one of the tracts. The neighboring houses, required to be a specific distance from others, would have to do the same. Eventually, all of the tracts would be occupied with houses on their southwest corners—breaking their original symmetry because of a single, arbitrary, local decision. If the first house had been built in the northeast corner instead, perhaps that would have set the overall trend as well. Similarly, the phase choice of a Higgs boson locally sets the overall phase globally. As Higgs demonstrated, once the boson field’s phase is set, it acquires a mass associated with its nonzero energy. This mass does not arise out of the blue; rather it represents the transformation of energy into mass described by Einstein’s special theory of relativity that takes place during the transition between the different vacuum states. Moreover, the Higgs boson interacts with other particles and bestows them with their own masses. Thus, the Higgs could well have set the masses for all of the massive particles in the universe. Because of its ability to seemingly pull mass out of the blue, it has been nicknamed the “God particle”—an epithet with which Higgs himself is not particularly comfortable. It took awhile for the modest professor to get used to a particle named after himself, let alone one assigned divine features. Higgs’s idea was so radical that his original paper was rejected by the leading European journal, Physics Letters. He later recalled his disappointment: I was indignant. I believed that what I had shown could have important consequences in particle physics. Later my colleague . . . at CERN told me that the theorists there did not see the point of what I had done . . . Realizing that my paper had been short on salestalk, I rewrote it with the addition of two extra paragraphs, one of which discussed spontaneous breaking of the currently fashionable SU(3) flavor [quark type] symmetry, and sent it to Physical Review Letters . . . . This time it was accepted. 1 Higgs’s paper stimulated a novel look at unifying the electromagnetic and weak forces into a single theory. The critical idea is that these forces are conveyed by means of a quartet of exchange particles, three of which acquire mass through the Higgs mechanism. An exchange particle is a boson that cements the connection between a set of matter particles, causing attraction, repulsion, or transformation. The more massive the exchange particle, the shorter the range of the corresponding interaction. As the carriers of a force with indefinite range—electromagnetism—photons are massless. Moreover, because they don’t affect the charge of interacting particles, they are electrically neutral. Two of the exchange particles for the weak force, however, called the W + and W - bosons, are charged and massive, reflecting the properties of the interaction they convey—charge-transforming and short-ranged. There is also a neutral weak force carrier, called the Z boson. Its existence was proposed in 1960 by Harvard theorist Sheldon Glashow. All three of the weak exchange particles have since been found. Once Higgs’s mechanism was included, along with representations of the exchange particles and fields representing various types of matter, all of the pieces for uniting electromagnetism with the weak interaction snapped into place. In 1967, American physicist Steven Weinberg, working at MIT, and Pakistani physicist Abdus Salam, working at Cambridge, independently developed a successful theory of electroweak unification. It is a masterful theory—the crowning achievement of decades of experimental and theoretical explorations of the nature of subatomic particles. Its designation as the Standard Model is a recognition of its extraordinary importance. According to theoretical predictions, a remnant of the original Higgs field ought to be leftover and detectable. Surprisingly, despite several decades of experimental investigations at that energy, the Higgs boson has yet to be found. Through the LHC, the physics community hopes at long last to identify the Higgs boson and establish the Standard Model on debt-free grounds. LHC researchers are fully aware that the Standard Model could prove to be incomplete. Too many mysteries remain about inequities in the universe for the Standard Model to be the be-all and end-all, anyway. Because the Higgs has yet to be found and other interactions are yet to be united satisfactorily, among other things, many physicists today are agnostic about the Standard Model’s ultimate validity. Although it has been enormously successful in explaining most particle phenomena, like many beautifully painted old frescoes it has acquired cracks. At the LHC, researchers often consider the Standard Model predictions along with several alternatives, hoping that experimental results will distinguish among the possibilities. For example, experimenters are preparing themselves for Higgs bosons of higher mass than the Standard Model forecasts or even, as some theories foretell, a triplet of Higgs particles. As midwives to a possible impending birth, they need to ready themselves for a variety of natal scenarios. Of the unification models that have emerged in the past few decades, the most popular by far has been string theory. String theory envisions the most elementary constituents of nature as incredibly minuscule (less than 10 -33 inches, called the Planck length) vibrating strands of energy instead of point particles (as envisioned in the Standard Model). Thus they have a finite, but unobservably small, rather than infinitesimal extent. An immediate mathematical advantage is that any equations that include inverse length are finite, rather than infinite. This helps avoid certain mathematical maladies that plague standard quantum field theory, in which particular terms become indefinitely and unrealistically large. String theory is sometimes called the Theory of Everything (TOE) because it purports to include all known interactions. Its finiteness makes it particularly adept to handle gravitation, which has resisted all previous attempts at inclusion within a unified theory—including Einstein’s famous effort. Critics, however, have pointed to string theory’s embarrassment of riches. Not only could it potentially include the Standard Model as one of its subsets, but it also seems to encompass myriad physically unrealistic configurations. Therefore one of the long-term goals of string theory is narrowing it down to a single TOE that precisely models our own universe. According to string theory, different fields and particles are distinct modes of energetic vibrations. If a guitar is out of tune, you can try to tighten its strings. Similarly the energetic vibrations of string theory respond to changes in tension. They also exhibit harmonic patterns, like the overtones that enrich a musical composition. These string configurations correspond to the assorted masses, spins, and other properties of various types of constituents. String theory started out as solely a model of the strong interaction. In that guise, it encompassed only carriers of force—in other words, bosons. Bosonic string theory could never describe material particles, represented at the tiniest level by fermions. Theorists were motivated to find a way of describing fermions too and model the stuff of matter along with the agents of attraction. To include fermionic strings along with bosonic strings, physicist Pierre Ramond of the University of Florida proposed the concept of supersymmetry in 1971. Ramond’s notion of a transformation connecting matter with force quickly caught fire and ignited the interest of all manner of theorists—even those unenthusiastic about strings themselves. A symmetry uniting fermions with bosons seemed to be the ultimate particle democracy. Moreover, unlike conventional quantum field theory, like the Standard Model, supersymmetry makes ample room for gravity. For the first time in the history of quantum physics, gravity seemed within reach of incorporation into a unified field theory. Suddenly, Einstein’s dormant quest for unification sprang back to life like an antique car equipped with a roaring new engine. Propelled by the dynamo of supersymmetry, which acquired the nickname “SUSY,” field theorists who believed in its power found themselves with the choice of several different routes. One was to press forward with superstrings, the supersymmetric theory of strings, and to explore their fundamental properties, hoping these would match up with observed aspects of elementary particles. In 1984, an important result by Michael Green and John Schwarz showing that superstring theory lacks certain mathematical blemishes called “anomalies” was cause for celebration. Superstring theory’s vibrant vehicle seemed to gleam even more. One challenge for those taking the fundamental route, however, was making their case to experimentalists. String theory calculations are often tricky and involve many free parameters. These could be adjusted to accommodate a wide range of predictions. Also, until Ed Witten and other theorists showed their equivalence in the mid-1990s, string theories appeared to come in several different varieties. Given such a multiplicity of parameters and theories, researchers were unsure exactly what to test. At any rate, a realm so tiny that nuclei loomed like galaxies in comparison seemed virtually impossible to explore. Moreover, superstrings are mathematically consistent only if they live in a world of ten dimensions or more. To accommodate the fact that people observe only three dimensions of space and the dimension of time, theorists recalled an idea developed by Swedish physicist Oskar Klein in the 1920s and proposed that six of the dimensions are curled into a ball so tiny that it cannot physically be observed. That worked well mathematically but offered no incentive for experimenters to try to probe the theory. Given the inability to obtain experimental proof, string theory’s skeptics—Glashow and Richard Feynman, among the prominent examples—argued that it remained on shaky ground. Laboratory researchers were enticed to a greater extent by a more conservative application of supersymmetry, called the Minimal Supersymmetric Standard Model (MSSM). Proposed in 1981 by Stanford University physicist Savas Dimopoulos, along with Howard Georgi, it offered a way of extending the Standard Model to include additional fields with the goal of preparing it to be part of a greater unified theory. These fields included supersymmetric companion particles, the lightest of which could potentially be seen in the lab. The ultimate unification would include gravity. Yet gravity is far weaker than the other forces. Tracing back the history of the universe to a time when gravity could have been comparable in strength to its kindred interactions requires us to ponder its conditions less than 10 -43 seconds after the Big Bang. At that moment, called the Planck time, the cosmos would have been unimaginably hot and compact, so much so that quantum mechanical principles pertaining to nature’s smallest scales would apply to the realm of gravitation. For the briefest instant, the disparate worlds of general relativity and quantum mechanics would be joined through the shotgun marriage of quantum gravity. Because unification of all of the natural forces would have taken place at such high energies, the particles involved would be extremely heavy. Their mass would be a quadrillion times what could possibly be found at the LHC. Interacting with the Higgs, the Planck scale particles would tug its energy so high as to destabilize the Standard Model. In particular, it would render the weak interaction in theory much feebler than actually observed. To avoid such a catastrophe, Dimopoulos and Georgi made use of auspicious mathematical cancellations that occurred when they constructed a supersymmetric description of a unified field theory. The cancellations negated the influence of higher mass terms and protected the Higgs from being yanked to unrealistic energies. One caveat is that the Higgs itself would be replaced by a family of such particles—charged along with neutral—including a supersymmetric companion called the higgsino. If some of the low-mass supersymmetric companions are found, they would offer vital clues as to what lies beyond the Standard Model. They would reveal whether the MSSM or other extensions are correct, and if so, help tune the values of their unspecified parameters (the MSSM has more than a hundred). Ultimately, the findings could provide a valuable hint as to what string theory (or another unified field theory) might look like at much higher energies. Because string theory has so many different possible configurations and its full energy could be well beyond reach, it is unlikely, however, that any LHC results would either confirm or disprove string theory altogether. At best, they would simply offer more information about string theory’s limits and constraints. The experimental discovery of supersymmetry, for instance, would not validate string theory but might assure some of its proponents that they are on the right track. One of the groups most desperately seeking SUSY consists of researchers trying to resolve one of the deepest dilemmas facing science today: the missing matter mystery. Astronomers are puzzled by unseen matter, scattered throughout the universe, that makes its presence known only through gravitational tugs—for example, through extra forces on stars in the outer reaches of galaxies. The dark matter mystery is one of the deepest conundrums in astronomy. Some researchers think the answer could be massive but invisible, supersymmetric companion particles. Could a supersymmetric payload be the hidden ballast loading down the cosmic craft? Soon the world’s most powerful high-energy device could possibly reveal nature’s unseen cargo. Resolving all of these mysteries requires the impact of high-energy collisions monitored carefully by sophisticated detectors to determine the properties of their massive byproducts. Such methods have a long and distinguished history. The story of using collisions to probe the deep structure of matter began a century ago, with gold-foil experiments conducted in 1909. Naturally, the instruments used were far, far simpler back then. Scientists at that time were trying to explore the inner world of the atom. Little was known about the atomic interior until collisions revealed its secrets. You can’t crack open a coconut through the impact of a palm leaf; you need a sturdy mallet applied with vigor and precision. Revealing the atom’s structure would require a special kind of sledgehammer and the steadiest of arms to wield it.",
        "char_count": 24751
      },
      {
        "heading": "Chapter 8",
        "text": "3 Striking Gold Rutherford ’s Scattering Experiments Now I know what the atom looks like! —ERNEST RUTHERFORD, 1911 In a remote farming region of the country the Maoris call Aotearoa, the Land of the Long White Cloud, a young settler was digging potatoes. With mighty aim, the boy broke up the soil and shoveled the crop that would support his family in troubling times. Though he had little chance of striking gold—unlike other parts of New Zealand, his region didn’t have much—he was nevertheless destined for a golden future. Ernest Rutherford, who would become the first to split open the atom, was born to a family of early New Zealand settlers. His grandfather, George Rutherford, a wheelwright from Dundee, Scotland, had come to the Nelson colony on the tip of the South Island to help assemble a sawmill. Once the mill was established, the elder Rutherford moved his family to the village of Brightwater (now called Spring Grove) south of Nelson in the Wairoa River valley. There, George’s son James, a flax maker, married an English settler named Martha, who gave birth to Ernest on August 30, 1871. Ernest Rutherford (1871-1937), the father of nuclear physics. Attending school in Nelson and university at Canterbury College in Christchurch, the largest and most English city on the South Island, Rutherford proved diligent and capable. A fellow student described him as a “boyish, frank, simple, and very likable youth, with no precocious genius, but once he saw his goal, he went straight to the central point.” 1 Rutherford’s nimble hands could work wonders with any kind of mechanical device. His youthful pursuits would prepare him well for his deft manipulation of atoms and their nuclei. With surgical dexterity, he disassembled clocks, constructed working models of a water mill, and put together a homemade camera that he used to snap pictures. At Canterbury, he became fascinated by the electromagnetic discoveries taking place in Europe, and decided to build his own instruments. Following in the footsteps of Gustav Hertz, he constructed a radio transmitter and receiver—research that would anticipate Guglielmo Marconi’s invention of the wireless telegraph. Rutherford showed how radio waves could travel long distances, penetrate walls, and magnetize iron. His clever undertakings would make him an attractive candidate for a new research program in Cambridge, England. Coincidentally, in the year of Rutherford’s birth, a new physical laboratory had been established at Cambridge, with Maxwell its first director. Named after the esteemed physicist Henry Cavendish, who, among other accomplishments, was the first to isolate the element hydrogen, Cavendish Laboratory would become the world’s leading center for atomic physics. Its original location was near the center of the venerable university town on a narrow side street called Free School Lane. Maxwell had supervised its construction and planned out its equipment, making it the first laboratory in the world dedicated to physics research. Following Maxwell’s death in 1879, another well-known physicist, Lord Rayleigh, had assumed the directorship. Then, in 1884, that mantle passed to the extraordinary leadership of J. J. (Joseph John) Thomson. An intense intellectual with long, dark hair, wire-framed glasses, and a scruffy mustache, Thomson adroitly presided over a revolution in scientific education that allowed students vastly more opportunities for research. For physics students of earlier times, experimental research was merely the dessert course of a long banquet of mathematical studies—a treat that their tutors would sometimes only grudgingly allow them to partake. After satisfying their requirements with theoretical examinations of mechanics, heat, optics, and so forth, students would perhaps get a chance to sample some of the laboratory apparatus. At Cavendish, with its state-of-the-art equipment, these brief tastes would become a much richer meal unto itself. Thomson was pleased to take advantage of a new program allowing students from other universities to come to Cambridge, perform supervised laboratory research, write up their results in a thesis, and receive a postgraduate degree. Today we are accustomed to research Ph.D.s—it’s the bread and butter of academia—but back in the late nineteenth century the concept was novel. Such graduate student assistance would help spark the revolution in physics soon to follow. The new program began in 1895, with Rutherford one of the first invitees. He was funded through an 1851 scholarship offered to talented young inhabitants of the British Dominion (now the Commonwealth). His move from rural New Zealand to academic Cambridge would prove extraordinary not only for his own career but also for the history of atomic physics. The moment Rutherford encountered his fate is a matter of legend. Reportedly, his mother received a telegram bearing the good news and brought it out to the potato garden where he was digging. When she told him what he had won, at first he couldn’t believe his ears. After the realization sank in, he tossed his spade aside and exclaimed, “That’s the last potato I’ll dig.” 2 Bringing his homemade radio detector along, Rutherford sailed to London, where he promptly slipped on a banana peel and injured his knee. Fortunately, the country lad had no more missteps as he made his way through the smoky, labyrinthine city. Journeying north, he left the smoke for the fresh air of the English countryside and arrived at the hallowed jumble of colleges and courtyards on the River Cam. There he took up residence at Trinity College, founded in 1546 by King Henry VIII, where the arched Great Gate and legends of Newton’s feats tower over nervous entering students. (Cambridge is organized into a number of residential colleges, of which Trinity is the largest.) From Trinity, Cavendish was just a short, pleasant walk away. Along with Rutherford, the labs of Cambridge were soon filled with research students from around the world. Reveling in the cosmopolitan atmosphere, Thomson invited his young assistants for tea in his office every afternoon. As Thomson recalled, “We discussed almost every subject under the Sun except physics. I did not encourage talking about physics because the meeting was intended as a relaxation . . . and also because the habit of talking ‘shop’ is very easy to acquire but very hard to cure, and if it is not cured the power of taking part in a general conversation may become atrophied for want of use.” 3 Despite Thomson’s efforts to help young researchers lighten up, the pressures at Cambridge must have been intense. “When I come home from researching, I can’t keep quiet for a minute and generally get in a rather nervous state,” Rutherford once wrote. His solution to his nervousness was to take up pipe smoking, a habit he would maintain for life. “If I took to smoking occasionally,” he continued, “it would keep me anchored a bit. . . . Every scientific man ought to smoke as he has to have the patience of a dozen Jobs in research work.” 4 To make matters worse, many of the traditional students viewed the newcomers as interlopers. Taunted by some of his upper-crust colleagues as a yokel from the antipodes, Rutherford bore an extra burden. About one such mocker, he commented, “There is one demonstrator on whose chest I should like to dance a Maori war-dance.” 5 Thomson was a meticulous experimentalist and had been engaged for a time in his own explorations of the properties of electricity. Constructing a clever apparatus, he investigated the combined effects of electric and magnetic fields on what was known as cathode rays: negatively charged beams of electricity passing between negatively and positively charged electrodes (terminals attached by wires to each end of a battery). The negative electrode produces the cathode rays and the positive electrode attracts them. Electric and magnetic fields affect charges in different ways. Applying an electric field to a moving negative charge creates a force opposite to the field’s direction. In contrast, a magnetic field generates a force at right angles to the field’s direction. Also, unlike electric forces, magnetic forces depend on the charges’ velocities. Thomson found a way of balancing the electric and magnetic forces in a manner that revealed this speed, which he used to determine the ratio of the charge of the rays to their mass. Making the assumption that these rays bear the same charge as ionized hydrogen, he found the mass of the rays to be about ten thousand times smaller than hydrogen’s. In other words, cathode rays consist of elementary particles much, much lighter than atoms. Repeating the experiment numerous times under a variety of conditions, he always got the same results. Thomson called these negatively charged particles corpuscles, but they were later dubbed electrons, a name that has stuck. They offered the first glimpse of an intricate world within the atom. Initially, Thomson’s phenomenal discovery was met with skepticism. As he recalled, “At first there were very few who believed in the existence of these bodies smaller than atoms. I was even told long afterwards by a distinguished physicist who had been present at my lecture at the Royal Institution that he thought I had been ‘pulling their legs.’ I was not surprised at this, as I had myself come to this explanation with great reluctance, and it was only after I was convinced that the experiment left no escape from it that I published my belief in the existence of bodies smaller than atoms.” 6 Meanwhile, on the other side of the English Channel, the discovery of radioactive decay challenged the notion of atomic permanence. In 1896, Parisian physicist Henri Becquerel scattered uranium salts over a photographic plate wrapped in black paper, and was astonished to find that the plate darkened over time due to mysterious rays produced by the salts. Unlike the X-ray radiation found by Roentgen, Becquerel’s rays emerged spontaneously without the need for electrical apparatus. Becquerel found that any type of compound containing uranium gave off these rays, in a rate proportional to the amount of uranium, suggesting that the uranium atoms themselves were producing the radiation. Similarly working in Paris, Polish-born physicist Marie Curie confirmed Becquerel’s findings and, along with her husband, Pierre, extended them to two new elements she discovered: radium and polonium. These elements emitted radiation at a higher rate than uranium and diminished in quantity over time. She coined the term radioactivity to describe the phenomenon of atoms spontaneously breaking down by giving off radiation. For their monumental discovery of the impermanence of atoms through radioactive processes, replacing Dalton’s century-old static concept with a more dynamic vision, Becquerel and the Curies would share the 1903 Nobel Prize. Rutherford followed these developments with great interest. While his mentor Thomson was engaged in discovering the electron, Rutherford concentrated his attention on using radioactive materials as a source for ionizing gases. Somehow the emissions from uranium and other radioactive materials seemed to have the property of knocking the electrical neutrality out of surrounding gases, transforming them into electrically active conductors. The radiation seemed to perform the same function as rubbing dry sticks together and producing a spark. Radioactivity ignited Rutherford’s curiosity as well and launched him on a rigorous investigation of its properties that would revolutionize physics. From a novice keen on developing radio detectors and other electromagnetic devices, he would emerge from his experience an extraordinary experimentalist adept at using radiation to decipher the world of the atom. Using the property that magnetic fields steer differently charged particles along distinct paths, he determined that radioactive materials produce positive and negative kinds of emissions, which he named, respectively, alpha and beta particles. (Beta particles turned out to be simply electrons. Villard discovered gamma radiation, a third, electrically neutral type, shortly after Rutherford’s classification.) Magnetic fields cause alpha particles to spiral in one direction and beta in the other—like horses racing in opposite directions around a circular track. Testing the ability of each kind of radiation to be stopped by barriers, he demonstrated that alpha particles are more easily blocked than beta. This suggested that alpha particles are larger in size than beta. In 1898, in the midst of his studies of radioactive materials, Rutherford decided to take time off for a matter of the heart. He headed briefly to New Zealand to marry his high school sweetheart, Mary Newton. They didn’t return to England, however. Married life required a decent salary, he reasoned, so he accepted an offer of a professorship at McGill University in Montreal, Canada, that paid five hundred British pounds per year—respectable at the time and equivalent to about fifty thousand dollars today. The couple sailed to the colder clime, where Rutherford soon resumed his investigations. At McGill, Rutherford focused on trying to uncloak alpha particles and reveal their true identities. Replicating Thomson’s charge-to-mass ratio experiment with alpha particles instead of electrons, he determined their charge—curiously finding it to be precisely the same as helium ions. He began to suspect that the most massive products of radioactivity decay were just mild-mannered helium in disguise. Just when Rutherford could use some help in unraveling atomic mysteries, a new sleuth arrived in town. In 1900, Frederick Soddy, a chemist from Sussex, England, was appointed to a position at McGill. Learning of Rutherford’s work, he offered his expertise, and together they set out to understand the process of radioactivity. They developed a hypothesis that radioactive atoms, such as uranium, radium, and thorium, disintegrated into simpler atoms associated with other chemical elements by releasing alpha particles. Interested in medieval history, when alchemists tried to transform base materials into gold, Soddy recognized that radioactive transmutation could lead to the fulfillment of that dream. In 1903, soon after Rutherford announced their theory of transmutation, Soddy decided to join forces with a noted expert in helium and other inert gases (neon and so forth), chemist William Ramsay of University College, London. Ramsay and Soddy conducted careful experiments in which they collected the alpha particles produced by decaying radium in a glass tube. Then, after the particles accumulated into a gas, they studied its spectral lines and found them identical to those of helium. Spectral lines are bands of specific frequencies (in the visible spectrum, particular colors) that make up the characteristic signature of an element when it either emits or absorbs light. For the emission spectrum of helium, certain violet, yellow, green, blue-green, and red lines always appear, along with two distinct shades of blue. Ramsay and Soddy found this fingerprint in what they observed, offering proof that alpha particles constitute ionized helium. Soddy would later coin the term “isotope” to describe when elements exist in two or more distinct forms with different atomic weights. For example, deuterium, or heavy hydrogen, is chemically identical to the standard form, but has approximately twice its atomic weight. Tritium, a radioactive isotope of hydrogen, has about three times the weight of the ordinary variety. It decays into helium-3, a lighter isotope of common helium. In what he called the Displacement Law, Soddy demonstrated how alpha decay causes elements to drop down two spaces on the periodic table, as if sliding backward during a game of snakes and ladders. Beta decay, in contrast, causes a move one space forward, to one of the isotopes of the element in the slot ahead. That’s exactly what happens when tritium turns into helium-3 and moves forward in the periodic table. Suppose you encounter a strange kind of marble dispenser with its contents shielded from view. Sometimes blue marbles pop out of the machine and it flashes once. Sometimes red marbles pop out and it flashes twice. What would you think is inside? You might guess that the interior is an even mixture of red and blue marbles, distributed hither and thither like plums in a pudding. By 1904, physicists knew that atoms transmuted by producing emissions of different charges and masses, but they didn’t know how all of these fit together. Thomson decided to venture a guess that positive and negative particles were distributed evenly—with the latter being much smaller and thereby freer to move. He hoped that the proof of his “plum pudding model” would be in the testing, but alas it would turn out to be plumb wrong—disproven, as fate would have it, by his former protégé from New Zealand. The next stage of Rutherford’s life was arguably his most productive. In 1907, the University of Manchester, the northern English setting of Dalton’s explorations, appointed him to a new position as chair of physics. Manchester’s gain was a huge loss for McGill. By then, Rutherford had become a commanding presence, “riding the crest of a wave” of his own making—as he once boasted to his biographer (and former student) Arthur Eve. 7 As helmsman, he ran a tight ship—recruiting some of the best young researchers, setting them challenging problems, and dismissing those who fell short. With a booming voice and a propensity toward fits of temper and yelling at equipment during stressful moments, the mustached, pipe-smoking professor could be an intimidating commander indeed. Moments of stress and anger would quickly pass, however, like the blazing sun behind calming puffy clouds, and no one could be friendlier, warmer, or more supportive. Chaim Weizmann, a Manchester biochemist who would later become the first president of Israel, befriended Rutherford at the time and described him as: Youthful, energetic, boisterous; he suggested everything but the scientist. He talked readily and vigorously on every subject under the sun without knowing anything about it. Going down to the refectory for lunch I would hear the loud, friendly voice rolling up the corridor. . . . He was a kindly person, but he did not suffer fools gladly. 8 Comparing Rutherford to Einstein, whom he also knew well, Weizmann recalled: As scientists the two men were strongly contrasting types—Einstein all calculation, Rutherford all experiment. The personal contrast was not less remarkable: Einstein looks like an etherealized body, Rutherford looked like a big, healthy, boisterous New Zealander—which is exactly what he was. But there is no doubt that as an experimenter Rutherford was a genius, one of the greatest. He worked by intuition and whatever he touched turned to gold. 9 At Manchester, Rutherford had meaty goals: using alpha particles to crack open the atom and reveal its contents. Alpha particles, he realized, would be large enough to make ideal probes of deep atomic structure. In particular, he wanted to test Thomson’s plum pudding model and see if each atom’s interior was an evenly distributed mix of large positive and small negative chunks. To carry out his project, he was lucky enough to snag two prize catches: a precious supply of radium (for which he had vied with Ramsay) and the valuable services of German physicist Hans Geiger, who had worked for the former physics chair. Rutherford assigned Geiger the task of developing a reliable way of detecting alpha particles. The method Geiger pioneered—counting sparks that pass between electrodes on a metal tube when incoming alpha particles ionize a gas sealed inside, making it a conductor—became the prototype for what would become his most famous invention: the Geiger counter. Geiger counters rely on the principle that electricity travels around closed loops. Each time a sample emits an alpha particle, electricity rounds the circuit between the electrodes and the conducting gas—producing an audible click. Despite the utility of Geiger’s innovation, Rutherford usually relied on a second means of detection: using a screen coated with zinc sulfide, a material that lights up when alpha particles hit it through a process known as scintillation. In 1908, Rutherford took a break from his research to collect the Nobel Prize in Chemistry for his work with alpha particles. He didn’t stay away from the lab for long. Equipped with reliable detection techniques, he developed another project involving Geiger, in conjunction with an extraordinary undergraduate, Ernest Marsden. Just twenty years old at the time (1909), Marsden had a background curiously parallel to Rutherford’s. Like Rutherford, Marsden came from humble roots, with a father in the textile industry. Marsden’s dad was a cotton weaver from Lancashire, the local English county. Rutherford started his life in New Zealand and ended up in England; for Marsden it would be the reverse. And each performed vital experimental research while still in their undergraduate years. In Marsden’s case, he was just completing his course of study when asked to contribute his talents. Rutherford recalled the simple query that led to Geiger and Marsden’s monumental collaboration. “One day Geiger came to me and said, ‘Don’t you think that young Marsden . . . ought to begin a small research?’ Now I had thought that too, so I said, ‘Why not let him see if any alpha particles can be scattered through a large angle?’ ” 10 Legendary for posing just the right questions at precisely the right time, Rutherford had a hunch that the possibility of alpha particles scattering backward from a metal would reveal something about the material. Although he was curious to see what would happen, he didn’t necessarily expect a positive outcome. But given even the slightest chance of the particles bouncing off a hidden something, he felt it would be a sin not to try. For certain types of sensitive measurements, particle physicists have to be like nocturnal cats on the prowl; they need to see well in the dark to spot the subtle signs of their prey. That’s an area in which younger scientists can have an advantage—not just with better vision but also with patience. No wonder Rutherford and Geiger recruited a twenty-year-old for the alpha particle scattering experiment. Marsden was instructed to cover the windows, making the lab as dark as possible, and then to sit and wait until his pupils were dilated enough to sense every errant speck of light. Only then was he supposed to start taking readings. Placing plates of various thicknesses and types of metal (lead, platinum, and so forth) near a glass tube filled with a radium compound, Marsden waited for alpha particles to emerge from the tube, hit the plates, and either pass through or bounce off. A zinc sulfide screen, acting as a scintillator, was positioned to record the rates and angles of any alpha particles that happened to reflect. After testing each kind of metal, recording the constellations of sparks his sensitive eyes could see, he shared the data with Geiger. They soon realized that thin sheets of gold offered the highest rate of bounces. Even then, the vast majority of alpha particles passed right through the foil as if it were the skin of a ghost. In the rare cases of reflection, the majority took place at very large angles (ninety degrees or higher), indicating that something hard and focused within the gold was bouncing the alpha particles back. Glowing with excitement, Geiger ran up to Rutherford. “We have been able to get some of the alpha particles coming backwards!” he reported. Rutherford was absolutely delighted. “It was quite the most incredible event that has ever happened to me in my life,” Rutherford recalled. “It was almost as incredible as if you fired a 15-inch shell at a piece of tissue paper and it came back and hit you.” 11 If Thomson’s plum pudding model was correct, then alpha particles impacting a gold foil would be modestly diverted by the gelatinous mixture of charges within the gold atoms and bounce back at fairly small angles. But that’s not what Geiger and Marsden found. Like champion sluggers in a baseball game, something within the atoms slammed back the projectiles at large angles only if they were within certain narrow strike zones; otherwise, they continued straight through. In 1911, Rutherford decided to publish his own alternative to the Thomson model. “I think I can devise an atom much superior to J. J.’s,” he informed a colleague. 12 His groundbreaking paper introduced the idea that each atom has a nucleus—a tiny center packed with positive charge and the bulk of the atom’s mass. When the alpha particles hit the gold, that’s what batted them back, but only in the unlikely chance that they were right on target. Atoms are almost completely empty space. The nuclei constitute but a minuscule portion of their volume—the rest is unfathomable nothingness. If an atom were the size of Earth, then a cross-section of its nucleus would be roughly the size of a football stadium. Rutherford colorfully described striking a nuclear target as akin to locating a gnat in the Albert Hall, a huge performance venue in London. Despite their minuteness, nuclei play a critical role for determining the properties of atoms. As Rutherford surmised, the amount of positive charge in the nucleus corresponds to its place in the periodic table—called its atomic number. Starting with one for hydrogen, each atom’s nucleus houses the positive equivalent of the charge of the electron multiplied by its atomic number. For example, gold, the seventy-ninth element, has a nucleus charged to the positive equivalent of seventy-nine electrons. Balancing out the central positive charge is the same number of negatively charged electrons—rendering the atom electrically neutral unless it is ionized. These electrons, Rutherford asserted, are scattered in a sphere uniformly distributed around the center. Rutherford’s model was a great conceptual leap, but it left certain questions unanswered. Although it brilliantly explained the Geiger-Marsden scattering results, it didn’t address many aspects of what was known about the atom at the time. For example, it didn’t account for why the spectral lines of hydrogen, helium, and other atoms have distinct patterns. If electrons in the atom are evenly spaced, how come atomic light spectra are not? And how did Planck’s quantum concept and Einstein’s photoelectric effect, showing how electrons can exchange energy via discrete bundles of light, fit into the picture? Fortunately, in the spring of 1912, Rutherford’s department welcomed a young visitor from Denmark who would help resolve these issues. Niels Bohr, a freshly minted Ph.D. from Copenhagen with an athletic build and a long face with prominent jowls, arrived at Manchester after half a year with Thomson in Cambridge. Bohr had written to Rutherford asking if he could spend some time learning about radioactivity. He had learned from Thomson about Rutherford’s nuclear model and was intrigued about exploring its implications. While performing some calculations about the impact of alpha particles on atoms, Bohr decided to introduce the notion that electrons vibrate with only particular values of energy, multiples of Planck’s constant. In a stroke, he forever painted atoms with the variegated coating of quantum theory. After returning to Copenhagen in the summer of that year, Bohr continued his studies of atomic structure, focusing on the question of why atoms don’t spontaneously collapse. Something must prevent the negative electrons from plunging toward the positive nucleus, like a meteorite hurtling toward Earth. In Newtonian physics, a conserved property called angular momentum characterizes the tendency of rotating objects to maintain the same rate of turning. Specifically, mass times velocity times orbital radius tends to remain constant—the reason why ballet dancers twirl faster when they tuck their arms closer to their bodies. Bohr noticed that by requiring an electron’s angular momentum to be a multiple of Planck’s constant divided by twice the number pi (3.1415 . . . ), he forced it to maintain specific orbits and energies. That is, electrons could reside only particular distances from an atom’s nucleus, in discrete levels called quantum states. Bohr’s insight led to enormous strides in tackling the question of why atomic spectral lines are arranged in certain patterns. In his model of the atom, electrons neither gain nor lose energy if they maintain the same quantum state—a situation akin to an idealized, absolutely stable planetary orbit. Therefore, superficially, Bohr’s picture treats electrons like little “Mercurys,” “Venuses,” and so forth, revolving around a nuclear “Sun.” Instead of gravity acting as the central force, the electrostatic attraction between negative electrons and the positive nucleus does the job. At that point, however, the solar system analogy ends, and Bohr’s theory veers on a radically different course. Unlike planets, electrons sometimes “jump” from one quantum state to another, either toward or away from the nucleus. These jumps are instant and spontaneous, resulting in either the loss or gain of a quantum of energy, depending on whether the motion is to a lower or higher energy level. In line with the photoelectric effect, these energy quanta, later called photons or light particles, have frequencies equal to the energy transferred divided by Planck’s constant. Thus, the particular lines of color in the emission spectra of hydrogen and other atoms are due to the luminous ballast flung away when electrons enact specific dives—generally the longer the dive, the greater the frequency. Indeed, Bohr’s calculations matched up perfectly with the known formulas for the spacings of hydrogen spectral lines—a stunning success for his model. In the winter of 1913, Bohr wrote to Rutherford with his results and was disappointed to receive a mixed response. Ever the practical thinker, Rutherford found what he saw as a major flaw. He informed Bohr, “There appears to me one grave difficulty in your hypothesis, which I have no doubt you fully realize, namely how does an electron decide what frequency it is going to vibrate at when it passes from one stationary state to another? It seems to me that you have to assume that the electron knows beforehand where it is going to stop.” 13 With his perceptive comment, Rutherford identified one of the principal quandaries involving Bohr’s atomic model. How can you predict when an electron will abandon the tranquillity of the state it is in and venture to a new one? How can you determine exactly in which state the electron ends up? Bohr’s model couldn’t say—and Rutherford was bothered. Only in 1925 would Rutherford’s critique be addressed, and even then the answer was most perplexing. Bohr, by that time, had become the head of his own institute for theoretical physics (now the Niels Bohr Institute) in Copenhagen, where he hosted a stellar array of young researchers. One of the very brightest, German physicist Werner Heisenberg, who studied in Munich and Göttingen, developed a brilliant alternative description of electrons in the atom that, although it didn’t explain why electrons jumped, could accurately calculate the chances of their doing so. Heisenberg’s “matrix mechanics” introduced a new abstraction to physics that confused many old-timers and revolted some of the prominent physicists who understood its implications—most famously Einstein, who argued vehemently against it. It draped a veil of uncertainty around the atom—and indeed all of nature on that scale or smaller—demonstrating that not all physical properties can be glimpsed at once. Like many a rebellious youth, Heisenberg began his line of reasoning by abandoning many of the long held suppositions of his elders. Instead of treating the electron as an actual orbiting particle, he reduced it to a mere abstraction: a mathematical state. To represent position, momentum (mass times velocity), and other measurable physical properties, he multiplied the representation state by different quantities. His Ph.D. adviser, Göttingen physicist Max Born, suggested encoding these quantities in arrays called matrices—hence the term “matrix mechanics,” also known as quantum mechanics. Equipped with powerful new mathematical tools, Heisenberg felt that he could explore the very depths of the atom. As he recalled, “I had the feeling that, through the surface of atomic phenomena, I was looking at a strangely beautiful interior, and felt almost giddy at the thought that I now had to probe this wealth of mathematical structures nature had so generously spread before me.” 14 In classical Newtonian physics, both position and momentum can be measured at the same time. Not so in quantum mechanics, as Heisenberg cleverly demonstrated. If position and momentum matrices are both applied to a state, the order of their application makes a profound difference. Applying position first and then momentum generally produces a different result than applying momentum first and then position. The situation in which the order of operations matters is called noncommutative—in contrast with commutative forms of arithmetic such as addition and multiplication. While four times two is the same as two times four, position times momentum is not the same as momentum times position. This noncommutativity renders it impossible to know both quantities simultaneously with perfect certainty, a state of affairs Heisenberg later formalized as the uncertainty principle. In quantum mechanics, Heisenberg’s uncertainty principle mandates, for example, that when the position of an electron is ascertained, its momentum goes all fuzzy. Because momentum is proportional to speed, an electron can’t tell you where it is and how fast it’s going at the same time. Electrons are mercurial creatures indeed, not Mercurial—more like elusive quicksilver than an orbiting planet. Despite the inherent uncertainty in quantum mechanics, as shown by Heisenberg, it offers accurate predictions of probabilities. So while it doesn’t guarantee that a bet will pay off, at least it tells you the odds. For example, it tells you the chances that an electron will plunge from any given state to another. If the chances are zero, then you know that such a transition is forbidden. Otherwise, it is allowed and you can expect a line in the atom’s spectrum with corresponding frequency. In 1926, physicist Erwin Schrödinger proposed a more tangible alternative version of quantum mechanics, called wave mechanics. In line with a theory proposed by French physicist Louis de Broglie, Schrödinger’s version imagines electrons as “matter waves”—akin to light waves, but representing material particles rather than electromagnetic radiation. These wave functions respond to physical forces in a manner described by a relationship called Schrödinger’s equation. Subject to the electrostatic attraction of an atomic nucleus, for example, wave functions representing electrons form “clouds” of various shapes, energies, and average distances from the center of the atom. These clouds are not actual arrangements of material, but rather distributions of the likelihood of an electron’s being in different points in space. We can think of these wave formations as akin to the vibrations of a guitar string. Because it is attached on both ends, a plucked guitar string produces what is called a standing wave. Unlike a rolling ocean wave heading toward a beach, a standing wave is constrained to move only up and down. Within such restrictions it can have a number of peaks—one, two, or more—as long as it is a whole number, not a fraction. Wave mechanics identifies the principal quantum number of an electron with the number of peaks of its wave function, offering a natural explanation for why certain states exist and not others. Much to Heisenberg’s chagrin, many of his colleagues favored Schrödinger’s depiction over his—perhaps because they were accustomed to models of sound waves, light waves, and kindred phenomena. Matrices seemed too abstract. Fortunately, as the sharp-witted Viennese physicist Wolfgang Pauli proved, Heisenberg’s and Schrödinger’s descriptions are completely equivalent. Like digital and analog clocks they’re equally trustworthy instruments and can be relied on according to taste. Pauli offered his own critical contribution to quantum mechanics: the concept that no two electrons can be in exactly the same quantum state. His “exclusion principle” inspired two young Dutch researchers, Samuel Goudsmit and George Uhlenbeck, to propose that electrons can exist in two orientations, called spin. Contrary to its name, spin has nothing to do with actual spinning, but rather with an electron’s magnetic properties. If we imagine placing an electron in a vertical magnetic field (for instance, directly above a magnetized coil of wire), then the electron’s own minimagnet could be aligned in the same direction as the external field, called “spin-up,” or in the opposite direction, called “spin-down.” Ambidextrous by nature, an electron normally consists of an equal mixture of spin-up and spin-down states. How can a single particle have two opposite qualities at once? In mundane experience, compass needles can’t point north and south at the same time, but the quantum world defies conventional explanation. Until an electron’s spin is measured, quantum uncertainty dictates that an electron’s spin is ambiguous. Only after a researcher switches on an external magnetic field does an electron reduce into a spin-up or spin-down orientation—a process known as wave function collapse. If two electrons are paired and one is determined to be spin-up, the other automatically flips spin-down. This switching takes place even if the electrons are widely separated—an intuition-defying effect Einstein called “spooky action at a distance.” Because of such unintuitive connections, Einstein thought a deeper, more straightforward theory would someday replace quantum mechanics. Bohr, on the other hand, embraced contradictions. He reveled in unions of opposites—such as the notion that electrons are waves and particles at the same time, which he called the principle of complementarity. Prone to enigmatic statements, he once said, “A great truth is a truth whose opposite is also a great truth.” Appropriately, right in the center of his coat of arms he placed the yin-yang symbol of Taoist contrasts. 15 Despite their philosophical differences, Einstein shared with Bohr the realization that quantum mechanics matches up incredibly well with experimental data. One sign of Einstein’s recognition would be his nomination of Heisenberg and Schrödinger for the Nobel Prize in Physics, which Heisenberg was awarded in 1932 and Schrödinger shared with British quantum physicist Paul Dirac in 1933. (Einstein and Bohr were awardees in 1921 and 1922, respectively.) Rutherford would remain cautious about quantum theory, continuing to focus his attention mainly on experimental explorations of the atomic nucleus. In 1919, Thomson stepped down as Cavendish professor and director of Cavendish Laboratory, and Rutherford was appointed to that venerable position. During his final year at Manchester and his initial years at Cambridge, he focused on bombarding various nuclei with fast-moving alpha particles. Marsden had noticed that where alpha particles collide with hydrogen gas, even faster, more penetrating particles emerge. These were the nuclei of hydrogen atoms. Rutherford repeated Marsden’s experiment, replacing the hydrogen with nitrogen, and much to his astonishment, hydrogen nuclei emerged from that gas too. Striking a fluorescent screen, the scintillations produced by the hydrogen nuclei were so faint and tiny that they could be seen only through a microscope. Yet they offered important evidence that the nitrogen atoms were releasing particles from their cores. As the discovery of radioactivity showed that atoms could transmute on their own, Rutherford’s bombardment experiments demonstrated that atoms could be altered artificially as well. Rutherford coined a name for the positively charged particles found in all nuclei: protons. Some researchers wanted to call these “positive electrons,” but he objected, arguing that protons are far more massive than electrons and have little in common. When an actual positive electron was discovered, following predictions by Dirac, it ended up being called the positron. Positrons provided the first example of what is known as “antimatter”: similar to ordinary matter but oppositely charged. Protons, on the other hand, are a key constituent of conventional matter. A new type of particle detector, called the cloud chamber, aided Rutherford and his group in understanding the paths of particles, such as protons, after they are emitted from target nuclei. While scintillators and Geiger counters could measure the rate of emitted particles, cloud chambers could also capture their behavior as they move through space, leading to an improved understanding of their properties. Cloud chambers were invented by Scottish physicist Charles Wilson, who noticed during a hike up the mountain Ben Nevis that moist air tends to condense into water droplets in the presence of charged particles such as ions. The charges attract the water molecules and pull them out of the air, offering a vapor trail of electrically active regions. Realizing that the same principle could be used to detect unseen particles, Wilson designed a closed chamber filled with cold, humid air that displayed visible streaks of condensation whenever charged particles passed through—similar to the jet trails etched by airplanes in the sky. These patterns can be photographed, providing a valuable record of what transpires during an experiment. Although Wilson completed his first working model in 1911, it wasn’t until 1924 that cloud chambers came into use in nuclear physics. That year Patrick Blackett, a graduate student in Rutherford’s group, used such a device to record the release of protons in the transmutation of nitrogen. His data wonderfully complemented Rutherford’s scintillation experiments, presenting irrefutable evidence of artificial nuclear decay. Protons are not the only inhabitants of nuclei. In another of his legendary successful prognostications, in 1920 Rutherford predicted that nuclei harbor neutral particles along with protons. Twelve years later, Rutherford’s student James Chadwick would discover the neutron, similar in mass to the proton but electrically neutral. In a key paper written right after Chadwick’s discovery, “On the Structure of Atomic Nuclei,” Heisenberg introduced the modern picture of protons and neutrons constituting the cores of all atoms. The nuclear picture helps explain the different types of radioactivity. Alpha decay occurs when nuclei emit two protons and two neutrons at once—an exceptionally stable combination. Beta decay, on the other hand, derives from neutrons decaying into protons and electrons—with the beta particles comprising the released electrons. As Pauli showed, this couldn’t be the whole story because some extra momentum and energy couldn’t be accounted for. He predicted the existence of an unseen neutral particle that came to be known as the neutrino. Finally, gamma decay represents the release of energy when a nucleus transforms from a higher- to a lower-energy quantum state. While in alpha and beta decay, the number of protons and neutrons in the nucleus alters, resulting in a different element, in gamma decay that quantity stays the same. From Rutherford’s historic techniques and discoveries, an idea was forged: using elementary particles to probe the natural world on its tiniest scale. Radioactive materials pumping out alpha particles offered a reliable source for early investigations of the nucleus. They were perfect for Geiger and Marsden’s scattering experiments that proved that atoms have tiny cores. Yet, as Rutherford came to realize, exploring nuclear properties in a fuller and deeper way would require much higher energy probes. Breaking through the nuclear fortress would take a sturdy battering ram—particles propelled through artificial means to fantastically high velocities. He decided that Cavendish would build a particle accelerator—a project that he recognized would entail a certain amount of theoretical know-how. Fortunately, direct from Stalin’s own fortress nation, a whiz kid would slip away and bring his cache of quantum knowledge to Free School Lane.",
        "char_count": 44866
      },
      {
        "heading": "Chapter 9",
        "text": "4 Smashing Successes The First Accelerators What we require is an apparatus to give us a potential of the order of 10 million volts which can be safely accommodated in a reasonably sized room and operated by a few kilowatts of power. We require too an exhausted tube capable of withstanding this voltage . . . I see no reason why such a requirement cannot be made practical. —ERNEST RUTHERFORD (SPEECH AT THE OPENING OF THE METROPOLITAN-VICKERS HIGH TENSION LABORATORY, MANCHESTER, ENGLAND, 1930) The Soviet People’s Commissariat of Education issued its coveted stamp of approval, permitting one of its most brilliant physicists, George Gamow, the opportunity to spend a year at Cavendish. He had almost missed the chance due to an odd medical mix-up. During his clearance check-up, his doctor inadvertently reversed the digits of his blood pressure, flagging him for heart disease. Once that error was cleared up, he got the green light. The Rockefeller Foundation generously offered to support his travel and expenses. Fellowships funded through oil wealth weren’t exactly the revolutionary means to success Lenin had anticipated, but the Soviet Union at that time viewed the admission of one of its native sons to the world’s premier nuclear physics laboratory as a triumph for its educational system. It is lucky for the history of accelerators that Gamow managed to make it to England. His theoretical insights would offer the critical recipe for breaking up atomic nuclei and place Cavendish in the forefront of the race to build powerful atom smashers. Thanks in part to his contributions, and to the magnificent experimental work of his colleagues, Cavendish would become for a time the leading center for nuclear research in the world. The Leningrad-trained physicist arrived in Cambridge in September 1928 and quickly found lodging at a boardinghouse. When a friend visited him soon thereafter he was astonished: “Gamow! How did you manage to get this house?” At Gamow’s perplexed look, his friend pointed to the name of the building. By sheer coincidence it was called the “Kremlin.” Several weeks after joining Cavendish, Gamow experienced one of its director’s legendary bursts of temper. One day, without prior explanation, Rutherford called Gamow into his office. Red-faced, he started screaming about a letter he had just received from the Soviet Union. “What the hell do they mean?” he bellowed as he shoved it at Gamow. Gamow read over the letter. Written in scrawled English, it said: Dear Professor Rutherford, We students of our university physics club elect you our honorary president because you proved that atoms have balls. After Gamow patiently explained that the Russian word for atomic nucleus is similar to its word for cannonball, and that the letter was probably mistranslated, Rutherford calmed down and had a hearty laugh. 1 Among the first items Gamow procured at Cambridge were instruments that were ideal for striking spherical projectiles and hurling them toward distant targets. It was a set of golf clubs—par for the course at a collision laboratory. Gamow’s instructor in the sport was John Douglas Cockcroft, a young Cavendish researcher and avid golfer. Born in Todmorden, England, in 1897, Cockcroft took a circuitous path to physics. His father ran a cotton-manufacturing business, but, like Rutherford and Marsden, Cockcroft opted for science over textiles. He began studying mathematics at Manchester University, but then World War I broke out and he joined the British army. Returning to Manchester upon the armistice, he switched to electrical engineering and found a job in the field. Finding that career path personally unfulfilling, he enrolled at St. John’s College, Cambridge, and made his way to Rutherford’s lab. In golf, it can be frustrating when there’s a hill right in front of the green, occluding the direct path to the hole. In that case, you need a bit of strategy to figure out what club to use and how hard to swing it in order to clear the barrier. Tap the ball with not enough force, and it’s liable to fall short. Cockcroft worked on a problem in nuclear physics that offered a similar kind of challenge. He wanted to hurl particles toward nuclear targets with the goal of exciting them to higher energy levels and possibly breaking them into subcomponents. If smashing them together broke them up, seeing what came out would allow him and his colleagues to learn things about the makeup of an atom they couldn’t learn in any other way. Blocking the path to the nucleus, however, was the barrier caused by the mutual electrostatic repulsion of positively charged particles and the positive nuclear charge. They naturally push each other apart—a formidable obstacle to overcome—like the north poles of bar magnets resisting being brought together, only far stronger. Gamow knew just how to handle the issue theoretically. Plugging the parameters corresponding to protons and alpha particles (the particles radioactive atoms such as uranium give off) into his “quantum tunneling” formula, Gamow discovered that the former would need sixteen times less initial energy than the latter for the same probability of penetration. The choice was clear: protons offer much more economical projectiles. If protons could be induced to move fast enough, a few might pass through the force barrier around an atom and smash into its nucleus. What exactly would happen once they reached their targets was unknown, but, convinced by Gamow, Rutherford decided it would be worthwhile to try. It would be the one major step Rutherford took that was driven by theoretical predictions. Already involved in planning the details of an atom smasher was an adept young experimentalist, Ernest Thomas Sinton Walton. Born in Dungaravan, Ireland, in 1903, he was the son of a traveling Methodist preacher. In 1915, Walton enrolled in a Methodist boarding school where he excelled in the sciences. Following his graduation in 1922, he became a student at Trinity College in Dublin, where he received a master’s degree in 1927. Upon being awarded an Exhibition of 1851 scholarship to Cambridge, he joined the group at Cavendish and soon became one of Rutherford’s trusted assistants. In late 1928, Walton came across an extraordinarily innovative research paper by Norwegian engineer Rolf Wideröe that described his attempts to accelerate particles by means of a device called the ray transformer. Wideröe’s mechanism combined several basic concepts in electromagnetic theory. It starts with the idea of an electromagnetic coil: a current-carrying wire wrapped in a loop that produces a magnetic field in its vicinity. If the wire has a changing current, then the magnetic field changes over time. Then, according to Faraday’s law of induction, the changing magnetic field produces a second current in any wire that happens to be nearby. If that second wire is in a loop too, the setup is known as a transformer—a familiar system for transferring power from one wire to another. In a way, it’s analogous to the spinning of a bicycle’s pedals giving rise to the turning of its wheels—with the chain representing the varying magnetic field connecting the two. Wideröe’s principal innovation was to replace the second wire with electrons accelerated through a vacuum-filled ring. These electrons would be removed from atoms and propelled through space by what is called the electromotive force produced by the changing magnetic field. To keep the electrons moving in a loop, like race cars on a circular track, he envisioned a central magnet that would steer them round and round. Unfortunately, in trials of his machine at Aachen University in Germany, he found that “islands of electrons” built up in the tube, sapping the revolving electrons’ energy. For some reason, the magnet couldn’t keep the electrons moving smoothly, though he couldn’t figure out why. The best Wideröe could manage given the turbulence was to get the electrons to circle around the loop one and a half times. Frustrated by the problems with the circular track, Wideröe finally decided to abandon the project and turn to a different scheme. Borrowing a concept he found in a 1924 article by Swedish physicist Gustav Ising, he pursued the idea of a linear accelerator and built a small prototype, about one yard long. Rather than a ring, it used a pair of “drift tubes” (straight, isolated, vacuum-filled pipes) in which particles would be sped up by successive “kicks” of an electric field. These boosts were arranged rather cleverly—allowing the particles to be lifted up to higher speeds twice by use of the same voltage difference—something like the continuously ascending stairways in some of Escher’s paintings. Just when the particles seemed to reach the top, there was more to climb. Voltage, electric potential energy per charge, is a measure of how easy it is for particles of specific mass and charge to accelerate from one place to another; the higher the voltage difference, the greater the acceleration, all other factors being equal. In other words, voltage is a measure of how steep that staircase is—and how much of a boost it gives. Particles began their journeys through a drift tube with high voltage (twenty-five thousand volts) at the entrance point and low voltage at the exit. This voltage difference caused them to speed up. When the particles were halfway through and already moving quickly, Wideröe tricked them by reversing the voltage difference, setting the formerly low voltage to high. Because they were already moving at high speeds it was too late for them to turn back. They rushed through the tail end of the first tube, across a gap, and then on to the start of a second tube, where the same voltage difference (once again, due to an initially high voltage and a final low voltage) accelerated them even farther. Because it used the same voltage difference twice, Wideröe’s method doubled the impact of the boost, enabling a lower voltage source than otherwise required. At the end of the second tube, Wideröe placed a photographic plate to record the streaks produced by the high-velocity particles as they impacted. Experimenting with potassium and sodium ions as the projectiles, he was able to run them through his device. The ions were made by stripping atoms of their outer electrons. The positively charged ions were then compelled by the voltage differences to accelerate through the tubes before hitting the plate. After collecting enough data, Wideröe incorporated his findings into a doctoral thesis for Aachen University. The thesis was published in a journal his Ph.D. adviser edited. Fascinated by Wideröe’s work, in December 1928, Walton proposed to Rutherford the idea of building a linear accelerator at Cavendish. Rutherford was keen to devise such a device that could look inside one of the lighter elements, such as lithium. (Lithium is the third element in the periodic table after hydrogen and helium and its atom is now known to have three protons and four neutrons in its core.) The next month, Gamow gave a talk that presented his barrier penetration formula to the group. Cockcroft was eager to apply this formula to the issue of penetrating the lithium nucleus with protons. Estimates showed that it would take several hundred thousand electron volts to do the job. By human standards, even 1 MeV (one million electron volts) is an extraordinarily tiny amount of energy—approximately one billionth of a billionth of a single dietary calorie (technically, a kilocalorie). Elementary particles obviously don’t have to worry about slimming down—however for them it’s quite an energizing burst! Upon hearing these results, Rutherford called Cockcroft and Walton into his office. “Build me a one-million-electron volt accelerator,” he instructed. “We will crack the lithium atom open without any trouble.” 2 Soon Cockcroft and Walton were hard at work building a linear accelerator that they would locate, when it was complete, in a converted lecture hall. They rigged up a straight tube with a specially designed high-voltage power supply, now known as the Cockcroft-Walton generator. It included a mechanism known as a voltage multiplying circuit that included four high-voltage generators stacked in a ladderlike formation twelve feet high. Capacitors (charge-storing devices) in the circuit helped oost a relatively modest input voltage to an overall voltage of up to seven hundred thousand. Propelled by this high voltage, protons would be accelerated by the electric forces through an evacuated tube and collide with nuclear targets on the other end—with any disintegrations recorded as sparks on a fluorescent screen placed inside the vacuum. A Cockcroft-Walton generator, one of the earliest types of accelerator. This example is retired and located in the garden of Microcosm, CERN’s science museum. In 1931, Walton received his Ph.D. from Cambridge. With the Cavendish accelerator on the brink of completion, Rutherford certainly couldn’t afford to lose one of its principal architects. Walton was appointed Clerk Maxwell Research Scholar, a position he would hold for an additional three years while continuing to work with Cockcroft and Rutherford. Cavendish was far from the only player in the race to split the atom. Physicists around the world were well aware of what Rutherford was trying to do and hoped to unlock the nucleus themselves with their own powerful atom smashers. Aside from scientific interest, another motivation that would become increasingly important was anticipation of colossal energy locked inside the atomic core. Einstein’s famous equation for the equi-valence of energy and mass, E = mc 2 , indicated that if any mass were lost during a nuclear disintegration it would be converted into energy—and this could be formidable. In 1904, even before Einstein’s finding, Rutherford had written, “If it were ever possible to control at will the rate of disintegration of the radio elements, an enormous amount of energy could be obtained from a small amount of matter.” 3 (In 1933, he would qualify this statement when, in a prediction uncharacteristically off the mark, he expressed the opinion that atomic power could never be controlled in a way that would be commercially viable.) A highly innovative thinker who would become a key participant in the development of nuclear energy was the Hungarian physicist Leo Szilard. In December 1928, while living in Berlin, Szilard took out a patent for his own concept of a linear accelerator. Like Ising and Wideröe, Szilard envisioned an oscillating (direction switching) electric field that would prod charges along. In his patent application, titled “Acceleration of Corpuscles,” he described a way of lining up charged ions so they ride the crest of a traveling wave forcing them to move ever faster: With our arrangement, the electric field can be conceived of as a combination of an electric field in accelerated motion from left to right and an electric field in decelerated motion from right to left. The device is operated in such a way that the velocity of the accelerated ion equals, at each point, the local velocity of the field moving left to right. 4 Curiously, Szilard never pursued his design. He developed patent applications for two other accelerator schemes that he similarly never followed up on. History does not record whether or not his patent applications were even accepted—conceivably the patent officers were aware of the earlier papers by Ising and Wideröe. Around the same time as Cockcroft and Walton began to build their apparatus, American physicist Robert Jemison Van de Graaff developed a simple but powerful accelerator model that, because of its compactness and mobility, would become the nuclear physics workhorse for many years. Born in Tuscaloosa, Alabama, in 1901, Van de Graaff began his career on a practical track. After receiving B.S. and M.S. degrees in mechanical engineering from the University of Alabama, he worked for a year at the Alabama Power Company. He could well have remained in the electrical industry, but Europe beckoned, and in 1924, he moved to Paris to study at the Sorbonne. The great Marie Curie herself taught him about radiation—acquainting him in her lectures with the mysteries of nuclear decay. His savvy won him a Rhodes scholarship, enabling him to continue his studies at Oxford. There he learned about Rutherford’s nuclear experiments and the quest to accelerate particles to high velocities. Oxford awarded him a Ph.D. in physics in 1928. In 1929, Princeton University appointed Van de Graaff as a national research fellow at the Palmer Physics Laboratory, the center of its experimental program. He soon designed and built a prototype for a novel kind of electrostatic generator that could build up enormous amounts of charge and deliver colossal jolts. Its basic idea is to deliver a continuous stream of charge from a power source to a metal sphere using a swift, insulated conveyor belt. Van de Graaff constructed his original device using a silk ribbon and a tin can; later he upgraded to other materials. Near the bottom of the belt, a sharp, energized comb connected to the power source ionizes its immediate surroundings, delivering charge to the belt. Whisked upward, the charge clings to the belt until another comb at the top scrapes it off and it passes to the sphere. A pressurized gas blankets the entire generator, creating an insulated cocoon that allows more and more charge to build up on the sphere. Using the Van de Graaff generator as an accelerator involves placing a particle source (a radioactive material or an ion source, for example) near the opening of a hollow tube, each situated within the sphere. The voltage difference between the sphere and the ground serves to propel the particles through the tube at high speeds. These projectiles can be directed toward a target at the other end. Van de Graaff worked continuously at Princeton and later at MIT to increase the maximum voltage of his generators. While his prototype could muster up to eighty thousand volts, an updated model he presented at the American Institute of Physics’s inaugural banquet in 1931 stunned the dining guests (fortunately not literally) by producing more than one million volts. A much larger machine he assembled on flatbed railroad cars in a converted aircraft hangar in South Dartmouth, Massachusetts, consisted of twin insulated columns, each twenty-five feet high, capped with fifteen-foot-diameter conducting spheres made of shiny aluminum. Its colossal power inspired the New York Times headline on November 29, 1933, “Man Hurls Bolt of 7,000,000 volts.” 5 According to Greek mythology, Prometheus stole the secret of fire from the gods, offering humanity the sacred knowledge of how to create sparks, kindle wood, light torches, and the like. Yet even after that security breach, mighty Zeus reserved the right to hurl thunderbolts at his foes, illuminating the heavens with his terrifying power. Through Van de Graaff ’s generator, even something like the awe-inspiring vision of lightning became scientifically reproducible, albeit on a smaller scale, ushering in a new Promethean age in which colossal energies became available for humankind’s use. Given such newly realized powers, perhaps it is not surprising that many horror films of the day, such as Frankenstein (1931) and Bride of Frankenstein (1935) most notably, offered sinister images of gargantuan laboratories spawning monsters electrified by means of colossal generators. Why rely on expensive generators for artificial thunderbolts, if the real thing is available in the skies for free? Indeed, though lightning is, of course, highly unpredictable and extremely dangerous, several physicists of that era explored the possibility of using lightning itself to accelerate particles. During the summers of 1927 and 1928, University of Berlin researchers Arno Brasch, Fritz Lange, and Kurt Urban rigged up an antenna more than a third of a mile across between two adjacent peaks in the southern Swiss Alps near the Italian border. They hung a metallic sphere from the antenna and wired another sphere to the ground to measure the voltage difference between the two conductors during thunderstorms. During one lightning strike, more than fifteen million volts passed through the device, according to the researchers’ estimates. Sadly, during their investigations Urban was killed. The two survivors returned to Berlin to test discharge tubes with the potential to withstand high voltages. Brasch and Lange published their results in 1931. 6 Lightning strikes, even of the artificial kind, are usually one-time-only affairs. Whenever great quantities of charge build up, it creates a huge voltage drop that maintains itself as long as the collected charge has nowhere else to go (if the apparatus is isolated or insulated, for example). Like cliff divers, particles plunging down the steep potential difference experience a force that accelerates them. But once they reach the ground, that’s it—end of story. However, as Wideröe pointed out in his “ray transformer” proposal, particles forced to travel in a ring, instead of a straight line, could be accelerated repeatedly each time they rounded the loop, building up to higher and higher energies. Although, after his initial experiments failed, Wideröe ceased working on the idea of a circular accelerator, his article inspired an extraordinary American physicist, Ernest Orlando Lawrence, to pursue this vital approach. Lawrence was born in the prairie town of Canton, South Dakota, in 1901. His parents, Carl and Gunda, were both school-teachers of Norwegian descent. Carl was the local superintendent of schools and also taught history and other subjects in the high school; Gerda instructed in mathematics. Ernest was a cheerful baby, whom the neighbors across the street, the Tuve family, contrasted with their own colicky, crying boy born six weeks earlier, Merle. Practically from birth Ernest and Merle were best friends. They would pull various pranks together, such as once dumping rubbish on another neighbor’s porch. The neighbor happened to be home and snatched Merle, before he escaped, through a hole in her fence. Meanwhile, Ernest managed to get away. They shared a code of honesty and tried not to fib, even when they were mischievous. When the boys were only eight years old, they became interested in electrical devices. Practically all of their waking hours, aside from school and chores, were spent hooking up crude batteries into circuits, connecting these power sources to bells, buzzers, and motors, and testing which combinations worked best. Tall and lanky, Lawrence earned the childhood nickname “Skinny,” which he didn’t seem to mind. His interests were as narrow as his build. Aside from tennis, he was little interested in sports and participated grudgingly in athletic activities, mainly when prodded by his father. Nor, as a teenager, was he much inclined to go on dates and other social events. Rather, he buried himself in his studies so that he could graduate from high school a year early, while continuing to spend his free time, along with Tuve, assembling various mechanical and electrical apparatuses. To earn money for switches, tubes, and other radio equipment, he spent one summer working on an area farm—a job he detested. The farmer he worked for had a low opinion of his skills, complaining, “He can’t farm worth a nickel.” 7 Despite his limitations in many areas beyond science, Lawrence’s single-mindedness would prove a great strength. Like a magnifying glass on dry wood, whatever topics Lawrence’s bright blue eyes did focus on would be set ablaze with his extraordinary energy and intuitive understanding. One of the first to recognize his talents was Lewis Akeley, dean of electrical engineering at the University of South Dakota, where he completed his undergraduate studies. Lawrence had transferred there in 1919 from St. Olaf College in Minnesota with the goal of preparing for a career in medicine, but Akeley steered him toward physics. Akeley was so impressed by Lawrence’s phenomenal knowledge of wireless communication that he decided to experiment with a new teaching arrangement. For senior seminar he asked Lawrence, the only upper-level physics major, to prepare and deliver the lectures himself. While Lawrence was speaking, Akeley sat smiling as an audience of one, marveling that he was lucky enough to get to know perhaps the next Michael Faraday. Meanwhile, Tuve was at the University of Minnesota and persuaded Lawrence to join its graduate program in physics. There, Lawrence found a new mentor, English-born physicist W. F. G. Swann, from whom he learned about the latest questions in quantum physics. Swann was a bit of a restless soul, an accomplished cellist as well as a researcher, who hated stodginess and valued creative thinking. Unhappy in Minnesota, he moved to Chicago and then to Yale, inspiring Lawrence to follow. Lawrence received his Ph.D. from Yale in 1925 and continued for three more years as national research fellow, working on new methods for determining Planck’s constant and the charge-to-mass ratio of the electron. Along with another research fellow, Jesse Beams, he developed a highly acclaimed way of measuring extremely short time intervals in atomic processes. They showed that the photoelectric effect, in which light releases electrons from metals, takes place in less than three billionths of a second—lending support to the idea that quantum events are instantaneous. 8 With his Ph.D. in hand, Lawrence finally found time to socialize, albeit in a manner unusual for a postdoctoral researcher. The daughter of the dean of the medical school, Mary Kimberly “Molly” Blumer, who was then only sixteen years old, needed a date for her high school prom. Word got out, and Lawrence agreed to be her escort. He was impressed with her quiet thoughtfulness, and after the prom he asked her if he could see her again. Politely, she said he could stop by, even though at that point in her life she understandably felt awkward being wooed by a man nine years her senior. Each time he visited her house, she would take any measure not to be alone with him—making sure her sisters accompanied them at all times. Sometimes she would even hide out in a family fishing boat in the Long Island Sound and refuse to return to shore. It is a tribute to his perseverance that they would eventually get married. Lawrence was courted in a different way by a rising star in the academic world, the University of California in Berkeley. Berkeley offered him an assistant professorship. When he turned it down in favor of remaining at Yale, Berkeley raised its offer to an associate professorship—a rank usually reserved for more seasoned faculty. Lawrence then decided to accept, thinking Berkeley would offer quicker advancement and a greater chance of working directly with graduate students. Some of his stuffier colleagues at Yale were taken aback that he would even consider switching to a non-Ivy League institution. “The Yale ego is really amusing,” Lawrence wrote to a friend. “The idea is too prevalent that Yale brings honor to a man and that a man cannot bring honor to Yale.” 9 In August 1928, Lawrence drove out west in an REO Flying Cloud Coupe to assume his new position. After crossing the American heartland and reaching the rolling Berkeley hills, he took time to admire the beauty of the Bay Area and the exciting cultural jumble of San Francisco. The campus, dominated by a Venetian-style bell tower, offered a different kind of splendor. Although rooted in European architectural themes, it seemed refreshingly bright and modern—a far cry from pompous East Coast tradition. Blessed with ample space and support for his work, he resumed his studies of the precise timing of atomic processes. Then, barely seven months after he started, his research took an unforeseen turn. Around April Fools’ Day of a year devastating for investors but auspicious for high-energy physics, Lawrence was sitting in the Berkeley library browsing through journals. Wideröe’s article leapt to his attention as if it were spring-loaded. It was the diagrams, not the words, that he noticed at first—sketches of electrodes and tubes arranged to propel particles. Of Wideröe’s two accelerator designs, the linear dual-tube arrangement and the ringed “ray transformer” scheme, Lawrence found the latter more appealing. Lawrence realized immediately that a straight-tube setup would be limiting, providing only a few kicks before particles reached their targets. By curving the tubes into semicircles with electrifying gaps in between, and bending particle paths with a central magnet, he saw that he could jolt the particles again and again. He noted the fortuitous coincidence in magnetism that for a given particle steered in a circular loop by a magnetic field, if the field is constant the ratio of the particle’s velocity to its orbital radius—a quantity known as angular velocity—similarly remains the same, even if the particle speeds up. Because angular velocity represents the rate by which an object travels around a circle, if it is constant then the object passes the same point in equal intervals of time—like a racehorse passing a grandstand precisely once a minute. This regularity, Lawrence, determined, would ensure that a voltage boost peaked at regular intervals (oscillating in the same rhythm as the orbits) could accelerate particles around a ring to higher and higher energies until they reached the level needed to penetrate a target nucleus. Lawrence realized the problem with Wideröe’s design, and his pileup of electrons, was all in timing the voltage boosts. Lawrence shared his design with Berkeley mathematician Donald Shane, who verified that the equations checked out. When Shane inquired, “What are you going to do with it?” Lawrence excitedly replied, “I’m going to bombard and break up atoms!” The following day, his exuberance grew even greater when additional calculations confirmed that particles in his planned accelerator could continue to circle faster and faster no matter how far they spiraled outward from the center of the ring. As he strutted through campus like a proud peacock, a colleague’s wife distinctly heard him exclaim, “I’m going to be famous!” 10 As he was accustomed to during childhood, Lawrence couldn’t wait to run his idea past Tuve, who was then working at the Carnegie Institution in Washington. Tuve was dubious about the scheme’s practicality. Ironically, the best friends were becoming rivals—following separate tracks in the race to split the nucleus. Along with Gregory Breit and Lawrence Hafstad, Tuve was involved in efforts to crank Tesla coils—paired wound coils for which lower voltage in one induces high voltage in the second—up to ultrahigh energies. However, these devices were extremely hard to insulate and wasted a lot of energy. After Van de Graaff developed his high-voltage generators, Tuve recognized their promise and began constructing his own. Because of doubts expressed by Tuve and other colleagues, Lawrence was at first hesitant to try out his concept, which he initially called the magnetic resonance accelerator and later became known as the cyclotron. It took some prodding by a noted scientist to get him going. Around Christmas 1929, he sat down for some bootleg wine (it was Prohibition) with German physicist Otto Stern—who was visiting the United States at the time—and outlined his scheme. Stern became excited and urged Lawrence to turn his design into reality. “Ernest, don’t just talk any more,” he urged. “You must . . . get to work on that.” 11 Placing himself in direct competition with Cockcroft, Walton, Van der Graaff, Tuve, and other nuclear researchers, Lawrence hadn’t a moment to spare to get his accelerator up and running. He took his first Ph.D. student, Niels Edlefsen, aside and inquired, “Now about this crazy idea of mine we’ve discussed. So simple I can’t understand why someone hasn’t tried it. Can you see anything wrong with it?” Edlefsen responded that the idea was sound. “Good!” said Lawrence. “Let’s go to work. You line up what we need right away.” 12 Under Lawrence’s supervision, Edlefsen assembled a hodgepodge of materials found around the lab into a working prototype. A round copper box, cut in half, served as the two electrodes—wired to a radio-frequency oscillator that offered a cyclic voltage boost. Edlefsen encased the device in glass and centered it between the four-inch poles of a guiding electromagnet. Finally, he sealed all of the connections with sticky wax. Completed in early 1930, it wasn’t very elegant. Nevertheless it was sufficient, after some tinkering, to get protons circulating—much to Lawrence’s delight. A thirty-seven-inch early cyclotron at the Radiation Laboratory, now the Lawrence Berkeley National Laboratory. For energies high enough to break through nuclear barriers, Lawrence realized that he needed a bigger machine with a more powerful magnet. Fortunately an industrial executive, who also taught at the university, offered him an eighty-ton magnet that had been gathering dust in a warehouse about fifty miles south in Palo Alto. Built for radio transmission, it had been rendered obsolete by technological advances. The generous donation prodded Lawrence to find a more spacious setting suitable for a much larger accelerator. He got lucky again; in 1931, an old building on campus was about to be demolished and he was given permission to use it. Christened the Radiation Laboratory (and nicknamed the “Rad Lab”), it and its successor buildings would serve for decades as his dedicated center for research. It would eventually be renamed in honor of its founder and is now known as the Lawrence Berkeley National Laboratory. Another pressing issue was how to move the colossal magnet to the lab. When yet another donor offered him funds to that effect, Lawrence scored a triple play in the tight budgetary age of the Great Depression. He finally had ample space and equipment to construct a powerful machine. In 1932, a banner year for nuclear physics, remarkable experiments around the world cast powerful spotlights on the murky inner workings of atoms. At Columbia University, chemist Harold Urey discovered deuterium, an isotope of hydrogen with approximately twice the mass of the standard version. James Chadwick’s identification of the neutron, found through meticulous observations at Cavendish, explained why deuterium is twice as massive as its similarly charged brother: the heavier isotope is bloated with extra neutrons. Speculations arose as to whether neutrons are particles in their own right, or alternatively protons and electrons somehow clumped together to make an electrically neutral particle. A couple of different theories had been bandied about, and only experimentation could tell which of the theorists has guessed right. For example, beta decay is when a radioactive substance gives off electrons. Those electrons, some suggested, must be coming from neutrons breaking into protons and electrons. (We now know that it is the weak interaction that is mediating a transformation involving the quarks that form protons and neutrons, along with the electron and a neutrino.) Carl Anderson’s discovery of the positron offered another possible explanation for the relationship between neutrons and protons. He found the positron in cloud chamber photographs taken at Caltech of positively charged cosmic rays (radiation from space passing through Earth’s atmosphere) with the same mass as the electron. We now know a positron is the antimatter version of an electron, but at the time, Anderson wondered if the neutron is fundamental, and the proton an amalgamation of a neutron and a positron. Testing these alternatives would require precise measurements of the masses of protons and neutrons, to see if one was sufficiently heavier than the other to accommodate an electron or positron. (Indeed, as we now know, the neutron is heavier, but is composed of quarks, not protons and electrons.) While Lawrence, along with Wisconsin-born graduate student M. (Milton) Stanley Livingston, toiled on the larger cyclotron, word came of victory in the race to split the lithium nucleus. The first to reach the finish line were Cockcroft and Walton, using the Cavendish linear accelerator. Walton recalled the moment of discovery when they finally bombarded the lithium target with protons and observed the stunning results: On the morning of April 14, 1932, I carried out the usual conditioning of the apparatus. When the voltage had risen to about 400,000 volts, I decided to have a look through the microscope which was focused on the fluorescent screen. By crawling on my hands and knees to avoid the high voltage, I was able to reach the bottom of the accelerating tube. To my delight, I saw tiny flashes of light looking just like the scintillations produced by alpha particles which I had read about in books but which I had never previously seen. 13 After observing what surely looked like the decay of lithium, Walton called Cockcroft into the lab, who agreed with that explanation. Then they invited Rutherford to crawl into the chamber and check out the scintillations himself. They turned off the voltage, and he ducked inside. When Rutherford came out, he said: Those scintillations look mighty like alpha particle ones and I ought to be able to recognize an alpha particle scintillation when I see one. I was in at the birth of the alpha particle and I have been observing them ever since. 14 Uncharacteristically, Rutherford asked Cockcroft and Walton to keep the news a “dead secret” until they could conduct more measurements. As Walton explained in a letter to his girlfriend, Freda Wilson (whom he would marry in 1934): He [Rutherford] suggested this course because he was afraid that the news would spread like wild fire through the physics labs of the world and it was important that no lurid accounts should appear in the daily papers etc. before we had published our own account of it. 15 Cockcroft and Walton ran the experiment further times using a cloud chamber to record the alpha particle tracks. (Recall that a cloud chamber is a box full of vapor for which charged particles passing through create a visible misty trail.) Calculating the masses before and after the collision, they confirmed that each lithium nucleus, with three protons and four neutrons, had been cajoled by an extra proton to break up into two alpha particles, each of two protons and two neutrons. They’d literally cut the lithium ions in half! Moreover, the energy released during each hit corresponded precisely to the mass difference between the initial and final states, times the speed of light squared. Their experiment confirmed Einstein’s famous formula. Satisfied with the accuracy and importance of their results, they published their findings in the prestigious journal Nature. For their exemplary work, Cockcroft and Walton would share the 1951 Nobel Prize for physics. The news from Cambridge didn’t dampen Lawrence’s spirits. He had much to celebrate. For one thing, he had just married Molly and was on his honeymoon. His dogged persistence in romance as well as in science had finally paid off. The coy young woman had grown to love her awkward but accomplished suitor. They would have a large family together—four girls and two boys. Another cause for Lawrence’s optimism was his strong conviction that he was at the forefront of a new scientific era. Ultimately, he realized, cyclotrons could yield much higher energies than linear accelerators could muster, and would thereby be essential for future probes of the nucleus. He wasted no time in confirming Cockcroft and Walton’s lithium results with an eleven-inch cyclotron. The larger device in the Rad Lab with the eighty-ton magnet was still under completion. When it was ready in March 1933, Lawrence bombarded lithium with protons and generated a bounty of highly energetic alpha particles—ricocheting back with impressive range. He also struck a variety of elements with deuterons, producing protons of Olympian stamina—some sprinting up to fifteen inches. By that point, he was more than ready to share his results with the physics community at large. The Seventh Solvay Conference, held in Brussels during the last week of October 1933, was a milestone for discussion of the remarkable advances in nuclear physics. Among the scientific luminaries present were quantum pioneers Bohr, de Broglie, Pauli, Dirac, Heisenberg, and Schrödinger. The Parisian contingent included Marie Curie, along with her daughter and son-in-law, Irene Joliot-Curie and Frédéric Joliot, each an esteemed nuclear chemist and future Nobel laureate. From Russia came Gamow—the start of his permanent exile, as it turned out. Two years earlier, he had returned to his home-land by way of Copenhagen. Unhappy living under Stalin’s iron thumb, he and his wife had attempted to escape across the Black Sea to Turkey but had been foiled by foul weather. Remarkably, an invitation by Bohr allowed both of them to slip into Belgium, where Gamow announced to his surprised host that they would never go back. The Cavendish contribution to the meeting was impressive. Headed by Rutherford, it included Cockcroft, Walton, Chadwick, and Blackett. Finally, though Lawrence was the lone American attendee, his presence was vital, in as much that cyclotrons represented the future of nuclear exploration and that the United States would for decades be the principal testing ground for such devices. Cockcroft delivered the conference’s first talk, “The Disintegration of Elements by Accelerated Protons.” Listening eagerly to his every word was Lawrence, keen to demonstrate the superiority of the cyclotron in handling the job. Perusing Cockcroft’s handout, Lawrence noted a statement that “only small currents are possible” from the cyclotron and emphatically crossed it out. In the margin he wrote, “Not true,” expressing his clear impatience with Cockcroft’s assertions. 16 When it came time for discussion, Lawrence was quick to respond. He presented an account of his own device and argued that it offered the best way forward to explore the nucleus. He also offered his own estimation of the mass of the neutron—controversially, much lower than Chadwick’s value. Further experiments conducted by Tuve later that year would demonstrate that Lawrence was wrong; a mistake he would frankly acknowledge. The neutron turned out to be slightly bulkier than the proton. After Solvay, Lawrence traveled to England and spent a pleasant couple of days at Cavendish. Rutherford warmly welcomed him and led him on a personal tour. After some heated discussions about lithium bombardment results, Rutherford said of Lawrence, “He’s a brash young man but he’ll learn.” 17 Lawrence tried to convince Rutherford to build a cyclotron at Cavendish. Chadwick and Cockcroft joined in the chorus, arguing that it was the only way for the lab to remain competitive. Rutherford would not budge. He had a preference for homemade equipment and was reluctant to import another group’s idea. Moreover, he disliked trolling for funds and knew a cyclotron would be expensive. Rutherford’s reluctance cost him dearly. In 1935, Chadwick, frustrated with the lack of progress, departed for a position at the University of Liverpool where he began to solicit funds for a cyclotron. On a visit to Cambridge in the summer of 1936, he and his former mentor were barely on speaking terms. Around the same time, Australian-born physicist Mark Oliphant, another of Rutherford’s protégés, was offered a position at the University of Birmingham, which he would assume the following year. Pressed by the loss of some of his top researchers, an embittered Rutherford finally agreed to let Cockcroft construct a cyclotron at Cambridge. While Rutherford hedged, Lawrence was busy collecting funds to build an even larger cyclotron at Berkeley. Tremendously successful at fund-raising, he had no trouble continuing to expand the Radiation Laboratory’s work. Oliphant, who would visit there and get to know Lawrence as well as Rutherford, explained the difference in their styles: “The Cavendish laboratory, under Rutherford and his predecessors, was always short of money. Rutherford had no flair and no inclination for raising funds. . . . Lawrence, on the other hand, had shrewd business sense and was adept at raising funds for the work of his laboratory.” Oliphant pointed out that Lawrence, who originally was on a premed track at university, had the savvy to foresee the medical applications of cyclotrons and how these could be used to draw funding. In a 1935 letter to Bohr, Lawrence wrote, “As you know, it is so much easier to get funds for medical research.” Unlike Rutherford, who suggested and personally supervised almost every experiment his lab undertook, Lawrence liked to delegate authority. He had exemplary management skills that impressed his benefactors in government and industry and enabled his lab to expand. As Oliphant noted: His direct approach, his self-confidence, the quality and high achievement of his colleagues, and the great momentum of the researchers under his direction bred confidence in those from whom the money came. His judgment was good, both of men and of the projects they wished to undertake, and he showed a rare ability to utilize to the full the diverse skills and experiences of the various members of his staff. He became the prototype of the director of the large modern laboratory, the costs of which rose to undreamt of magnitude, his managerial skill resulting in dividends of important scientific knowledge fully justifying the expenditure. 18 On October 19, 1937, Rutherford died of a strangulated hernia. Having been raised to peerage six years earlier, he was buried with the honors accorded his position as “Right Honourable Lord of Nelson.” His coat of arms reflected both his national and his scientific heritage: images of a New Zealand kiwi bird and a Maori warrior, along with a motto borrowed from Lucretius, “ Primordia Quaerare Rerum (To seek the first principles of things).” Fittingly, his ashes were interred in a grave at Westminster Abbey next to the final resting places of Newton and Lord Kelvin.",
        "char_count": 46492
      },
      {
        "heading": "Chapter 10",
        "text": "5 A Compelling Quartet The Four Fundamental Forces The grand aim of all science . . . is to cover the greatest number of empirical facts by logical deduction from the smallest possible number of hypotheses or axioms. —ALBERT EINSTEIN (THE PROBLEM OF SPACE, ETHER, AND THE FIELD IN PHYSICS, 1954, TRANSLATED BY SONJA BARGMANN) In 1939, Niels Bohr arrived at Princeton with a grave secret. He had just learned that Nazi Germany was pioneering the methods of nuclear fission: the splitting of uranium and other large nuclei. The unspoken question was whether the powerful energies of atomic cores could be used by Hitler to manufacture deadly weapons. To understand fission better, Bohr was working with John Wheeler to develop a model of how nuclei deform and fragment. Out of respect, Bohr attended one of Einstein’s lectures on unification. Einstein presented an abstract mathematical model of uniting gravitation with electromagnetism. It did not mention nuclear forces, nor did it even address quantum mechanics. Bohr reportedly left the talk in silence. His disinterest characterized the spirit of the times; the nucleus was the new frontier. Nuclear physics had by then become intensely political. The previous year, Otto Hahn, a German chemist who had assisted Rutherford during his days at McGill, along with Lise Meitner and Fritz Strassmann had discovered how to induce the fission of a particular isotope of uranium through the bombardment of neutrons. When later that year Meitner fled the Nazis after the Anschluss (annexation of Austria), she brought word of the discovery to her nephew Otto Frisch, who was working with Bohr. Bohr became alarmed by the prospects that the Nazis could use this finding to develop a bomb—an anxiety that others in the know soon shared. These fears intensified when Szilard and Italian physicist Enrico Fermi demonstrated that neutrons produced by uranium nuclei splitting apart could trigger other nuclei to split—with the ensuing chain reaction releasing enormous quantities of energy. Szilard wrote a letter to Roosevelt warning of the danger and persuaded Einstein to sign it. Soon the Manhattan Project was born, leading to the development by the Americans of the atomic bomb. The nucleus was a supreme puzzle. What holds it together? Why does it decay in certain ways? What causes some isotopes to disintegrate more readily than others? How come the number of neutrons in most atoms greatly exceeds the number of protons? Why does there seem to be an upper limit on the size of nuclei found in nature? Could artificial nuclei of any size be produced? Throughout the turbulent years culminating in the Second World War, one of the foremost pioneers in helping to resolve those mysteries was Fermi. Born in Rome on September 29, 1901, young Enrico was a child prodigy with an amazing aptitude for math and physics. By age ten he was studying the nuances of geometric equations such as the formula for a circle. After the tragic death of his teenage brother, he immersed himself in books as a way of trying to cope, leading to even further acceleration in his studies. Following a meteoric path through school and university, he received a doctorate from the University of Pisa when he was only twenty-one. During the mid-1920s, he spent time in Gottingen, Leiden, and Florence, before becoming professor of physics at the University of Rome. Among other critical contributions Fermi made to nuclear and particle physics, in 1933, he developed the first mathematical model of beta decay. The impetus to do so arose when at the Seventh Solvay Conference earlier that year, Pauli spoke formally for the first time about the theory of the neutrino. Pauli explained that when beta rays are emitted from the radioactive decay of a nucleus, an unseen, electrically neutral, lightweight particle must be produced to account for unobserved extra energy. He had originally called it a neutron, but when those heavier particles were discovered, he took up a suggestion by Fermi and switched to calling it by its Italian diminutive. Fermi proceeded to calculate how the decay process would work. Though, as it would turn out, his model was missing several key ingredients, it offered the monumental unveiling of a wholly new force in nature—the weak interaction. It is the force that causes certain types of particle transformations, producing unstable phenomena such as beta decay. As physicist Emilio Segrè, who worked under Fermi, recalled: Fermi gave the first account of this theory to several of his Roman friends while we were spending the Christmas vacation of 1933 in the Alps. It was in the evening after a full day of skiing; we were all sitting on one bed in a hotel room, and I could hardly keep still in that position, bruised as I was after several falls on icy snow. Fermi was fully aware of the importance of his accomplishment and said that he thought he would be remembered for this paper, his best so far. 1 Fermi’s model of beta decay imagines it as an exchange process involving particles coming together at a point. For example, if a proton meets up with an electron, the proton can transfer its positive charge to the electron, transforming itself into a neutron and the electron into a neutrino. Alternatively, a proton can exchange its charge and become a neutron, along with a positron and a neutrino. As a third possibility, a neutron can transmute into a proton, in conjunction with an electron and an antineutrino (like a neutrino but with a different production mechanism). Each of these involves a huddling together and a transfer—like a football player approaching a member of the opposing team, grabbing the ball, and heading off in another direction. In electromagnetism, two electric currents—streams of moving electric charge—can interact with each other by means of the exchange of a photon. Because the photon is an electrically neutral particle, no charge is transferred in the process. Rather, the photon exchange can either bring the currents together or separate them depending on the nature and direction of the moving charges. In modern terminology, we say the photon is the exchange particle conveying the electromagnetic force. Exchange particles, including photons, belong to a class of particles called bosons. The smallest ingredients of matter—now known to be quarks and leptons—are all fermions. If fermions are like the bones and muscles of the body, bosons supply the nerve impulses that provide their dynamics. For the weak force, as Fermi noted, two “currents,” one the proton/neutron and the other the electron/neutrino, can exchange charge and identity during their process of interaction. Here Fermi generalized the concept of current to mean not just moving charges but also any stream of particles that may keep or alter certain properties during an interaction. Just as mass measures the impact of gravity, and charge the strength of electromagnetism, Fermi identified a factor—now known as the Fermi weak coupling constant—that sets the strength of the weak interaction. He used this information to construct a method, known as Fermi’s “golden rule,” for calculating the odds of a particular decay process taking place. Suddenly, the long-established gravitational and electromagnetic interactions had a brand-new neighbor. But no one knew back then how to relate the new kid on the block to the old-timers. Types of elementary particles. To make matters even more complicated, in 1934, Japanese physicist Hideki Yukawa postulated a fourth fundamental interaction, similarly on the nuclear scale. Yukawa noted that while beta decay is a rare event, another linkage between protons and neutrons is much more common and significantly more powerful. Rather than causing decay, it enables coherence. To distinguish Yukawa’s nuclear interaction from Fermi’s, the former became known as the strong force. The need for a strong force bringing together nucleons (nuclear particles) has to do with their proximity and, in the proton’s case, their identical charge. Judging each other on the basis of charge alone, protons wouldn’t want to stick together. Their mutually repulsive electrostatic forces would make them want to get as far away from each other as possible, like the north poles of two magnets pushing each other apart. The closer together they’d get, their shared desire to flee would grow even greater. Then how do they fit into a cramped nucleus on the order of a quadrillionth of an inch? Born in Tokyo in 1907, Yukawa grew up at a time when the Japanese physics community was very isolated and there was very little interaction with European researchers. His father, who became a geology professor, strongly encouraged him to pursue his scientific interests. Attending the university where his father taught, Kyoto University, he demonstrated keen creativity in dealing with mathematical challenges—which would propel him to a pioneering role in establishing theoretical physics in his native land. At the age of twenty-seven, while still a Ph.D. student, he developed a brilliant way of treating nuclear interactions that became a model for describing the various natural forces. Yukawa noted that while electromagnetic interactions can bridge vast distances, nuclear forces tend to drop off very quickly. The magnetic effects of Earth’s iron core can, for example, align a compass thousands of miles away, but nuclear stickiness scarcely reaches beyond a range about one trillionth of the size of a flea. He attributed the difference in scale to a distinction in the type of boson conveying the interaction. (Remember that bosons are like the universe’s nervous system, conveying all interactions.) The photon, a massless boson, serves to link electrical currents spanning an enormous range of distances. If it were massive, however, its range would shrink down considerably, because the inverse-squared decline in interactive strength over distance represented by Maxwell’s wave equations would be replaced by an exponentially steeper drop. The situation would be a bit like throwing a Frisbee back and forth across a lawn and then replacing it with a lead dumbbell. With the far heavier weight, you’d have to stand much closer to keep up the exchange. By substituting nuclear charge for electric charge, and massive bosons, called mesons, for photons, Yukawa found that he could describe the sharp, pinpoint dynamics of the force between nucleons—demonstrating why the interaction is powerful enough to bind nuclei tightly together while being insignificant at scales larger than atomic cores. All that would be needed was a hitherto unseen particle. If Dirac’s hypothesized positrons could be found, why not mesons? Nature sometimes plays wicked tricks. In 1936, Carl Anderson observed a strange new particle in a stream of cosmic rays. Because a magnetic field diverted it less than protons and more than electrons or positrons, he estimated its mass to be somewhere in between—a little more than two hundred times the mass of the electron. On the face of things, it seemed the answer to nuclear physicists’ dreams. It fit in well with Yukawa’s predictions for the mass of the exchange boson for the strong force, and physicists wondered if it was the real deal. Strangely enough, any resemblance between the cosmic intruder and Yukawa’s hypothesized particle was pure coincidence. Further tests revealed the new particle to be identical to the electron in all properties except mass. Indeed it turned out to be a lepton, a category that doesn’t experience the strong force at all, rather than a hadron, the term denoting strongly interacting particles. (Lepton and hadron derive from the Greek for “thin” and “thick,” respectively—a reference to their relative weights that is not always accurate; some leptons are heavier than some hadrons.) Anderson’s particle was eventually renamed the muon, to distinguish it from Yukawa’s exchange particle. Pointing out the muon’s seeming redundancy and lack of relevance to the theories of his time, physicist Isidor I. Rabi famously remarked, “Who ordered that?” True mesons would not be found for more than a decade. Not many nuclear physicists were contemplating pure science during that interval; much energy was subsumed by the war effort. Only after the war ended could the quest for understanding the world of particles resume in earnest. In 1947, a team of physicists led by Cecil Powell of the University of Bristol, England, discovered tracks of the first known meson, in a photographic image of cosmic ray events. Born in Tonbridge in Kent, England, in 1903, Powell had an unlucky early family life. His grandfather was a gun maker who had the misfortune of accidentally blinding someone while out shooting—an action that led to a lawsuit and financial ruin. Powell’s father tried to continue in the family trade, but the advent of assembly-line production bankrupted him. Fortunately, Powell himself decided to pursue a different career path. Receiving a scholarship to Cambridge in 1921, he consulted with Rutherford about joining the Cavendish group as a research student. Rutherford agreed and arranged for Charles Wilson to be his supervisor. Powell soon became an expert on building cloud chambers and using them for detection. In the mid-1930s, after Cockcroft and Walton built their accelerator, Powell constructed his own and actively studied collisions between high-energy protons and neutrons. By then he had relocated to Bristol. While at first he used cloud chambers to record the paths of the by-products, he later found that a certain type of photographic emulsion (a silver bromide and iodide coating) produced superior images. Placing chemically treated plates along the paths of particle beams, he could observe disintegrations as black “stars” against a transparent background—indicating all of the offshoots of an interaction. Moreover the length of particle tracks on the plates offered a clear picture of the decay products’ energies—with any missing energy indicating possible unseen marauders, such as neutrinos, that have discreetly stolen it away. In 1945, Italian physicist Giuseppe Occhialini joined the Bristol group, inviting one of his most promising students, César Lattes, along one year later. Together with Powell they embarked upon an extraordinary study of the tracks produced by cosmic rays. To obtain their data they brought covered photographic plates up to lofty altitudes, including an observatory high up in the French Pyrenees and onboard RAF (Royal Air Force) aircraft. After exposing the plates to the steady stream of incoming celestial particles, the researchers were awestruck by the complex webs of patterns they etched—intricate family trees of subatomic births, life journeys, and deaths. As Powell recalled: When [the plates] were recovered and developed at Bristol it was immediately apparent that a whole new world had been revealed. The track of a slow proton was so packed with developed grains that it appeared almost like a solid rod of silver, and the tiny volume of emulsion appeared under the microscope to be crowded with disintegrations produced by fast cosmic ray particles with much greater energies than any which could have been produced artificially at the time. It was as if, suddenly, we had broken into a walled orchard, where protected trees had flourished and all kinds of exotic fruits had ripened in great profusion. 2 Among the patterns they saw was a curious case of one midsize particle stopping and decaying into another, appearing as if a slightly more massive type of muon gave birth to the conventional variety. Yet a long line of prior experiments indicated that if muons decay they always produce electrons, not more muons. Consequently, the researchers concluded that the parent particle must have been something else. They named it the “pi meson,” which became “pion” for short. It soon became clear that the pion matched the exchange particle predicted by Yukawa. Around the same time, George Rochester of the University of Manchester detected in cloud chamber images a heavier type of meson, called the neutral kaon, that decays along a V-shaped track into two pions—one positive and the other negative. In short order, researchers realized that pions and kaons each have positive, negative, and neutral varieties—with neutral kaons themselves coming in two distinct types, one shorter lived than the other. The importance of the discovery of mesons was so widely recognized that Powell received the Nobel Prize in lightning speed—in 1950, only three years later. Occhialini would share the 1979 Wolf Prize, another prestigious award, with George Uhlenbeck. The Bristol team’s discovery represented the culmination of the Cavendish era of experimental particle physics. From the 1950s until the 1970s, the vast majority of new findings would take place by means of American accelerators, particularly successors to Lawrence’s cyclotron. An exciting period of experimentation would demonstrate that Powell’s “orchard of particles” is full of strange fruit indeed. While high-energy physicists, as researchers exploring experimental particle physics came to be known, tracked an ever-increasing variety of subatomic events, a number of nuclear physicists joined with astronomers in attempts to unravel how the natural elements formed. An influential paper by physicist Hans Bethe, “Energy Production in Stars,” published in 1939, showed how the process of nuclear fusion, the uniting of smaller into larger nuclei, enables stars to shine. Through a cycle in which ordinary hydrogen combines into deuterium, deuterium unites with more hydrogen to produce helium-3, and finally helium-3 combines with itself to make helium-4 and two extra protons, stars generate enormous amounts of energy and radiate it into space. Bethe proposed other cycles involving higher elements such as carbon. George Gamow, by then at George Washington University, humorously borrowed Bethe’s name while applying his idea to the early universe in a famous 1948 paper with Ralph Alpher, “The Origin of Chemical Elements.” Although Alpher and Gamow were the paper’s true authors, they inserted Bethe’s appellation to complete the trilogy of the first Greek letters; hence it is sometimes known as the “alphabetical paper.” Alpher and Gamow’s theory of element production relies on the universe having originated in an extremely dense, ultrahot state, dubbed by Fred Hoyle the “Big Bang.” (Hoyle, a critic of the theory, meant his appellation to be derogatory, but the name stuck.) The idea that the universe was once extremely small was first proposed by Belgian mathematician and priest Georges Lemaitre, and gained considerable clout when American astronomer Edwin Hubble discovered that distant galaxies are moving away from ours, implying that space is expanding. Alpher and Gamow hypothesized that helium, lithium, and all higher elements were forged in the furnace of the fiery nascent universe. Curiously enough, although they were right about helium, they were wrong about the other elements. While the primordial universe was indeed hot enough to fuse helium from hydrogen, as it expanded, it markedly cooled down and could not have produced higher elements in sufficient quantities to explain their current amounts. Thus the carbon and oxygen in plants and animals were not produced in the Big Bang. Rather, as Hoyle and three of his colleagues demonstrated, elements higher than helium were wrought in a different type of cauldron—the intense infernos of stellar cores—and released into space through the stellar explosions called supernovas. Gamow was flummoxed by the idea that there could be two distinct mechanisms for element production. In typical humorous fashion, he channeled his bafflement and disappointment into mock biblical verse: a poem titled “New Genesis.” “In the beginning,” the verse begins, “God created radiation and ylem (primordial matter).” It continues by imagining God fashioning element after element simply by calling out their mass numbers in order. Unfortunately, God forgot mass number five, almost dooming the whole enterprise. Rather than starting again, He crafted an alternative solution: “And God said: ‘Let there be Hoyle’ . . . and told him to make heavy elements in any way he pleased.” 3 Despite its failure to explain synthesis of higher elements, the Big Bang theory has proven a monumentally successful description of the genesis of the universe. A critical confirmation of the theory came in 1965 when Arno Penzias and Robert W. Wilson pointed a horn antenna into space and discovered a constant radio hiss in all directions with a temperature of around three degrees above absolute zero (the lower limit of temperature). After learning of these results, Princeton physicist Robert Dicke demonstrated that its distribution and temperature were consistent with expectations for a hot early universe expanding and cooling down over time. In the 1990s and 2000s, designated satellites, called the COBE (Cosmic Background Explorer) and the WMAP (Wilkinson Microwave Anisotropy Probe), mapped out the fine details of the cosmic background radiation and demonstrated that its temperature profile, though largely uniform, was pocked with slightly hotter and colder spots—signs that the early universe harbored embryonic structures that would grow up into stars, galaxies, and other astronomical formations. This colorfully illustrated profile was nicknamed “Baby Picture of the Universe.” The Baby Picture harkens back to a very special era, about three hundred thousand years after the Big Bang, in which electrons joined together with nuclei to form atoms. Before this “era of recombination,” electromagnetic radiation largely bounced between charged particles in a situation akin to a pinball machine. However, once the negative electrons and positive cores settled down into neutral atoms, it was like turning off the “machine” and letting the radiation move freely. Released into space the hot radiation filled the universe—bearing subtle temperature differences reflecting slightly denser and slighter more spread out pockets of atoms. As the cosmos evolved, the radiation cooled down and the denser regions drew more and more matter. When regions accumulated the critical amount of hydrogen to fuse together, maintain steady chain reactions, and release energy in the form of light and heat, they began to shine and stars were born. The creation of stars, planets, galaxies, and so forth is the celestial drama that engages astrophysicists and astronomers. Particle physicists are largely interested in the back story: what happened before recombination. The details of how photons, electrons, protons, neutrons, and other constituents interacted with one another in the eons before atoms, and particularly in the first moments after the Big Bang reflect the properties of the fundamental natural interactions. Therefore, like colliders, the early universe represents a kind of particle physics laboratory; any discoveries from one venue can be compared to the other. The same year that Alpher and Gamow published their alphabet paper, three physicists, Julian Schwinger and Richard Feynman of the United States and Sin-Itiro Tomonaga of Japan, independently produced a remarkable set of works describing the quantum theory of the electromagnetic interaction. (Tomonaga developed his ideas during the Second World War when it was impossible for him to promote them.) Distilled into a comprehensive theory through the vision of Princeton physicist Freeman Dyson, quantum electrodynamics (QED), as it was called, became seen as the prototype for explaining how natural forces operate. Of all the authors who developed QED, the one who offered the most visual representation was Feynman. He composed a remarkably clever shorthand for describing how particles communicate with one another—with rays (arrowed line segments) representing electrons and other charged particles, and squiggles denoting photons. Two electrons exchanging a photon, for example, can be depicted as rays coming closer over time, connecting up with a squiggle, and then diverging. Assigning each possible picture a certain value, and developing a means for these to be added up, Feynman showed how the probability of all manner of electromagnetic interactions could be determined. The widely used notation became known as Feynman diagrams. Through QED came the alleviation of certain mathematical maladies afflicting the quantum theory of electrons and other charged particles. In trying to apply earlier versions of quantum field theory to electrons, theorists obtained the nonsensical answer “infinity” when performing certain calculations. In a process called renormalization, Feynman showed that the values of particular diagrams nicely canceled out, yielding finite solutions instead. Inspired by the power of QED, in the 1950s, various theorists attempted to apply similar techniques to the weak, strong, and gravitational interactions. None of the efforts in this theoretical triathlon would come easy—with each leg of the race offering unique challenges. By that point, Fermi’s theory of beta decay had been extended to muons and become known as the Universal Fermi Interaction. Confirmation of one critical prediction of the theory came during the middle of the decade, when Frederick Reines and Clyde Cowan, scientists working at Los Alamos National Laboratory, placed a large vat of fluid near a nuclear reactor and observed the first direct indications of neutrinos. The experiment was set up to measure rare cases in which neutrinos from the reactor would interact with protons in the liquid, changing them into neutrons and positrons (antimatter electrons) in a process that is called reverse beta decay. When particles meet their antimatter counterparts, they annihilate each other in a burst of energy, producing photons. Neutrons, when absorbed by the liquid, also produce photons. Therefore Reines and Cowan realized that twin flashes (in another light-sensitive fluid) triggered by dual streams of photons would signal the existence of neutrinos. Amazingly, they found such a rare signal. Subsequent experiments they and others performed using considerably larger tanks of fluid confirmed their groundbreaking results. By the time of the confirmation of the final component of Fermi’s theory—the prototype of the weak interaction—physicists had begun to realize its significant gaps. These manifested themselves by way of comparison with the triumphs of QED. QED is a theory replete with many natural symmetries. Looking at Feynman diagrams representing its processes, many of these symmetries are apparent. For example, flip the time axis, reversing the direction of time, and you can’t tell the difference from the original. Thus, processes run the same backward and forward in time. That is a symmetry called time-reversal invariance. Another symmetry, known as parity, involves looking at the mirror image of a process. If the mirror image is the same, as in the case of QED, that is called conservation of parity. For example, the letter “O,” looking the same in the mirror, has conserved parity, while the letter “Q” clearly doesn’t because of its tail. In QED, mass is also perfectly conserved—representing yet another symmetry. When electrons (or other charged particles) volley photons back and forth, the photons carry no mass whatsoever. Electrons keep their identities during electromagnetic processes and never change identities. Comparing that to beta decay, in which electrons sacrifice charge and mass and end up as neutrinos, the difference is eminently clear. The question of symmetries in the weak interaction came to the forefront in 1956 when Chinese American physicists Tsung Dao Lee and Chen Ning (Frank) Yang proposed a brilliant solution to a mystery involving meson decay. Curiously, positively charged kaons have two different modes of decay: into either two or three pions. Because each of these final states has a different parity, physicists thought at first that the initial particles constituted two separate types. Lee and Yang demonstrated that if the weak interaction violated parity, then one type of particle could be involved with both kinds of processes. The “mirror-image” of certain weak decays could in some cases be something different. Parity violation seemed to breach common sense, but it turned out to be essential to understanding nuances of the weak interaction. Unlike the weak interaction, the strong force does not have the issue of parity violation. Thanks to Yukawa, researchers in the 1950s had a head start in developing a quantum theory of that powerful but short-ranged force. However, because at that point experimentalists had yet to probe the structure of nucleons themselves, the Yukawa theory was incomplete. The final ingredient in assembling a unified model of interactions would be a quantum theory of gravity. After QED was developed, physicists trying to develop an analogous theory of gravitation encountered one brick wall after another. The most pressing dilemma was that while QED describes encounters that take place over time, such as one electron being scattered by another due to a photon exchange, gravitation, according to general relativity, is a feature stemming from the curvature of a timeless four-dimensional geometry. In other words, it has the agility of a statue. Even to start thinking about quantum gravity required performing the magic trick of turning a timeless theory into an evolving theory. A major breakthrough came in 1957 when Richard Arnowitt, Stanley Deser, and Charles Misner developed a way of cutting space-time’s loaf into three-dimensional slices changing over time. Their method, called ADM formalism, enabled researchers to craft a dynamic theory of gravity ripe for quantization. Another major problem with linking gravity to the other forces involves their vast discrepancy in strength—a dilemma that has come to be known as the hierarchy problem. At the subatomic level, gravitation is 10 40 (1 followed by 40 zeroes) times punier than electromagnetism, which itself is much less formidable than the strong force. Bringing all of these together in a single theory is a serious dilemma that has yet to be satisfactorily resolved. Finally, yet another wrench thrown into the works involves renormalizing any gravitational counterparts to QED. To theorists’ chagrin, the methods used by Schwinger, Feynman, and Tomonaga were ineffective in removing infinite terms that popped up in attempts to quantize gravity. Gravity has proven a stubborn ox indeed. Unification is one of the loftiest goals of the human enterprise. We long for completeness, yet each discovery of commonalities seems accompanied by novel examples of diversity. Electricity and magnetism get along together just perfectly, as Maxwell showed, but the other forces each have glaring differences. The periodic table seemed fine for a while to explain the elements until scientists encountered isotopes. Rutherford, Bohr, Heisenberg, and their colleagues seemed to wrap up the world of the atom in a neat parcel, until neutrinos, antimatter, muons, and mesons arrived on the scene. From the mid-1950s until the mid-1990s, powerful new accelerators would reveal a vastly more complex realm of particles than anyone could have imagined. Suddenly, ordinary protons, neutrons, and electrons would be vastly outnumbered by a zoo of particles with bizarre properties and a wide range of lifetimes. Only a subset of the elementary particles could even be found in atoms; most had nothing to do with them save their reactions to the fundamental forces. It would be like walking into a barn and finding the placid cows and sheep being serenaded by wild rhinoceri, hyenas, platypi, mammoths, and a host of unidentified alien creatures. Given the ridiculously diverse menagerie nature had revealed, finding any semblance of unity would require extraordinary pattern-recognition skills, a keen imagination, and a hearty sense of humor.",
        "char_count": 32165
      },
      {
        "heading": "Chapter 11",
        "text": "6 A Tale of Two Rings the Tevatron and Super Proton Synchrotron Its true that there were a few flaws in my logic. The rivers of ground water that flowed through their experiments, the walls of piling rusting away, the impossible access, and all without benefit of toilet facilities. But someof the users had their finest moment down in these pitys–the discovery of beauty, the bottom quark, where else?! Alas, as far as I know not one piling has been pulled up, not one pit has yet been refilled with earth. —ROBERT R. WILSON (LECTURE AT THE THIRD INTERNATIONAL SYMPOSIUM ON THE HISTORY OF PARTICLE PHYSICS, STANFORD LINEAR ACCELERATOR CENTER, JUNE 1992) After finding the misplaced rubber gasket that had stopped up his cyclotron during an important demonstration of its medical uses, Lawrence was absolutely furious. “You get out of this laboratory!” he screamed at the young assistant. “Don’t you ever come back!” 1 Robert R. (Bob) Wilson, a graduate student at the Berkeley Radiation Laboratory who would blossom into the designer and leader of the greatest enterprise in the history of American high-energy physics, was absolutely crushed. With the laboratory dressed up in hospital white, and patients ready to be treated for their cancerous tumors, how could he have been so careless? Patients were literally waiting for days while the cyclotron refused to work, all because of his silly mistake. No words could express the depth of his remorse. Lawrence rehired Wilson, only to fire him again after he ruined a pair of expensive pliers by melting them in a hot flame. The second dismissal wasn’t quite so bad. “I thought I’d probably get back somehow,” Wilson recalled. 2 To say that Wilson’s career took many twists and turns before he became the force behind the establishment of Fermilab, the foremost accelerator lab in the United States and for a time in the world, is an understatement. Born in Frontier, Wyoming, in 1914, he came, like Rutherford and Lawrence, from a pioneering family. Wilson’s mother, Edith, was the daughter of a rancher who had come to the region during a gold rush. She married Wilson’s father when he was working in town as a surveyor. A stern, practical man, he could never appreciate the academic proclivities of his son. When Wilson, who was a well-read youth, wanted to head off to Berkeley for college, his father tried to forbid him—insisting that he go into business instead. Unsupported by his dad, Wilson set out at the age of eighteen for a life of adventure in particle physics. At Berkeley, eyeing Lawrence’s lab for the first time, Wilson marveled like a child at a Christmas display. He was awestruck by the fancy equipment and the researchers’ exuberance. Although on a personal level he found Lawrence egotistical, at least initially, he decided to pursue working at the Rad Lab for his undergraduate research project. Nervously, he traipsed over to Lawrence’s office to ask about a position, and was greatly relieved when the great director replied, “Oh, yes, yes, yes.” Wilson became an expert at cyclotron design, particularly with regard to producing stable particle orbits. He completed his undergraduate studies at Berkeley and continued as Lawrence’s graduate student. He witnessed the Rad Lab becoming a shining example for high-energy research around the world—its physicists respected for their experience. Wilson also learned a great deal from Lawrence’s leadership skills. “I’m sure he had a profound influence on me,” Wilson recalled. “His style of running that laboratory was very impressive. He led by example. . . . We were infected by his enthusiasm and optimism, and his sense of priorities and of pushing hard.” 3 In 1940, after getting his Ph.D. from Berkeley, Wilson got married to California native Jane Scheyer and moved east with her to Princeton, New Jersey. He served there as instructor for three years before being recruited to Los Alamos to work on the Manhattan Project. After the war, he spent a year at Harvard, then became appointed director of the Laboratory for Nuclear Studies at Cornell, where he served from 1947 to 1967. There he ran four different electron synchrotrons—the final one yielding energies up to 12 GeV—and established a reputation as an outstanding supervisor. Synchrotrons, invented in the 1940s, offer far more flexibility than conventional cyclotrons by stepping up their magnetic fields in tandem with the requirements of the packs of particles rounding their tracks. Particles are injected into a synchrotron in bunches, like cyclists clustered together during a race. As each grouping reaches higher energies, the magnetic field is ramped up so that instead of spiraling outward the particles maintain the same radial distance. Fiercer creatures require stronger leashes. Another key characteristic of a synchrotron is that its central magnet is replaced by bending magnets placed at equal intervals around the beam path. These serve a similar purpose but enable the device to encompass a wide area (a football field or farmlands, for example), thus permitting a much larger radius and increasing its power well beyond room-size instruments. Yet another difference between synchrotrons and the original cyclotrons has to do with variations in the driving electric field. While the electric fields of cyclotrons vary periodically, offering a constant cadence of boosts, those of synchrotrons keep pace with the particle packets—preventing them from falling out of step once they reach relativistic speeds. It’s like a father who is pushing his son on a swing increasing his rhythm for greater effect after it has sped up. Similarly, synchrotrons are flexible enough to raise the energy bar of already energetic particles. Wilson’s tenure at Cornell coincided with a dramatic rise of the use of synchrotrons in particle physics. The extraordinary power and flexibility of synchrotrons would prove critical for the discovery of massive new types of particles. Large synchrotrons would ultimately supply the dynamos for mighty particle colliders that would be used to search for evidence of unity—such as identifying the exchange particles for electroweak unification. Over decades, researchers at various laboratories would find ways of increasing synchrotrons’ ring sizes and improving the focusing power of their magnets to make them more effective at producing high-energy particles. The 1950s and 1960s were a golden age for synchrotron design. In Berkeley, two engineers under Lawrence’s supervision, William Brobeck and Edward Lofgren, constructed a concert-hall-size proton synchrotron called the Bevatron. Completed in 1954, it could reach energies of up to 6 GeV. Unfortunately, its costs were driven up by a doughnut-shaped vacuum chamber (and surrounding magnet) with such wide openings, it seemed made for race cars rather than for particles. Another early synchrotron, the Cosmotron, built on a converted army base in bucolic Brookhaven, New York, was more efficiently designed—possessing apertures that, though narrow, had sufficient room to accommodate the particle beams. Team leaders M. Stanley Livingston, Ernest Courant, John Blewett, G. Kenneth Green, and others managed to perform this feat through the use of 288 C-shaped magnets that carefully guided the proton pulses through the pipe of the seventy-five-foot diameter accelerator. It took but a second for the protons to travel 135,000 miles (through millions of revolutions) and reach energies of 3 GeV before smashing into targets. 4 When the Cosmotron first came on line in May 1952, the New York Times applauded its inaugural “Billion Volt Shot.” 5 Courant’s experience with adjusting the magnets of the Cosmotron to focus the beam as tightly as possible led him to a critical insight that paved the way for the next generation of machines. He calculated that by switching adjacent magnets to face in opposite directions—alternatively inward and outward—he could greatly augment their focusing power. His finding, called strong focusing, paved the way for the construction at Brookhaven of the Alternating Gradient Synchrotron, an even mightier accelerator that opened in 1960 and is still in use today. Meanwhile, at the European Organization for Nuclear Research (CERN) in Geneva, Switzerland, Niels Bohr smashed a bottle of champagne and inaugurated the Proton Synchrotron (PS), another strong-focusing accelerator. It was a triumph for the reemergence of European science after the war. CERN had been established a decade earlier, through a resolution put forth by Rabi at the fifth UNESCO conference authorizing that agency, “to assist and encourage the formation and organization of regional centres and laboratories in order to increase and make more fruitful the international collaboration of scientists.” 6 By the time the PS opened, the CERN council, consisting of representatives of Belgium, Denmark, France, (West) Germany, Greece, Italy, the Netherlands, Norway, Spain, Sweden, Switzerland, the United Kingdom, and Yugoslavia, had met numerous times, and established its scientific laboratory near the village of Meyrin—part of the Geneva canton, close to the French border. The smashing new accelerator bolstered the center’s reputation as an international hub of high-energy research. Wilson worked hard at Cornell to compete with the burgeoning laboratories at Berkeley, Brookhaven, and CERN. He established a reputation as a highly capable leader. Yet he wanted to be more than just a scientist and administrator. In a highly unusual move for a scientist of such ambition, Wilson took time off to pursue a second career as a sculptor. In 1961, he traveled to Rome and enrolled at the Accademia di Belle Arti, where he learned how to create modern sculpture. He was also interested in architecture and other aspects of design. All of Wilson’s passions beautifully merged together when, in 1967, he was offered the supreme challenge of designing the foremost accelerator laboratory in the United States, to be built among the cornfields of rural Batavia, Illinois—about thirty-five miles west of Chicago. Originally called the National Accelerator Lab, it was renamed in 1974 after Fermi. In taking on the responsibility, Wilson set out to make the lab as user-friendly as possible—open to whoever wanted to conduct experiments requiring high energies, without regard for hierarchy. He wanted to avoid the restrictions of having just a handful of leaders, in the mode of Rutherford and Lawrence, setting the course for all of the lab’s projects. A second goal of Wilson’s, meshing well with the democratic spirit he established, was to keep construction and operating costs as low as possible. The U.S. Atomic Energy Commission requested that construction time be kept to less than seven years, with a maximum expense of $250 million (reduced, due to cost-cutting measures, from an original allotment of $340 million). Miraculously, Wilson finished ahead of schedule and within the tight budget—all while doubling the accelerator’s energy from an anticipated 200 GeV to more than 400 GeV. He truly wanted the greatest bang for the buck. Despite financial restraints, Wilson fervently aspired to bring aesthetics to lab design. He involved himself in all aspects of planning the lab’s architecture—including a futuristic central tower of concrete and glass—and even crafted innovative sculpture to beautify the landscape. A painter was recruited to bathe the equipment in bright colors. Unprecedented for an experimental facility, its art won accolades from the New Republic ’s critic Kenneth Everett, who called it a “rare combination of artistic and scientific aspiration.” 7 With tastes reflecting the utilitarian spirit of the 1960s, Wilson’s creations managed to impress while not sapping budgets. Finally, as a born frontiersman, he believed in living in harmony with the land and was an early environmentalist. He recycled many of the original barns by converting them to buildings used for social functions, housing, and other purposes. Wildlife from mallard ducks to muskrats found refuge in the ponds, the fields, and even the machinery. As a reminder of his roots, and also as a symbol of the pioneering nature of modern physics, he brought in a herd of bison to graze freely in a grove. Their shaggy descendants still roam the grounds today. Wilson felt very much at home wandering Fermilab on horseback—as if it were a ranch that happened to be raising protons and mesons instead of cattle and sheep. Dressed in jeans, a windbreaker, cowboy boots, and a black fedora, he’d mount his gray mare, Star, and ride her around his enterprise—as if warming up for the Preakness—to inspect its fine details. An aerial view of Fermi National Accelerator Laboratory (Fermilab) showing the main ring and principal office tower. No aspect of the accelerator center was too trivial for Wilson to tweak—from the distinctive geometric rooftops (a geodesic dome in one case) to the no-frills dirt floors—even the specifics of how the kitchen was run. On a limited budget choices needed to be made—roofs versus floors, for instance—and Wilson thought that he needed to make these himself, lest he incur the wrath of the Atomic Energy Commission. As one of the bulwarks against excess spending, Wilson hired a hardheaded administrative assistant named Priscilla Duffield, who was formerly Lawrence’s secretary at the Rad Lab and then J. Robert Oppenheimer’s secretary at Los Alamos during the Manhattan Project. J. David Jackson, acting head of theoretical physics at Fermilab from 1972 to 1973, remembered her as a “tall, imposing, no-nonsense woman.” She would become incensed by the mere hint of unauthorized expenditure. Jackson recalled her sharp reaction when she found out about a wine-and-cheese seminar he helped organize. She stormed into my office, looking for my scalp. “What do you think you’re doing, serving wine at that seminar? Don’t you know it’s illegal to spend government money on such things?” I said that I wasn’t spending government money on the wine. She said, “Well who is paying for it?” I said, “I am.” And she said, “Oh.” It was the one time I saw Priscilla just a little bit penitent. 8 Not every decision Wilson made worked out for the best, due to his passionate effort to cut costs. By steaming single-mindedly ahead with certain structural choices, he almost launched the whole project over a precipice. Not considering that magnets might sometimes need to be replaced, he had them welded to the beam line running through the tunnel of the main ring. 9 Neglecting to protect the tunnel from the humid Illinois summers, some of the magnets acquired moisture and started to crack. Imagine the horror of the eager researchers primed for discovery when right before the accelerator was about to be turned on many of its magnets failed and couldn’t easily be removed. Fortunately, a stalwart team of experimentalists gathered quickly and resolved the problem. In contrast to the permanently secured magnets, Wilson made the opposite choice for the places where physicists would take measurements. To ensure minimal cost and maximal flexibility, he designed the working areas to be as provisional as anthills. He came to realize that his makeshift structures, though thrifty, were not very popular. As Wilson remarked: These enclosures are indeed rough-and ready places. . . . Indeed some of the users were advised by their older colleagues to “abandon all hope, ye who enter here!” I fear that I bear the responsibility for this fiasco. In the frenzy of saving big bucks, I had the fantasy of not putting up (or down) any laboratory building at all. Instead the idea was that, once an experiment had been accepted, an outline of the necessary space would be drawn in an empty field at the end of one of the proton beams, then steel interlocking piles would be driven . . . down to the necessary depth. . . . The experimental equipment would be lowered to a luxurious graveled floor, and finally a removable steel roof would be covered with the requisite thickness of earth. . . . Simple and inexpensive, is it not? I still find it difficult to understand why all those users stopped speaking to me. 10 Wilson nicknamed the experimental area for proton studies, constituting the termini of beams shunted from the four-mile-long main synchrotron ring, the “proton pits”; other research zones were dedicated to mesons and neutrinos. He was especially proud of the fifteen-foot bubble chamber, lauded by Berkeley physicist Paul Hernandez as the “Jewel in the Crown” for its type of detector. 11 A bubble chamber consists of a large vat of liquid hydrogen surrounded by an immense guiding magnet. After protons collide, the magnet would steer charged debris along swirling paths through the fluid. The hydrogen along the tracks would bubble away, enabling experimentalists to photograph these trails and calculate the properties of the particles that produced them. Because their different charges would experience opposite magnetic forces, positive and negative particles would spiral in opposite directions. The Big European Bubble Chamber, a device for tracking particles, on display at CERN’s Microcosm museum. Other types of detectors commonly used in high-energy physics include scintillation counters, photomultipliers, Cherenkov detectors, calorimeters, spark chambers, and drift chambers. The reason for such a diverse toolbox of measuring instruments is to glean as much information as quickly as possible. Many particles, once born, are extremely short lived, and decay almost immediately into other particles. Sometimes the only signs of an interaction are missing energy, momentum, and other conserved quantities. Like detectives at a crime scene, physicists investigating possible culprits must cordon off the collision site—by surrounding as much of it as possible with data-collecting instruments—and rapidly gather a cache of evidence. Only then can they hope to reconstruct the event and determine what actually transpired. Scintillation counters, an update on Rutherford’s favorite technique for spotting particles by means of flashes in fluorescent materials, rely on atomic electrons becoming energized by passing particles and then releasing this energy as light. Moldable, fluorescent plastics and liquid additives called fluors have served well for this purpose. Photomultipliers are electronic devices that amplify faint light (from scintillators, for example) so it is much more discernable. Cherenkov detectors depend on a different physical property, called the Cherenkov effect. Discovered in 1934 by physicist Pavel Cherenkov, of the Lebedev Physical Institute in Moscow, it is a phenomenon that occurs when a particle travels faster than light does in a particular material. Although nothing can exceed the speed of light in a vacuum, light moves slower in certain substances and can thereby be outpaced. Like jets creating a sonic boom (an audible shock wave) when they exceed sound’s velocity in air, particles racing past light’s material speed emit a cone of radiant energy in the direction of motion called Cherenkov radiation. Conveniently, the angle of the cone directly depends on the particle’s velocity, offering a practical way of measuring this important factor. Another class of apparatus, called calorimeters, enables researchers to record the energies of particles. These are dense materials that trigger a cascade of decays, through processes such as pair production (creation of electron-positron companions) and bremstrahlung (radiation generated when particles slow down), releasing a storehouse of energy in the process. By trapping some or all of this energy, physicists can try to determine how energetic the original must have been. While electromagnetic calorimeters rely on electromagnetic processes to produce the cascades, hadronic calorimeters depend on the strong interaction instead. Hadrons are particles that experience the strong force, such as protons, neutrons, various types of mesons, and an assortment of heavier particles. They are each composed of quarks. Leptons such as electrons, positrons, muons, and neutrinos, on the other hand, are particles that ignore the strong force. They are not made of quarks but, rather, are fundamental. Hadronic calorimeters capture the energy of hadrons but not leptons. Along with bubble chambers, various other types of instruments can be used to measure particle trajectories. Spark chambers, useful for charged particles, involve electrical signals passing like lightning through regions of a gas ionized by particles whizzing past. Drift chambers are more sophisticated devices that use electronics to record the time particles take to move from one point to another. The invention of the computer provided a vital tool for high-energy research. It allowed researchers the luxury of sifting through vast amounts of data and accessing which subset displayed the fingerprints of potentially interesting events. Otherwise finding rare decay products would be a hopeless task—like locating a single four-leaf clover in the vast expanse of the American prairie. By the time Fermilab became operational in the early 1970s, one of its principal features was already out of date. Along the lines of Rutherford’s experiments, beams produced by the accelerator slammed into fixed targets. According to conservation principles, most of the collision energy served to channel secondary particles along a tight path past the target. Merely a fraction of the energy could be used to produce the new particles themselves. Technically, this is because the useful energy for a fixed-target collision increases at the relatively slow rate of the square root of the beam energy. If, with improvements to a fixed-target device, protons were accelerated to one hundred times more energy, for instance, its effective energy would increase only tenfold. Not only was this situation inefficient, the narrowness of the particle jets produced made it difficult for researchers to examine what was created. As far back as 1953, Wideröe, with his extraordinary foresight, had patented a design for a far more efficient type of accelerator, now known as a collider. 12 He recognized that by smashing particles together head-on, a much larger portion of the collision energy would be transformative rather than kinetic (engendering motion). Because he was working as an industrial engineer at the time, the physics community did not take note of his patent. Three years later, however, a team of synchrotron developers, led by physicist Donald Kerst, independently proposed the idea of colliding particle beams with each other. Published in the leading journal Physical Review and discussed at a 1956 CERN symposium in Geneva, Kerst’s proposal stimulated efforts to boost the usefulness of conventional accelerators by turning them into colliders. We can envision the difference between fixed-target accelerators and colliders by imagining two different kinds of accidents involving diesel locomotives. In the first case, picture an engine car racing out of control and hitting the back of a boxcar that’s sitting at the junction of two tracks. Conceivably, the impact of the engine car could cause the boxcar to roll down one of the tracks, the engine car down the other, and both would escape unscathed. The collision energy would be mainly kinetic. However, suppose two engine cars (of comparable size and speed), traveling in opposite directions, plow into each other head on. In that case it would be hard to picture a happy outcome. The bulk of the energy would likely end up producing a burning wreck. What would be horrific for a transportation engineer would work out nicely for high-energy physicists in their quest to add more fuel to the fire and spark the creation of new particles. At the same CERN conference, Princeton physicist Gerald O’Neill proposed a clever way of implementing the collider idea by use of linked storage rings. Particles accelerated in a synchrotron, he envisioned, could be directed into two different storage rings, where they would orbit in opposite directions before smashing together at a designated intersection point. His idea formed the basis of several important electron-positron collision projects during the 1960s and early 1970s, culminating in the completion of the SPEAR ring at SLAC in 1972—where Burton Richter, SPEAR’s developer, would codiscover the J/psi particle (a heavy meson composed of quarks with properties called “charm” and “anticharm”), and Martin Perl would discover the ultraheavy tau lepton, among other findings. These discoveries would help provide evidence that quarks and leptons are organized into three distinct generations: the up and down quarks, electron and neutrino in the first; the strange and charm quarks, muon and muon neutrino in the second; and the tau lepton (along with the later-discovered top and bottom quarks and tau neutrino) in the third. Either individually, as in the case of leptons, or grouped into various combinations to form different hadrons, as in the case of quarks, these constitute the basis of matter. In 1971, CERN inaugurated the world’s first hadron collider: the Intersecting Storage Rings (ISR). CERN’s then existing Proton Synchrotron accelerated bunches of protons to energies of 28 GeV, upon which an injection system whisked them off to one of two storage carousels. There, they were “stacked,” a process involving timing the proton injections so that groups are packed in closely together but still flowing smoothly. It’s a bit like a traffic signal allowing cars to merge onto a highway only at particular intervals to pace them just right and increase the road’s capacity. Through stacking, the proton beams circulating around the rings increase their luminosity, or rate of collisions per area, a function of the beam intensity. Boosting the luminosity is akin to upping the firing rate and focus of a machine gun to maximize its chances of hitting a target. A higher collision rate increases the chances of exceptional events taking place, such as the production of rare particles. Shortly after the ISR came online, CERN researchers decided to test out a novel method for increasing luminosity, called stochastic cooling. Developed by Dutch physicist Simon van der Meer, who was in charge of the steering magnets at CERN, it offered a way to tighten up the bunches of protons into denser clusters, allowing them to be stacked much closer together. The basic idea is to test how far particles deviate from the average of their group and kick them back in line if they stray too far. These correcting nudges cause each bunch to have less prominent fluctuations and “cool down” to a more tightly packed state—creating more room to stack more clusters and increase the beam intensity. Van der Meer’s enhancement of beam luminosity represented such an important enhancement for colliders—opening the door to pivotal discoveries—that it would earn him the 1984 Nobel Prize in Physics (along with Italian physicist Carlo Rubbia). Anticipating the competition CERN would provide with its radically improved methods, Wilson argued for upgrades to the Fermilab accelerator that would at least double its effective energy. The reason was clear. A critical advance in theoretical physics, the unification of electromagnetism and the weak interactions into a single quantum theory, had triggered an intense race to discover the massive particles it predicted. The chance to verify a stunning new form of unity inspired a whole generation of experimentalists to join teams at Fermilab, CERN, and elsewhere and dedicate themselves to an epic search through unprecedented quantities of data generated through extraordinary energies. The Standard Model of electroweak unification, proposed independently in 1967 by Steven Weinberg and Abdus Salam, predicts four new massive bosons, to supplement the familiar massless photon. Two of these, the W + and W - , serve as the exchange bosons for the weak interaction involving positive and negative charge transfers respectively (for example, interactions involving electrons and neutrinos, or positrons and antineutrinos). A third, the Z 0 , conveys the neutral version of the weak interaction. This was inserted, based upon Sheldon Glashow’s work, to make it a mathematically balanced theory, even though no one at the time had ever observed a neutral weak current. Together, the W + , W - , and Z 0 are known as the intermediate vector bosons, the designation “vector” referring to their particular transformative properties. The fourth predicted particle is the Higgs boson, which through its spontaneous symmetry breaking (as discussed in chapter 2), supplies mass to the W + , W - , and Z 0 bosons, along with the quarks and leptons. The scenario sketched by Weinberg and Salam meant that finding these new bosons wouldn’t be easy. At high-enough temperatures—during the initial instants of the Big Bang, for example—the theory’s symmetry would be unbroken and the W and Z bosons would be massless too. However, below a critical temperature—today’s conditions, for example—the spontaneous breaking of the original symmetry would give ample mass to these bosons. To detect them, therefore, would require the extraordinarily energetic conditions of the world’s mightiest accelerators. In 1970, three intrepid experimentalists—Carlo Rubbia, then at Harvard, Alfred K. Mann, of the University of Pennsylvania, and David Cline, of the University of Wisconsin—initiated a fledgling effort at Fermilab to find the W boson. Nicknamed the HPWF collaboration, after the initials of the universities involved (and Fermilab), the group set up shop in the neutrino building. The geodesic roof of that metal structure leaked badly during rainstorms and the floors were dirt, so team members often needed to wade through muddy puddles to get to their equipment. Wilson’s cost-cutting measures had led to working conditions suitable for one of Dante’s lower circles. The following year, a young virtuoso in field theory, Gerard ’t Hooft of the University of Utrecht, Holland, working under the supervision of Martinus Veltman, proved that the Weinberg-Salam theory could be renormalized (infinite terms canceled out), just like quantum electrodynamics. This made the theory extremely attractive. Giddy from these remarkable results, Weinberg was eager to have one of the basic predictions of electroweak theory tested: the existence of neutral weak currents. As Rubbia later recounted, Weinberg “brainwashed” the HPWF team to switch course and look for neutral currents instead. 13 Rubbia asked Larry Sulak, a colleague from Harvard working with the group, to install a new trigger for the detector that would be sensitive to neutral current events. These would involve fermions keeping their own identities as they interact with each other through the weak force—for example, electrons remaining electrons and protons remaining protons. The problem was that common electromagnetic interactions similarly preserve particle characteristics; electrons stay electrons during those events too. Therefore, the major challenge was to find the weak neutral needle among the haystack of electromagnetic events that similarly conserve charge and mass. Neutrino events offered the best chance for this, because as light neutral leptons their principal mode of interaction is the weak force. If a neutral hadron, such as a neutron, interacted with a neutrino in an event that kept both particles the same, the weak neutral current would be the natural culprit. A competing team from CERN, led by Jack Fry and Dieter Haidt, also took up the gauntlet. Using the Gargamelle heavy-liquid bubble chamber, pumped full of freon, that had recently been installed at CERN’s Proton Synchrotron inside a colossal superconducting magnet, they spent the fall and winter of 1972 searching for neutrino-induced neutrons. As skiers etched zigzag tracks in the snowy slopes near Geneva, Fry and Haidt examined the frozen trails of cascading particles—their specific paths in the bubble chamber marking their interactions and properties. The summer brought new joys. By July 1973, the group had collected sufficient evidence of neutral current events to present its work. The HPWF collaboration announced its own promising results around the same time. Alas, summer’s heat sometimes shapes cruel mirages. After modifying its equipment and retesting its data, the HPWF team’s findings vanished amid the desert sands of statistical insignificance. Skeptics wondered if electroweak unity was simply a beautiful illusion. Nervous that its own results would become similarly wiped out, the Gargamelle group set out for more testing, and found, to its delight, that its findings were on firm footing. Meanwhile, the HPWF group reexamined its results one more time, resolved the issues that had plagued its analysis, and proclaimed success as well. For the first time in the history of science, a wholly new mode of interaction—the neutral weak current—had been anticipated by theory before being found by experiment. Haidt later described the impact of his team’s findings: “The discovery of weak neutral currents . . . brought CERN a leading role in the field. The new effect marked the experimental beginning of the Standard Model of electroweak interactions, and triggered huge activity at CERN and all over the world, both on the experimental and theoretical sides.” 14 From the neutral current results, theorists developed fresh estimates of the mass of the W boson, stimulating an international race to find that particle. Leading the pack was an energized CERN, anxious to prove that its neutral current victory was no fluke. The European community had already identified the land and allocated the funds to begin constructing the Super Proton Synchrotron (SPS), a four-mile-long accelerator intended to be—at 300 GeV—the most energetic in the world. In the midst of construction, however, Fermilab’s Main Ring surpassed the SPS’s intended energy—a major disappointment for the Europeans. When you are locked in battle, even the smallest delay can offer the other side an opening for victory. In the case of the race to identify the weak bosons, CERN’s opportunity arose when Rubbia became exasperated by the failure of Fermilab to commit to building a proton-antiproton collider—an idea initially suggested by his young Harvard colleague Peter McIntyre and then developed in a 1976 paper by Cline, McIntyre, and himself. The three of them urged Wilson and the Fermilab program committee to plan out a means for running proton and antiproton beams through the same ring in opposite directions. Through enough high-energy smash-ups, they proposed, perhaps somewhere in the debris would lie the sought-after particles. At that time, Wilson was committed instead to building the Tevatron—the world’s first synchrotron with superconducting magnets guiding the beams. The name Tevatron derives from its goal of energizing protons up to 1 TeV (one teravolt or one trillion electron volts). The Tevatron would indeed be used as a collider, but until the superconducting technology was tested, the fiscally conservative director didn’t want to offer a firm guarantee. Like a persistent salesman, Rubbia knocked on CERN’s door next. Because he had worked there in the 1960s, he was very familiar with the organization. Born in Gorizia, Italy, in 1934, he had come to CERN for the first time when he was twenty-six, following a university education in Pisa and Milan and a year and a half at Columbia in the United States. Since the early 1970s, Rubbia had kept up an impossibly frantic schedule, spending time at Harvard, Fermilab, and CERN. These formative experiences, coupled with a natural self-assurance, offered him the clout to suggest CERN’s next move. In shaping a new direction for CERN, Rubbia found the perfect partner in Simon van der Meer. Rubbia realized that the Dutch physicist’s stochastic cooling technique would offer an ideal means of fashioning dense proton and antiproton beams. This would enable the two beams to circle in contrary ways through the SPS—greatly augmenting its center-of-mass energy by transforming it into a collider. Persuaded by Rubbia’s cogent reasoning, Leon van Hove, CERN’s codirector at the time, helped shepherd the concept through the bureaucracy. With amazing speed, researchers assembled the Antiproton Accumulator, a revolutionary means of building up an intense beam of those particles, and linked it to the SPS. By 1981, only five years after Cline, McIntyre, and Rubbia had proposed the idea, the SPS became operational as a proton-antiproton collider—the major purpose for which it was used throughout the decade. Although the more powerful Tevatron opened in 1983, its collider operations wouldn’t begin until 1985, offering CERN a significant head start. With the SPS and later the Tevatron came the rise of “supergroups” of researchers—teams representing dozens of institutions and hundreds of experimentalists each. High-energy physicists gravitated to the two centers hoping to share the glory of wrapping up the Standard Model, completing the third generation of fundamental particles (supplementing the tau lepton and the bottom quark—the latter found by Leon Lederman and his colleagues at Fermilab in 1977), and perhaps even discovering wholly unexpected new ones. Gone were the days of Rutherford and Lawrence—where experimental papers included but a few authors—perhaps the supervising professor, a postdoctoral researcher, and a couple of graduate students. With the burgeoning teams, some articles even included the long list of authors as lengthy footnotes. You practically needed a magnifying glass to see which contributors lent their expertise to which projects. Moreover, because of the increasing specialization associated with the new particle-production “factories,” and the many years often required to obtain results, research supervisors began to adopt a more flexible attitude toward what constituted acceptable Ph.D. theses. For example, completing Monte Carlo simulations (using a random-number generator to predict possible outcomes), writing software, building and testing new detectors, and so forth, could constitute elements of approved dissertations. Otherwise, not only wouldn’t there have been enough theses to accommodate all of the graduate students working in each experimental supergroup, but also the time to get such degrees while waiting for final data would have, in many cases, been inordinately long. Upon the reinauguration of the SPS as a collider, two detectors were readied for service—each supported by its own extensive team. The first, UA1 (Underground Area 1), was Rubbia’s brainchild—an extraordinarily complex instrument that made use of state-of-the-art electronics to probe collisions from almost every possible angle. The property of covering almost the entire solid angle, known as “hermeticity,” became a mainstay of detectors from that point on. No one had seen such a massive detector before—at approximately two thousand tons it was truly a Goliath. Its complexity and bulk girth inspired a French newspaper to root for the second, smaller detector UA2 (Underground Area 2), as the dexterous “David” that would slay the unwieldy giant. Reportedly, this characterization infuriated Rubbia, who considered himself the true maverick. 15 The initial run, in December 1981, was dedicated to testing some of the predictions of quantum chromodynamics (QCD), the leading gauge theory of the strong interaction. Developed in the 1970s, QCD models the interactions among the quarks in hadrons, mediated via exchange particles called gluons. Through volleying gluons among one another, quarks of different colors cement their connections—forming baryons or mesons. The gluon concept replaced the idea of pion exchange, which failed to explain why quarks like to assemble in certain groupings and are never found roaming freely. The UA1 and UA2 detectors looked for the hard knocks of quark kernels against one another, measured the energy produced, and compared the results to theoretical QCD models. Splendidly, particularly in the UA2 results, many of the QCD predictions proved right on the mark. After savoring the delectable appetizer of the QCD findings, it would be time for the main course. The W and Z bosons were ripe for the plucking and—thanks to the capabilities of the upgrading SPS—it would finally not be a stretch to reach for such exotic fruit. The sensitive detectors of each group were primed to taste the characteristic flavor combinations of the rare morsels. In the case of the W bosons, the researchers expected that the quarks and antiquarks from the protons and antiprotons (up and antidown, for example) would unite briefly at high energies to produce these exchange particles. These would be extremely short lived, almost immediately decaying into charged leptons and neutrinos. Particles too fleeting to be directly detected are called resonances—manifesting themselves only through peaks in production at particular energies corresponding to their masses. It’s like trying to find signs of a snowman built (from freezer scrapings) during a hot summer day; a sufficiently sized puddle of water would be a giveaway. Around Christmas 1982, the SPS was colliding protons and antiprotons with astonishing beam luminosities of more than 10 29 (1 followed by 29 zeroes) incident particles per square inch each second. In the UA1 detector, these yielded about 1 million events interesting enough to trigger data collection. Of these, six events met the criteria (particular amounts of energy and momentum associated with electrons fleeing at certain angles) to represent W boson candidates. Further data narrowed down the mass of the W boson to be approximately 81 GeV/c 2 (divided by the speed of light squared, in accordance with Einstein’s famous mass-energy equation). Meanwhile, UA2 gathered four candidate events, confirming the important discovery. Snagging the Z boson happened just a few months later, during a run in April/May 1983. This time, the teams looked for a different signal: the production of electron-positron pairs of particular energies. UA1 found the mass of the Z to be approximately 95.5 GeV/c 2 —with the UA2 group corroborating this result. Papers in Physics Letters B triumphantly announced these findings, much to the delight of the physics community around the world. The discoveries were so telling, no one from that point on could question the reality of electroweak unity. As CERN researcher Daniel Denegri, a member of the UA1 collaboration, recalled the exhilaration of the day: “This period, around the end of 1982 and throughout 1983, was an amazing time from both a professional and personal point of view. It was an unforgettable time of extreme effort, tension, excitement, satisfaction and joy.” The boost to European morale because of the weak boson findings cannot be overestimated. After decades of looking to the United States as the main innovator in high-energy physics, the continent of Einstein, Bohr, and the Curies finally got its groove back. As Denegri noted, “The discovery of the W and Z at CERN . . . signaled that the ‘old side’ of the Atlantic regained its eminence in particle physics.” 16 Although American researchers were happy for their colleagues across the ocean, and pleased that electroweak unification held up under close scrutiny, they could not conceal their disappointment that CERN had beaten them to the punch. Like baseball, accelerator physics had become an American pastime, so it was like losing the World Series to Switzerland. A New York Times editorial laid out the score: “Europe 3, U.S. Not Even Z-Zero.” 17 The first major repercussion of the European triumph was the cancellation of ISABELLE, a proton-proton collider then under construction at Brookhaven. Although hundreds of millions of dollars had already been spent on the project and its tunnel had already been excavated, in July 1983, a subpanel of the High Energy Physics Advisory Panel of the Department of Energy decided that the anticipated energy of the collider, around 400 GeV, would be insufficient to generate new discoveries beyond what had just been found. With the W and Z identified, the next step would be to find the remaining ingredients of the Standard Model including the top quark, the tau neutrino, and the Higgs. Other goals included finding hypothetical new particles predicted in models seeking to extend the Standard Model into more comprehensive unification schemes. For example, in the 1970s and 1980s, a number of researchers developed Grand Unified Theories—schemes designed to incorporate QCD along with the electroweak interaction into a single theory. The idea was that at high enough energies, such as in the nascent moments of the Big Bang, all of these interactions would be comparable in strength. With the cooling of the universe, these would bifurcate during two distinct phase transitions into the strong and electroweak interactions and then the strong, weak, and electromagnetic interactions. Thus the original perfect symmetry would break down over time as the vacuum changed its fundamental character. Even farther reaching unification schemes proposed around that period included supersymmetry, the hypothesized means of uniting fermions and bosons into a comprehensive theory. Each fermion, according to this hypothesis, has a boson counterpart, called its superpartner. Similarly, each boson has a fermion companion. When the universe was a steaming primordial soup, the partners and superpartners were on equal footing, but since then, with the universe cooling, supersymmetry has spontaneously broken—rendering the superpartners too massive to be readily observed. Following a tradition in particle physics of zany nomenclature, the hypothetical boson superpartners of electrons were christened “selectrons” and those of quarks, “squarks.” The fermion counterparts of photons were named “photinos,” those of gluons, “gluinos,” and those of the W and Z, the bizarre-sounding “winos” and “zinos.” Theorists hoped signs of the lightest of these superpartners would turn up in collider debris. As a result of these and other novel theories, by the mid-to-late 1980s, though many of the major predictions of the Standard Model had been verified, no one could complain that there weren’t enough projects in high-energy physics to go around. The problem would be cranking out enough juice to spawn the sought-after particles. The SPS collider, at 450 GeV, had quickly reached its limits, with no sign to be found of coveted gems such as the top quark or the Higgs, let alone more exotic particles. Another CERN project, the Large Electron-Positron Collider (LEP), proved ambitious in size, if not in overall energy. A ring seventeen miles in circumference and hundreds of feet deep, it extended CERN’s reach far beyond the Geneva suburbs into the verdant countryside across the French-Swiss border. One of the reasons it was built so large was to reduce the amount of radiation emitted by the electrons and positrons—the greater the radius, the smaller the radiative energy lost. The LEP’s construction required some adjustments to CERN operations. The SPS was adapted to serve as a source for electrons and positrons, which were injected into the LEP ring in countercircling beams before being brought to crash together in a crescendo of energy. By knowing the ring radius, the frequency of the electrons and positrons, and other factors, researchers could calculate the total energy of each collision, allowing for precise determinations of the masses of particles produced. During its eleven-year run (1989-2000), the LEP was the most powerful lepton collider in the world—but, because electrons are so much lighter than protons, lepton colliders are generally weaker than comparably sized hadron colliders. Its energy ranged from just under 100 GeV (when it opened) to slightly over 200 GeV (after upgrades)—insufficient, as it turned out, to find the Higgs or to beat competitors to the top quark. Nevertheless, it was an adept factory for manufacturing W and Z bosons, pinning down their masses with a jeweler’s precision. The top quark would be located among the same Illinois cornfields where the bottom quark was found almost two decades earlier. (The two quarks are sometimes also called “truth” and “beauty.”) Nobody expected the wait would be so long and that the second member of the third quark family would be quite so heavy. Its 1995 discovery would be the pinnacle (so far) of the Tevatron’s impressive run. Wilson had stepped down from Fermilab’s directorship in 1978, shortly after the upsilon—the first particle known to house a bottom quark—was discovered. After pouring his heart and soul into the Tevatron, he had become incensed when the Department of Energy initially didn’t offer enough funding that year to keep it on schedule for a speedy completion. 18 To buttress his argument, he had handed in his resignation and astonishingly it was accepted. Fresh off his bottom quark discovery, Lederman was appointed the new director. He would preside over the Tevatron’s opening and chart its course throughout the 1980s. (In 1989, John Peoples became director—succeeded by Michael Witherell and then Pier Oddone. Lederman has maintained a role as director emeritus.) Physicists around the world celebrated the Tevatron’s inauguration, keenly aware that its superior power would offer the best chance to advance scientific understanding of the subatomic realm. On July 3, 1983, twelve hours after its beam was turned on, it reached 512 GeV and broke the world record for energy produced in an accelerator. Among the applauders, Herwig Schopper, CERN’s director-general at the time, sent Lederman a gracious message by telex: Our warmest congratulations for the extraordinary achievement to accelerate protons for the first time in a superconducting ring to energies never obtained before. Fermilab pioneered the construction of superconducting magnets, opening up a new domain of future accelerators. Please convey our admiration to all the staff concerned. 19 Though CERN remained Fermilab’s major competitor, much of the competition at the Tevatron was internal. With the success of the vying UA1 and UA2 groups as models for a Darwinian approach to discovery, Lederman advocated competing teams at the Tevatron, too. Each would use its own designated detector and analyze its own data. The natural advantage of such a strategy was to subject each group’s findings to independent verification by the other. The first Tevatron team, called the Collider Detector at Fermilab (CDF) Collaboration, consisted of thousands of researchers and technicians from the United States, Canada, Italy, Japan, and China—representing three dozen universities and other institutions. The sheer number of people involved meant that the first few pages of each paper the collaboration published consisted simply of a long list of names. Still in operation today, the CDF is a multifaceted, hundred-ton device that surrounds one of the beam intersection points and sifts through collision debris for interesting events. As in the case of the SPS, only a minute percentage of all collisions are suitable for analysis. Only if the quark and antiquark constituents of the proton and antiproton beams strike each other directly, interact, and produce debris flying off at large angles, are the collisions worth talking about. Otherwise they are of little note, akin to commuters inadvertently brushing past one another on the way to their trains. If particle offspring meet the large angle criteria, the CDF, like all complex detectors, subjects them to a barrage of tests. As in traditional devices such as cloud chambers, ionization plays a major role in modern methods for tracking charged particles. Using thin materials technology, a delicate instrument called a Silicon Vertex Tracker sniffs out the subtlest whiff of charge, pinpointing the locations of fleeing subatomic bodies within ten-thousandths of an inch. An immerse superconducting magnet surrounds another unit, called the Central Tracking Chamber, steering charged particles in a way that allows their momenta to be gauged. Like marines on their first day of boot camp, that’s just the beginning of the rigors the particles must face. The next ordeal includes two different energy-trapping devices, electromagnetic and hadronic calorimeters. These force the particles through hurdles (lead sheets and iron plates, respectively), induce jets or showers, and record the energy they sweat off in the process. Those with the endurance to continue through the calorimetry without losing much energy are likely muons and are picked up by the muon tracker just beyond. Certain initial readings act as triggers, signaling that something significant may be in the works. Immediately, the full data collection machinery kicks in and records everything that can possibly be known about the event—positions, momenta, and energies—tens of thousands of bits of information in many cases. Otherwise, rare, sought-after processes would be buried in an avalanche of mundane decays. The final step takes place not in the actual detector at all, but rather in the virtual world of computers. Like crime scene detectives, sophisticated software reconstructs what likely happened. Each event of potential interest is dissected—with any missing energy or momentum duly noted. Because energy and momentum are normally conserved, their absence might point to unseen subatomic thieves such as neutrinos. Thus reconstruction offers the only way of filling in the gaps and representing the full picture of what happens during collisions. Around the Tevatron ring from the CDF another formidable group of experimentalists, called the D0 (pronounced “dee zero”) Collaboration, collects vital data with its own detector. Like the CDF it has a tracking system, calorimeters, and muondetection and triggering systems—with somewhat more emphasis on calorimetry than tracking. Researchers working on D0 projects have hailed from countries around the globe—from Argentina and Brazil to the United Kingdom and the United States. One of the consistent contributors to the D0 Collaboration is Stony Brook University in New York. As a graduate student there during the early preparatory stages for the project, I witnessed how much testing and calibration takes place to make sure each detector element performs optimally. Calibration involves comparing a piece of equipment’s readings to known values. For example, a researcher could calibrate a temperature sensor by seeing if its readings match those of an analogue thermometer. Without calibration, a detector’s results could well be flawed—like a scale improperly balanced and indicating the wrong weight. To help calibrate a Cherenkov detector, I recall having to render a room the size of a closet perfectly light-tight, so that only cosmic rays could enter. It took numerous hours in the dark and many layers of duct tape to make sure no stray photons could be seen. That was only one of many thousands of tests performed by many thousands of researchers over many thousands of days before actual runs could even begin. Like raising exotic orchids, high-energy physics certainly requires patience—making the blossoming all the lovelier. The extraordinary hard work and persistence of the CDF and D0 teams wonderfully paid off when on March 2, 1995, at a specially arranged meeting at Fermilab, both groups reported incontrovertible evidence that they had identified the top quark. Each had released preliminary results earlier—but they wanted to be certain before announcing firm conclusions. Their proof came from evaluating the energy and other properties of leptons and jets produced in numerous candidate events. Based on these values, each team found the mass to be about 175 GeV, the heaviest particle known to date—weighing as much as a gold atom. No wonder it took such a powerful collider to produce it! A bittersweet aspect of the discovery is that it was announced barely two years after the cancellation of what would have been the next logical step for American physics. What would have been the largest, most powerful collider in the world was axed in a budget-cutting frenzy. High-energy physics in the United States would never be the same.",
        "char_count": 56662
      },
      {
        "heading": "Chapter 12",
        "text": "7 Deep in the Heart of Texas The Rise and Fall of the Superconducting Super Collider It was a tragedy, a catastrophe, a scientific Titanic. . . . The Superconducting Super Collider is . . . gone forever. —HERMAN WOUK, A HOLE IN TEXAS (2004) In the heart of cowboy country, about thirty miles south of Dallas, the town of Waxahachie bears a brutal scar. Where ninety homes once stood among nearby farmland, 135 acres of land lie arid and abandoned. Pocking the soil are seventeen shafts, hundreds of feet deep, now plugged up and useless. A fourteen-mile tunnel, a masterpiece of engineering that now leads absolutely nowhere, forms an arc-shaped gash underground—believed to be slowly filling with water. Less tangible, but even more indelible, wounds have been the injury to the Texas economy and the damage to the American scientific community’s morale. No one imagined, when the Superconducting Super Collider (SSC) project was in the planning stages, that its outcome would be so dreadful. Ironically, it came into being through the demise of another ill-fated project, ISABELLE. At the July 1983 meeting that led to the severing of ISABELLE’s lifeline, members of the same federal panel recommended constructing a much higher energy machine. They proposed pursuing a suggestion by Leon Lederman—put forth the previous year at a high-energy workshop in Snowmass, Colorado, for a colossal device with superconducting magnets set in a flat, unpopulated region of the United States. Given CERN’s discovery of the weak boson and Fermilab’s announcement that it had broken accelerator energy records, it was time to think big. For particle physicists, building bigger and better machines makes perfect sense. What are land and money compared to the benefits of unlocking nature’s deepest secrets? Sure there is always a risk that billions of dollars and years of effort would be wasted, but if we didn’t try we would never be able to complete our understanding of the universe. Yet, as certain critics argue, in many other fields of physics (and science in general), important experiments are conducted at far less cost. Some of these have yielded vital societal benefits—for example, the discovery of transistors revolutionized the electronics industry. Is it then worth it to pursue multibillion-dollar projects? The debate over “big science” versus less expensive, “desk-top” experimentation would play a major role in the fate of the SSC. Envisioned as a 20 TeV collider—much higher energy than either the Super Proton Synchrotron (SPS) or the Tevatron—the SSC was originally known as the “Desertron.” According to historians Lillian Hoddeson and Adrienne W. Kolb, there were two main reasons for this designation: “It was thought to require a large expanse available only in the desert, and as it was to penetrate the bleak ‘desert’ of physical processes described by the theory of grand unification.” 1 The fear was that the newly opened Tevatron would not prove powerful enough to bridge the gap between the final ingredients for the Standard Model and any interesting new physics that lay beyond. No one knew then—and we still don’t know—if the Tevatron has the capacity to find the Higgs, let alone even higher energy particles predicted by various Grand Unified Theories and supersymmetric theories. It would be immensely frustrating if elegant new unification theories, linking the electroweak and strong forces in mathematically satisfying ways, could never be physically tested. The frustration would be akin to discerning life on a distant planet but not being able to reach it. Spanning the broad expanse between imagination and investigation would surely require unprecedented technology. What if the Europeans developed the next generation of colliders themselves, leaving the home of the brave shaking in its boots? Lederman correctly surmised that CERN’s seventeen-mile Large Electron-Positron Collider tunnel would be a tempting place to insert a ring of superconducting magnets and create a thunderous proton collider. Best get started on a native machine, American physicists realized, before the Old Country helped itself to a buffet of Nobel Prizes. In December 1983, the Department of Energy formed a planning group, called the Reference Designs Study (RDS), drawing talented individuals, including directors and staff, from the major accelerator labs in the United States. Representatives from Fermilab, Stanford Linear Accelerator Center, Brookhaven, and Cornell ironed out the preliminary details of how one of the most ambitious scientific projects of all time would be implemented. To be fair to all, the meetings rotated from lab to lab. Cornell physicist Maury Tigner, one of Wilson’s former students, headed the group. By April 1984, the RDS had produced three different options for a proton-proton collider design with 20 TeV of energy per beam and a luminosity of about 10 34 (1 followed by 34 zeroes) particles per square inch per second. That’s about 100,000 times more intense than the SPS beams that spawned the W and Z bosons—like packing the entire population of Topeka, Kansas, into a subway turnstile intended to fit a single person. To accomplish this tight squeeze, each option involved a distinct superconducting magnet design—a strong one with a giant iron yoke and a superconducting coil, a relatively weak one with even more iron (called superferric and producing a smoother magnetic field), and a third, medium-strength one that was iron-free (perhaps they already had too many irons in the fire). In a report to the Department of Energy (DOE), the team concluded that all three designs were feasible and recommended further study. The next phase in planning the SSC took place through a team called the Central Design Group (CDG), situated at Lawrence Berkeley National Laboratory and also led by Tigner. Several different labs, including the Berkeley Lab, Brookhaven, Fermilab, and the Texas Accelerator Center, a research institute established by collider expert Peter McIntyre, were recruited to investigate the various superconducting magnet designs. The majority of the group supported the strong-field magnet that would require a ring about fifty-two miles in circumference, as opposed to the weak-field design that would necessitate a ring up to a hundred miles long. It would be hard enough to find enough land to support the smaller ring. By late 1986, the SSC design had been submitted to the DOE and the major labs were united in their support. Because of the projected multibillion-dollar cost for the project, to move forward the approval of President Ronald Reagan, the American leader at the time, was required. On the face of it, that would seem to be a hard sell, given that the federal budget was already stretched through various military and scientific programs. Expensive projects at the time included the Strategic Defense Initiative (more commonly known as “Star Wars”) for developing missile-interception systems and a program to establish an international space station. How could the SSC carve out its own piece of a shrinking pie? Luckily for the prospects of gaining approval, if there was a frontier to be conquered or an enemy to be defeated, Reagan believed in taking major risks. Famously, long before becoming a politician, he played the role of a football player for an underdog team in the film Knute Rockne, All American . Like his character George Gipp, better known as “the Gipper,” optimism and determination steered his judgments. The SSC was a project on the scientific frontier that represented a means of remaining competitive with Europe. That was the angle its proponents emphasized to win over Reagan’s support. A DOE official asked Lederman if he and his staff could produce a ten-minute video for the president about the questions in high-energy physics the SSC could potentially resolve. To appeal to Reagan’s cowboy spirit, Lederman decided to emphasize the frontier aspects of the research. In the video, an actor playing a curious judge visits a lab and asks physicists questions about their work. At the end he remarks that although he finds such research hard to comprehend, he appreciates the spirit behind it, which “reminds [him] of what it must have been like to explore the West.” 2 Apparently the SSC advocates’ arguments were persuasive, because Reagan was deeply impressed. Members of his cabinet, concerned about the fallout from the project’s asteroidlike impact on the budget, ardently tried to intercept it. With all of their strategic defenses, however, they could not shoot it down. At Reagan’s January 1987 announcement that he would support the SSC, he took out an index card and recited the credo of writer Jack London: I would rather be ashes than dust, I would rather my spark should burn out in a brilliant blaze, Than it should be stifled in dry rot. I would rather be a superb meteor, With every atom of me in magnificent glow, Than a sleepy and permanent planet. 3 After reading the credo, Reagan mentioned that football player Ken Stabler, known for coming from behind for victory, was once asked to explain what it meant. The quarterback distilled its sentiments into the motto, “Throw deep!” 4 Surely the erstwhile “Gipper”-turned-president would aim no lower. The SSC would move ahead, if he could help it. At a White House ceremony the following year, Reagan heralded the value of the SSC, saying, “The Superconducting Super Collider is the doorway to that new world of quantum change, of quantum progress for science and for our economy.” 5 Following Reagan’s endorsement came the battle for congressional approval, which would not be so easy. Many members of Congress balked at the idea of the United States carrying the ball alone. Consequently, the SSC was marketed as an international enterprise, involving Japan, Taiwan, South Korea, various European nations, and others. Newsweek described selling the project this way: “The DOE promised from the start that other nations would help bankroll the SSC. That pledge has greased the project’s way through many sticky budgetary hearings.” 6 Significant international support was hard to come by, however. The Europeans in particular were naturally more interested in seeing CERN succeed than in supporting an American enterprise. That’s around the time the Large Hadron Collider (LHC) project was first proposed—clearly a higher priority for Europe. A New York Times editorial on May 20, 1988, argued that any American funding toward the SSC would be better spent contributing toward the LHC instead: This is a tempting but dangerous initiative because funds to pay for it almost certainly would be stripped from other physics research. . . . The field is of high intellectual interest, and it would be a sad day if the United States did not remain a major player. But European physicists have shown how an existing collider ring at Geneva could be upgraded to within probable reach of the Higgs boson. Buying into the European ring would be cheaper. 7 By mid-to-late 1988, Congress had allocated $200 million toward the SSC. Proceeding with caution, it mandated that the money could be used only for planning and site selection. Because an election was imminent, funds for the actual construction would be left to the consideration of the next administration. Once Congress offered a kind of yellow light for the project to move forward cautiously, the politics behind the venture became even more intense. Many depressed regions salivated over the potential for jobs. Which state would be lucky enough to acquire what the Times called “a $6 billion plum”? 8 To be fair, the competition to find a suitable site was judged by a committee established by the respected and politically neutral National Academy of Sciences and National Academy of Engineering. Of the forty-three proposals submitted from twenty-five states, including seven from the state of Texas alone, the committee narrowed them down to seven. The Lone Star State was clearly the most eager; its government established the Texas National Research Laboratory Commission (TNRLC) well in advance and sweetened the pie by offering $1 billion toward the project from its own budget. What better place to think big than in Texas? Its submission was so hefty—rumored to weigh tons—it was hoisted to the DOE office by truck. 9 In November 1988, after considering the relative merits of the finalists, the DOE announced that Ellis County, Texas—a flat, chalky prairie region with little vegetation except for grasses, shrubs, mesquite, and cactus—was the winning location. By odd coincidence, the site location announcement occurred just two days after a Texan—then Vice President George Herbert Walker Bush—was elected president. The DOE selection group assured the public that politics played no role in the decision. Through a spokesperson, Bush asserted that he had no involvement in the process and that he found out about the choice when everyone else did. 10 With the choice of a completely undeveloped site in Texas, many supporters of Fermilab, which had also bid, were left fuming. Fermilab already had much of the infrastructure in place to support an expanded mission; a new location would require starting from scratch with all new staff, buildings, and equipment. In particular, the Tevatron could have been adapted, like the SPS at CERN, to serve as a preaccelerator for the protons entering the collider. “If it was at Fermilab, it would have existed now,” 11 said Brookhaven physicist Venetios Polychronakos, who was involved in planning an SSC experiment. Some feared a brain drain from Fermilab, with top researchers finding new positions in Texas. Lederman, who had a key stake in both institutions as Fermilab’s director and one of the SSC’s original proposers, expressed mixed feelings. He anticipated a “certain loss of prestige” for his own lab. 12 However, he expected that it would remain a premier research facility—at least during the years when the SSC was under construction. Soon after its bid was accepted, the Texas state government, through the TNRLC, assembled a parcel of almost seventeen thousand acres near Waxahachie. For the land of Pecos Bill, that was just a mere pasture. The TNRLC also arranged for environmental studies and administered a research and development program to support the lab. The state’s commitment to the project remained steadfast until the end. The federal commitment to the project was murkier, as there were many clashing forces involved. Congress, the DOE, and research physicists themselves each had different interests, which were sometimes at odds. Although Tigner’s CDG performed the bulk of the original planning for the project, when it came time to move forward with constructing the collider and setting up the lab, the group was bypassed in favor of the Universities Research Association (URA)—a consortium that managed Fermilab and with which the DOE felt comfortable working. Tigner was seen as a “cowboy in the Wilson tradition” 13 and as potentially having difficulty bending to the demands of Congress and the DOE. Thus, the URA instead chose a relative newcomer, Harvard physicist Roy Schwitters, to become lab director. After serving briefly under Schwitters as deputy director, Tigner stepped down in February 1989 and returned to Cornell. Sadly, with his resignation, the construction of the SSC would need to proceed without his vital technical experience, including the five years he spent helping design the accelerator. As scientific historian Michael Riordan has pointed out, Schwitters and the URA sharply departed from prior practice by integrating private industrial contractors into the decision-making process. 14 Before the SSC, accelerator laboratories were planned solely by research physicists—who would employ technicians if needed for particular tasks. As we’ve seen, for instance, Wilson designed almost all aspects of Fermilab himself. Schwitters had a different philosophy, involving industrial representatives as well as academics to solve the engineering challenges associated with building what would have been the world’s most formidable scientific apparatus. Among these were corporations heavily involved in the defense and aerospace industries, and for whom it was their first exposure to high-energy physics. Many of the industrial workers switched jobs because of military cutbacks due to the end of the cold war. Because they were used to a certain mind-set, the lab assumed some of the secretive aspects of a defense institute. Moreover, some of the established physicists felt that they couldn’t handle the scientific demands. These factors, as Riordan noted, created a clash of cultures that alienated many of the experienced researchers and made it hard to recruit new ones. Despite these internal tensions, during the first Bush administration, the SSC benefited from strong federal support. Familiar with the Texas landscape due to his years as a businessman and politician in that state, President Bush considered the SSC a national scientific priority and pressed Congress each year to fund it. The DOE distributed particular tasks such as building and testing detectors throughout almost every state, offering politicians around the county further incentive to favor it. The program even survived a doubling of its estimated completion cost to a whopping $8 billion, announced in early 1990. This came about when engineering studies forced a major redesign of the project due to issues with the magnets and other concerns. Superconducting magnets are in general extremely delicate instruments. The stronger a magnet’s field, the greater its internal forces and the higher the chance that its coil and other parts will subtly oscillate. Vibrations cause heating, which can ruin the superconducting state and weaken or destroy the magnets. At 6.5 Tesla (the metric unit of magnetism)—more than 50 percent stronger than the Tevatron’s field—the SSC’s magnets were very much at risk. To minimize tiny movements, the magnets included carefully placed steel clamps. Getting them to work effectively was a matter of trial and error. In an important preliminary test of twelve magnets, only three passed muster. Designers struggled to improve the performance. Another question concerned the size of the magnets’ openings. Smaller apertures were cheaper but entailed a greater risk to the streams of protons passing through. Any misalignment could reduce the rate of collisions and sabotage the experiment. Ultimately, after considerable discussion, the SSC administration decided to enlarge the magnet openings to allow more room for error. Other design changes made at that time included increasing the ring circumference to fifty-four miles and doubling the proton injection energy (the energy protons are accelerated to before they enter the main ring). All of these modifications forced the bill sky high. Although some members of Congress became livid when learning about the huge increase in the cost, the general reaction at that time was to increase oversight rather than close down the project. Construction funds started to flow, and the lab began to take shape starting in the fall of 1990. As planned, the SSC was to have a succession of accelerators boosting protons to higher and higher energies before they would enter the enormous collider ring. These consisted of a linear accelerator and three synchrotrons of increasing size: the Low Energy Booster, the Medium Energy Booster, and the High Energy Booster. Tunnels for the linear accelerator and the smallest synchrotron were the first to be excavated. Boxy structures, to support future operations underground, sprang up like prairie grass along the flat terrain, including the Magnet Development Lab, the Magnet Test Lab, and the Accelerator Systems String Test Center. These were facilities for designing, building, and testing the various types of superconducting magnets needed for the project. Two large companies, General Dynamics and Westinghouse, took on the task of building the thousands of dipole magnets that would steer the protons, like roped-in cattle, around what would have been the largest underground rodeo in the world. Meanwhile, drawn by the prestige of contributing to a kind of Manhattan Project for particle physics, or simply finding a good-paying position, more than two thousand workers relocated to Texas. The lure of potentially finding the Higgs boson or supersymmetric companion particles enticed many an adventurous physicist to venture south of glittery Dallas and try his or her luck with collider roulette. For researchers who already had thriving careers, it was a significant gamble. Some took leave from their full-time positions; others gave up their old jobs completely with hopes of starting anew. In the tradition of colliders supporting a pair of major detectors, with collaborations lined up behind these, two groups’ proposals were approved for the SSC. The first, called the SDC (Solenoidal Detector Collaboration), involved almost a thousand researchers from more than a hundred institutions worldwide and was headed by George Trilling of the Berkeley Lab. Its general-purpose detector was designed to stand eight stories high, weigh twenty-six thousand tons, and cost $500 million. The target date for it to start collecting data was fall 1999—offering hope of finding the Higgs before the toll of the millennial bells. The second group, called GEM (Gammas, Electrons, and Muons), was led by Barry Barish of Caltech, an accomplished experimentalist with a stately beard and shoulder-length silver hair, along with liquid argon calorimetry coinventor William Willis of Columbia University, and a humongous cadre of researchers. Their project involved a detector specially fashioned for pinpoint measurements of electrons, photons, and muons. GEM was supposed to be located around the ring from the SDC at a different intersection point, collecting data independently, like competing newspapers housed in separate city offices. Unfortunately, neither of these detectors ever had a chance to taste flavorful particles. As the SSC project rolled through the early 1990s, it accumulated more and more opposition—not just from politicians dismayed that it would break the budget but also from fellow physicists in fields other than high energy. Most branches of experimental physics don’t require $8 billion budgets, yet can still yield groundbreaking results. Take for example high-temperature superconductivity. In the 1980s, Swiss physicist Karl Müller and German physicist Johannes Bednorz, working with reasonably priced materials in the modestly sized (compared to CERN or Fermilab at least) complex of IBM’s Zurich Research Laboratory, revolutionized physics with their discovery of a ceramic compound that could conduct electricity perfectly at temperatures higher than previously known superconductors. Other experiments in various labs, including work by Paul Chu at the University of Houston, turned up substances with even higher transition temperatures. Although these ceramic superconductors still need to be quite cold, some maintain their properties above the temperature of liquid nitrogen. Immersing a material in liquid nitrogen is far cheaper than the drastic methods used to create the near-absolute-zero superconductors once believed to be the only types. Therefore not only did Müller and Bednorz’s finding come with a much cheaper price tag than, say, the top quark, it also led to cost saving for future research and the potential for more widespread applications of superconductivity. Because discoveries related to material properties bear more directly on people’s lives than does high-energy physics, many researchers in these fields, such as Cornell physicist Neil Ashcroft, have argued that they deserve at least as much support. “Things are out of whack,” he said. “Condensed-matter physics is at the heart of modern technology, of computer chips, of all the electronic gadgets behind the new industrial order. Yet relative to the big projects, it’s neglected.” 15 Another leading critic of “big science,” who was skeptical about channeling so much funding into the Super Collider, was Arno Penzias, codiscoverer of the cosmic microwave background. Penzias said, “One of the big arguments for the S.S.C. is that it will inspire public interest in science and attract young people to the field. But if we can’t educate them properly because we’ve spent our money on big machines instead of universities, where’s the point? As a nation we must take a new look at our scientific priorities and ask ourselves what we really want.” 16 On the other hand, who could anticipate what would have been the long-term spin-offs of the SSC? In the past, some discoveries that seemed very theoretical at the time, such as nuclear magnetic resonance, have ended up saving countless lives through enhanced techniques for medical imaging and treatment. But since nobody had a crystal ball for the SSC and its potential applications, its critics painted it as just big and expensive. The rising crescendo of arguments against “big science” and in support of smaller, less expensive projects jived well with growing congressional sentiments that the SSC was getting out of hand. Given that Congress was promised that substantial foreign contributions would fill out the SSC’s budget, when these failed to materialize, many members were understandably miffed. Some didn’t think that Schwitters and the DOE under Secretary of Energy James Watkins were managing the project effectively. Still, it came as a surprise when in June 1992 the House of Representatives voted 232-181 in favor of a budget amendment that would end the project. 17 Only the Senate’s support for the SSC temporarily kept it alive. In the spirit of former senator William Proxmire’s “Golden Fleece Awards” for alleged government boondoggles, many of those who favored terminating the SSC painted it as a wasteful endeavor that would benefit only a small group of eggheads. In times of tight budgets, they wondered, why channel billions of dollars into crashing particles together to validate theories rather than, say, blasting away at the all-too-real federal deficit behemoth? “Voting against the SSC became at some point a symbol of fiscal responsibility,” said its then associate director Raphael Kasper, who is currently vice president of research at Columbia. “Here was an expensive project that you could vote against.” 18 In January 1993, Bill Clinton succeeded Bush as president. Without the Texas connection, a key strand of the SSC’s support dissolved. Although Clinton indicated that he backed the project, particularly in a June letter to the House Appropriations Committee, he advocated extending the time line for three extra years to reduce the annual impact on the federal budget. Postponing the SSC’s targeted opening date (to 2003) made it seem an even riskier venture, however, because it could well have been obsolete by the time it went on line. What if the Tevatron had found the Higgs boson by then? Once the collider lab’s anticipated costs rose to approximately $10 billion, largely because of the pushing back of its schedule, it was only a matter of time before an increasingly frugal Congress signed a do-not-resuscitate order. A House of Representatives vote on October 19, 1993, denied by a two-to-one margin a funding bill that would have supported further construction. Instead, the SSC’s annual appropriation was directed to moth-ball the part of the facility that had already been built. By then $2 billion had already been spent and more than one-quarter of the project was complete—all for naught. The tangible result of a decade of planning and hard work would just be boarded up and shrouded in dirt. Requiescat in pace. The cancellation of the SSC did, in the short term, save federal money. Along with many other cost-cutting measures, the federal budget would be balanced by the end of the decade. (Ironically, in the 2000s, the deficit would skyrocket again, making all of the cost cutting moot!) Yet, what is the long-term price of a national decline in scientific prestige? Skipping the moon landings, eschewing the robotic exploration of Mars, and abstaining from telescopic glimpses at the swirling mists of ancient galaxies would have each cut government expenses, too—while extinguishing the flames of our collective imagination. If it is a choice between science and sustenance, that’s one thing, but surely our society is rich enough to support both. It remains to be seen whether the United States will ever resume its pioneering mantle in high-energy physics. Thus in retrospect, many see the abandonment of what would have been the premier collider in the world as a grave error. According to Fermilab physicist William John Womersley, “The SSC has cast a very long shadow over high-energy physics and big science in general. We’re still dealing with the legacy.” 19 In the aftermath of the closure, those who took the career risk and moved down to Texas for the SSC met with varying degrees of disappointment. Some regrouped, sent out their résumés (or were recruited), and managed to find new positions in other labs or universities. For the experienced physicists, finding an academic position was hard, because not many universities wished to hire at the senior level, and the closure of the SSC reduced the need for professors in the high-energy field. A survey taken one year after the closure found that while 72 percent of those in the SSC’s Physics Research Division had found employment, only 55 percent of those positions were in high-energy physics. 20 Other workers, who had laid down deep roots in Texas and didn’t want to leave, either found other types of jobs or simply retired early. A few stayed to help sell off the equipment and assist in attempts to convert the site to alternative uses. Given all of the time and energy that went into assembling the land, digging the tunnels, and constructing the buildings, it is remarkable that the site has yet to be put to good use. The federal government transferred the property to the state of Texas, which in turn deeded it to Ellis County. For more than fifteen years, the county has tried in vain to market the structures, particularly the former Magnetic Development Laboratory. Like Dickens’s forlorn spinster, Miss Havisham, the relic building is a jilted bride frozen in time with no interested suitors. An agreement to convert it into a distribution center for pharmaceutical products fell through, and informal plans to house an antiterrorism training base never materialized. In 2006, trucking magnate J. B. Hunt’s plans to use it as a data center were abandoned upon his death. 21 It did, however, play a background role in a straight-to-video action flick, Universal Soldier II . 22 To mention another has-been, the Norma Desmond of labs finally had its close-up. Though it’s instructive to ponder what could have been in hypothetical scenarios about alternative choices, in truth physicists can’t afford to wallow in disappointment. An energetic frontier is ripe for exploration and there’s no time for looking back. Leaving the plains and pains of Texas behind, in the late 1990s the American particle physics community regrouped and headed either north to Illinois, for renewed efforts at the Tevatron, or across the ocean to the cantoned land where cubed meat and melted cheese deliciously collide. After all, Geneva, Switzerland, has distinct charms, some of which Lederman described well. Comparing it to Waxahachie, he wrote, “Geneva . . . has fewer good rib restaurants but more fondue and is easier to spell and pronounce.” 23 Humanity’s best chance of finding the Higgs boson and possibly identifying some of the lightest supersymmetric companion particles now rests with the Large Hadron Collider. Though it will crash particles together at lower energies than the SSC was supposed to—14 TeV in total instead of 20 TeV—most theoretical estimates indicate that if the Higgs is out there the LHC will find it. If all goes well, modern physics will soon have cause for celebration.",
        "char_count": 32269
      }
    ]
  }
}